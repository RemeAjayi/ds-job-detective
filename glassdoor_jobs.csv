,Job Title,Job Description,Company Name,Location
0,Data Scientist (Remote),"As a critical member of the Stream Systems’ team, the Data Scientist is responsible for acting as a subject matter expert when it comes to statistical analysis, machine learning (ML), and deep learning. He/she will work with the development and BD teams to define end to end, ML Based solutions to develop or enhance new/existing features.

Priority will be given to candidates with expertise in the following areas:

Deep learning frameworks such as TensorFlow and PyTorch
Frameworks for in-production ML code (e.g. MLFlow)
Cloud computing such as Amazon Web Services (AWS)
Deploying machine learning models in production
Development and deployment using Docker
A strong command of SQL and working with multiple relational databases and data warehouses (Postgres, Snowflake, etc.)
Strong programming skills in Python with experience of libraries such as Pandas, scikit-learn, NumPy and SciPy
Tools such as Git and Jira
Data collection and data pipelines
Productization best practices for ML-based solutions

Who we are:
Stream Systems is a privately owned, Canadian software company headquartered in Calgary, Alberta. It enables companies to identify, assess, and reduce their system bottlenecks by providing complex models and simulation toolkits which can be tailored to a client’s individual capital assets. Each solution bridges engineering, operations, and finance thus creating a risk-free virtual world to allow you to experiment with business rules, operating procedures, and asset configuration for brown and greenfield projects. Stream Systems is well positioned to fundamentally shift how a company makes business decisions.

For more information, please visit www.streamsystems.ca.

Open to contractors as well as full-time employee placements.

Due to COVID-19, we are currently working from home to keep our staff and clients safe. Fortunately, we have the tools and infrastructure to set you up for a successful home-based position. For this reason, we are accepting applications to work remotely from anywhere in Canada.

We thank all those who apply but only qualified applicants will be contacted. Successful completion of a Criminal Background check will be required.
INDQCE","Cadre
5.0",Calgary
1,Data Scientist (Remote),"As a critical member of the Stream Systems’ team, the Data Scientist is responsible for acting as a subject matter expert when it comes to statistical analysis, machine learning (ML), and deep learning. He/she will work with the development and BD teams to define end to end, ML Based solutions to develop or enhance new/existing features.

Priority will be given to candidates with expertise in the following areas:

Deep learning frameworks such as TensorFlow and PyTorch
Frameworks for in-production ML code (e.g. MLFlow)
Cloud computing such as Amazon Web Services (AWS)
Deploying machine learning models in production
Development and deployment using Docker
A strong command of SQL and working with multiple relational databases and data warehouses (Postgres, Snowflake, etc.)
Strong programming skills in Python with experience of libraries such as Pandas, scikit-learn, NumPy and SciPy
Tools such as Git and Jira
Data collection and data pipelines
Productization best practices for ML-based solutions

Who we are:
Stream Systems is a privately owned, Canadian software company headquartered in Calgary, Alberta. It enables companies to identify, assess, and reduce their system bottlenecks by providing complex models and simulation toolkits which can be tailored to a client’s individual capital assets. Each solution bridges engineering, operations, and finance thus creating a risk-free virtual world to allow you to experiment with business rules, operating procedures, and asset configuration for brown and greenfield projects. Stream Systems is well positioned to fundamentally shift how a company makes business decisions.

For more information, please visit www.streamsystems.ca.

Open to contractors as well as full-time employee placements.

Due to COVID-19, we are currently working from home to keep our staff and clients safe. Fortunately, we have the tools and infrastructure to set you up for a successful home-based position. For this reason, we are accepting applications to work remotely from anywhere in Canada.

We thank all those who apply but only qualified applicants will be contacted. Successful completion of a Criminal Background check will be required.
INDQCE","Cadre
5.0",Calgary
2,Sr. Data Analyst,"Numerator is a data and tech company bringing speed and scale to market research. Headquartered in Chicago, IL, Numerator has more than 2,000 employees worldwide. The company blends proprietary data with advanced technology to create unique insights for the market research industry that has been slow to change. The majority of Fortune 100 companies are Numerator clients.

Job Description

As our Senior Data Analyst - TruView on our data science team, you will get the opportunity to build data products, drive actionable insights, and tackle high-impact business problems. You will tell the story behind the data– painting a picture to our cross-functional partners, explaining what the numbers are telling us, and recommending new ways to leverage data.

This role will focus on our new, innovative product called TruView. As this is a small, entrepreneurial subteam, you’ll be an ideal fit if you thrive being autonomous, delivering results despite ambiguity, and want to relish the opportunity to make an impact on a highly visible, fast-growth team and product.

You will have solid technical abilities to retrieve, manipulate, analyze, and visualize data and excellent communication capabilities to all levels. You enjoy leading and working with product, engineering, data science teams, client services, and other stakeholders to find the best solution to the problem at hand, iterate over it, and balance technical data complexity with delivering timely customer value. Additionally, the ideal candidate will have experience managing analytical projects from conception to completion, being hands-on throughout.

If you seek an environment where you get to do meaningful work with a great, fun data science team, we want to hear from you!

What you get to do

Provide bespoke analysis and insights that influence our data product, business, and clients.
Partner with Product, Data Science, and Engineering teams to identify, investigate, and deliver analytics that leverages our data lake, warehouse, and data science models.
Lead analysis to discover new or improved methodologies; support our data scientists in evaluating algorithms effectiveness, performance, and business impact.
Identify new areas of analytic opportunity and work collaboratively to implement them, such as designing KPIs & quality metrics to maximize the control of our data pipeline.
Provide analysis consulting & support to both internal stakeholders and external clients.



Skills & Requirements

What you bring

3+ years of industry experience with granular data analysis, predictive analytics, or analytics technology products.
1+ years of experience in a senior role or leading data analytic position where you executed technical & business solutions for analytics deliverables.
Fluency in SQL, querying databases, and intermediate data munging.
Experience with data visualization tools such as Tableau & Mode (or Looker, Periscope, D3, etc.)
A data storyteller who is comfortable communicating results in a crisp and effective manner to all audiences (technical and non-technical).
Flexible analytical skills and can evangelize the use of data for sound decision-making across functions.
Experience launching metric dashboards and scorecards.
Strong oral and written communication skills with an ability to collaborate with and influence cross-functional partners.
Self-motivated, self-directed, and able to thrive in a fast-paced environment in an industry that constantly changes.
A mindset of designing for the future but building for now.
An eagerness to learn from others and help others grow with you.
A love of data and finding interesting questions to ask of it.

Nice to haves

Hands-on experience reading/writing code as Data Engineer, Technical Data Analyst, or Data Scientist.
Previous experience working with purchase panel data, CPG data, marketing insights, or the retail industry.
Proficiency in at least one scripting/statistics/data analysis packages, such as Python or R, or the demonstrated desire to grow and learn more.
Experience with understanding, analyzing, and modeling user data and granular behavioral trends.
Exposure to machine learning concepts.

What we offer

More data than you could imagine to play with!
Data that matters and that is shaping the impact of billion dollar brands.
Brillant, motivated and passionate colleagues with whom to spend your time with.
An inclusive and collaborative company culture- we work in an open environment while working together to get things done and adapt to the changing needs as they come.
Market competitive total compensation package.
An opportunity to have an impact in a technologically data-driven company; quarterly hack days.
Volunteer time off and charitable donation matching.
Strong support for career growth, including mentorship programs, leadership training, access to conferences, and employee resource groups.
Great benefits package including health/vision/dental, unlimited PTO, flexible schedule, 401K matching, travel reimbursement and more.

If this sounds like something you would like to be part of, we’d love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience.

While this position can be remote, Numerator is only able to hire in many, but not all, states and provinces. In certain cases, if you are not located in a specific area where Numerator is able to hire, you may not be eligible for employment.

We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.","Numerator
4.1",Remote
3,Radar E/W Scientists,"RadarE/W Scientists, Ottawa Canada

Remote work [in Canada] is available*
Permanent, Full Time

With over 45,000 employees, Leonardo is a global technology organisation and a key player in the international defence and security market. Leonardo Canada - Electronics is expanding and we have an immediate need for several key resources to support the next phase of our growth. We offer a competitive compensation package and a work environment that supports, encourages and challenges its employees to grow personally. For additional information on Leonardo, please visit our website at www.leonardocompany.com/en (http://www.leonardocompany.com/en)

We have exciting permanent opportunities for Radar E/W Scientists (additional interest and experience with the EO/IR (Electro-Optical/Infra-Red) spectrum would be an asset) to actively work on optical systems modelling, design, analysis and signal processing of sensor data.

Responsibilities:
× Developing physics-based ECM and IRCM design, testing and customer support of our products & models to be integrated within our Sea, Air, and Land simulators;
× Enhancing our software architecture products to meet current and future demands;
× Developing interfaces between our products and external applications;
× Test and develop equations and algorithms written in MATLAB, Simulink, and C/C++;
× Create and maintain documentation for in-house and end-user applications;
× Become subject matter experts in EW with a focus on EO/IR and UV algorithms, image exploitation processing and target tracking;
× Research military sensor, weapon and ECM systems and develop input data sets that will configure the corresponding product models to match those real-world systems;
× Provide EW analysis services to defence-related customers;

Education:
× Bachelor’s degree or higher, from an accredited university in an appropriate engineering field such as electrical engineering or engineering physics with courses in in control systems, radar systems or optical systems theory.

General Knowledge & Experience in order to be successful :
× Customer support
× Technical documentation writing
× Real system development and/or Modeling and simulation
× Real System Development and/or Hardware / Software in the loop simulation and/or test and integration
× Developing and testing software modules in MATLAB/Simulink, work with C/C++ & Java
× Chaff, flare, DIRCM, hyperspectral imagery, IRCM
× Data Classification

Assets
× Master’s or PhD degree in a related field of study
× IRCM/ECM/Threat System design and analysis
× Advanced knowledge of image and signal processing Guided weapon systems
× Aerospace subsystems (propulsion, aerodynamics, autopilot, guidance)
× Cyber warfare
× Artificial Intelligence / Machine learning
× Control theory
× Target tracking
× Electromagnetic wave propagation
× Knowledge of Verification and Validation (V&V) concepts
× Practical experience with standard software test and evaluation tools.
× Active Canadian Secret Security Clearance

Personal Attributes
× Excellent communication skills, team player with the drive and commitment toward maintaining high standards;
× Ability to produce clear concise documentation.

Security Clearance
It is a condition of employment that the successful candidate receive a secret level security clearance.

To obtain such a clearance, the candidate:
Must be either a Canadian citizen or permanent resident of Canada;
Must have lived in Canada continuously for the past 10 years & not have a criminal record;
Must be able to obtain a Canadian Industrial Security Clearance to NATO SECRET level;
Must be eligible for Controlled Goods Regulations Program (CGRP) government clearances.

Job Type: Full-time, Permanent

APPLY: If your qualifications meet the job description and related requirements, we'd love to hear from you!
Please submit your application today!

Special needs of candidates with disabilities will be accommodated. Successful candidates must fulfil requirements for Canadian Controlled Goods Program (CGP) and Canadian Security Clearance. Leonardo supports the principles of employment equity and is an equal opportunity employer. Please apply to this position as indicated. Visit us at https://leonardocompany.ca/",Leonardo Canada - Electronics (TTI - Tactical Technologies Inc.),Ottawa
4,Radar E/W Scientists,"RadarE/W Scientists, Ottawa Canada

Remote work [in Canada] is available*
Permanent, Full Time

With over 45,000 employees, Leonardo is a global technology organisation and a key player in the international defence and security market. Leonardo Canada - Electronics is expanding and we have an immediate need for several key resources to support the next phase of our growth. We offer a competitive compensation package and a work environment that supports, encourages and challenges its employees to grow personally. For additional information on Leonardo, please visit our website at www.leonardocompany.com/en (http://www.leonardocompany.com/en)

We have exciting permanent opportunities for Radar E/W Scientists (additional interest and experience with the EO/IR (Electro-Optical/Infra-Red) spectrum would be an asset) to actively work on optical systems modelling, design, analysis and signal processing of sensor data.

Responsibilities:
× Developing physics-based ECM and IRCM design, testing and customer support of our products & models to be integrated within our Sea, Air, and Land simulators;
× Enhancing our software architecture products to meet current and future demands;
× Developing interfaces between our products and external applications;
× Test and develop equations and algorithms written in MATLAB, Simulink, and C/C++;
× Create and maintain documentation for in-house and end-user applications;
× Become subject matter experts in EW with a focus on EO/IR and UV algorithms, image exploitation processing and target tracking;
× Research military sensor, weapon and ECM systems and develop input data sets that will configure the corresponding product models to match those real-world systems;
× Provide EW analysis services to defence-related customers;

Education:
× Bachelor’s degree or higher, from an accredited university in an appropriate engineering field such as electrical engineering or engineering physics with courses in in control systems, radar systems or optical systems theory.

General Knowledge & Experience in order to be successful :
× Customer support
× Technical documentation writing
× Real system development and/or Modeling and simulation
× Real System Development and/or Hardware / Software in the loop simulation and/or test and integration
× Developing and testing software modules in MATLAB/Simulink, work with C/C++ & Java
× Chaff, flare, DIRCM, hyperspectral imagery, IRCM
× Data Classification

Assets
× Master’s or PhD degree in a related field of study
× IRCM/ECM/Threat System design and analysis
× Advanced knowledge of image and signal processing Guided weapon systems
× Aerospace subsystems (propulsion, aerodynamics, autopilot, guidance)
× Cyber warfare
× Artificial Intelligence / Machine learning
× Control theory
× Target tracking
× Electromagnetic wave propagation
× Knowledge of Verification and Validation (V&V) concepts
× Practical experience with standard software test and evaluation tools.
× Active Canadian Secret Security Clearance

Personal Attributes
× Excellent communication skills, team player with the drive and commitment toward maintaining high standards;
× Ability to produce clear concise documentation.

Security Clearance
It is a condition of employment that the successful candidate receive a secret level security clearance.

To obtain such a clearance, the candidate:
Must be either a Canadian citizen or permanent resident of Canada;
Must have lived in Canada continuously for the past 10 years & not have a criminal record;
Must be able to obtain a Canadian Industrial Security Clearance to NATO SECRET level;
Must be eligible for Controlled Goods Regulations Program (CGRP) government clearances.

Job Type: Full-time, Permanent

APPLY: If your qualifications meet the job description and related requirements, we'd love to hear from you!
Please submit your application today!

Special needs of candidates with disabilities will be accommodated. Successful candidates must fulfil requirements for Canadian Controlled Goods Program (CGP) and Canadian Security Clearance. Leonardo supports the principles of employment equity and is an equal opportunity employer. Please apply to this position as indicated. Visit us at https://leonardocompany.ca/",Leonardo Canada - Electronics (TTI - Tactical Technologies Inc.),Ottawa
5,Research & Analytical Director - Data Scientist,"Pink Triangle Press (PTP) is looking for a Research & Analytics Director to lead the newly created analytics team. As part of the Growth Team, the Research & Analytics Director (“RAD”) supports the evaluation and improvement of profitability and customer satisfaction for PTP’s products (Dating products: Squirt.org, GuySpy; Journalism products: Xtra (Xtramagazine.com). They also align and direct the management, development and integration of data analytics and business intelligence necessary for supporting the mission, vision strategies, objectives and goals of PTP. As a newly created department the role will require to work partly on strategies and partly on day-to-day analytics. The role has one analyst as a direct report.

Due to COVID-19 guidelines, this role is currently 100% remote / work from home until further notice. Expectations are that this person will work from the Toronto office when in-office working is allowed. All interviews will be conducted virtually.

Provide management visibility into data-driven, actionable insights that inform PTP’s strategic direction and KPIs

Provide thought leadership and act as a subject matter expert in the designing and recommending of appropriate analytical approaches and methodology in addressing key issues within the organization
Determine the adoption of suitable tools that drive innovation and create advantage for PTP
Support the SLT in making strategic, data driven decisions in regard to existing, new products, customer segments, investments
Define the business intelligence needs and analytics tools requirements across PTP
Lead measurement framework development and defines the business KPIs
Drive and oversee initiatives to meet and exceed performance expectations, key metrics and enable overall profitability of PTP
Assess risks of growth opportunities as well provide analytics that will position the organization for dynamic growth

Stay informed and keep up with the latest industry and customer trends and best practices to improve PTP’s competitiveness in its markets

Proactively monitor market trends and inform the leaders of the specific areas that will impact the competitiveness of PTP’s brands
Anticipate business and research trends, understand the big picture but also the nuances of the business and research
Oversee the research function utilizing a number of methods: surveys, focus groups and usability research to collect and analyze customer behaviour and feedback, and provide recommendations based on the analysis

Analyze PTP products to maximize profits, audition growth and customer satisfaction

Work with the product owners to establish analytics framework to collect data regarding product usage, and come up with recommendations how the usage of the product can be improved
Establish user feedback loops to evaluate product updates and feature adoption
Work with the marketing team to establish analysis frameworks for media buying and traffic generation patterns to maximize product usage and profits
Evaluate customer behaviour and buying patterns/models
Use analysis to identify opportunities for revenue growth
Direct structured testing programmes of UX and persuasion for new and existing products to increase profitability

Oversee PTP’s data collection and design strategy to improve on data collection and data management

Develop insights and analytics, marketing technology roadmaps, identify marketing technology relevant for insight, establish key milestones and deliverables
Improve data collection and build/maintain our source of truth
Ensure that data is organized in a way that is easy to access and understand
Work with departmental leaders to ensure consistent data collection strategies across PTP
Manage development of audience insight (e.g from Customer/Audience panel)

Experience

5-10 years of analytics management experience in a digital environment
Bachelor’s degree in Statistics, Mathematics or Computer Science
Ability to quickly understand the data needs of various departments
Knowledge of reporting tools/dashboards (Tibco, Tableau, Google Analytics, Google Tag Manager, etc.);
Advanced knowledge in SQL, Python or R
Deep technical background in analytics, applied data science, and reporting spanning across areas such as marketing attribution, experimentation, optimization techniques, data engineering & architecture, statistics modeling and behavioral analytics
Extensive experience in measuring online and offline marketing strategy using various methodologies such as incrementality, attribution and cross-channel interaction
Strong understanding on how the data should be captured, stored and structured in data warehousing environment
Demonstrated track record of successful analysis of online customer behaviour

*Note that the right person for this role will be comfortable working with and around sexually explicit products and material.

If this job sounds like it's for you, please apply!

Come work with us

We’re an awesome organization that makes a difference, works hard, and still knows how to have fun!

Our company

Founded in 1971 to advance the struggle for sexual liberation, Pink Triangle Press is Canada’s leading LGBT media organization. We publish Xtramagazine.com, and we also operate the gay adult dating website Squirt.org, the Gay dating app Guy Spy and have produced a number of television projects, including the travel show Bump! and The Gayest Show Ever.

Our culture

We believe in flexibility, and the celebration of individuality here at PTP - and we think our organizational culture reflects that! We have a casual dress code, a friendly atmosphere, and where the position permits we have flexible hours. We believe in being good at what we do, and working hard – but that fun can be had along the way. We have an attractive benefits package, an employee and family assistance program, and a company-matched pension plan.

You do not need to be a part of the LGBT community in order to work here – allies are absolutely welcome to apply.

PTP is committed to Employment Equity, and to providing a fair and equitable work environment. We encourage applications from women, Aboriginal people, those living with disabilities, and people who are visible minorities. We are a trans-inclusive organization.

PTP is committed to ensuring accessible services and communications to individuals with disabilities. Once an applicant has been selected for an interview, requests for accommodation can be made at any stage of the recruitment process. Applicants should make their accommodation needs known when contacted.

Due to the volume of submissions, only applicants selected for the next step in our recruitment process will be contacted.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Company events
Company pension
Dental care
Disability insurance
Employee assistance program
Extended health care
Flexible schedule
Life insurance
Paid time off
Vision care

Schedule:

8 hour shift
Monday to Friday

Application question(s):

Bachelor’s degree in Statistics, Mathematics or Computer Science

Education:

Bachelor's Degree (preferred)

Experience:

Analytics Management: 5 years (preferred)

Work remotely:

Temporarily due to COVID-19","Pink Triangle Press
3.5",Midtown Toronto
6,Bilingual Senior Data Scientist,"Position Summary

The Senior Data Scientist will serve as a technical reference for the Core Data Science team in delivering analytically driven research projects for the Group. The candidate will be able to demonstrate a proven track record in identifying and leading data science projects while delivering compelling business insights using cutting edge data science methods. The candidate will be instrumental to shaping Air Liquide R&D data science perspectives on major business issues.

Your challenge at Air Liquide:

Provide technical expertise to the team of data scientists and support end-to-end rigorous and creative analytics research process.
Ensure the flawless deployment and delivery of analytics solutions with demonstrated business performance and to the satisfaction of internal sponsors.
Lead the end-to-end development of scalable and production-grade predictive models, Artificial Intelligence and machine learning solutions that can create proven business value for their respective entities.
Provide thought leadership to business executives and analytic leaders to develop a vision and roadmap for analytics across the Air Liquide group. Build strong relationships with Academic and business communities to build and maintain cutting edge expertise in analytics, Artificial Analytics and Machine Learning.
Present research findings to senior leadership both within and outside of Air Liquide

*
Who we are looking for :

Required

Phd/Master’s degree in computer science, mathematics, physics, applied science, engineering or similar disciplines with demonstrated research capability.
8+ years of relevant experience in an analytical function in the corporate world..
Substantial experience with analytical tools and techniques and a proven track record on analytics projects solving business problems and/or improving bottom line.
Demonstrated ability to independently drive novel data-driven research projects, from project ideation to full deployment.
Established network of thought leaders and recognized experts on leading-edge tools and methods in Artificial Intelligence and Machine Learning.
Capacity to interface effectively with senior management and build business momentum around data analytics.
Programming experience in Python.
Good communication skills in French and in English

Preferred

Understanding and/or past experience of the Industrial or energy sectors is a plus.

*** Thank you for your interest in Air Liquide. Please note that only shortlisted candidates will be contacted. For more information on our company, visit us online at www.airliquide.ca

Scientifique senior des données

Résumé du poste

Le Scientifique senior des données sera une référence technique pour l'équipe Core Data Science dans le cadre de la réalisation de projets de recherche pour le Groupe axés sur l'analyse. Vous serez en mesure de faire preuve d'une expérience avérée dans l'identification et la direction de projets de science des données tout en fournissant des informations commerciales convaincantes à l'aide de méthodes de science des données de pointe. Vous aurez un rôle déterminant dans l'élaboration des perspectives de la science des données d'Air Liquide R&D sur des questions commerciales majeures.

Votre défi chez Air Liquide :

Fournir une expertise technique à l'équipe de scientifiques des données tout en soutenant un processus de recherche analytique rigoureux et créatif de bout en bout.
Assurer le déploiement et la livraison sans faille de solutions d'analyse avec un rendement commercial démontré et à la satisfaction des sponsors internes.
Diriger le développement de bout en bout de modèles prévisionnels évolutifs et de grande production, de solutions d'intelligence artificielle et d'apprentissage automatisé qui peuvent créer une valeur commerciale avérée pour leurs entités respectives.
Fournir un leadership éclairé aux dirigeants d'entreprise et aux leaders analytiques pour développer une vision et une feuille de route pour l'analytique à travers le groupe Air Liquide. Construire de solides relations avec les communautés académiques et commerciales pour construire et maintenir une expertise de pointe en matière d'analytique, d'analyse artificielle et d'apprentissage automatisé.
Présenter les résultats de recherches aux hauts dirigeants, tant à l'intérieur qu'à l'extérieur d'Air Liquide.

Qui recherchons-nous ?

Exigences

Doctorat/Maîtrise en informatique, mathématiques, physique, sciences appliquées, ingénierie ou dans des disciplines similaires avec une capacité de recherche avérée.
Minimum de 8 ans d'expérience pertinente dans une fonction analytique dans le monde de l'entreprise.
Une bonne connaissance des outils et techniques d'analyse et une expérience avérée dans des projets d'analyse visant à résoudre des problèmes commerciaux et/ou à améliorer les résultats.
Capacité avérée à gérer de manière autonome des projets de recherche novateurs fondés sur des données, de l'idéation du projet au déploiement complet.
Réseau établi de leaders d'opinion et d'experts reconnus sur les outils et méthodes de pointe en matière d'intelligence artificielle et d'apprentissage automatisé.
Capacité d'interagir efficacement avec la haute direction et de créer une dynamique commerciale autour de l'analyse des données..
Expérience de la programmation sous Python.
Bonne capacité de communication en français et en anglais

Atout

Une compréhension et/ou une expérience antérieure des secteurs de l'industrie ou de l'énergie constitue un atout.

*** Merci de l'intérêt que vous portez à Air Liquide. Veuillez noter que seuls les candidats présélectionnés seront contactés. Pour plus d'informations sur notre société, visitez-nous en ligne à l'adresse www.airliquide.ca. *

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

Education:

Master's Degree (preferred)

Experience:

Analytical Function: 8 years (preferred)
Python: 5 years (preferred)
Machine Learning: 8 years (preferred)","Air Liquide
3.8",Montreal
7,Machine Learning Engineer / Data Scientist,"CATCHY INTRO

Honestly, we’ve been brainstorming this “catchy intro” for about 20 minutes and everything that we throw at the wall is either too serious, or just downright lame, with no authenticity behind it. Which is absolutely hilarious, considering everyday TerraSense strives for authenticity. So that’s it. That’s what you get. Our not-so-super-catchy, not-super-lame, but not-super-corporate intro. Authentic. Hey, come work here and help us on this journey.

*
WHY WORK WITH US?*

Our two main products target the Utilities and Defense sectors. Besides understanding how to use machine learning to predict maintenance for transmission lines, or how to take the metadata from two sensors and fuse them together, we actually do appreciate the soft skills too. We strive to foster a culture of success, innovation, respect, and did we mention authenticity? That’s right, if you hate what the CTO is saying, we fully expect you to step up and tell him he’s wrong (or that you disagree). The Product Manager does all the time and she still hasn’t been fired.

*
WHAT YOU WOULD BE DOING...*

... on the development team for our MIST product, working to create and deploy aerial surveillance with artificial intelligence. The product will utilize edge computing, computer vision and deep learning algorithms. Okay so we hope that you got this far and are slightly intrigued by our culture and what you would be doing. Here comes the hard part. This role requires you to be a Canadian Citizen or Permanent Resident having resided in Canada for at least 10 years as well as a criminal record and credit check. You will be required to work locally with flexibility on work hours. These are hard requirements with no negotiation, so please do not apply to this particular role if you don’t meet these requirements. We will have other roles that come up without such stringent requirements, but there is no wiggle room on this one.

*
QUALIFICATIONS*

Excellent knowledge of Python
2 years of experience in building and shipping great software
Experience with deploying ML on the edge or in the cloud
Strong knowledge of ML frameworks (eg. TensorFlow, PyTorch, CUDA)
Knowledge of computer vision models, frameworks, and tools
Eligible for security clearance and to work in Canada
Bonus: Experience with Docker, video analytics, and/or GUI development a plus
Bonus: Networking and cybersecurity experience

COMPENSATION

Competitive salary and stock options based on experience, competency and length of service
5 weeks paid vacation
Training and professional development allowance, and extended medical and dental
Beer Tuesdays at our neighbourhood microbrewery (post Covid!)

*
NON - COMPENSATION CONSIDERATIONS*

Accountability: We truly do work hard, play hard and expect everyone to self manage...meaning we don’t track hours.
Flexibility: If your best time to work is from 10pm to 2am then we want to support that so we try to enable team communication by committing to M-Th 10am-2pm “office hours.” The rest is up to you.

Job Type: Full-time

Schedule:

8 hour shift",TerraSense Analytics Ltd,Kelowna
8,Machine Learning Engineer / Data Scientist,"CATCHY INTRO

Honestly, we’ve been brainstorming this “catchy intro” for about 20 minutes and everything that we throw at the wall is either too serious, or just downright lame, with no authenticity behind it. Which is absolutely hilarious, considering everyday TerraSense strives for authenticity. So that’s it. That’s what you get. Our not-so-super-catchy, not-super-lame, but not-super-corporate intro. Authentic. Hey, come work here and help us on this journey.

*
WHY WORK WITH US?*

Our two main products target the Utilities and Defense sectors. Besides understanding how to use machine learning to predict maintenance for transmission lines, or how to take the metadata from two sensors and fuse them together, we actually do appreciate the soft skills too. We strive to foster a culture of success, innovation, respect, and did we mention authenticity? That’s right, if you hate what the CTO is saying, we fully expect you to step up and tell him he’s wrong (or that you disagree). The Product Manager does all the time and she still hasn’t been fired.

*
WHAT YOU WOULD BE DOING...*

... on the development team for our MIST product, working to create and deploy aerial surveillance with artificial intelligence. The product will utilize edge computing, computer vision and deep learning algorithms. Okay so we hope that you got this far and are slightly intrigued by our culture and what you would be doing. Here comes the hard part. This role requires you to be a Canadian Citizen or Permanent Resident having resided in Canada for at least 10 years as well as a criminal record and credit check. You will be required to work locally with flexibility on work hours. These are hard requirements with no negotiation, so please do not apply to this particular role if you don’t meet these requirements. We will have other roles that come up without such stringent requirements, but there is no wiggle room on this one.

*
QUALIFICATIONS*

Excellent knowledge of Python
2 years of experience in building and shipping great software
Experience with deploying ML on the edge or in the cloud
Strong knowledge of ML frameworks (eg. TensorFlow, PyTorch, CUDA)
Knowledge of computer vision models, frameworks, and tools
Eligible for security clearance and to work in Canada
Bonus: Experience with Docker, video analytics, and/or GUI development a plus
Bonus: Networking and cybersecurity experience

COMPENSATION

Competitive salary and stock options based on experience, competency and length of service
5 weeks paid vacation
Training and professional development allowance, and extended medical and dental
Beer Tuesdays at our neighbourhood microbrewery (post Covid!)

*
NON - COMPENSATION CONSIDERATIONS*

Accountability: We truly do work hard, play hard and expect everyone to self manage...meaning we don’t track hours.
Flexibility: If your best time to work is from 10pm to 2am then we want to support that so we try to enable team communication by committing to M-Th 10am-2pm “office hours.” The rest is up to you.

Job Type: Full-time

Schedule:

8 hour shift",TerraSense Analytics Ltd,Kelowna
9,Sr. Data Engineer,"Numerator is a data and tech company bringing speed and scale to market research. Headquartered in Chicago, IL, Numerator has more than 2,000 employees worldwide. The company blends proprietary data with advanced technology to create unique insights for the market research industry that has been slow to change. The majority of Fortune 100 companies are Numerator clients.

Job Description

Numerator is looking for a Sr. Data Engineer who is a Big Data enthusiast and has a passion for working with an interesting robust set of data. In this role, you will work in our platform to help ensure that our data quality is flawless.

As a company, we have millions of new data points every day that come into our system. You will be working with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our customers, on-time. You will be using the latest cloud data warehouse technologies to build robust and reliable data pipelines.

A major requirement for this role is to understand, author, and deploy production code, the ideal candidate should also be experienced with processing large quantities of data, building algorithms alongside software engineers, and delivering to production.

You will have a broad impact and exposure across Numerator as you help build out and expand our technology platforms across several software products. This is a fast-paced role with high growth, visibility, impact, and where many of the decisions for new projects will be driven by you and your team from inception through production.

What you get to do

Develop expertise in the different upstream data stores and systems across Numerator
Design, develop and maintain data integration pipelines for Numerators growing data sets and product offerings
Collaborate with product and engineering teams to take requirements from prototype to production
Build data validation testing frameworks to ensure high data quality and integrity
Write and maintain documentation on data pipelines and schemas

Skills & Requirements

What we are looking for

5+ years of experience in building a data warehouse and data pipelines
Knowledge of software engineering best practices across the development lifecycle, coding standards, code reviews, source management, build processes, testing, and operations
Expert in SQL, including advanced analytical queries, window functions, CTEs and query optimization
Advanced proficiency in Python (data structures, algorithms, object oriented programming, using APIs)
Experience administering a cloud data warehouse (Redshift, Snowflake, Vertica)
Experience with ETL tooling (especially Airflow) and data processing, and knowing how to transform data to meet business goals
Experience with schema design and dimensional data modeling
Knowledge of and experience implementing data security and governance best practices
Curious and interested in learning about the latest in data warehouse technology and willingness to mentor junior team members
BS in Mathematics, Statistics, Computer Science, Engineering, Economics, Physics, or other behavioral and/or equivalent quantitative science.

Nice to have

Amazon Web Services (EC2, DMS, RDS) experience
Terraform and/or ansible (or similar) for infrastructure deployment
Airflow - Experience building and monitoring DAGs, developing custom operators and using script templating solutions
Experience supporting production systems and developing on-call/incident management playbooks
Ability to work with team members located in multiple geographies and time zones.

What we offer you

More data than you could imagine to play with!
Data that matters and that is shaping the impact of billion dollar brands.
Brillant, motivated and passionate colleagues with whom to spend your time.
An inclusive and collaborative company culture- we work in an open environment while working together to get things done, and adapt to the changing needs as they come.
Market competitive total compensation package.
Volunteer time off and charitable donation matching.
Regular hackathons to build your own projects and work with people across the entire company
Strong support for career growth, including mentorship programs, leadership training, access to conferences and employee resource groups.
Great benefits package including health/vision/dental, exceptional maternity leave coverage, unlimited PTO, flexible schedule, 401K/RRSPs matching and much more.

If this sounds like something you would like to be part of, we’d love for you to apply! Don't worry if you think that you don't meet all the qualifications here. The tools, technology, and methodologies we use are constantly changing and we value talent and interest over specific experience.

While this position can be remote, Numerator is only able to hire in many, but not all, states and provinces. In certain cases, if you are not located in a specific area where Numerator is able to hire, you may not be eligible for employment.

We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by the law.","Numerator
4.1",Remote
10,Material Engineer/Scientist,"This is a unique opportunity to join the technical team of an early-stage company to support the development of a novel implantable medical device and ensuring its readiness for early human use. The Materials Engineer/Scientist will be responsible for conducting applied industrial research activities in accordance with an established quality management system. The Materials Engineer/Scientist will provide subject matter expert input into device evaluations and pipeline projects that relate to metal and polymer material properties. The Materials Engineer/Scientist will work in a fast paced and dynamic environment where taking initiative and collaborating cross-functionally are critical for success.

Key Responsibilities:

Act as a key contact for material characterization, structure, properties, processing and performance
Perform and evaluate hands-on processing of materials including heat-treatment, solvent cleaning, and sterilization
Develop and validate test methods related to material properties
Collaborate with multiple parties to execute testing according to standardised testing methods for material evaluation
Compile, analyze and present technical data to provide objective traceable evidence of material properties for device Design History File (DHF) compilation
Completion of technical reports related to materials evaluation
Assist in the review of manufacturing processes for impact on material properties
Contribute to Failure Mode and Effects Analysis (FMEA) of device and accessories by evaluating applicable risk scenarios and degradation mechanisms with potential mitigation tasks
Assist with other product development documentation activities.

Education and Experience Requirements:

BS in Materials Engineering, Biomaterials, Materials Science, or Polymer Science (Masters preferred)
Minimum of 2 years of materials science industrial experience
Hands-on experience with material testing equipment such as Tensile Testing, Hardness, Corrosion, Spectroscopy (Raman, Energy-Dispersive, FTIR), Thermal Analysis (Differential Scanning Calorimetry (DSC), Thermogravimetric analysis (TGA)), Microscopy (Light, Scanning Electron), Resorption/Hydrolytic Degradation, etc.
Experience with new product development preferred.

Additional Skills:

· Working knowledge of ISO 9001 and/or ISO 13485 is preferred.

· Excellent documentation, communication and interpersonal relationship skills.

· Ability to adhere to Quality Management Systems requirements.

· Ability to manage competing priorities in a fast-paced environment.

· Experience with statistical analysis and related software appreciated.

· Proven expertise in usage of MS Office Suite.

Candidates must reside in or relocate to Calgary AB and be legally entitled to work full time in Canada.

Job Types: Full-time, Permanent

Salary: $50,000.00-$100,000.00 per year

Benefits:

On-site parking
Paid time off

Schedule:

Monday to Friday

COVID-19 considerations:
Fluid Biotech Inc. is following all applicable city, provincial and facility safety requirements.

Ability to commute/relocate:

Calgary, AB (required)

Education:

Bachelor's Degree (required)

Work remotely:

No",Fluid Biotech Inc.,Calgary
11,Business Intelligence Data Engineer,"About Blackline

Blackline Safety is a world leader in the development and manufacturing of wirelessly connected safety products. We offer the broadest and most complete portfolio available in the industry. Our products are designed to save lives and we monitor personnel working alone in populated areas, complex indoor facilities, and the remote reaches of our planet. Blackline’s products are used to keep people safe in the event of falls, missed check-ins, person-downs, and exposure to explosive or toxic gas. Our design, development, sales, marketing, support, and production are all performed in-house at our headquarters in Calgary, AB. Blackline Safety is a publicly-traded company (TSXV: BLN).

Blackline Safety is looking for a Data Engineer to help build and drive our Blackline Analytics and Blackline Vision platform. We have a world-class connected safety system and we are building a Data analytics and Data science platform to match it.

Who are you?

You believe big data helps businesses solve real-world problems. You have an aptitude for engineering and manipulating various forms of data frameworks including but not limited to Data warehousing, Modeling, Analytics, and Integrations from various data sources. You are not bound to a single tool or platform and can solve problems in creative ways. You are proficient in different computing languages such as SQL, Python, DAX and aspire to learn alternate ways of resolving issues. You trust in data-driven problem solving and believe visualizing large datasets is a necessity to achieve that. You like to explore datasets to find insights that nobody else sees. You can communicate these ideas through visualizations. You are team-oriented, self-motivated, creative, and excited to find answers to questions that the answer might not be obvious without going through large amounts of data.

What will you do?

You have an ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams. You will be a part of a high performing team that is focused on building solutions utilizing various approaches including agile; capable of digesting real-time feedback and working smartly to advance Blackline Analytics and Blackline Vision platforms. You are self-driven, need minimal supervision and are comfortable pushing your own projects and getting things done.

You will be responsible for expanding and optimizing our data pipeline architecture, as well as optimizing data flows and collection for analytics and data science teams. The pipeline needs to be scalable, precise, repeatable, secure, and accurate. You will work with some of the largest and most varied data sets (both batch and real-time) in the wireless industry. You will expand and develop the Blackline analytics platform alongside other data analysts and data scientists to make data-driven decisions, build innovative data products and roll out advanced analytics. Your contribution will help us increase internal efficiencies and evolve our products and services by leveraging large and diverse datasets generated by customers from around the world. The data architecture and framework and the technologies include IoT, ECS, Fargate, RDS MySQL, RedShift, Spark, EMR, Kinesis (Streams, Firehose, Analytics), Lambda, Datalakes, Deltalakes, Event bus, DataDog, CD/CI pipelines on CodePipeline and CodeBuild, CloudFormation, ALP, Python, Java, and more.

Requirements:

3+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field.
Experience working with APIs, integrations into reporting documents, building API endpoints for real-time reporting
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL), Postgres, JSON as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience with big data tools: Hadoop, Spark, Kafka, DataDog, EventBus, AWS cloud services: EC2, EMR, RDS, Redshift, API calls, API generation
Hands-on experience with Cloud Data Warehouse (Snowflake, Azure or Redshift) and Big Data technologies (e.g S3, Hadoop, Hive, Spark, Flink, Kafka, etc). Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large, disconnected datasets using ETL/ELT, Matillion, SSIS, Trefecta, etc and integrating data from silos to a Master Data source
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores

Optional:

Knowledge of NetSuite, other 3rd party software integrations
Knowledge of Satori Reporting or any other turnkey integrative reporting
Knowledge of Power platform operations, query, flow and BI and integrations
Knowledge of Master Data Management

Blackline Safety offers:

An exciting high-growth environment
An experienced, dynamic, and motivated team
Supportive, challenging, and collaborative work
Competitive salary and vacation
Medical, dental, and drug benefits
Company stock purchase plan with matching contributions

Our clients depend on Blackline Safety to monitor the wellbeing of their employees at work — you can help to make a difference. Come work with Blackline Safety in an exciting, fast-paced work environment.

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

Education:

Bachelor's Degree (preferred)

Experience:

building API endpoints for real-time reporting: 3 years (preferred)
building and optimizing ‘big data’ data pipelines: 3 years (preferred)
big data tools: 3 years (preferred)
Data Engineering: 3 years (preferred)
Advanced SQL knowledge and relational database: 3 years (preferred)

Work remotely:

Temporarily due to COVID-19","Blackline Safety
3.8",Calgary
12,"Developer, Data Science","Req Id: 295813


At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we advance how Canadians connect with each other and the world.


If you’re ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.


Bell is making unmatched investments in our world-leading broadband fibre and wireless networks because we know they’re the backbone of the products and services our customers love. If you’re excited about transforming the way people connect, our Network team is the right place for you.


Artificial Intelligence is among the fastest growing business and technology disciplines. Specifically in Telecom, there are great opportunities to utilize machine learning and advanced analytics solutions to evolve network planning and operations and prepare for the future network.


Bell’s Network Big Data & AI team is focused on utilizing machine learning, big data and advanced analytics technologies to enable Bell’s future AI powered networks.

This is a rare opportunity for a motivated data and analytics professional to join a fast growing team of machine learning experts to design, develop data solution to support the entire Bell Network community.


Key responsibilities:

Lead a team of data scientists and AI/ML developers in the design, development and deployment of AI-enabled solutions to address complex business problems
Work with Network Big Data & AI CoE team members, Network Engineering, Operations as well as other Bell Businesses to understand and analyze business needs
Review AI/ML solutions developed by team members to ensure they are efficient, scalable and resilient
Refine CI/CD processes related to AI/ML solutions
Explore new sources of information to uncover new business opportunities at all levels of the business (strategic to operational)
Exercise leading edge analytics skills to identify previously undetected patterns of behavior or correlations between related datasets
Work with and present to all management levels
Maintain and expand knowledge of data systems and current technology through training opportunities
Work in an agile environment and contribute to the improvement of our development processes


Required Competencies:

A Bachelors or Master’s degree in computer science, math, applied science / engineering, or equivalent
Minimum 2 years’ experience leading a devops team
Minimum 5 years’ experience with Machine Learning and Artificial Intelligence algorithms and approaches
Minimum 4 years’ experience designing, documenting and presenting communicating ML solutions to complex business problems
Excellent documentation and communication skills. Must be able to clearly communicate with a wide range of roles from hands-on developer to Senior Executive team
Ability to assist other ML developers with designing, developing and reviewing their solutions.
Familiarity working with NoSQL databases and unstructured/semi-structured data
Experience working with CI/CD tools and approaches
Experience with Kubernetes or other container orchestration systems
Experience with Jupyter Notebook, GIT, and other software management tools
Advanced skills with SQL and database systems such as MySQL, MariaDB, Oracle, SQL Server, Teradata, Hive, Impala
Skills with multiple analytical tools such as Microstrategy, R, Python, Scala, Tableau
Highly analytical skills and ability to work with large and complex technical data sets
Ability to leverage insights and opportunities from data and metrics to build strategies and make recommendations
Knowledge of, and preferably experience with, Big Data and/or software development, and/or developing visualization tools
Ability to work with a team towards common goals
Ability to quickly learn new programming languages and frameworks
Able to manage multiple projects and priorities
Self starter who is comfortable working with and presenting to all management levels


Preferred Competencies:

Statistics and math background
Experience in Telecom or IT is a strong asset


#LI-MS1

#tech

#EmployeeReferralProgram


Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.


Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Montreal || Canada : Ontario : Mississauga || Canada : Ontario : Ottawa || Canada : Ontario : Toronto || Canada : Quebec : Montreal || Canada : Quebec : Verdun
Application Deadline: 07/09/2021


Please apply directly online to be considered for this role. Applications through email will not be accepted.


At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.


Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.


Created: Canada, QC, Montreal


Bell, one of Canada's Top 100 Employers.","Bell Canada
3.9",Montreal
13,"Advisor, Wireless Data Analytics & A.I.","Req Id: 299656


At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we advance how Canadians connect with each other and the world.


If you’re ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.


Bell is making unmatched investments in our world-leading broadband fibre and wireless networks because we know they’re the backbone of the products and services our customers love. If you’re excited about transforming the way people connect, our Network team is the right place for you.


Bell’s Wireless Orchestration & Insights team is focused on utilizing Big Data, advanced analytics and machine learning technologies to enable Bell’s AI powered networks.


This is a rare opportunity for seasoned Data Scientist to join our fast growing team of data engineers and scientists as we design and develop solutions to support the Bell Wireless community.


Job Description:

As a member of the Network Big Data team and reporting to the Network Big Data Manager for Wireless, the Advisor will play a leading role in the development of new intelligence insights on existing network and customer data. By working closely with our business partners you will establish detailed project deliverables and work with SMEs to profile data and integrate new data sets. Your main goal will be to ensure data pipelines for analysis, intelligence, and reporting are delivered with the utmost quality and reliability.


Primary Responsibilities:

Lead a team of data engineers, data analysts, and data scientists, to deliver dashboards, reports, and advanced AI models that provide insights and support wireless engineering and operations domains
Help establish and maintain an operational support model for high availability production environments. Provide technical guidance for off-hour failures when required
Work directly with all stakeholders to prioritize projects and work with the development team to ensure reference architecture is respected at the tactical level
Work with subject matter experts to build project requirements documentation, and ensure that project scope is maintained and resources are used effectively
Oversee and participate in all aspects of Big Data solution delivery life cycle from analysis and data profiling to design, development, testing, delivery, and support
Work with Analytics Administrators and other teams to develop and follow standardized practices for delivering new products and capabilities using Big Data technologies and adapt as new tools and systems are developed
Create formal written deliverables and other documentation, and ensure designs, code, and documentation are aligned with enterprise direction, principles, and standards
Provide technical input to assist in the development of strategic business cases used at management and executive levels for Big Data evolution
Work on analytics projects as a developer when required


Basic Qualifications:

Bachelor in Computer Science, Computer Engineering, Electrical Engineering, Management Information Systems, or Computer Information Systems is required
Must be proficient in SQL/HiveQL and other query languages
Experience with MicroStrategy and other data visualization tools (Kibana, Tableau, etc)
Played a leading role in the delivery of multiple end-to-end projects using Hadoop
Experience working with traditional ETL tools & Data Warehousing architectures
Knowledge of predictive analytics techniques (e.g. predictive modeling, statistical programming, machine learning, data mining, data visualization)
Detail oriented and able to manage a constantly changing environment.
Strong personal leadership and collaborative skills, combined with comprehensive, practical experience and knowledge in end-to-end delivery of Big Data solutions
Experience leading project teams or management experience
Strong communication, technology awareness, and capability to interact work with senior technology leaders is a must
Ability to clearly communicate complex technical ideas, regardless of the technical capacity of the audience
Strong inter-personal and communication skills including written, verbal, and technology illustrations.
Good knowledge on Agile Methodology and the Scrum process
Delivery of high-quality work, on time and with little supervision
Critical Thinking/Analytic abilities


Preferred Qualifications:

Experience in wireless telecommunications systems and data those systems produce
Knowledge of Nokia, Ericsson, Samsung, Cisco, etc for RAN and CORE operations
Coding applications using Hadoop components - HDFS, Hive, Impala, Sqoop, Flume, Kafka, Confluent Kafka, StreamSets, HBase, etc.
Designing and Deploying solutions Big Data solutions in public cloud environments (AWS, GCP, Azure, etc)
Demonstrated capability with business development in big data infrastructure business


Preferred Skills:

Bilingual (French/English) who has the capacity to adapt his communication to most of the situations and audience. Proficient in planning his communications, facilitating a meeting or workshop;
Able to proactively plan his/her work over multiple timeframes – week-months-year and juggle multiple priorities and deliver as per commitments;
Able to plan and execute complex tasks without supervision, identify potential roadblocks and mobilise resources to remove them and achieve goals;
Able to identify and analyze complex problem, identify root cause, provide detailed description and plan, design and deliver workaround/solution;
Capable to evaluate without supervision the effort & time required to complete a deliverable and/or task thru collaboration, teamwork, honesty, commitment and respect;
Comfortable interviewing non-technical people to gather/discuss requirements;
Wireless/Telecom Operations and Engineering business Knowledge including basic understanding of Radio access, Core network and Value added Services technologies and configurations.


#LI-MS1

#tech

#indeed

#EmployeeReferralProgram


Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.


Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Montreal || Canada : Ontario : Mississauga || Canada : Ontario : Toronto || Canada : Quebec : Montreal || Canada : Quebec : Verdun
Application Deadline: 07/09/2021


Please apply directly online to be considered for this role. Applications through email will not be accepted.


At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.


Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.


Created: Canada, QC, Montreal


Bell, one of Canada's Top 100 Employers.","Bell Canada
3.9",Montreal
14,"Advisor, Wireless Data Analytics & A.I.","Req Id: 299656


At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we advance how Canadians connect with each other and the world.


If you’re ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.


Bell is making unmatched investments in our world-leading broadband fibre and wireless networks because we know they’re the backbone of the products and services our customers love. If you’re excited about transforming the way people connect, our Network team is the right place for you.


Bell’s Wireless Orchestration & Insights team is focused on utilizing Big Data, advanced analytics and machine learning technologies to enable Bell’s AI powered networks.


This is a rare opportunity for seasoned Data Scientist to join our fast growing team of data engineers and scientists as we design and develop solutions to support the Bell Wireless community.


Job Description:

As a member of the Network Big Data team and reporting to the Network Big Data Manager for Wireless, the Advisor will play a leading role in the development of new intelligence insights on existing network and customer data. By working closely with our business partners you will establish detailed project deliverables and work with SMEs to profile data and integrate new data sets. Your main goal will be to ensure data pipelines for analysis, intelligence, and reporting are delivered with the utmost quality and reliability.


Primary Responsibilities:

Lead a team of data engineers, data analysts, and data scientists, to deliver dashboards, reports, and advanced AI models that provide insights and support wireless engineering and operations domains
Help establish and maintain an operational support model for high availability production environments. Provide technical guidance for off-hour failures when required
Work directly with all stakeholders to prioritize projects and work with the development team to ensure reference architecture is respected at the tactical level
Work with subject matter experts to build project requirements documentation, and ensure that project scope is maintained and resources are used effectively
Oversee and participate in all aspects of Big Data solution delivery life cycle from analysis and data profiling to design, development, testing, delivery, and support
Work with Analytics Administrators and other teams to develop and follow standardized practices for delivering new products and capabilities using Big Data technologies and adapt as new tools and systems are developed
Create formal written deliverables and other documentation, and ensure designs, code, and documentation are aligned with enterprise direction, principles, and standards
Provide technical input to assist in the development of strategic business cases used at management and executive levels for Big Data evolution
Work on analytics projects as a developer when required


Basic Qualifications:

Bachelor in Computer Science, Computer Engineering, Electrical Engineering, Management Information Systems, or Computer Information Systems is required
Must be proficient in SQL/HiveQL and other query languages
Experience with MicroStrategy and other data visualization tools (Kibana, Tableau, etc)
Played a leading role in the delivery of multiple end-to-end projects using Hadoop
Experience working with traditional ETL tools & Data Warehousing architectures
Knowledge of predictive analytics techniques (e.g. predictive modeling, statistical programming, machine learning, data mining, data visualization)
Detail oriented and able to manage a constantly changing environment.
Strong personal leadership and collaborative skills, combined with comprehensive, practical experience and knowledge in end-to-end delivery of Big Data solutions
Experience leading project teams or management experience
Strong communication, technology awareness, and capability to interact work with senior technology leaders is a must
Ability to clearly communicate complex technical ideas, regardless of the technical capacity of the audience
Strong inter-personal and communication skills including written, verbal, and technology illustrations.
Good knowledge on Agile Methodology and the Scrum process
Delivery of high-quality work, on time and with little supervision
Critical Thinking/Analytic abilities


Preferred Qualifications:

Experience in wireless telecommunications systems and data those systems produce
Knowledge of Nokia, Ericsson, Samsung, Cisco, etc for RAN and CORE operations
Coding applications using Hadoop components - HDFS, Hive, Impala, Sqoop, Flume, Kafka, Confluent Kafka, StreamSets, HBase, etc.
Designing and Deploying solutions Big Data solutions in public cloud environments (AWS, GCP, Azure, etc)
Demonstrated capability with business development in big data infrastructure business


Preferred Skills:

Bilingual (French/English) who has the capacity to adapt his communication to most of the situations and audience. Proficient in planning his communications, facilitating a meeting or workshop;
Able to proactively plan his/her work over multiple timeframes – week-months-year and juggle multiple priorities and deliver as per commitments;
Able to plan and execute complex tasks without supervision, identify potential roadblocks and mobilise resources to remove them and achieve goals;
Able to identify and analyze complex problem, identify root cause, provide detailed description and plan, design and deliver workaround/solution;
Capable to evaluate without supervision the effort & time required to complete a deliverable and/or task thru collaboration, teamwork, honesty, commitment and respect;
Comfortable interviewing non-technical people to gather/discuss requirements;
Wireless/Telecom Operations and Engineering business Knowledge including basic understanding of Radio access, Core network and Value added Services technologies and configurations.


#LI-MS1

#tech

#indeed

#EmployeeReferralProgram


Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.


Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Montreal || Canada : Ontario : Mississauga || Canada : Ontario : Toronto || Canada : Quebec : Montreal || Canada : Quebec : Verdun
Application Deadline: 07/09/2021


Please apply directly online to be considered for this role. Applications through email will not be accepted.


At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.


Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.


Created: Canada, QC, Montreal


Bell, one of Canada's Top 100 Employers.","Bell Canada
3.9",Montreal
15,Data Engineer,"Data Engineer

Are you a go-getter who has a passion in building next gen data solutions for business problems? Are you a big fan of simplification and automation?

One of our top clients, the largest e-commerce investor is Looking for a Data Engineer to join their smart team to build the data-driven app for early-stage founders.

100% Remote Opportunity (Within Canada)

Job Description:

What we look for:

5+ years of experience as a Data Engineer.
Able to architect and scale data integrations (Shopify, PayPal, plaid, etc.) from third-party API docs independently, extracting the right business value for the vision and roadmap.
Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes.
Comfortable working in server and database environments that are changing constantly.
Comfortable in a fast pace, relational databases and schemas involving time-series.
Skills and interest in Python, SQL, Snowflake, Kubernetes, and pipeline management/orchestration tools (Eg. Airflow), Expert in coding.
Great communication skills and fast-paced learning
Comfort working in a high growth, constantly changing environment.
Heavy bias towards action. Ability to solve problems end-to-end on your own.
Implement ideas and experiments on your own with minimal support.
Have a strong business sense, you can foresee potential issues and solve them quickly.

Responsibilities:

You will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development.
Collaborate with all functions, ranging from core Engineering team to Data Science team to the marketing team.
You be in constant communication with the team to understand what features of the platform need to be built out and solve bug fixes when necessary.
You will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself.

If you are interested in this opportunity, please apply for this position with your updated resume.

TOR123","Vaco
3.7",Remote
16,Data Scientist & Analyst (PhD Required),"PLEASE APPLY via the Company HR Page

https://www.numerixsquant.com/careers.php#data-scientist

We are a data-driven company with a collegial atmosphere looking for team members who can do great work for application in the algorithmic trading industry.

Our ideal candidate is a recent or soon to be PhD graduate with experience in an academic or post-doc research workplace looking to apply their capabilities to the real world. Our approach is to train successful candidates about our industry, markets and products, as such we are looking for people seeking their initial entry position in the financial markets.

About You:

You are driven by intellectual challenges, curiosity, and solving problems. You continuously seek to understand new and better approaches to analyze and interpret ‘dirty’ data to improve understanding and reporting of investment results. You love to see your work put into practice. For individuals currently living outside of Vancouver, we offer relocation assistance.

What You’ll Do:

Initial significant project is enhancing the understanding and reporting of investments returns
Developing and bringing research projects to completion
Identifying timely and unique data sets, exploring underlying data drivers, and developing understanding, quantities and reporting for use in an existing trading system

What You Bring:

Required: Ph.D. in mathematics, physics or related fields in quantitative disciplines with a Masters in the hard sciences (including if you will be graduating with a Ph.D. within the next 12 months)
Highly analytical, keen attention to detail
Innate curiosity and an exceptional critical thinker who is results-oriented
Demonstrated expertise in statistics and mathematical modelling
Strong communications skills (both verbal and written)
Thrive in a performance-based environment
Require excellence of yourself and in the work you produce

Nice to Have:

Experience participating in national or international math, physics or computer science competitions is strongly preferred
Strong experience with Python, C++, R and kdb+ (Linux environment) and coding concepts
Legally entitled to work in Canada (however for exceptional candidates we can provide immigration assistance)

PLEASE APPLY via the Company HR Page

https://www.numerixsquant.com/careers.php#data-scientist

Job Type: Full-time

Salary: $100,000.00-$110,000.00 per year

Additional pay:

Bonus pay

Benefits:

Casual dress
Dental care
Disability insurance
Discounted or free food
Extended health care
Flexible schedule
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Education:

Doctoral Degree (required)

Work remotely:

No",NumerixSQuant,Vancouver
17,Data Scientist & Analyst (PhD Required),"PLEASE APPLY via the Company HR Page

https://www.numerixsquant.com/careers.php#data-scientist

We are a data-driven company with a collegial atmosphere looking for team members who can do great work for application in the algorithmic trading industry.

Our ideal candidate is a recent or soon to be PhD graduate with experience in an academic or post-doc research workplace looking to apply their capabilities to the real world. Our approach is to train successful candidates about our industry, markets and products, as such we are looking for people seeking their initial entry position in the financial markets.

About You:

You are driven by intellectual challenges, curiosity, and solving problems. You continuously seek to understand new and better approaches to analyze and interpret ‘dirty’ data to improve understanding and reporting of investment results. You love to see your work put into practice. For individuals currently living outside of Vancouver, we offer relocation assistance.

What You’ll Do:

Initial significant project is enhancing the understanding and reporting of investments returns
Developing and bringing research projects to completion
Identifying timely and unique data sets, exploring underlying data drivers, and developing understanding, quantities and reporting for use in an existing trading system

What You Bring:

Required: Ph.D. in mathematics, physics or related fields in quantitative disciplines with a Masters in the hard sciences (including if you will be graduating with a Ph.D. within the next 12 months)
Highly analytical, keen attention to detail
Innate curiosity and an exceptional critical thinker who is results-oriented
Demonstrated expertise in statistics and mathematical modelling
Strong communications skills (both verbal and written)
Thrive in a performance-based environment
Require excellence of yourself and in the work you produce

Nice to Have:

Experience participating in national or international math, physics or computer science competitions is strongly preferred
Strong experience with Python, C++, R and kdb+ (Linux environment) and coding concepts
Legally entitled to work in Canada (however for exceptional candidates we can provide immigration assistance)

PLEASE APPLY via the Company HR Page

https://www.numerixsquant.com/careers.php#data-scientist

Job Type: Full-time

Salary: $100,000.00-$110,000.00 per year

Additional pay:

Bonus pay

Benefits:

Casual dress
Dental care
Disability insurance
Discounted or free food
Extended health care
Flexible schedule
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Education:

Doctoral Degree (required)

Work remotely:

No",NumerixSQuant,Vancouver
18,Junior Data Scientist,"Reporting to the Technical Manager, Digital Products, the Junior Data Scientist works as part of a team to analyze structured and unstructured data, model complex problems, and identify opportunities for process and product optimization by using statistical, algorithmic, mining, and visual techniques. This role assists in developing machine learning (ML) predictive and prescriptive analytics models through the innovative understanding and use of large data sets and the verification of effectiveness to improve clinical processes and patient outcomes. The Junior Data Scientist supports Providence Health Care (PHC) strategic priorities by understanding the clinical, financial, and operational issues to be solved and working closely with stakeholders, clinical and technical experts, and functional teams to leverage knowledge, interpret outputs, deploy solutions, and provide actionable insights. The role also assists in developing a solid and sustainable machine learning foundation and competency for PHC.
Skills
Knowledge of supervised machine learning, decision trees, and logistic regression.
Display comprehensive understanding of, and skills using, statistical and data mining techniques such as GLM/Regression, Random Forest, Boosting, Trees, text mining, network analysis, simulation, scenario analysis, and clustering analysis.
Demonstrated ability to perform analytical functions and transform database structures including creating datasets and writing computer code to execute complex queries using statistical computer languages such as Python, R, and SQL.
Demonstrated proficiency working with large volumes of data across multiple servers using distributed data/computing tools such as Hadoop, Spark, MySQL, AWS, etc.
Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).
Demonstrated understanding of data privacy, security and related tools such as anonymization and encryption
Demonstrated ability to use web services such as Redshift, S3, DigitalOcean, etc.
Demonstrated skills in using data visualization tools (such as Jupyter, Matplotlib, D3, ggplot, Periscope, Business Objects) and to visually present complex data to stakeholders for consideration.
Demonstrated skills in knowledge synthesis and translation activities including working with and sorting and manipulating unstructured data from different platforms.
Excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non-technical partners and to communicate to multiple audiences using data storytelling and through graphics.
Demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building.
Strong analytical, critical thinking, and evaluation skills to discern and help solve the important problems facing health care, to identify new ways to leverage our data, and to direct efforts in the right direction.
Education
A Masters’ Degree in Mathematics, Statistics, Computer Science, Engineering or other quantitative degree is required plus three (3) years’ experience working with large datasets and machine learning models including experience using statistical and data mining techniques, and distributed data/computing tools; writing computer code; querying databases; and using statistical computer languages, or an equivalent combination of education, training and experience.
Duties
1. Assists in transforming data into critical information and knowledge by working as part of the digital products team and with clinical management and staff, project/program managers, and members of the health informatics team to develop and implement ML Models. Uses these advanced ML models to identify patterns, trends, and opportunities to assist in making predictions or reducing workload that will have a significant impact across various clinical domains within PHC.

2. Identifies, cleans, and integrates large sets of structured and unstructured datasets from disparate sources for use in ML models and products. Enhances data collection procedures to include information that is relevant for building advanced ML models. Provides input to applications, databases, and systems used to assess study data quality.

3. Works as part of the digital products team to use advanced ML processes to convert data from non-functional forms, such as scanned image text, to functional forms ready for use in further ML models.

4. Assists in developing predictive and prescriptive analytic models in support of the organization’s clinical and business initiatives and priorities by working as part of the digital products team to apply advanced statistical and computational methods and innovative use of data, collaborate with Developers in the construction of analytic models, and maintain detailed project status plans to achieve ML development cycle timelines and avoid development delays.

5. Reviews clinical data at aggregate levels on a regular basis using analytical reporting tools to support the identification of risks and data patterns or trends. Creates analytical reports and presentations to facilitate review and adoption of data-driven choices. Collaborates with project/program teams to address data-related questions and to recommend potential solutions.

6. Works with other members of the digital products team to assist with recommendations to management regarding strategic actions to maintain the ML development pipeline, analytic architectures, and life cycle, to avoid potential negative consequences and system failures, and to increase the positive impacts of ML systems.

7. Works closely with clinical and management teams across PHC to strategize, develop, and implement artificial intelligence (AI) products that translate into improved quality of care, clinical outcomes, reduced costs, temporal efficiencies, and process improvements.

8. Identifies, engages, and collaborates with specific stakeholders as required for the development of AI products designed around PHC’s strategic priorities and clinical/business problems. Assesses and implements improvements to AI products as needed and creates anomaly detection systems to track performance and data accuracy.

9. Assists the digital product team members to communicate analytic solutions to management and shares AI product status throughout the various stages of the product lifecycle.

10. Works with other members of the digital products team to support management in the development of strategies for scaling successful projects across the organization based on feedback from clinical/business clients and end-users by maintaining project and other documentation, reviewing findings, and presenting analysis and actionable insights for further discussion and decision.

11. Assists data scientists in fostering and developing a solid and sustainable machine learning foundation and competency for PHC. Assists management with the dissemination of successes and failures in an effort to increase analytics literacy and adoption across PHC.

12. Keeps up-to-date with the latest technology trends and methods by staying abreast of state-of-the-art literature in the fields of operations research, statistical modeling, statistical process control and mathematical optimization.

13. Performs other related duties as required.","Providence Health Care
4.1",Vancouver
19,Scientifique de recherche en génie environnemental/Environmental Engineering Research Scientist,"English follows:

Scientifique de recherche en génie environnemental

Opportunité d’évoluer au sein d’une organisation mondiale
Milieu de travail innovateur offrant de nombreux défis professionnels
Environnement de développement technologique et d’innovation
Postes basés au Saguenay-Lac-St-Jean

À propos du poste

Nous sommes à la recherche d’un scientifique de recherche en génie environnemental qui participera au développement technologique en Environnement au sein du Centre de Recherche et Développement Arvida (CRDA) de Rio Tinto division Aluminium.

Ce poste constitue une excellente occasion de développer et de proposer des solutions technologiques améliorant les plans d'affaire des différentes usines de Rio Tinto. Vous travaillerez selon un horaire de 5 jours de travail, 2 jours de congé et relèverez du Chef de Programme Environnement, vous aurez les tâches suivantes:

Participer à l’innovation dans le domaine du développement technologique en environnement dans le secteur de l’aluminium
Développer un réseau de contacts et coordonner des travaux avec des partenaires internes et externes
Exécuter des projets de recherche et développement visant la réduction de l’empreinte environnementale de l’industrie de l’aluminium
Exécuter des analyses de données complexes en utilisant des outils modernes des sciences des données
Assurer le leadership technique de plusieurs projets (coordination des travaux avec partenaires externes) et superviser du personnel technique œuvrant en laboratoire
Définir les protocoles expérimentaux en utilisant les meilleures pratiques d'amélioration des affaires, en intégrant les besoins des clients et en assurant le respect des règles de santé, sécurité et environnement

À propos de vous

Pour que votre candidature soit prise en considération, les exigences sont les suivantes :

Baccalauréat/maitrise en génie de l’environnement, ou discipline du génie connexe avec volet environnemental (génie chimique, mécanique, civil, etc.)
Cinq à dix ans d’expérience en milieu industriel, minier ou firme de génie conseil
Expertise en traitement des rejets industriels et miniers atmosphériques, incluant la gestion des gaz à effet de serre
Bonne maîtrise des outils des sciences des données avec volet environnemental
Excellentes aptitudes en relations interpersonnelles, travail d’équipe, communication et leadership d’influence.
Maîtrise complète du français (parlé et écrit)
Maîtrise avancée de l’anglais (parlé et écrit)

Atouts:

Expérience en efficacité énergétique
Connaissance des langages de programmation en sciences des données (R, Python)
Connaissance des outils LEAN et Six Sigma
Connaissance de la gestion de projet Agile
Connaissance des procédés de production de produits d’aluminium

Votre lieu de travail

Le titulaire du poste sera amené à travailler dans la région du Saguenay et pourrait devoir se déplacer occasionnellement au Canada et à l’extérieur du pays

Nous avons toujours su que Rio Tinto offre un milieu de travail formidable, et c’est maintenant officiel ! Récemment, nous avons été nommés parmi les meilleurs employeurs au Canada notamment grâce à nos possibilités de développement et à notre norme mondiale en matière de congé parental.

Nous voulons avant tout offrir un milieu de travail stimulant, où nos employés innovent afin de trouver de meilleures façons de produire les matières qui servent à façonner le monde moderne, des téléphones intelligents jusqu’aux immeubles en passant par les avions et les voitures, et les appareils médicaux électroniques. #meilleursemployeurs.

Ce que nous offrons

Obtenez la reconnaissance de vos contributions, de votre capacité de réflexion et de votre travail acharné, et la satisfaction de savoir que vous avez aidé le monde à progresser.

Environnement de travail au sein duquel la sécurité est toujours la priorité absolue
Occasions de développement de carrière et aide à la formation pour réaliser vos aspirations sur le plan technique et du leadership
Salaire de base concurrentiel établi en fonction de vos compétences et de votre expérience, et programme incitatif annuel
Accès en tout temps à des programmes de santé/médicaux favorables à la famille, et à des régimes de retraite et d’épargne
Régime d’actionnariat intéressant
Congés pour divers motifs (vacances/annuels, congé parental payé, congés de maladie)
Rabais pour les employés

À propos de Rio Tinto

À l’origine de chaque idée, de chaque innovation, de chaque petite chose qu’on appelle « progrès », il y a une personne : un explorateur, un inventeur, un entrepreneur. Un pionnier.

Depuis près de 150 ans, Rio Tinto est une entreprise de pionniers – des générations d’employés audacieux partout dans le monde qui ont en commun la vision de produire des matières essentielles au progrès humain.

Notre minerai de fer façonne la silhouette des villes, de Shanghai à Sydney. Notre aluminium premier métal certifié « responsable » au monde – allège les avions et les voitures. Notre cuivre aide les éoliennes à produire de l’énergie. Notre bore contribue à nourrir le monde et permet d’explorer l’univers. Nos diamants célèbrent les plus beaux moments de la vie.

Chaque voix compte

Nous sommes déterminés à créer un milieu inclusif où les employés se sentent à l’aise d’être eux-mêmes. Nous souhaitons de plus que chacun ait l’impression que sa voix compte, que toutes les cultures sont respectées et que les points de vue, aussi variés soient-ils, sont non seulement bienvenus, mais également essentiels à notre succès. Nous nous traitons mutuellement avec équité et dignité, sans égard à la race, au genre, à la nationalité, à l’origine ethnique, à la religion, à l’âge, à l’orientation sexuelle ou à tout autre aspect distinctif.

Chez Rio Tinto, nous accueillons favorablement et encourageons les candidatures d’Autochtones, de femmes, de membres de la communauté LGBTQ2S+, de travailleurs âgés, de personnes handicapées et de représentants d’origines diverses.

Veuillez noter que vous devez répondre à toutes les questions de présélection pour que votre candidature soit prise en compte.

Environmental Engineering Research Scientist

Opportunity to work for a global organization
Innovative work environment that offers many professional challenges
Technological development and innovation environment
Positions based in Saguenay-Lac-St-Jean

About the role

We are looking for an environmental engineering research scientist who will participate in technological development at the Arvida Research and Development Centre (ARDC) of Rio Tinto Aluminium Division.

This role is an excellent opportunity to develop and propose technological solutions improving the business plans of Rio Tinto’s different plants. You will work on a 5-day work schedule with 2 days off, and will report to the Environment Program Manager. You will have the following duties:

Participating in innovation in the field of environmental technology development in the aluminium sector.
Developing a contact network and coordinating work with internal and external partners.
Conducting research and development projects aiming at reduction of the aluminium industry's environmental footprint.
Performing complex data analyses by using modern data science tools.
Providing technical leadership for several projects (coordinating work with external partners) and supervising technical staff working in the laboratory.
Defining the experimental protocols by using business improvement best practices, integrating the clients’ needs and ensuring that health, safety and environment regulations are respected.

About you

For your candidacy to be considered, the requirements are as follows:

Bachelor’s/Master's degree in Environmental Engineering, or a related engineering discipline with an environmental component (chemical, mechanical, civil engineering, etc.)
Five to ten years’ experience in an industrial or mining environment or an engineering firm.
Expertise in treatment of industrial and mining atmospheric releases, including management of greenhouse gases.
Good proficiency in data science tools with an environmental component.
Excellent interpersonal relations, teamwork and influential leadership skills.
Complete proficiency in French (spoken and written).
Advanced proficiency in English (spoken and written).

Assets:

Experience in energy efficiency
Knowledge of programming languages in data sciences (R, Python)
Knowledge of LEAN and Six Sigma tools
Knowledge of Agile project management
Knowledge of production processes for aluminium products

Where you will be working

The incumbent will be asked to work in the Saguenay region and might have to travel occasionally in Canada and outside the country.

We have always known that Rio Tinto offers a tremendous work environment, and it’s now official! Recently, we were named one of Canada’s best employers, particularly due to our development potential and our global standard for parental leave.

Above all, we wish to offer a stimulating work environment, where our employees innovate to find better ways of producing materials that serve to shape the modern world, from smartphones to buildings, including aircraft, cars and electronic medical devices. #meilleursemployeurs.

What we offer

Be recognized for your contribution, your thinking, and your hard work, and go home knowing you’ve helped the world progress.

A work environment where safety is always the number one priority
Career development & education assistance to further your technical or leadership ambitions
A competitive base salary reflective of your skills and experience with annual incentive program
Ongoing access to family-friendly health and medical programs, pension and savings plans
Attractive share ownership plan
Leave for all of life’s reasons (vacation/annual, paid parental, sick leave)
Exclusive employee discounts

About Rio Tinto

Every idea, every innovation, every little thing the world calls ‘progress’ begins with a first step, and someone willing to take it: explorers, inventors, entrepreneurs. Pioneers.

For nearly 150 years, Rio Tinto has been a company of pioneers – generations of people spanning the globe, all with the grit and vision to produce materials essential to human progress.

Our iron ore has shaped skylines from Shanghai to Sydney. Our aluminium – the world’s first to be certified “responsible” – helps planes fly and makes cars lighter. Our copper helps wind turbines power cities and our boron helps feed the world and explore the universe. Our diamonds help us celebrate the best parts of life.

Every Voice Matters

At Rio Tinto, we particularly welcome and encourage applications from Indigenous Peoples, women, the LGBTQIA2 community, mature workers, people with disabilities and people from different cultural backgrounds.

We are committed to an inclusive environment where people feel comfortable to be themselves. We want our people to feel that all voices are heard, all cultures respected and that a variety of perspectives are not only welcome – they are essential to our success. We treat each other fairly and with dignity regardless of race, gender, nationality, ethnic origin, religion, age, sexual orientation, or anything else that makes us different.

Please note, in order to be successfully considered for this role you must complete all pre-screening questions.","Rio Tinto
4.0",Saguenay
20,Scientifique de recherche en génie environnemental/Environmental Engineering Research Scientist,"English follows:

Scientifique de recherche en génie environnemental

Opportunité d’évoluer au sein d’une organisation mondiale
Milieu de travail innovateur offrant de nombreux défis professionnels
Environnement de développement technologique et d’innovation
Postes basés au Saguenay-Lac-St-Jean

À propos du poste

Nous sommes à la recherche d’un scientifique de recherche en génie environnemental qui participera au développement technologique en Environnement au sein du Centre de Recherche et Développement Arvida (CRDA) de Rio Tinto division Aluminium.

Ce poste constitue une excellente occasion de développer et de proposer des solutions technologiques améliorant les plans d'affaire des différentes usines de Rio Tinto. Vous travaillerez selon un horaire de 5 jours de travail, 2 jours de congé et relèverez du Chef de Programme Environnement, vous aurez les tâches suivantes:

Participer à l’innovation dans le domaine du développement technologique en environnement dans le secteur de l’aluminium
Développer un réseau de contacts et coordonner des travaux avec des partenaires internes et externes
Exécuter des projets de recherche et développement visant la réduction de l’empreinte environnementale de l’industrie de l’aluminium
Exécuter des analyses de données complexes en utilisant des outils modernes des sciences des données
Assurer le leadership technique de plusieurs projets (coordination des travaux avec partenaires externes) et superviser du personnel technique œuvrant en laboratoire
Définir les protocoles expérimentaux en utilisant les meilleures pratiques d'amélioration des affaires, en intégrant les besoins des clients et en assurant le respect des règles de santé, sécurité et environnement

À propos de vous

Pour que votre candidature soit prise en considération, les exigences sont les suivantes :

Baccalauréat/maitrise en génie de l’environnement, ou discipline du génie connexe avec volet environnemental (génie chimique, mécanique, civil, etc.)
Cinq à dix ans d’expérience en milieu industriel, minier ou firme de génie conseil
Expertise en traitement des rejets industriels et miniers atmosphériques, incluant la gestion des gaz à effet de serre
Bonne maîtrise des outils des sciences des données avec volet environnemental
Excellentes aptitudes en relations interpersonnelles, travail d’équipe, communication et leadership d’influence.
Maîtrise complète du français (parlé et écrit)
Maîtrise avancée de l’anglais (parlé et écrit)

Atouts:

Expérience en efficacité énergétique
Connaissance des langages de programmation en sciences des données (R, Python)
Connaissance des outils LEAN et Six Sigma
Connaissance de la gestion de projet Agile
Connaissance des procédés de production de produits d’aluminium

Votre lieu de travail

Le titulaire du poste sera amené à travailler dans la région du Saguenay et pourrait devoir se déplacer occasionnellement au Canada et à l’extérieur du pays

Nous avons toujours su que Rio Tinto offre un milieu de travail formidable, et c’est maintenant officiel ! Récemment, nous avons été nommés parmi les meilleurs employeurs au Canada notamment grâce à nos possibilités de développement et à notre norme mondiale en matière de congé parental.

Nous voulons avant tout offrir un milieu de travail stimulant, où nos employés innovent afin de trouver de meilleures façons de produire les matières qui servent à façonner le monde moderne, des téléphones intelligents jusqu’aux immeubles en passant par les avions et les voitures, et les appareils médicaux électroniques. #meilleursemployeurs.

Ce que nous offrons

Obtenez la reconnaissance de vos contributions, de votre capacité de réflexion et de votre travail acharné, et la satisfaction de savoir que vous avez aidé le monde à progresser.

Environnement de travail au sein duquel la sécurité est toujours la priorité absolue
Occasions de développement de carrière et aide à la formation pour réaliser vos aspirations sur le plan technique et du leadership
Salaire de base concurrentiel établi en fonction de vos compétences et de votre expérience, et programme incitatif annuel
Accès en tout temps à des programmes de santé/médicaux favorables à la famille, et à des régimes de retraite et d’épargne
Régime d’actionnariat intéressant
Congés pour divers motifs (vacances/annuels, congé parental payé, congés de maladie)
Rabais pour les employés

À propos de Rio Tinto

À l’origine de chaque idée, de chaque innovation, de chaque petite chose qu’on appelle « progrès », il y a une personne : un explorateur, un inventeur, un entrepreneur. Un pionnier.

Depuis près de 150 ans, Rio Tinto est une entreprise de pionniers – des générations d’employés audacieux partout dans le monde qui ont en commun la vision de produire des matières essentielles au progrès humain.

Notre minerai de fer façonne la silhouette des villes, de Shanghai à Sydney. Notre aluminium premier métal certifié « responsable » au monde – allège les avions et les voitures. Notre cuivre aide les éoliennes à produire de l’énergie. Notre bore contribue à nourrir le monde et permet d’explorer l’univers. Nos diamants célèbrent les plus beaux moments de la vie.

Chaque voix compte

Nous sommes déterminés à créer un milieu inclusif où les employés se sentent à l’aise d’être eux-mêmes. Nous souhaitons de plus que chacun ait l’impression que sa voix compte, que toutes les cultures sont respectées et que les points de vue, aussi variés soient-ils, sont non seulement bienvenus, mais également essentiels à notre succès. Nous nous traitons mutuellement avec équité et dignité, sans égard à la race, au genre, à la nationalité, à l’origine ethnique, à la religion, à l’âge, à l’orientation sexuelle ou à tout autre aspect distinctif.

Chez Rio Tinto, nous accueillons favorablement et encourageons les candidatures d’Autochtones, de femmes, de membres de la communauté LGBTQ2S+, de travailleurs âgés, de personnes handicapées et de représentants d’origines diverses.

Veuillez noter que vous devez répondre à toutes les questions de présélection pour que votre candidature soit prise en compte.

Environmental Engineering Research Scientist

Opportunity to work for a global organization
Innovative work environment that offers many professional challenges
Technological development and innovation environment
Positions based in Saguenay-Lac-St-Jean

About the role

We are looking for an environmental engineering research scientist who will participate in technological development at the Arvida Research and Development Centre (ARDC) of Rio Tinto Aluminium Division.

This role is an excellent opportunity to develop and propose technological solutions improving the business plans of Rio Tinto’s different plants. You will work on a 5-day work schedule with 2 days off, and will report to the Environment Program Manager. You will have the following duties:

Participating in innovation in the field of environmental technology development in the aluminium sector.
Developing a contact network and coordinating work with internal and external partners.
Conducting research and development projects aiming at reduction of the aluminium industry's environmental footprint.
Performing complex data analyses by using modern data science tools.
Providing technical leadership for several projects (coordinating work with external partners) and supervising technical staff working in the laboratory.
Defining the experimental protocols by using business improvement best practices, integrating the clients’ needs and ensuring that health, safety and environment regulations are respected.

About you

For your candidacy to be considered, the requirements are as follows:

Bachelor’s/Master's degree in Environmental Engineering, or a related engineering discipline with an environmental component (chemical, mechanical, civil engineering, etc.)
Five to ten years’ experience in an industrial or mining environment or an engineering firm.
Expertise in treatment of industrial and mining atmospheric releases, including management of greenhouse gases.
Good proficiency in data science tools with an environmental component.
Excellent interpersonal relations, teamwork and influential leadership skills.
Complete proficiency in French (spoken and written).
Advanced proficiency in English (spoken and written).

Assets:

Experience in energy efficiency
Knowledge of programming languages in data sciences (R, Python)
Knowledge of LEAN and Six Sigma tools
Knowledge of Agile project management
Knowledge of production processes for aluminium products

Where you will be working

The incumbent will be asked to work in the Saguenay region and might have to travel occasionally in Canada and outside the country.

We have always known that Rio Tinto offers a tremendous work environment, and it’s now official! Recently, we were named one of Canada’s best employers, particularly due to our development potential and our global standard for parental leave.

Above all, we wish to offer a stimulating work environment, where our employees innovate to find better ways of producing materials that serve to shape the modern world, from smartphones to buildings, including aircraft, cars and electronic medical devices. #meilleursemployeurs.

What we offer

Be recognized for your contribution, your thinking, and your hard work, and go home knowing you’ve helped the world progress.

A work environment where safety is always the number one priority
Career development & education assistance to further your technical or leadership ambitions
A competitive base salary reflective of your skills and experience with annual incentive program
Ongoing access to family-friendly health and medical programs, pension and savings plans
Attractive share ownership plan
Leave for all of life’s reasons (vacation/annual, paid parental, sick leave)
Exclusive employee discounts

About Rio Tinto

Every idea, every innovation, every little thing the world calls ‘progress’ begins with a first step, and someone willing to take it: explorers, inventors, entrepreneurs. Pioneers.

For nearly 150 years, Rio Tinto has been a company of pioneers – generations of people spanning the globe, all with the grit and vision to produce materials essential to human progress.

Our iron ore has shaped skylines from Shanghai to Sydney. Our aluminium – the world’s first to be certified “responsible” – helps planes fly and makes cars lighter. Our copper helps wind turbines power cities and our boron helps feed the world and explore the universe. Our diamonds help us celebrate the best parts of life.

Every Voice Matters

At Rio Tinto, we particularly welcome and encourage applications from Indigenous Peoples, women, the LGBTQIA2 community, mature workers, people with disabilities and people from different cultural backgrounds.

We are committed to an inclusive environment where people feel comfortable to be themselves. We want our people to feel that all voices are heard, all cultures respected and that a variety of perspectives are not only welcome – they are essential to our success. We treat each other fairly and with dignity regardless of race, gender, nationality, ethnic origin, religion, age, sexual orientation, or anything else that makes us different.

Please note, in order to be successfully considered for this role you must complete all pre-screening questions.","Rio Tinto
4.0",Saguenay
21,"Scientist, Chemical Sciences","Paraza Pharma, Inc. is a fast-growing pharmaceutical research company offering a dynamic and collaborative work environment where scientific excellence, innovation and creativity are at the forefront. Here, diversity, new points of view and a creative spirit are valued and considered as real assets. We provide our employees with ongoing support, training and development opportunities to expand their horizons while contributing to our shared passion for Drug Discovery.

The Medicinal Chemistry and Chemical Development groups at Paraza are seeking energetic, results-oriented individuals with proven track records of success to join our dynamic teams. The successful candidate is expected to have extensive experience in modern organic synthesis. In addition, we are looking for individuals with abilities to analyze complex data sets, demonstrate sound decision-making and analytical skills and able to provide creative proposals and solutions to advance on-going projects. The candidate will be expected to work independently within a team structure, design and execute synthetic routes and troubleshoot when needed. The key responsibilities of the successful candidates include the following:

Design and synthesis of novel target molecules as part of a medicinal chemistry team
Collection, analysis and interpretation of data sets. Proposal of follow-up experiments based on data trends
Troubleshoot and optimize reaction sequences
Participation in multidisciplinary team meetings
Prepare summary documents and presentations to chemistry and project teams

Minimum Qualifications

PhD in Organic, Bioorganic or Medicinal Chemistry, with 0-2 years of post-doctoral experience

Preferred Qualifications

Comprehensive and up-to-date knowledge of synthetic organic chemistry
Demonstrated laboratory proficiency
Experience with the operation of standard laboratory instrumentation (e.g. NMR, MS, automated chromatography), and data analysis
Able to work within a team structure and effectively communicate with colleagues at all levels
Proven research track record as evidenced by a strong publication and/or patent record
Entrepreneurial spirit, and constantly seeking creative solutions to challenging problems
Excellent oral and written communication skills

Job Types: Full-time, Permanent

Benefits:

Casual dress
Company pension
Dental care
Disability insurance
Employee assistance program
Extended health care
Life insurance
On-site parking
RRSP match
Stock options
Vision care

Schedule:

Day shift
Monday to Friday

Work remotely:

No

COVID-19 precaution(s):

Remote interview process
Personal protective equipment provided or required
Social distancing guidelines in place
Sanitizing, disinfecting, or cleaning procedures in place","Paraza Pharma, Inc.
4.7",Saint-Laurent
22,"Associate Scientist, Chemical Sciences","Paraza Pharma, Inc. is a fast-growing pharmaceutical research company offering a dynamic and collaborative work environment where scientific excellence, innovation and creativity are at the forefront. Here, diversity, new points of view and a creative spirit are valued and considered as real assets. We provide our employees with ongoing support, training and development opportunities to expand their horizons while contributing to our shared passion for Drug Discovery.

The Medicinal Chemistry and Chemical Development groups at Paraza are seeking energetic, results-oriented individuals with proven track records of success to join our dynamic teams. The successful candidate is expected to have experience in modern organic synthesis with good laboratory skills and high productivity. The candidate will be expected to work independently within a team structure, design and execute synthetic routes and troubleshoot when needed. The key responsibilities of the successful candidate include the following:

· Synthesis of target molecules as part of a medicinal chemistry team

· Troubleshoot and optimize reaction sequences

· Participation in medicinal chemistry team meetings

· Presentation of results to chemistry and project teams

Minimum Qualifications

· MSc in Organic, Bioorganic or Medicinal Chemistry

Preferred Qualifications

· Comprehensive knowledge of modern synthetic organic chemistry

· Demonstrated laboratory proficiency

· In-depth knowledge and hands-on experience with a range of standard laboratory instrumentation, purification techniques (e.g. NMR, MS, automated chromatography), and data analysis

· Proven research track record as evidenced by a strong publication and/or patent record

· Excellent oral and written communication skills

Job Types: Full-time, Permanent

Benefits:

Assurance Dentaire
Assurance Invalidité
Assurance Maladie Complémentaire
Assurance Vie
Assurance Vision
Options d'Achats d'Actions
Programme d'Aide aux Employés
REER Collectif
Stationnement sur place

Schedule:

Du Lundi au Vendredi
Quart de jour

Work remotely:

No

COVID-19 precaution(s):

Remote interview process
Personal protective equipment provided or required
Social distancing guidelines in place
Sanitizing, disinfecting, or cleaning procedures in place","Paraza Pharma, Inc.
4.7",Saint-Laurent
23,Data Scientist,"Reporting to the Technical Manager, Digital Products, the Data Scientist analyzes structured and unstructured data, models complex problems, and identifies opportunities for process and product optimization by using statistical, algorithmic, mining, and visual techniques. This role develops machine learning (ML) predictive and prescriptive analytics models through the innovative understanding and use of large data sets and the verification of effectiveness to improve clinical processes and patient outcomes. The Data Scientist supports Providence Health Care (PHC) strategic priorities by understanding the clinical, financial, and operational issues to be solved and working closely with stakeholders, clinical and technical experts, and functional teams to leverage knowledge, interpret outputs, deploy solutions, and provide actionable insights. The role also serves a key role in developing a solid and sustainable machine learning foundation and competency for PHC.
Skills
Thorough knowledge of the principles, processes, procedures, and methods involved in data mining, data analysis, statistical methods, and machine learning.
Demonstrated skills in AI product design and the analysis of quantitative data for the purpose of creating actionable insights and measureable impact on organizational outcomes.
Proven ability to plan, organize, and coordinate AI product activities.
Demonstrated proficiency using machine learning methods and techniques (including neural networks, reinforcement learning, and adversarial learning) and machine learning software packages, and in manipulating large datasets.
Knowledge of supervised machine learning, decision trees, and logistic regression.
Display comprehensive understanding of, and skills using, statistical and data mining techniques such as GLM/Regression, Random Forest, Boosting, Trees, text mining, network analysis, simulation, scenario analysis, and clustering analysis.
Demonstrated ability to perform analytical functions and transform database structures including creating datasets and writing computer code to execute complex queries using statistical computer languages such as Python, R, and SQL.
Demonstrated proficiency working with large volumes of data across multiple servers using distributed data/computing tools such as Hadoop, Spark, MySQL, AWS, etc.
Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).
Demonstrated understanding of data privacy, security and related tools such as anonymization and encryption
Demonstrated ability to use web services such as Redshift, S3, DigitalOcean, etc.
Demonstrated skills in using data visualization tools (such as Jupyter, Matplotlib, D3, ggplot, Periscope, Business Objects) and to visually present complex data to stakeholders for consideration.
Demonstrated skills in knowledge synthesis and translation activities including working with and sorting and manipulating unstructured data from different platforms.
Excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non-technical partners and to communicate to multiple audiences using data storytelling and through graphics.
Demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building.
Strong analytical, critical thinking, and evaluation skills to discern and help solve the important problems facing health care, to identify new ways to leverage our data, and to direct efforts in the right direction.

Education
A Masters’ Degree in Mathematics, Statistics, Computer Science, Engineering or other quantitative degree is required plus five (5) to seven (7) years’ experience working with large datasets and machine learning models including experience using statistical and data mining techniques, and distributed data/computing tools; writing computer code; querying databases; and using statistical computer languages.
Duties
1. Transforms data into critical information and knowledge by working with clinical management and staff, project/program managers, and members of the health informatics team to develop and implement ML Models. Uses these advanced ML models to identify patterns, trends, and opportunities to make predictions or reduce workload that will have a significant impact across various clinical domains within PHC.

2. Identifies, cleans, and integrates large sets of structured and unstructured datasets from disparate sources for use in ML models and products. Enhances data collection procedures to include information that is relevant for building advanced ML models. Provides input to applications, databases, and systems used to assess study data quality.

3. Uses advanced ML processes to convert data from non-functional forms, such as scanned image text, to functional forms ready for use in further ML models.

4. Develops predictive and prescriptive analytic models in support of the organization’s clinical and business initiatives and priorities by applying advanced statistical and computational methods and innovative use of data, collaborating with and guiding Developers in the construction of analytic models, and maintaining detailed project status plans to achieve ML development cycle timelines and avoid development delays.

5. Reviews clinical data at aggregate levels on a regular basis using analytical reporting tools to support the identification of risks and data patterns or trends. Creates analytical reports and presentations to facilitate review and adoption of data-driven choices. Collaborates with project/program teams to address data-related questions and to recommend potential solutions.

6. Makes recommendations to management regarding strategic actions to maintain the ML development pipeline, analytic architectures, and life cycle, to avoid potential negative consequences and system failures, and to increase the positive impacts of ML systems.

7. Works closely with clinical and management teams across PHC to strategize, develop, and implement artificial intelligence (AI) products that translate into improved quality of care, clinical outcomes, reduced costs, temporal efficiencies, and process improvements.

8. Identifies, engages, and collaborates with specific stakeholders as required for the development of AI products designed around PHC’s strategic priorities and clinical/business problems. Assesses and implements improvements to AI products as needed and creates anomaly detection systems to track performance and data accuracy.

9. Communicates analytic solutions to management and shares AI product status throughout the various stages of the product lifecycle.

10. Supports management in the development of strategies for scaling successful projects across the organization based on feedback from clinical/business clients and end-users by maintaining project and other documentation, reviewing findings, and presenting analysis and actionable insights for further discussion and decision.

11. Works to foster and develop a solid and sustainable machine learning foundation and competency for PHC. Assists management with the dissemination of successes and failures in an effort to increase analytics literacy and adoption across PHC.

12. Keeps up-to-date with the latest technology trends and methods by staying abreast of state-of-the-art literature in the fields of operations research, statistical modeling, statistical process control and mathematical optimization.

13. Performs other related duties as required.","Providence Health Care
4.1",Vancouver
24,Data Scientist,"Spare is looking for a Data Scientist to join the growing Data Science team!
If you love numbers, and you love making a change, this could well be the job for you.

Think of the Data Science team as a ‘startup within a startup’: it questions assumptions, explores alternative solutions, and keeps Spare on the cutting edge.

You’ll be working with a talented and motivated team that puts mobility data to good use, making a positive impact on lives across the globe.

*
Location: this person can be based anywhere on the east side of Canada*

*
✨What you’ll do* ✨

Insightful analytics: Delve into Spare’s huge databases to improve our operations, and those of our customers.
Predictive modelling: Build and deploy cutting-edge models to optimize customer experiences, boost revenue generation and inform strategic business decisions.
Product development: Work closely with product and engineering teams, such as the Spare Realize and Spare Analyze teams, to integrate data more effectively in their products, and to create a delightful user experience.
Professional services: Work closely with Spare’s Growth team to deliver high quality consultancy-style reports advising customers on how to design optimal transportation services.
Planning and simulations: Work closely with Spare’s Partner Success team to run transportation simulations using our in-house transit planning tools.
Communication: Present your research and analysis internally and externally, to help your colleagues and customers to identify opportunities for growth or improvement.
Exploration: Research and discover new methods to acquire meaningful data, and new applications for existing data.
Innovation: Change the world of transportation, one day at a time!

*
✨You’re right for this role because you...✨*

Have proven experience in data science – interpret that how you will!
Have experience using different languages (R, Python, SQL) to manipulate large amounts of data and draw valuable insights. You can also identify what ‘valuable’ means to different groups of people.
Have some technical expertise regarding data models and/or database design development.
Have a Bachelor’s degree (at least) where you used maths/statistics as a key part of your work.
Can compellingly visualize and communicate your insights to a variety of stakeholders, from colleagues to customers to CEOs.
Have a solution-seeking attitude, and a critical eye for detail.
Love learning, and helping others to learn too.
Thrive in a fast-paced, highly collaborative work environment with a flat organizational structure.
Are interested in helping us create value for communities through our products, and want to make a global impact.

✨What we're doing @ Spare ✨
Spare is a SaaS platform that enables anyone to launch a smart transportation service. Our mission is to empower cities to transform how their communities move with accessible, sustainable transportation networks, starting with on-demand transit!

We believe in creating a space for everyone to share their ideas, empowering creativity and continuous learning. We're still at the beginning of our story, and every team member has a key role in shaping the upcoming chapters and Spare's direction. You will be able to influence your career progression and generate a lasting impact by making headway on the cause for shared mobility.

Not a mobility geek? Take a moment to think about why you chose to live where you do, how easy it is for you to move around, and what makes a city livable. Mobility is paramount in every aspect of our lives, but not everyone has equal and easy access to public transit. Let's change it together!

*
✨About Our Team ✨*
We strive to build a diverse company full of inclusive, fun, hard-working people who treat their colleagues exceptionally well. We look for the kind of people who are dedicated to going above and beyond and will build up the team as a whole by helping each team member achieve their own individual goals.

Spare is for the creative, the personal, the passionate, the uncompromising, and those who want to truly understand the impact transportation has on daily life. We’re still at the beginning of our story, and every team member has a key role in where we are headed.

*
✨What we offer ✨*
A passionate, dedicated team, focused on innovation and building a world-class platform.

The opportunity to make an impact on communities around the world. Add an aspect of social good into your day!

We offer competitive salaries, equity, and a comprehensive benefits package including health, dental, and paramedical coverage, as well as an Employee and Family Assistance Program to support the wellbeing of you and your family (equivalent to 12 hours of counselling annually, as well as financial and caregiver support).

Health, wellness and education support through our $500 Lifestyle Spending policy. Take a course or buy a kayak - it's on us!

Completely remote-optional work environment and beautiful downtown Vancouver office space if/when you prefer to be in the office.

An inclusive environment, where we focus every day on our people and the people in communities around us.

Check out our Hiring Process blog post to learn about what to expect next!

_
Spare Labs is an equal opportunity employer. All applicants will be considered for employment without attention to race, colour, religion, sex, sexual orientation, gender identity, national origin, or disability status._

Job Type: Full-time","Spare Labs
4.9",Midtown Toronto
25,Research Scientist,"Research Scientist, Health Economics and Outcomes Research (HEOR)

We are an independent consultancy in Vancouver British Columbia, specializing in epidemiology and health economics, with a particular focus on creating customized solutions to best meet our clients’ diverse needs. Our team comprises epidemiologists, health economists, statisticians, and IT specialists. Our projects are led by senior team members with extensive experience across a wide range of HEOR studies. We have an extensive network of external academic and clinical experts who collaborate on studies that lie within their core areas of expertise. We are looking to hire an experienced research scientist to support a wide variety of health economic and epidemiologic research projects.

The position is a full-time six-month contract with the potential for extension to a full-time permanent position.

Responsibilities include:

Leading design, protocol development, implementation and interpretation of retrospective observational studies and systematic reviews
For prospective observational or chart review studies, coordinating, managing, and developing
Study protocols for patient data collection
Ethics application submissions
Data collection materials (surveys, chart review forms, etc)
Managing sites, and/or data collection activities with general public or patient study participants
Conducting statistical analyses
Managing large datasets
Mentoring junior team members
Scientific writing
Client communications

Education:

MSc or PhD in Epidemiology, Health Economics, Statistics, Biostatistics, or Public Health, or equivalent experience

Experience:

3-5 years of health research experience in a consultancy or academic work environment
Experience with at least one of observational studies, economic models, or systematic reviews
Managerial, leadership and project management skills - Excellent oral and written communication
Strong independent working skills
Organizational, multi-tasking and problem solving skills, with the ability to work independently within a team environment as well as the ability to work under pressure to meet deadlines
Proficiency with Microsoft Outlook, Excel, Word, PowerPoint is required; familiarity with a statistical or data visualization package would be an advantage.

Contract length: 6 months

Job Types: Full-time, Contract

Benefits:

Casual dress
Work from home

Schedule:

8 hour shift

Work remotely:

Temporarily due to COVID-19",Broadstreet Health Economics and Outcomes Research,Vancouver
26,Research Scientist,"Research Scientist, Health Economics and Outcomes Research (HEOR)

We are an independent consultancy in Vancouver British Columbia, specializing in epidemiology and health economics, with a particular focus on creating customized solutions to best meet our clients’ diverse needs. Our team comprises epidemiologists, health economists, statisticians, and IT specialists. Our projects are led by senior team members with extensive experience across a wide range of HEOR studies. We have an extensive network of external academic and clinical experts who collaborate on studies that lie within their core areas of expertise. We are looking to hire an experienced research scientist to support a wide variety of health economic and epidemiologic research projects.

The position is a full-time six-month contract with the potential for extension to a full-time permanent position.

Responsibilities include:

Leading design, protocol development, implementation and interpretation of retrospective observational studies and systematic reviews
For prospective observational or chart review studies, coordinating, managing, and developing
Study protocols for patient data collection
Ethics application submissions
Data collection materials (surveys, chart review forms, etc)
Managing sites, and/or data collection activities with general public or patient study participants
Conducting statistical analyses
Managing large datasets
Mentoring junior team members
Scientific writing
Client communications

Education:

MSc or PhD in Epidemiology, Health Economics, Statistics, Biostatistics, or Public Health, or equivalent experience

Experience:

3-5 years of health research experience in a consultancy or academic work environment
Experience with at least one of observational studies, economic models, or systematic reviews
Managerial, leadership and project management skills - Excellent oral and written communication
Strong independent working skills
Organizational, multi-tasking and problem solving skills, with the ability to work independently within a team environment as well as the ability to work under pressure to meet deadlines
Proficiency with Microsoft Outlook, Excel, Word, PowerPoint is required; familiarity with a statistical or data visualization package would be an advantage.

Contract length: 6 months

Job Types: Full-time, Contract

Benefits:

Casual dress
Work from home

Schedule:

8 hour shift

Work remotely:

Temporarily due to COVID-19",Broadstreet Health Economics and Outcomes Research,Vancouver
27,Data Scientist,"Our research team’s core mission is protecting Microsoft 365 users across devices, identities, applications, and data via cross-category, tightly integrated threat protection for sec ops and sec-admins. If you believe that cyber-attacks can happen without ever dropping an executable on disk and that a forward rule and a token can do more damage than Powershell, this role may be for you!

Protecting M365 users is a big challenge, but with the signals we have built today in Microsoft Defender for Office 365 and Microsoft Cloud App Security, we are the best equipped company in the world to realize this opportunity and fundamentally change the security world, both for our customers and for attackers.

While each of the individual Microsoft Defender security products provide best in class protection across endpoints and cloud, combining all of these optics and protection capabilities brings the complete attacker behavior into focus like never before, allowing innovative new detection and response approaches across the entire attack graph and providing SOCs unparalleled scale, reduced time-to-investigate, and reduced time-to-remediate across their digital estate. To help design our single federated protection solution spanning all M365 cloud security products, we are seeking a Senior Data Scientist with AI skills, security knowledge, and a growth mindset. We want your help innovating and designing our solution across Microsoft 365’s security portfolio.
Responsibilities
Partner with geographically distributed product teams and security researchers to identify, understand, and address security challenges across devices, identities, applications, and data assets.
Formulate and build data processing pipelines to fuel data-driven research (e.g., statistics, machine learning, & data mining) and create new innovations across Microsoft 365’s broad security signals.
Partner closely with fellow practitioners to iteratively refine systems as research evolves.
Deliver reusable components to research and product teams by communicating to a variety of stakeholders through documentation and presentation.
Facilitate tech transfer by partnering with product teams to deliver new product capabilities.
Contribute to active engagement with the security ecosystem through papers, presentations, blogs, and/or external collaborations.
Invest in your growth as a security practitioner by actively seeking new knowledge from the data, from your colleagues, and from external communities
Qualifications
Required Qualifications:
5+ years of data engineering experience with a background in fueling rigorous data-driven inference methods (such as statistics, machine learning, and sound experimental design).
2+ years of cyber security experience with a background in modern risk matrices (e.g., MITRE ATT&CK) and emerging enterprise threats (including insider risk and attacks against Azure/AWS and cloud services such as O365, Exchange, and Azure AD).
BS or equivalent experience in computer science, engineering, or information technology.
Excellent programming skills (e.g., C#) and proficient at working with and manipulating large data sets (i.e., billions of events per day), using modern big-data systems (e.g., Azure storage/compute), and interfacing with scientific tools (e.g., Python, Spark/Scala, or Azure ML).
Excellent cross-group and interpersonal skills, with the ability to articulate the business need for product improvements.
Preferred Qualifications:
Cyber security experience with a background in modern risk matrices (e.g., MITRE ATT&CK) and emerging enterprise threats (including insider risk and attacks against Azure/AWS and cloud services such as O365, Exchange, and Azure AD)
Industry recognized author of security research papers, blogs, presentations, or books.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
28,Data Scientist,"Our research team’s core mission is protecting Microsoft 365 users across devices, identities, applications, and data via cross-category, tightly integrated threat protection for sec ops and sec-admins. If you believe that cyber-attacks can happen without ever dropping an executable on disk and that a forward rule and a token can do more damage than Powershell, this role may be for you!

Protecting M365 users is a big challenge, but with the signals we have built today in Microsoft Defender for Office 365 and Microsoft Cloud App Security, we are the best equipped company in the world to realize this opportunity and fundamentally change the security world, both for our customers and for attackers.

While each of the individual Microsoft Defender security products provide best in class protection across endpoints and cloud, combining all of these optics and protection capabilities brings the complete attacker behavior into focus like never before, allowing innovative new detection and response approaches across the entire attack graph and providing SOCs unparalleled scale, reduced time-to-investigate, and reduced time-to-remediate across their digital estate. To help design our single federated protection solution spanning all M365 cloud security products, we are seeking a Senior Data Scientist with AI skills, security knowledge, and a growth mindset. We want your help innovating and designing our solution across Microsoft 365’s security portfolio.
Responsibilities
Partner with geographically distributed product teams and security researchers to identify, understand, and address security challenges across devices, identities, applications, and data assets.
Formulate and build data processing pipelines to fuel data-driven research (e.g., statistics, machine learning, & data mining) and create new innovations across Microsoft 365’s broad security signals.
Partner closely with fellow practitioners to iteratively refine systems as research evolves.
Deliver reusable components to research and product teams by communicating to a variety of stakeholders through documentation and presentation.
Facilitate tech transfer by partnering with product teams to deliver new product capabilities.
Contribute to active engagement with the security ecosystem through papers, presentations, blogs, and/or external collaborations.
Invest in your growth as a security practitioner by actively seeking new knowledge from the data, from your colleagues, and from external communities
Qualifications
Required Qualifications:
5+ years of data engineering experience with a background in fueling rigorous data-driven inference methods (such as statistics, machine learning, and sound experimental design).
2+ years of cyber security experience with a background in modern risk matrices (e.g., MITRE ATT&CK) and emerging enterprise threats (including insider risk and attacks against Azure/AWS and cloud services such as O365, Exchange, and Azure AD).
BS or equivalent experience in computer science, engineering, or information technology.
Excellent programming skills (e.g., C#) and proficient at working with and manipulating large data sets (i.e., billions of events per day), using modern big-data systems (e.g., Azure storage/compute), and interfacing with scientific tools (e.g., Python, Spark/Scala, or Azure ML).
Excellent cross-group and interpersonal skills, with the ability to articulate the business need for product improvements.
Preferred Qualifications:
Cyber security experience with a background in modern risk matrices (e.g., MITRE ATT&CK) and emerging enterprise threats (including insider risk and attacks against Azure/AWS and cloud services such as O365, Exchange, and Azure AD)
Industry recognized author of security research papers, blogs, presentations, or books.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
29,Data & Applied Scientist,"Are you an applied scientist interested in understanding what happens on the web and making it better? Join the Content Services team!
Our projects range from website understanding to improving the shopping experience on the web. For example, a project called Clarity harnesses the power of big data to enable millions of website creators and owners to see what their customers experience is like and give them powerful insight that show where, how and why to improve those experiences. We also work on making the web better for everyone with work like Edge Shopping that making buying things faster, easier and cheaper.
At the foundation of work is data about the user experience: We capture signals about each user’s web experiences across many hundreds of thousands of sites and analyze billions of experiences each day. From that wealth of data, we unlock insights about experience challenges and opportunities Our data is extremely rich, complex and big at a scale you will find in few other places.
Your work affects millions of users each day in Microsoft products. Our challenges span many areas in AI—from behavioral classification, recommendation systems, to summarization. We use ideas from a wide range of areas (NLP, DL, statistics, distributed AI, predictive, interpretable ML, etc.). Over the course of several months you might work on problem ranging from detecting automated user agents to figuring out which coupons will work best on a website.
We are a diverse team of data scientists, designers and engineers who excel at their craft, are passionate about their work, and have fun while doing it. As strong believers in open source, we contribute back via projects like github.com/Microsoft/clarity.
Want to use state-of-the-art ideas on extremely rich large-scale data? Want to work on a newly formed team that runs like a startup and is growing rapidly? Come join us!
Responsibilities
As an ML-focused applied scientist you will:
Own data science work from beginning to end: from understanding business requirements, data discovery and extraction, to model development and evaluation.
Use state-of-the-art approaches in ML and data science to large-scale experience and behavior to deliver high impact product features.
Optimize your models for large-scale production deployment with stringent performance requirements.
Be comfortable solving problems in domains where figuring out the right problems to solve is key to your success and impact.
Bring an open mind, a can-do attribute, and collaborative mindset to each day at work.
Qualifications
Required
Bachelor’s degree in a related field focusing on machine learning and AI.
Demonstrated ability to deliver ML/AI solutions in a product setting.
Preferred
3+ years of relevant work experience
Masters/PhD degree in a related field focusing on machine learning and applied AI.
Experience applying ML and AI techniques to large-scale behavioral data.
Be a strong communicator able work with both internal (data science, design, engineering, researchers) and external (our customers) stakeholders

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

#MachineLearning# #ContentServices# #webXT#","Microsoft
4.4",Vancouver
30,Data Scientist,"At Canada Drives, we believe the experience of buying a vehicle should be easy and satisfying. Since 2010, we have used technology to simplify the process of finding the right vehicle for any Canadian of all financial circumstances. Through our online application process today we connect nearly half a million Canadians per year with dealerships across Canada.




For our next decade, we are excited to launch 100% online vehicle purchasing, with wide selection, great deals, and with speedy at-home delivery. Our vision is that buying and financing a vehicle will be fair, fast, simple and seamless.




We are excited to be offering this role and we want you to join our expanding team!




What You’ll Be Doing:




We have available positions for curious, motivated analytical experts to bring the power of data-driven insights to the automotive retail and consumer finance customer experience. Your work will impact potentially millions of Canadians, helping match customers with the perfect vehicle, at the right price and with the best financing. As a Data Scientist, you will have the opportunity to apply a range of methods and tools from machine learning, statistics, data analysis, operations research and modern programming to a range of use cases across the automotive retail experience. You will be a trusted resource inside Canada Drives, providing insights, reports and sharing the data story.




We are seeking someone who will thrive and be a champion of our culture of learning, entrepreneurship, and shared accountability. We have a unique opportunity to grow our data team from the ground up, taking advantage of an industry-leading data access to transform the retail automotive experience for Canadians.




NOTE – This is a full time permanent position, eligible for remote/work-from-home position and is open to all applicants from across Canada who are legally entitled to work in Canada. Preference will be for candidates with proximity to Vancouver.




What You Should Already Have:

A Bachelor’s degree in a quantitative field, such as Engineering, Computer Science, Economics, Mathematics or a similar technical discipline.
2+ years experience in applying analytics, data engineering or data science
Proficiency in working with SQL, Python and/or R across large data sets
Proficiency in using modern data visualization tools, such as Tableau, PowerBI or similar
Confident communication skills and a willingness to seek our needs and find answers
The ability think think critically about complex problems, challenge assumptions and implement creative solutions



What Would Be Nice To Have:

A Master's degree or higher, focused in data science, analytics or software engineering
Experience applying data science in the eCommerce, logistics, digital marketing or consumer finance domains
Familiarity with related disciplines such as project management, user experience design, software development and digital marketing
Experience in establishing data technology foundations for agile business intelligence, data lakes and data workbenches, and applied machine learning/AI
Experience with large-scale data analysis technologies (e.g. Relational and NoSQL data stores, Spark framework, and cloud development in the AWS Ecosystem)
Experience working with Salesforce data models and with applications across the Salesforce Ecosystem
Specializations and applied experience in the following areas:
Pricing Analysis and Appraisal
Customer Segmentation and Intent Modeling
Marketing Attribution and Targeting
Logistics Simulation and Optimization
Recommendation Engines
Funnel Analysis and Site Flow Optimization
Consumer Credit and Risk Modeling","Canada Drives
4.0",Vancouver
31,Data Scientist,"ABOUT MOBSQUAD

We are a well-funded, hyper-growth, scale-up looking for an experienced Data Scientist. If you've ever dreamed of working with a top tier technology company scale-up, on leading edge technologies, backed by the very best venture capitalists in the world, then this is your chance.

Some details about MobSquad:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling its clients to quickly have a turnkey ""virtual"" Canadian subsidiary. MobSquad ensures technology professionals with US work visa challenges remain working with their current company, but nearshore from Canada. This is accomplished via MobSquad's unique partnership with the Canadian Government, enabling work visas to be issued for technology professionals and their respective families within four to six weeks, and Canadian permanent residency within six to eight months. Additionally, MobSquad has unfettered access to top-tier global technology talent which it relocates to Canada and pairs with American as well as Canadian clients on an exclusive, long-term basis, helping firms not only retain their existing world-class technology talent base, but grow it substantially.

We're a Certified B corporation, and have made numerous contributions to charitable organizations, as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition.

For our workplace culture, we were recognized as the 3rd best place to work in Canada (for a small company) in 2020, as well as recognized specifically for being one of the best workplaces nationally for: inclusion; mental wellness; giving back; youth; and technology. We were also recognized as one of the best start-ups to work for across Canada.

For our innovative business model, we have been featured in numerous media outlets including: Asian Pacific Post; BetaKit; Bloomberg; CBC; Global News; Gothamist; International Business Times; MIT Technology Review; Nearshore Americas; Nikkei Asian Review; NPR; The Economic Times of India; The Financial Times; The Globe and Mail; The Information; The New York Times; and The Washington Post.

Harvard Business School published a case study on MobSquad last fall, and Harvard Business Review featured us multiple times in an article that appeared on the cover of their November/December 2020 edition.

You can learn more about us on our website.

ABOUT THE ROLE

As a Data Scientist, you will be part of a Canada-based team working remotely with a leading US scale-up. Your team will operate alongside many other talented developers and data scientists in Canada, and you will be an integral part of the tech community that MobSquad has built.

This role requires someone who has demonstrated an ability to bridge the gap between the theoretical and the practical. The ideal candidate has deployed or attempted to execute Artificial Intelligence theories from various Machine Learning (ML) models and algorithms. MobSquad is looking for proven researchers with a track record of publishing in impactful journals and conferences, or those with years of hands-on industry experience.

This role offers the opportunity to apply your knowledge of statistics and your analytical skills to mine data at scale and develop large-scale ML models to reveal the value in data. You will support feature prototyping and utilize best practices to write production-grade code. You will build data pipelines, implement ML-based analytical algorithms, and work closely with the software development team to set up back-end systems and interfaces that will deliver next-generation analytics.

ABOUT YOU

You have an advanced degree (M.S. or PhD) in Data Science, Computer Science, Engineering, or a comparable analytical field from an accredited institution
You are expert in data mining, machine learning, deep learning, statistical modeling, and data visualization techniques using data-oriented tools and languages such as Python, R, and MATLAB
You have over three years of experience or demonstrated fluency in relevant programming languages (Python, R, Scala, Java, C/C++, C#)
You have over three years of experience working with SQL (MySQL, SQL Server) as well as NoSQL (Cassandra, Hbase) databases
You have experience setting up and using large-scale distributed data-processing frameworks such as Apache Spark and Hadoop MapReduce
You have experience working with enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services, or Google Cloud
You have demonstrated ability to develop high-quality code adhering to industry best practices (e.g., code review, unit testing, revision control)
You are familiar with designing experiments and collecting data for the purpose of deriving data analytics insights and solutions
You have experiencing creating and deploying recommendation and/or predictive models
You have work/project history reflective of a self-motivated professional who excels when given open-ended problems and broadly-defined goals, having an innate desire to discover the patterns and relationships in data that can be leveraged to provide business value

WHAT YOU'LL GET @MOBSQUAD

A full-time position that offers competitive compensation
A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings)
A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit
For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years

At MobSquad, we support and encourage building a work environment that is diverse, inclusive, and safe for all. We invite and welcome applicants of all backgrounds, regardless of race, religion, sexual orientation, gender identity, national origin, or disability.","MobSquad
4.1",Calgary
32,Data Scientist I,"TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us.

Department Overview

What does TD stand for? For starters, we believe in visionary leadership and insights. We believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data.

As part of our Data and Analytics team, you'll be a fundamental part of crafting business processes enterprise-wide by analyzing vast amounts of past and present data.

TD's vision for the future? Tailored, customized banking products, services and experiences for every single customer. If you've been in business as long as we have, you know there's no such thing as one size fits all, and a diverse, inclusive Data Analytics team is a massive part of that future achievement.

Job Description

About this Role

You are eager to provide your burgeoning technical expertise as part of a team that takes on consistently complex projects across a wide range of business units. You are familiar with data functions including data modelling, visualization, data profiling, data origin and lineage, report design and more. You will employ these disciplines to help create data related solutions to drive business results. You thrive on positive feedback and use your specialized knowledge to implement feedback systems that evaluate your team's progress and create innovative new ways improve your overall performance.

We are looking for someone to work as part of a trailblazing team of data scientists who create groundbreaking analytical solutions that improve our core work enterprise wide.

As a Data Scientist I, these are the essential qualifications of this role:

Guide on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the organization
Interpret the meaning of new strategic directions and set objectives and measurements
Implement monitoring and feedback systems to evaluate progress and identify ways of making continuous improvements
Capture and analyze information or data on current and future trends
Seek information on issues impacting the progress of organizational and process issues
Educate the organization on approaches, such as testing hypotheses and statistical validation of result
Help the organization understand the principles and the math behind the scientist process to drive organizational alignment
Translate up to date information into continuous improvement activities that enhance performance
Research organizational and professional trends, evaluate information sources, and collate and compare findings for bias, omission and accuracy, conduct objective analysis
Establish positive working relationships across multiple business and technology partners, program and project managers
Participate in knowledge transfer within the team and business units

Job Requirements

What can you bring to TD? Tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes:
Undergraduate degree or technical certificate
Five (5) or more years of relevant experience

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Job Family

Advanced Analytics & Modelling

Job Category - Primary

Enterprise Data & Analytics

Job Category(s)

Enterprise Data & Analytics

Hours

37.5

Business Line

TD Wealth

Time Type

Full Time

Employment Type

Regular

Country

Canada

**Province/State (Primary)

Ontario

City (Primary)

Toronto

Work Location

TD Centre - South - 79 Wellington Street West

Job Expires

24-Jun-2021","TD Bank
4.0",Midtown Toronto
33,Data Scientist I,"TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us.

Department Overview

What does TD stand for? For starters, we believe in visionary leadership and insights. We believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data.

As part of our Data and Analytics team, you'll be a fundamental part of crafting business processes enterprise-wide by analyzing vast amounts of past and present data.

TD's vision for the future? Tailored, customized banking products, services and experiences for every single customer. If you've been in business as long as we have, you know there's no such thing as one size fits all, and a diverse, inclusive Data Analytics team is a massive part of that future achievement.

Job Description

About this Role

You are eager to provide your burgeoning technical expertise as part of a team that takes on consistently complex projects across a wide range of business units. You are familiar with data functions including data modelling, visualization, data profiling, data origin and lineage, report design and more. You will employ these disciplines to help create data related solutions to drive business results. You thrive on positive feedback and use your specialized knowledge to implement feedback systems that evaluate your team's progress and create innovative new ways improve your overall performance.

We are looking for someone to work as part of a trailblazing team of data scientists who create groundbreaking analytical solutions that improve our core work enterprise wide.

As a Data Scientist I, these are the essential qualifications of this role:

Guide on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the organization
Interpret the meaning of new strategic directions and set objectives and measurements
Implement monitoring and feedback systems to evaluate progress and identify ways of making continuous improvements
Capture and analyze information or data on current and future trends
Seek information on issues impacting the progress of organizational and process issues
Educate the organization on approaches, such as testing hypotheses and statistical validation of result
Help the organization understand the principles and the math behind the scientist process to drive organizational alignment
Translate up to date information into continuous improvement activities that enhance performance
Research organizational and professional trends, evaluate information sources, and collate and compare findings for bias, omission and accuracy, conduct objective analysis
Establish positive working relationships across multiple business and technology partners, program and project managers
Participate in knowledge transfer within the team and business units

Job Requirements

What can you bring to TD? Tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes:
Undergraduate degree or technical certificate
Five (5) or more years of relevant experience

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Job Family

Advanced Analytics & Modelling

Job Category - Primary

Enterprise Data & Analytics

Job Category(s)

Enterprise Data & Analytics

Hours

37.5

Business Line

TD Wealth

Time Type

Full Time

Employment Type

Regular

Country

Canada

**Province/State (Primary)

Ontario

City (Primary)

Toronto

Work Location

TD Centre - South - 79 Wellington Street West

Job Expires

24-Jun-2021","TD Bank
4.0",Midtown Toronto
34,Data Scientist,"Ridership is in flux. Uncertainty about “who’s riding” is at all-time highs. Transit agencies need real-time insights to understand what’s happening in their cities — and so do the companies and academic partners that serve them.

And then there’s Transit: Where are people booking trips? Where are folks headed? What modes are they taking? Transit network planners would weep at having the data you’ll have access to. You will be tasked with teasing meaning and insight out of all that data — from O-D matrices, to survey analysis — to help our agency and operator partners deliver better service on the ground, while also protecting user privacy with swords and dragons.

If your brain is wired for cities, if organizing data gives you a dopamine rush, and if improving one of the world’s most highly-used navigation apps would make you feel like a QUEEN at the end of each day, this job is for you. You’ll be trusted to reach elegant, simple conclusions from our big black box of user data, complemented by in-app and in-person research.

Responsibilities

You’ll draw insights from existing data sources, have input into the way we collect and structure our data, test all the hypotheses (okay not all the hypotheses), create forecasts with that data, and talk data with our partners. You’ll design our in-app surveys and analyze the results. Since we’re not a giant company, you’ll get to determine how we package the data that partners care about — in a way that makes the most sense, and improves service.


✅ Requirements
You have a degree or hard-won experience in a quantitative field: stats, applied math, or econ — convince us it’s relevant. Bonus points for an advanced degree, lots of experience, and/or special projects you are legally sworn from talking about.
Your portfolio of work shows you can make data sing in reality, not just in theory
You’re always asking questions, and able to find something interesting in any dataset.
SQL and noSQL queries that befuddle other mortals are, to you, mere child’s play.
“Making sense of geospatial data is fun” — you.
You have a facility for Python, R, other languages used in analyzing data.
You can calculate the required sample size for statistical significance for a survey (perhaps you already have while reading this sentence…) and you can tell us why it’s not actually significant since it’s a convenience sample.
You are an organized, analytical problem solver with strong written, oral and visual communication skills.
Would be nice if…
You have experience with data engineering, ETL.
You can talk smack about modern machine learning techniques.
You have experience turning out production-ready code.
Passion for urbanism: you find cycling glamorous, you can navigate your city’s public transit system without a map, and you believe free parking should only ever exist on a Monopoly board.
Even better: you’ve worked at a transit agency or private mobility provider, or have a degree in transportation.

Don’t feel like all the requirements apply to you but you still think you’d be a great fit for Transit? Don’t hesitate to apply!


Compensation and benefits
Competitive salary and stock options
Comprehensive medical and dental coverage
5 weeks vacation
Apple laptop and equipment
$1,500 annual mobility allowance. STM? BIXI? Uber? E-bike? Scooter? Going car-free is free at Transit.
A training and development budget
Generous maternal/paternal/parental leave policy. Gotta fill out our tandem bicycles somehow!
Flexible work hours
Spend your days surrounded by first-rate teammates and the best view of Montreal Zoom backgrounds in the world
‍ A note on diversity

Public transit is used by overwhelmingly more women and people of colour than other modes of transportation. We try to make sure the diversity of our users is reflected in the team that serves them. Because when we include people of all races, genders, sexual orientations, ages, and identities — we end up building a better app for everyone who uses Transit.

We encourage candidates of all ages, genders, origins and orientations to apply. If you’d like to specify which pronouns you’d like to be referred to, feel free to include that in your application email.

And if your lived experience has given you a unique perspective on all things transportation, mobility, accessibility, urbanism? Let us know, and we’ll make sure your application gets the attention it merits.


How to apply

Send your resume, a brief explanation of why you want to work for Transit, a sample of an analysis you’ve done (including the final product), and any other information you find relevant to jobs+datascience@transitapp.com.","Transit App
4.5",Montreal
35,Data Scientist,"Job Description


Our Precima team helps retailers turn shopper insights into strategic advantage. We leverage our deep expertise in data science and technology to mine shopper data, uncovering what drives consumer decision making. By using advanced modeling, artificial intelligence and cloud-based SaaS solutions, we are able to put these insights at the fingertips of our clients.

As a Data Scientist, you’ll be part of a team of smart, highly skilled engineers and data scientists who are proud to partner with some of the world’s leading retailers on challenging, cutting-edge, data-driven solutions - all powered by our exceptional technology and people. Our core technologies currently include Java, Angular, Spring Boot, Apache NiFi, Mongo, Postgres and Snowflake, and we continue to adopt the best of breed in cloud-native, low-latency technologies. Our team is co-located and agile, with a central hub in Toronto.

What you’ll do

Be responsible for Analytics production support and deployment. This includes executing, developing, deploying and measuring Nielsen Precima’s analytical products that are configured for clients.

Produce accurate statistical analysis and ensure high quality of the data analysis produced.

Implement, score, and maintain advanced statistical and mathematical models and customer segmentation.

Interpret, document and present analytical results to multiple business disciplines, providing conclusions and recommendations based off customer-centric data.

Take analytical objectives and define data requirements. Extract, clean, and transform customer and item-level data for purposes of analysis, modeling/segmentation and reporting.

Participate in special projects and ad-hoc as required

We’re looking for people who have

Bachelor/Master Degree in Math/Statistics, Computer Science, Economics, Industrial Engineering.

Minimum of 1 - 2 years of directly related work in quantitative analysis with proven results in leveraging customer/transaction to address business objectives through a structured analysis - leading to insights and recommendations. Experience in retail and/or CPG is strongly preferred.

Strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis.

High proficiency in SQL and Python/R/or similar statistical packages

Ability to translate business objectives into analytical plan/framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams - and then to clients.

Ability to translate statistical and analytical results into clear written and verbal communication to internal/external stakeholders.

Excellent ability to be part of multiple projects/initiatives while simultaneously meeting deadlines in a diverse environment

Strong team player and ability to work in a collaborative environment



Additional Information


About NielsenIQ

NielsenIQ is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. We provide consumer packaged goods manufacturers/fast-moving consumer goods and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. Our approach marries proprietary NielsenIQ data with other data sources to help clients around the world understand what’s happening now, what’s happening next, and how to best act on this knowledge. We like to be in the middle of the action. That’s why you can find us at work in over 90 countries, covering more than 90% of the world’s population. For more information, visit www.niq.com.

NielsenIQ is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.",NielsenIQ,Midtown Toronto
36,Data Scientist,"Job Description


Our Precima team helps retailers turn shopper insights into strategic advantage. We leverage our deep expertise in data science and technology to mine shopper data, uncovering what drives consumer decision making. By using advanced modeling, artificial intelligence and cloud-based SaaS solutions, we are able to put these insights at the fingertips of our clients.

As a Data Scientist, you’ll be part of a team of smart, highly skilled engineers and data scientists who are proud to partner with some of the world’s leading retailers on challenging, cutting-edge, data-driven solutions - all powered by our exceptional technology and people. Our core technologies currently include Java, Angular, Spring Boot, Apache NiFi, Mongo, Postgres and Snowflake, and we continue to adopt the best of breed in cloud-native, low-latency technologies. Our team is co-located and agile, with a central hub in Toronto.

What you’ll do

Be responsible for Analytics production support and deployment. This includes executing, developing, deploying and measuring Nielsen Precima’s analytical products that are configured for clients.

Produce accurate statistical analysis and ensure high quality of the data analysis produced.

Implement, score, and maintain advanced statistical and mathematical models and customer segmentation.

Interpret, document and present analytical results to multiple business disciplines, providing conclusions and recommendations based off customer-centric data.

Take analytical objectives and define data requirements. Extract, clean, and transform customer and item-level data for purposes of analysis, modeling/segmentation and reporting.

Participate in special projects and ad-hoc as required

We’re looking for people who have

Bachelor/Master Degree in Math/Statistics, Computer Science, Economics, Industrial Engineering.

Minimum of 1 - 2 years of directly related work in quantitative analysis with proven results in leveraging customer/transaction to address business objectives through a structured analysis - leading to insights and recommendations. Experience in retail and/or CPG is strongly preferred.

Strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis.

High proficiency in SQL and Python/R/or similar statistical packages

Ability to translate business objectives into analytical plan/framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams - and then to clients.

Ability to translate statistical and analytical results into clear written and verbal communication to internal/external stakeholders.

Excellent ability to be part of multiple projects/initiatives while simultaneously meeting deadlines in a diverse environment

Strong team player and ability to work in a collaborative environment



Additional Information


About NielsenIQ

NielsenIQ is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. We provide consumer packaged goods manufacturers/fast-moving consumer goods and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. Our approach marries proprietary NielsenIQ data with other data sources to help clients around the world understand what’s happening now, what’s happening next, and how to best act on this knowledge. We like to be in the middle of the action. That’s why you can find us at work in over 90 countries, covering more than 90% of the world’s population. For more information, visit www.niq.com.

NielsenIQ is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.",NielsenIQ,Midtown Toronto
37,Data Scientist,"Our world relies on AI more and more each day. But what does it actually mean for AI to be 'reliable'? As you consider the question, are you finding that the rabbit hole grows deeper and deeper? Does it intrigue you as both a necessary and valuable question for people to answer? If so, we'd love to meet you.

At Datatron, we create technology to help the growing number of companies sprinting towards reliance on machine learning as part of their operations. Our combination of model ops and governance products ensure machine learning artifacts created by our customers are easy for them to deploy, highly available, and continuously measured for target performance...regardless of how they were developed. We help them guard against bias and drift, safely manage the release of new versions, and alert them to potential issues as they arise. We take pride in the unique, agnostic platform we provide and believe we are contributing to the cause of ethical AI; after all, can it fundamentally be ethical if you cannot rely on it?

As a Data Scientist on our team, you will be one of our primary subject matter experts and responsible for innovation in our products. You will be a leading voice in the field of AI governance, inventing cutting edge analysis techniques for assessing model performance, recommending the best means to evaluate the model across many domains and technologies to provide the widest support possible for our customer's data science teams. You will interact with fellow data scientists in different enterprises to understand what and how they deploy, how to effectively manage the necessary dependencies and support their operational realities, then collaborating with our product designers and engineers to create compelling new software features for our platform.

We're looking for people who have:
At least 3 to 5 years of full-time experience previously developing models for production use
Insight into how the operational realities of data science can be better managed and accelerated
Significant focus in the past on algorithm selection and identifying deployment considerations
Previous developed models requiring ensembling and sequential or multi-stage inference
Validated multiple forms of structured and unstructured data against machine learning output
Visualized inference results for benchmarking, comparing iterations, and identifying anomalies
Experience with two or more popular machine learning frameworks and workbench products
A willingness to adapt, are passionate about accelerating model lifecycles, and capable of working independently, putting in extra effort when necessary, as we are an early stage startup

Our benefits include:
Medical/dental/vision coverage
401k
Lunch provided daily (and dinner when required!)
Abundant snacks and drinks
Dedicated, heavily discounted parking and Clipper Direct
Gym reimbursement
Weekly happy hours and monthly company outings
$10k referral bonuses, because after we hire you, we'd love to hire some of your friends!

We are an equal opportunity employer and value diversity very highly at our company. For us, diversity is the true key to innovation and everyone in the Datatron family is equally embraced for their unique perspective and experiences. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Datatron Technologies,British Columbia
38,Data Scientist,"Our world relies on AI more and more each day. But what does it actually mean for AI to be 'reliable'? As you consider the question, are you finding that the rabbit hole grows deeper and deeper? Does it intrigue you as both a necessary and valuable question for people to answer? If so, we'd love to meet you.

At Datatron, we create technology to help the growing number of companies sprinting towards reliance on machine learning as part of their operations. Our combination of model ops and governance products ensure machine learning artifacts created by our customers are easy for them to deploy, highly available, and continuously measured for target performance...regardless of how they were developed. We help them guard against bias and drift, safely manage the release of new versions, and alert them to potential issues as they arise. We take pride in the unique, agnostic platform we provide and believe we are contributing to the cause of ethical AI; after all, can it fundamentally be ethical if you cannot rely on it?

As a Data Scientist on our team, you will be one of our primary subject matter experts and responsible for innovation in our products. You will be a leading voice in the field of AI governance, inventing cutting edge analysis techniques for assessing model performance, recommending the best means to evaluate the model across many domains and technologies to provide the widest support possible for our customer's data science teams. You will interact with fellow data scientists in different enterprises to understand what and how they deploy, how to effectively manage the necessary dependencies and support their operational realities, then collaborating with our product designers and engineers to create compelling new software features for our platform.

We're looking for people who have:
At least 3 to 5 years of full-time experience previously developing models for production use
Insight into how the operational realities of data science can be better managed and accelerated
Significant focus in the past on algorithm selection and identifying deployment considerations
Previous developed models requiring ensembling and sequential or multi-stage inference
Validated multiple forms of structured and unstructured data against machine learning output
Visualized inference results for benchmarking, comparing iterations, and identifying anomalies
Experience with two or more popular machine learning frameworks and workbench products
A willingness to adapt, are passionate about accelerating model lifecycles, and capable of working independently, putting in extra effort when necessary, as we are an early stage startup

Our benefits include:
Medical/dental/vision coverage
401k
Lunch provided daily (and dinner when required!)
Abundant snacks and drinks
Dedicated, heavily discounted parking and Clipper Direct
Gym reimbursement
Weekly happy hours and monthly company outings
$10k referral bonuses, because after we hire you, we'd love to hire some of your friends!

We are an equal opportunity employer and value diversity very highly at our company. For us, diversity is the true key to innovation and everyone in the Datatron family is equally embraced for their unique perspective and experiences. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Datatron Technologies,British Columbia
39,Data Scientist (Machine Learning),"Events in recent years have made us all too familiar with the havoc that natural disasters can wreak, and the increasing frequency and intensity with which they are occurring. Despite record levels of losses, conventional methods of risk modeling continue to paint at best an incomplete picture of these threats.

Zesty.ai uses novel data gathering and data science methods to produce higher quality information about the risks to property from catastrophes like floods and wildfires. While AI alone may not be able to thwart these disasters, it can help us become more prepared for them, and ultimately that will lead to better outcomes.

As a Data Scientist , you are comfortable and excited to work closely with the engineering team to build the best AI tech possible. You will develop top tier models from unique and diverse data sources to provide strong insights and maximize the impact of our company efforts. You thrive in a collaborative, creative environment that moves fast and are comfortable setting in place structures and processes to help the company scale.

The Opportunity:
Exploring data sets and developing new InsureTech models with data science (Machine learning, Deep learning).
Develop computer vision algorithms that extract insights from aerial imagery and geospatial data
Research and model aspects of the built environment utilizing satellite imagery, LiDAR and other datasets
Help develop training and cross­-validation data sets for machine learning algorithms
Translate product management, engineering, and business constraints and queries into tractable data science questions
Iterate rapidly on everything; all of the above happens in a fast paced business driven environment that you must be comfortable with

What You Bring to the Zesty.ai Lab Team:
BA / BS degree in Math, Physics, Computer Science, and Economics

MS or Ph.D. is certainly a bonus

1 - 2 years of experience working with computer vision and building and testing computer vision systems
2 - 3 years experience deploying machine learning models in production environments
2 - 3 years experience working with deep learning / neural network models (using TensorFlow, PyTorch, Keras, Caffe)
Ability to develop new models based on physics and AI sciences
Strong organizational and management skills with past experiences implementing best practices and processes
Experience working with large image datasets (great if you've already worked with satellite imagery) and related tools OpenCV, Pillow, etc.)
Proficient in SQL
Experience working with cloud platforms (AWS, Google Cloud, etc)
Must be legally eligible to work in Canada

Why Zesty.ai Lab:
Be part of a well-funded growth-stage start-up
Market competitive comp and equity incentives to give you a stake in our future
Comprehensive health care plan
Flexible Time Off
An upbeat and collaborative work culture
Company-sponsored outings and offsites

All your information will be kept confidential according to EEO guidelines.",Zesty.ai,Montreal
40,Data Scientist,"Type: Full-Time
Primary Location: Canada
Education: Bachelor’s Degree

Job Description

Our client, an international investment bank, is looking for a Data Scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting-edge data science tools and techniques. You will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine Machine Learning techniques with domain expertise across Fixed Income, Equities, and Credit. You will take point on running data science research projects and developing POCs along with building scalable, systematic solutions, and work to integrate these into the day-to-day lives of the users.

Job Requirements

Required:

Advanced Degree (MS or Ph.D.) in Statistics, Mathematics, Information Technology or a related field
5+ years of hands-on, technical experience with data science in a financial services setting
Demonstrated experience using a wide range of techniques and algorithms to deliver insights
Demonstrated experience in understanding business challenges and theoretical insights and translating them to working code
Multi-asset class experience, including securitized products (Fixed Income, Equities, and Credit, etc)
Hands-on experience with various Machine Learning tools, libraries, and development platforms, including Jupyter.
Programming experience in Python, SQL, VBA
Critical thinking and the ability to drive changes

Preferred:

Exposure to AutoML Platforms such as Data Robot/Dataiku/H2O.ai.
Ability to compose dashboards in one or more of Plotly Dash, Tableau, Qlikview, D3.js

Prospect 33 is an Equal Employment Opportunity/Affirmative Action Employer. We are a diverse and inclusive company. Great talent is always welcome at Prospect 33 regardless of background, ethnicity, race, gender, sexual orientation, religious views, or even political views.

Job Description

Our client, an international investment bank, is looking for a Data Scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting-edge data science tools and techniques. You will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine Machine Learning techniques with domain expertise across Fixed Income, Equities, and Credit. You will take point on running data science research projects and developing POCs along with building scalable, systematic solutions, and work to integrate these into the day-to-day lives of the users.#LI-NL1

Education: 3

Job Requirements

Required:

Advanced Degree (MS or Ph.D.) in Statistics, Mathematics, Information Technology or a related field
5+ years of hands-on, technical experience with data science in a financial services setting
Demonstrated experience using a wide range of techniques and algorithms to deliver insights
Demonstrated experience in understanding business challenges and theoretical insights and translating them to working code
Multi-asset class experience, including securitized products (Fixed Income, Equities, and Credit, etc)
Hands-on experience with various Machine Learning tools, libraries, and development platforms, including Jupyter.
Programming experience in Python, SQL, VBA
Critical thinking and the ability to drive changes

Preferred:

Exposure to AutoML Platforms such as Data Robot/Dataiku/H2O.ai.
Ability to compose dashboards in one or more of Plotly Dash, Tableau, Qlikview, D3.js

Prospect 33 is an equal opportunity employer.

"", ""title"": ""Data Scientist"", ""employmentType"": ""FULL_TIME"", ""@context"": ""https://schema.org/"", ""identifier"": {""@type"": ""PropertyValue"", ""value"": ""1805"", ""name"": ""Prospect33""}, ""hiringOrganization"": {""sameAs"": ""https://prospect33.com"", ""@type"": ""Organization"", ""name"": ""Prospect33""}, ""@type"": ""JobPosting"", ""datePosted"": ""2021-05-03 13:46:07.840632+00:00""}","Prospect 33
4.7",Canada
41,Data Scientist,"Type: Full-Time
Primary Location: Canada
Education: Bachelor’s Degree

Job Description

Our client, an international investment bank, is looking for a Data Scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting-edge data science tools and techniques. You will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine Machine Learning techniques with domain expertise across Fixed Income, Equities, and Credit. You will take point on running data science research projects and developing POCs along with building scalable, systematic solutions, and work to integrate these into the day-to-day lives of the users.

Job Requirements

Required:

Advanced Degree (MS or Ph.D.) in Statistics, Mathematics, Information Technology or a related field
5+ years of hands-on, technical experience with data science in a financial services setting
Demonstrated experience using a wide range of techniques and algorithms to deliver insights
Demonstrated experience in understanding business challenges and theoretical insights and translating them to working code
Multi-asset class experience, including securitized products (Fixed Income, Equities, and Credit, etc)
Hands-on experience with various Machine Learning tools, libraries, and development platforms, including Jupyter.
Programming experience in Python, SQL, VBA
Critical thinking and the ability to drive changes

Preferred:

Exposure to AutoML Platforms such as Data Robot/Dataiku/H2O.ai.
Ability to compose dashboards in one or more of Plotly Dash, Tableau, Qlikview, D3.js

Prospect 33 is an Equal Employment Opportunity/Affirmative Action Employer. We are a diverse and inclusive company. Great talent is always welcome at Prospect 33 regardless of background, ethnicity, race, gender, sexual orientation, religious views, or even political views.

Job Description

Our client, an international investment bank, is looking for a Data Scientist to join their quantitative division, partnering with the trading desks across the firm to design, prototype, and deliver analytics solutions by deploying cutting-edge data science tools and techniques. You will be an integral part of the team that works closely with portfolio managers, technology leaders, and data platform owners through the organization to combine Machine Learning techniques with domain expertise across Fixed Income, Equities, and Credit. You will take point on running data science research projects and developing POCs along with building scalable, systematic solutions, and work to integrate these into the day-to-day lives of the users.#LI-NL1

Education: 3

Job Requirements

Required:

Advanced Degree (MS or Ph.D.) in Statistics, Mathematics, Information Technology or a related field
5+ years of hands-on, technical experience with data science in a financial services setting
Demonstrated experience using a wide range of techniques and algorithms to deliver insights
Demonstrated experience in understanding business challenges and theoretical insights and translating them to working code
Multi-asset class experience, including securitized products (Fixed Income, Equities, and Credit, etc)
Hands-on experience with various Machine Learning tools, libraries, and development platforms, including Jupyter.
Programming experience in Python, SQL, VBA
Critical thinking and the ability to drive changes

Preferred:

Exposure to AutoML Platforms such as Data Robot/Dataiku/H2O.ai.
Ability to compose dashboards in one or more of Plotly Dash, Tableau, Qlikview, D3.js

Prospect 33 is an equal opportunity employer.

"", ""title"": ""Data Scientist"", ""employmentType"": ""FULL_TIME"", ""@context"": ""https://schema.org/"", ""identifier"": {""@type"": ""PropertyValue"", ""value"": ""1805"", ""name"": ""Prospect33""}, ""hiringOrganization"": {""sameAs"": ""https://prospect33.com"", ""@type"": ""Organization"", ""name"": ""Prospect33""}, ""@type"": ""JobPosting"", ""datePosted"": ""2021-05-03 13:46:07.840632+00:00""}","Prospect 33
4.7",Canada
42,Data Scientist - Product Data Science,"Company Description


Twitter serves the public conversation by encouraging people all over the world to connect, learn, debate, and solve problems together. We believe conversation can change the world, and that’s why Tweeps (that’s what we call Twitter employees) come to work every day.



Job Description


You will work closely with our partners in Product, Engineering, Design, and Research to understand customer behavior, inform product decisions, and increase healthy participation on Twitter.

You will support the entire product development lifecycle from product ideation to opportunity sizing, from measurement design to experimentation, from causal analysis to post-launch learning, and iteration into the next development cycle. You will analyze how changes to the platform affect customer behavior and business outcomes. You will also communicate findings to cross-functional partners and use data to improve the team’s strategy.



Qualifications


You are a data scientist with a track record of delivering results. You find satisfaction in collaborating with partners and shipping changes that deliver measurable business impact. You apply machine learning and data science techniques when applicable, but are just as happy to implement a simple heuristic if it meets business needs. You are looking to join a strong, high-performing team.

You are great at:

Collaborating with product managers, engineers, and designers to drive business impact through data science

Performing analyses on raw event data in modern data warehouse systems

Taking ambiguous business and technical problems to an appropriate solution

Defining metrics and using data to better understand customer needs

Qualifications:

Advanced degree in a quantitative field (PhD preferred)

Expertise solving complex and highly impactful quantitative business problems with at least one scripting language (Python, R, etc.) and SQL

Experience with one or more of the following in an applied setting: developing statistical frameworks to understand customers and their behaviors, advanced statistical techniques for A/B testing, methods for experimental design, causal inference, or quasi-experimental analysis

[Bonus] Ability to create/improve reproducible analysis libraries

[Bonus] Experience with PySpark or BigQuery


Additional Information


We are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.","Twitter
4.2",Midtown Toronto
43,Data Scientist - Product Data Science,"Company Description


Twitter serves the public conversation by encouraging people all over the world to connect, learn, debate, and solve problems together. We believe conversation can change the world, and that’s why Tweeps (that’s what we call Twitter employees) come to work every day.



Job Description


You will work closely with our partners in Product, Engineering, Design, and Research to understand customer behavior, inform product decisions, and increase healthy participation on Twitter.

You will support the entire product development lifecycle from product ideation to opportunity sizing, from measurement design to experimentation, from causal analysis to post-launch learning, and iteration into the next development cycle. You will analyze how changes to the platform affect customer behavior and business outcomes. You will also communicate findings to cross-functional partners and use data to improve the team’s strategy.



Qualifications


You are a data scientist with a track record of delivering results. You find satisfaction in collaborating with partners and shipping changes that deliver measurable business impact. You apply machine learning and data science techniques when applicable, but are just as happy to implement a simple heuristic if it meets business needs. You are looking to join a strong, high-performing team.

You are great at:

Collaborating with product managers, engineers, and designers to drive business impact through data science

Performing analyses on raw event data in modern data warehouse systems

Taking ambiguous business and technical problems to an appropriate solution

Defining metrics and using data to better understand customer needs

Qualifications:

Advanced degree in a quantitative field (PhD preferred)

Expertise solving complex and highly impactful quantitative business problems with at least one scripting language (Python, R, etc.) and SQL

Experience with one or more of the following in an applied setting: developing statistical frameworks to understand customers and their behaviors, advanced statistical techniques for A/B testing, methods for experimental design, causal inference, or quasi-experimental analysis

[Bonus] Ability to create/improve reproducible analysis libraries

[Bonus] Experience with PySpark or BigQuery


Additional Information


We are committed to an inclusive and diverse Twitter. Twitter is an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.","Twitter
4.2",Midtown Toronto
44,Data Scientist,"At Novisto, our vision is to be the world's leading software solution for integrated corporate sustainability management. Our purpose is to advance a more inclusive and resilient society by enabling organizations to create value through sustainability.

You will have the chance to work with incredibly talented and driven people within our engineering and business teams. While our employees are currently working remotely, we are taking thoughtful measures to ensure a smooth onboarding experience for any new employee joining our growing company.
We are looking for an experienced Data Scientist to join us.

You will be responsible for data discovery in vast amounts of data, applying data mining techniques, doing statistical analysis, and building high quality prediction systems.

Experience:
Degree in Computer Science or relevant field

5+ years with data related technologies

4+ years with NLP techniques and algorithms

2+ years with data mining, statistical analysis, prediction systems, visualisation tools

Experience with cloud services and infrastructure is a plus

Requirements:
Excellent understanding of machine learning techniques and algorithms

Experience with data visualisation tools

Good applied statistics skills, such as distributions, statistical testing, regression

Good scripting and programming skills

Extended experience with NLP techniques such as text preprocessing, text representation, keyword extraction, text classification, topic modelling, semantic extraction techniques, sentiment analysis

Experience with PDF parsing: text, tables and images

Experience with Python and data science packages such as Scikit-learn, pandas, numpy, Keras, Tensorflow, PyTorch

Experience with NLP packages such as gensim, nltk, spacy

Understanding of deep learning models for NLP such as BERT, RNN, LSTM

Personal skills:
Excellent communication and teamwork skills

An analytical mind, great attention to detail

What we offer:
The opportunity to join an early stage, well-financed company

The chance to have an impact by creating a product that is bringing positive change around the world

Generous health benefits

Beautiful office, in the heart of Old Montreal",Novisto,Montreal
45,Data Scientist,"Bachelor's Degree
3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
2 years working as a Data Scientist
Experience in as many of the following areas: measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, descriptive analytics, and regression analysis.
Good understanding of supervised and unsupervised learning models
Amazon Advertising is one of Amazon's fastest growing and most profitable businesses. As a core product offering within our advertising portfolio, Sponsored Products (SP) helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through Amazon. The SP team's primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

As a Data Scientist on this team you will:

Solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ML models by tailoring to business needs, and collaborating with Scientists, Engineers, BIE's, and Product Managers.
Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers to produce the required data.
Deliver with independence on challenging large scale problems with ambiguity.
Manage and drive the technical and analytical aspects of Advertiser segmentation; continually advance approach and methods.
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytic capabilities, platforms, and pipelines.
Apply statistical or machine learning knowledge to specific business problems and data.
Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.
Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
Build decision-making models and propose solution for the business problem you defined
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithms.
Why you love this opportunity
Amazon is investing heavily in building a world-class advertising business. This team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth
You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven fundamentally from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video https://youtu.be/zD_6Lzw8raE


PhD in Statistics, Economics or related quantitate field.
Experience in measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, manipulating data & analyzing very large data sets, descriptive analytics, and regression analysis.
Excellent quantitative modeling, good knowledge of ML methods, statistical analysis, and problem-solving skills.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data.
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences.
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Experience in advertising is a plus.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/ontario","AMZN CAN Fulfillment Svcs, ULC
3.8",Midtown Toronto
46,Data Scientist,"Stradigi AI, a leading artificial intelligence solutions provider, is looking for a Data Scientist who will support our pre- sales and marketing teams with insights gained from analyzing company data. The ideal candidate must have strong experience using a variety of data mining/data analysis methods using a variety of data tools, building, and implementing models, using/creating algorithms, and creating/running simulations.

What You'll Do

Participate and drive client workshops to capture business objectives and translate them into data requirements for ML purposes.

Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.

Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.

Assess the effectiveness and accuracy of new data sources and data gathering techniques.

Develop custom data models and algorithms to apply to data sets.

Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.

Coordinate with different functional teams to implement models and monitor outcomes.

Develop processes and tools to monitor and analyze model performance and data accuracy.

Required Qualifications

Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.

Experience working with and creating data architectures.

Financial knowledge or experience from capital markets is a definite asset.

Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.

Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.

Excellent written and verbal communication skills for coordinating across teams.

Strong presentation skills for both internal stakeholders and client workshops.

A drive to learn and master new technologies and techniques.

We are looking for someone with 4-7 years of experience manipulating data sets and building statistical models, has a Master's or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools:

Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.

Experience querying databases and using statistical computer languages: R, Python, SLQ, etc.

Experience using web services.

Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.

Experience analyzing data from 3rd party providers: Google Analytics, Facebook Insights, etc.

Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.

Experience visualizing/presenting data for stakeholders using: Tableau, Periscope, Business Objects.

Why consider Stradigi AI?

We offer very attractive salaries.

The opportunity to own shares in our company through our ESOP program.

RRSP matching up to 3%

A generous vacation program & additional paid time off during the holidays

Health, Dental and many additional wellness benefits

Flexible work arrangements, allowing you to work from home or the office","Stradigi AI
3.8",Montreal
47,Data Scientist,"Analytics, Toronto, FT
Your Role:

Explore customer data to uncover insights using data mining and analytic skills.
Training and tuning modern machine learning and AI algorithms to maximize performance and speed.
Building presentations to explain methodology, convey insights and share value based outcomes.
Work independently with tasks assigned.

Skills Required:

Bachelors degree in Math, Statistics, Engineering or Computer Science
Fluency in Python
Strong Communication and problem solving skills.
Exposure to Tableau an asset.","CakeAI
5.0",Midtown Toronto
48,"Data Scientist, Growth & Retention","Since being founded in 2011, Prodigy Education has grown from 3,000 local users to more than 100 million registered users worldwide. As one of the fastest-growing EdTech startups in North America, Prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. Anyone with an internet connection is welcome to create a free account for Prodigy’s popular Math Game for grades 1 to 8. Prodigy Education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. For more information visit www.prodigygame.com.

Our passion is our mission - to help every student in the world love learning!

Our Data team is scaling rapidly as we continue to hit our product and growth milestones! The work you do will aid the educational advancement of millions of students. You will have the chance to apply your analytics skills to not only help kids learn but also help our product and leadership teams to make better decisions.
We are looking for a modelling and ML expert to join our growing team. You will have the chance to apply your data analysis, modelling, and coding skills to help our Data, Finance, and Executive teams better understand our business and build the best possible company strategy. You will develop advanced models to analyze our paid memberships, and empower all teams with actionable insights on user conversion, churn, and engagement.
Your Impact:
Work with stakeholders, data scientists, and developers to create useful models to analyze our paid memberships.
Leverage data analytics and quantitative analysis to monitor the model's performance and identify new features to improve KPIs.
Develop a deep understanding of our internal and external users to identify how our models can help solve their pain points.
Iterate upon successful MVPs to ensure the user-experience and code quality matches our internal standards.
Collaborate with key cross-departmental stakeholders to maintain technical product roadmaps, prioritize requests, and ensure that business goals are being met.
Effectively scope projects so that they are lean, but also add enough value to validate your hypotheses and meet business needs.
Help our teams explore and understand our business and our users.
Design and develop a variety of metrics and models to inform the impact of company activities and lines of business.
Work on a variety of giant datasets, from their development and manipulation to visualizing them via polished dashboards.
Communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non-technical backgrounds.
Who You Are:
At least 3 years demonstrated experience with data science and modelling.
Specific experience delivering revenue-related models which leverage analytics and machine learning
Good written and verbal communication skills with the ability to present a strong rationale for product decisions
Applied computational and mathematical model builder.
Expert skills and knowledge of SQL and Python programming languages.
Demonstrated application of model-building and analytics to financially-relevant problems.
A team and customer centric mindset.
Passion for solving hard problems and building a great technical product, balancing speed and depth for greatest value.
Experience in business requirements analysis, design, implementation, and testing of solutions.
Ability to break down large projects into manageable tasks, and leverage agile methodologies such as Scrum and Kanban
Experience using analytics and user research to add significant value to a product
Expertise in working with BI platforms.
Ability to oversee and work simultaneously on different projects with a variety of timelines.
Willingness to learn and work in a hyper-growth company
Love for our mission of helping kids everywhere enjoy learning.


Our Core Technologies:
SQL & Python
Data-related technologies such as data lakes and warehouses, Spark, Databricks, and similar cloud services
Bonus Points For:
Degree(s) in Engineering, Computer Science, Stats, Mathematics, or related disciplines.
Demonstrated ability to solve hard mathematical, algorithmic, and statistical problems.
Expertise in forecasting, time series analysis, user segmentation, financial modelling, and analyzing Stripe or similar transaction data.
Experience working with cloud platforms like AWS, GCP, Databricks.
Experience working with A/B testing and experimentation, and applying statistical concepts.
Significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship.
Experience in the ed tech or SaaS industry
Previous experience scaling in a startup environment
What We Offer:
A culture of transparency, where team members are involved in important conversations
Full health benefits from day one (1) for you and your family, fully covered!
We are a profitable company, with eligibility to participate in stock options for all full-time permanent employees
Learning and development budget for all full time employees to use towards career growth and development opportunities
We recognize 9-5 is not for everyone! We offer flexible working hours that will allow you to schedule your work day with a bit more freedom!

While we operate 100% remotely for the time being, we understand the importance of togetherness. We offer frequent and fun team and company events, to stay connected and in the know.

Please note: During the Covid-19 pandemic, in order to keep all our candidates and team members safe, Prodigy is operating, hiring and onboarding 100% remotely for the time being.

Come as you are. We believe the power of our collective potential will transform education. We are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. We welcome applications from people from all underrepresented groups, including (but not limited to) people of any gender, age, or religion, members of the LGBTQIA2+ community, BIPOC and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of Prodigy Education. If you feel like you don’t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we’d still love for you to apply!

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Education will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require accommodation, please notify us and we will work with you to meet your needs.","Prodigy Game
4.8",Oakville
49,Data Scientist,"Trend Micro, a global leader in cybersecurity, is passionate about making the world safe for exchanging digital information today and in the future. Artfully applying our XGen™️ security strategy, our innovative solutions for consumers, businesses, and governments deliver connected security for data centers, cloud workloads, networks, and endpoints.

Optimized for leading environments, including Amazon Web Services, Microsoft®️, and VMware®️, our layered solutions enable organizations to automate the protection of valuable information from today’s threats. Our connected threat defense enables seamless sharing of threat intelligence and provides centralized visibility and investigation to make organizations their most resilient.

With over 6,500 employees in 50 countries and the world’s most advanced global threat research and intelligence, Trend Micro enables organizations to secure their connected world. www.trendmicro.com

Position Summary: As a part of our Ottawa based Advanced Technology Group at Trend Micro, you'll share in the proven success, innovation, and customer loyalty we've had in the area of Cloud and Data Center security. Your role will be to design, implement, test, deploy and support high quality software for data center and cloud systems. This is a software development role requiring exceptional programming skills, proven software design abilities and a high degree of adaptability and creativity. If you love writing beautiful, efficient, and productive code and have a passion for seeing your code in production continuously then we want to talk to you.

We’re looking for someone who:

Loves to work on a great cross functional team collaborating effectively with various groups to understand business objectives, customer needs and gaps, and deliver on the team objectives.

Will use their exceptional development skills to build innovative and sustainable solutions that solve our customer’s problems.

Has current experience in modern programming languages and frameworks such as go, rust, typescript, microservice design.

Has a strong foundation in maths and applied experience in data science platforms and tools such as Flink, Matlab, scikit, numpy, scala.

Has experience in data visualization techniques and tools such as d3, seaborn.

Has experience in networking, network security and cloud platforms including AWS, GCP.

Works fluently on a variety of platforms at varying heights in the software stack and is comfortable with low level and embedded domains as well as high level stacks.

Is a creative thinker that believes in end-end thinking to solve current and future customer problems.

Has knowledge or experience developing secure code and/or working in the security domain.

Has a bachelor of computer science degree (or equivalent).

Trend Micro welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Trend Micro
4.1",Ottawa
50,Data Scientist 2,"The Modern Life and Learning Studio is looking for a strong Data Scientist to join our Data Science team to enable us to understand and drive data-informed, high impact business decisions across our organization.

In this role, you will be joining a team hungry to learn, leverage and value your expertise to grow the Data Science discipline into the rhythm of our BXT (Business, Experience, Technology) team structure. You will help shape and strengthen the business strategy for Microsoft Whiteboard and figure out the user needs and how to meet them on a visual expression canvas. You will have the opportunity to work closely with our product engineers, PMs, designers, and user researchers.

The successful candidate will have experience analyzing data from a wide range of datasets and across a breadth of technology platforms. They enjoy challenging projects, have strong analytical and presentation skills, technical aptitude, and a collaborative work style. We are looking for people who see challenges as opportunities, people who can look at complex problems and are able to provide actionable insights and informed decisions.

Responsibilities
As a Data Scientist on the Modern Life and Learning Studio, you would be responsible for:
Influence and empower the immediate stakeholder to make product improvements that yield business value by effectively making compelling cases through storytelling, visualizations, and other influencing tools.
Data preparation, statistics, and machine learning to investigate problems with the goal of supporting the questions required to support the greatest business needs.
Excellent creative thinking skills with emphasis on developing innovative solutions to solve complex problems that may not have one clear answer.
Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.
Provide input to software engineering teams on new analytical capabilities needed.
Partner with Researchers to help product teams better understand their users.
Help designers explore and understand scenarios in the product to address the unmet needs of the users.
Qualifications
3+ years work experience as a Data Scientist.
2+ years of experience with R or Python and SQL.
2+ years of experience with one or more of the following technologies: C, C++, C#, Shell Scripting, Java, Scope, Hive, MapReduce, Scala, Spark, or Pig.
Bachelor’s degree is required, with preference given to a Quantitative (Statistics, Data Mining, Machine Learning, Mathematics, Computer Science, or Data Science), or Applied Science (Biology, Physics, Chemistry, or Psychology) discipline.; MS, or Dedicated Data Science training preferred.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
51,Data Scientist,"This role will start off as work from home, gradually you will be required to work in our Markham and Toronto Office.

Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat of this data-driven, technology revolution.

You will work on impactful projects that range from predicting customer life-time values and optimizing customer journeys to incorporating novel data sources for building cutting-edge pricing algorithms. You will leverage machine-learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. This team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers.

As a data-scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work. The team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!

The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. If you are passionate about Data Science and leveraging your analytical prowess to tackle business challenges, this role could be for you. We are embracing new technology and exploring new ways of working. With our constant advancement, you will be at the forefront of a fast-evolving field. These exciting roles are at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

What you need to succeed

As a senior data-scientist, you will need the following skills and experience to succeed in the role:

An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred.

5+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience).

5+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.

Python/R /Dataiku

REST/XML/JSON/API ingestion

Spark/Impala/Hive

Expertise in machine learning theory and predictive modelling lifecycle

API configuration

Conformance/Alignment to IT/Enterprise Architecture standards (where applicable)

Relevant experience in P&C (preferred)

Shiny App development

Geo-analytics experience (ESRI/KML/KMZ layer development) with specialization in weather & environmental data ingestion

What sets you apart

A growth mindset with versatile skills and able to work through problems from first-principles.

A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data.

A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions.

Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.

The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently.﻿

Position Objectives

Provide data support to Claims business inclusive of data mining, automated reporting and modelling.

Transformation of complex data sets into meaningful conclusions & recommendations

Develop innovative solutions for pattern recognition using machine learning and statistical approaches

Maintenance of expanding set of data mining tools, frameworks & approaches

Communicate actionable recommendations based on insights/model results

Deliver proactive analysis on CAT exposure, historical performance and decision making using weather and geo-analytical approaches (CAT Analytics role)

Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction (Sr Data Scientist)

Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) (Sr Data Scientist)

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.","Aviva
3.7",Markham
52,Data Scientist,"Do you want to work closely with the data and processes of a successful e-commerce business? Were looking for an Intermediate Data Scientist to come up with customized solutions based on state-of-the-art machine learning and deep learning algorithms to help understand the patterns in the e-commerce big data and extract meaningful conclusions and actionable results to help the business make progressive decisions.

Our Analytics team prides itself on providing everyone at Cymax with timely, accurate, and actionable information. Our hardworking team makes this possible by collecting, analyzing, and reporting data to give insight into the big picture. Whether through Business Intelligence, Data Science, or Operations Research, we use our expertise in big data to facilitate business decisions.

What you’ll do:

Identify the data-analytics problems that offer the most practical opportunities to the organization.
Study and understand the related datasets deeply and determine the most relevant datasets and KPIs.
Collect large sets of structured and unstructured data from disparate sources.
Clean and validate the data to ensure accuracy, completeness, and uniformity.
Devise and apply models and algorithms to mine big data in collaboration with AI engineers.
As a data scientist, you are expected to know the details of ML/DL algorithms, how to use or modify them, when to use them, and what algorithms are suitable for the specific problems that you are going to deal with.
Analyze the data to identify patterns and trends.
Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method.
Building Machine Learning/Deep Learning scalable models for production.
Communicate findings and results to stakeholders effectively.
Experience with data visualization and storytelling.
Familiar with the application of cutting-edge machine learning and deep learning algorithms in various topics from simple classification/regression to generative models.
Have a strong background in algorithm development and data-driven problem-solving methodologies using these algorithms.
Build Machine Learning Models to answer business driving questions for areas like automated marketing and e-commerce.
Have a deep understanding of very specific details of machine learning algorithms and be able to develop them from scratch or change their structure for a customized problem.
You will be involved in a variety of tasks in the process of developing AI products: data collection and synthesis, data analysis, algorithm design, and development.
Work with data analysts, AI engineers, and data engineers in the process of product development.
Use predictive modeling to increase and optimize customer experiences, revenue forecasting, pricing optimization, and other business outcomes.

Who you are:

4+ years relevant experience in advanced analytics, data science, machine learning, or artificial intelligence roles in the e-commerce space.
Familiar with all steps of industry-level machine learning methodologies.
Proficiency in various machine learning libraries such as TensorFlow, Keras, or PyTorch.
Engineering experience using large data systems on SQL, and good to have experience with Spark.
Good to have experience with Docker, and model deployment on K8s.
Expertise in framing a data-driven solution for a business problem.

Why work here!

The Cymax Group of brands build tech that runs business. Founded in 2004, our vision was simple: design an exceptional eCommerce experience. That idea evolved into a platform that includes online marketplaces Cymax Business and HomeSquare; Freight Club, a logistics solution; and digital supply chain tech enabling manufacturers with multichannel control: Channel Gate.

So, why work with us? For newbies to online selling, there is no better place to gain a comprehensive education on the end-to-end eCommerce experience. For the well-seasoned eComm aficionado, you’ll be on the cutting edge of eCommerce technology and innovation. For everyone, there's room to grow, mentorship, and a data-driven culture filled with diverse people who can’t wait to meet you. So why wait? Take your tech career to the next level and apply now!","Cymax Group
4.5",Vancouver
53,Specialist Data Science,"At CN, we work together to move our company—and North America—forward. Be part of our Information & Technology (I&T) team, a critical piece of the engine that keeps us in motion. From enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value-added tasks. You will be able to develop your skills and career in our close-knit, safety-focused culture working together as ONE TEAM. The careers we offer are meaningful because the work we do matters. Join us!

Job Summary

You will be part of a team that spans across all business domains. You will provide advanced analytical insights using data analysis and machine learning techniques. You will collaborate with teams across the company, exploring various data sources to help identify new opportunities while driving the adoption of AI. As an expert data scientist, you will combine your knowledge of machine learning and software development skills to automate model development, training, and deployment. You will leverage your experience in building reusable algorithms, functions, and libraries to use in model development for predictive and prescriptive analytics.

Story telling is critical to the change management practice of putting the model into real live environment. Success will be dependent on hypothesis generation, exploration of data, using AI to discover insights, to developing automation pipelines and visual – analytics all being explained to our stakeholder’s community.

The Data & Analytics team is helping CN to create a data-driven culture where everyone can make better decisions, grounded in trusted data, and augmented by the power and scale of analytics. Using advanced data platforms, and AI tooling, decisions can happen at just the right moment, impacting the environment, safety and operational excellence for our customers and team members, while always keeping an eye on the future, ready to explore...

We are highly innovative, and passionate, we believe anything is possible, by embracing people culture, using the right technology, and having an agile mindset, we will drive the highest value to customers…

Interested in working with a team of data innovators, and being part of a culture of transformation, creativity, and teamwork? If so, we would love to connect with you!




Main Responsibilities

Work with structured and unstructured raw data to design and develop innovative predictive models, metrics, and dashboards to uncover actionable insights
Visualize and report data findings creatively in a variety of visual formats that provide insights to the organization
Influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset
Support and evolve the Advanced Analytics and Data Science roadmap by leveraging industry research, best practices, and emerging tools/technology
Collaborate on end-to-end automation efforts required to bring models to production
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities

Requirements

Experience in the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques with hands-on work experience
5 or more years of hands-on work and practical business experience in Machine Learning and AI, including classification, clustering, time series analysis, NLP, demand forecasting and optimization
Excellent communication skills and capable of breaking down technical and complex concepts in a way that is understood by non-technical audiences

Education/Certification/Designation

Masters or PhD degree in a quantitative field such as Math, Statistics, Computer Science, Economics, or Data Science

Technical Skills/Knowledge

Solid development experience with Python and comfortable using various data science libraries such as Scikit-learn, Pandas, NumPy as well as frameworks like TensorFlow, Pytorch, Keras and have applied these skills towards solving actual business matters
Comfortable working in and with a Jupyter like environment and infrastructure, and familiar with GitHub, Data bricks
Have advanced knowledge in SQL and Apache Spark
Expert level experience with at least one of the cloud computing platforms – Azure, AWS, GCP
Familiar with Tableau and/or Power BI visual analytics purposes
Well versed in software and AI development lifecycles, including ML Ops
Have agile experience and have a bias for action, removing blocks to get results fast

Assets

Experience with SAFe agile methodology and work in a fast-paced environment
Having Azure or other cloud certifications, For example Azure Data Lake, Data Bricks



About CN

As a leading North American transportation and logistics company, CN is a true backbone of the economy. With a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. We transport US$200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000-mile network spanning Canada and mid-America. CN is the only Canadian company listed in the Transportation and Transportation Infrastructure sector of the Dow Jones Sustainability World Index (DJSI). Launched in 1999, the DJSI World represents the gold standard for corporate sustainability. At CN, we work as ONE TEAM, focused on safety, sustainability, and our customers, providing operational and supply chain excellence to deliver results.


CN is an employment equity employer and we encourage all qualified candidates to apply. We thank all applicants for their interest, however, only candidates under consideration will be contacted. Please monitor your email on a regular basis, as communication is primarily made through email.","Canadian National Railway
3.3",Edmonton
54,Data Scientist,"Introduction
Have you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.

Your Role and Responsibilities

As a Data Scientist working at the IBM Garage, you will be the Subject Matter Expert on Data and AI Statistical models and IBM’s leading edge analytic solutions and how they apply to solve the client’s business problems.
As part of the IBM Garage team, you will advise on and implement models in Machine Learning, Optimization, Neural Networks, and Artificial Intelligence such as Natural Language, and other quantitative approaches using IBM Data Science capabilities utilizing open source.
You will partner with clients to understand business problems and work side-by-side (virtually and in person) with clients and other Garage consultants on proofs of concept and minimally viable solutions that demonstrate business value and technical solutions. Projects with clients will typically be 2 to 6 weeks and you will work in squads with other data scientists, designers, data engineers, front end developers, architects and with clients. The clients’ Garage experience results in them purchasing IBM solutions.
You will deliver meaningful insights and predict emerging trends to inform business solutions that optimize client value.
To be successful in this role you:

Leverage Data Engineering techniques to gather, prepare, cleanse, and transform client data for analysis and AI automation, including automating data pipelines
Demonstrate strong business acumen and ability to understand business problems, formulate hypotheses and test conclusions to influence solution design
Leverage a variety of structured and unstructured data sources, analytics, AI tools, and programming languages to derive meaningful data insights (e.g., Python, R, Spark, TensorFlow, Jupyter, etc.)
Possess relevant industry and/or business domain knowledge such as Finance, Telco, Retail, Consumer Product and Health Care which you will apply to shape solutions
Work in an Agile fashion, iterating on the design to react to client feedback and demonstrate rapid progress
Expand partnerships at all levels of the client organization to identify new opportunities for data science applications
Prove the value of IBM’s Data and AI solutions to clients
those that are based in Montreal need to be fluently bilingual
IBMReferred_NorthAmerica

Required Technical and Professional Expertise
At least 1- 4 years as a Data Scientist with a deep understanding of Statistics and statistical practices, NLP/NLU, supervised and unsupervised learning and deep learning,

At least 1- 2 years of experience with identifying data sources, transforming data, etc.
At least 1 to 2 years in a client facing role, including facilitating client discussions and problem framing
Experience with a Data Science Programming language, such as Python or R coupled with SQL
Experience writing applications to visualize data using open source tools such as Shiny

Preferred Technical and Professional Expertise

Academic training in a quantitative discipline and/or a specialized degree in data science or analytics
Understanding of Analytics Life Cycle and / or Crisp DM method and practices
Experience with RESTful APIs and clustered data processing (e.g., Hadoop, Spark, Map-reduce, and Hive)
Demonstrable experience in private and public Cloud
Experience in developing and delivering appropriate analytic and/or machine learning models to achieve business goals

About Business UnitIBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementFor additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","IBM
3.9",Montreal
55,Data Scientist,"Who We Are

Lightspark is an innovative cleantech company, bringing innovative technology solutions to consumers, trade, utilities and government to help make a more sustainable future. We are building a dynamic enterprise software-as-a-service platform and are looking for people with a passion, curiosity and purpose for using their skills and creativity to make the world a better place.

Who You Are

You have a passion for putting your analytical data skills towards solving complex problems with a focus on geo-spatial techniques, working well with teams, and fighting hard to meet deadlines and build break-out products.

Job Description

We are looking for a data scientist that will help us discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, understanding GIS and geo-spatial mapping and building high quality prediction systems integrated with our products. Specifically, you will automate our building energy scoring using machine learning techniques, build recommendation systems, and further develop our catalog of products for energy efficiency and renewables building improvements.

Responsibilities
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining and statistical analysis using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Skills and Qualifications
Excellent understanding of machine learning techniques and algorithms
Experience working with geospatial data
Interest in climate change, energy efficiency and desirable that you have experience in energy and building modelling
Experience with common data science toolkits, such as Python, Weka, NumPy, MatLab, R, etc. Excellence in at least one of these is highly desirable
Great communication skills and ability to present information to management team in a way that explains concepts and thinking
Experience with Saas software development
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with PostgresSQL, spatial objects and experience with Redis, Amazon Web Services is required
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills a bonus, including Node JS, Javascript, GraphQL, React, Ruby on Rails and PHP
Data-oriented personality
If you are interested, please forward your cover letter and resume to hello @ lightsparkinc.com

About Lightspark

Lightspark Software Inc is a purpose driven SaaS company who has a mission to build a sustainable future by accelerating the engagement and success of energy efficiency and renewable technologies.

We do this by using big data, machine learning and advanced design thinking and user interfaces, to increase building owner conversions to deep energy retrofits and solve the friction points for multiple use cases, including utilities, cities, municipalities, trade and manufacturers.",Lightspark,Vancouver
56,Data Scientist,"Job Description

Status: Permanent – Full-time
Location: Montréal – Griffintown

At Brainfinance, we pride ourselves in offering the highest possible quality of customer experience. We are looking for a person who thrives in a team environment, who is passionate, driven and who yearns to grow personally and professionally. This person will become part of a team that thrives on the new challenges presented by a fast-paced and constantly evolving environment. The chosen candidate will possess a keen eye for detail and will come up with innovative ideas that will contribute to the success of both the company and the customer experience.

As a Data Scientist, you will be working with teammates who are passionate, helpful, and strive to get the best out of Big Data .

Responsibilities
Participating in daily and bi-weekly scrum activities (Daily scrum, sprint planning, sprint review, and sprint retrospective).
Working with Business Analysts and Business Units to understand the business and requirements.
Working with DevOps Engineers and Software Engineers (Mobile and Web) to integrate Big Data Science solutions.
Developing data analysis and science solutions with Python.
Leveraging NumPy, SciPy, Pandas, MLlib, Scikit-Learn, NLTK, Scrapy, and Keras.
Utilizing Apache Spark, Apache Kafka, and Apache Cassandra to develop scalable real-time and data-driven applications
Advantages
Competitive salary.
Fun and relaxed work environment.
Full health benefits - Medical.
Free healthy snacks and refreshments.
Advancement opportunities.
Great office location.
Providing opportunities to attend trainings and conferences
Requirements
A bachelor degree in software engineering or related fields ( A Ph.D. degree is a plus ).
Software engineers experienced with Python programming language.
3+ years of experience with Python Machine Learning and Optimization.
2+ years of experience with Apache Cassandra.
2+ years of experience with Apache Spark.
Familiarity with Apache Kafka and Apache Mesos.
Familiarity with Deep Learning libraries such as TensorFlow or Theano or CNTK.
Experience with GIT and Continuous Integration.
Being open to learn and explore new technologies.
Experience working in an agile environment (preferably, Scrum).","Brain Finance
3.3",Montreal
57,"Manager, Data and Digital Platforms","Position Summary

At Samsung Electronics Canada, we take pride in the creativity and diversity of our talented people – they are at the forefront of everything we do. Their skillset and mindset drive our continued success. We want the best of the best at Samsung to join our team, not just those who fit into our Culture but those who will ADD to our Culture and make Samsung an even better place to work.

Did we catch your attention yet?

If you want to work for one of the most recognized brands in the world and one of the Top 100 Employers in Canada...and have a ton of fun…. then please keep reading!

Our Perks:

Competitive Salary and Performance based incentive plan for all levels
Employer paid Medical and Dental coverage from day one
Group RRSP plan that helps you save for the future
Fantastic employee discount on all Samsung products
Subsidized Cafeteria; including free Starbucks coffee/latte machine
Access to Samsung U for 24/7 online learning
Employee Referral program- we want great talent like you!

Position Summary:

The Data and Digital Platforms Manager will play an important role in championing data as a corporate asset and increasing data, marketing platform and digital marketing measurement literacy across the organization. You will also lead all related data and analytics platforms and services, together with partners and vendors.
This role will require you to work cross functionally with marketing, business, ecommerce, IT and Samsung Headquarters teams to understand and develop Samsung’s data capabilities and infrastructure and use this knowledge to appropriately implement and evolve customer segmentation and measurement strategies across digital marketing campaigns. You will work closely with Samsung’s Digital, Media and CRM agencies of record to ensure all data and tag management requirements are adhered to. You will be required to present campaign and performance based reports and dashboards with a focus on providing insights to help optimize marketing activities. In addition, you will be required to contribute to the overall data management sophistication of the organization through best practices in data governance.

Role and Responsibilities

Essential Duties and Responsibilities:

Data & Platform Management (40%)

Lead the evolution and management of SECA’s data capabilities and infrastructure, including its data lake
Responsible for the successful implementation of data lake projects that align with business and marketing use cases and strategies by prioritizing business requests, maintaining learning agenda, working with internal stakeholders to propose new use cases and coordinating tests/modeling activities
Liaison with business leads to understand business needs and translate them into technical requirements that can be used by business analysts and data scientists to successfully create models, tests and other analyses
Ensure the outputs from business analysts and data scientist are aligned with initial request and delivers business value
Work with Solutions Architects to develop, optimize and automate data processing tasks
Maintain overall marketing data governance and compliance best practices in line with Global Samsung policy and Canadian Privacy Law
Lead the management of all advertising and digital analytics platforms
Maintain quality, consistency and standard of data across marketing properties
Collaborate with various internal and external agency stakeholders to build data structures harmonized across both online and offline channels
Build and maintain connections between all data driven marketing platforms
Work with data science and business analysts to implement data layer strategies that allow SECA to do in depth campaign and audience reporting
Work with digital marketing, ecommerce and agency leads to ensure best practices are followed around tagging requirements
Partner with internal and external teams to perform data quality audits, QA tags and identify issues, including building improvement plans
Provide recommendations for improvement around platform configurations and tags
Work with developers to communicate what an implementation is designed to accomplish
Ensure the data collected and used follows key regulations including PIPEDA and GDPR

Activation & Analysis (60%)

Lead the audience segmentation strategy and execution and govern its use throughout digital marketing & CRM campaigns leveraging the appropriate modeling, planning and targeting tools – DMP, Facebook, Google Marketing Platform
Lead the democratization of audience based insights across the organization to help inform business strategy through regular cadence of updates and support
Provide the agency and Digital Team with audience lists and push to the DMP and other media buying platforms to support campaign execution
Recommend & support ingestion of new data as required
Work with the agency to create, maintain and activate traits and segments in the DMP as well as our media platforms to enable targeted media execution
Monitor segment sizes and match rates across platforms and build improvement plans as required
Clearly show how improving the data & audience strategy has translated into greater ROI across campaigns (i.e. through greater media efficiency)
Lead measurement and reporting for digital marketing team, including audience centric analysis, by building processes around campaign performance analysis, contributing to all phases of the campaign: planning & KPI development, targeting, campaign optimization and measuring and reporting
Work with internal and external partners to develop full funnel dashboards and standardized reports to provide ongoing insight and learnings
Develop presentations for daily, weekly, monthly and quarterly performance reviews with Digital, Marketing and Business teams, as well as external agencies
Work in close collaboration with internal digital, brand and insights teams and external agencies to create key performance indicators across paid, owned and earned media channels and ROI models for all campaigns
Partner with marketing team members to bring learnings and improvement plans forward to better inform future campaigns
Collaborate with NAHQ and HQ counterparts to both share and adopt best practices around reporting and dashboarding initiatives
Maintain working knowledge of industry best practices and changes in analytics tools, platforms and 3rd party data sources to help better inform insights
Effectively communicate ongoing work and successes achieved

Requirements:

Education:

Bachelor’s degree preferably in Marketing, Mathematics or Economics with an exceptional understanding of data analytics

Knowledge:

Well versed in technical aspects of mainstream media buying platforms, audience targeting capabilities, how related pixels and events work and key metrics for success
Strong analytical skills: must have a demonstrated track record of excellence in analytics
Strong affinity for learning new tools and systems: experience analyzing data from digital marketing channels such as Email, Paid Search, Display, and Social
Strong quantitative skills, with an ability to analyze and interpret complex sets of data
Strong Microsoft Excel skills, including pivot tables and chart creation
Familiarity with Microsoft PowerPoint, and experience developing insightful presentations
Detail-oriented, organized and able to work on multiple projects over the course of a day and accurately set expectations regarding timing and deliverables
Effective communicator via both written and spoken word
Proactive self-starter who is able to work independently
Demonstrated ability to think outside the box and take initiative to solve problems as they arise
Ability to make sound decisions in a timely manner based on the appropriate balance of data, by asking the right questions, at the right time, to uncover findings and drive relevant action
Naturally curious with sharp critical thinking skills
Excellent project management skills, a sense of urgency, with the ability to multi-task
Strong attention to detail

Experience:

5+ years’ experience managing media platforms & implementing customer segmentation strategies with a solid understanding of digital marketing measurement principles, methodologies and best practices
Hands on experience building and implementing large scale data and/or martech projects including data centralization and integration projects
Hands on experience working with Adobe Audience Manager and Google Marketing Platform
Experience managing marketing and consumer data, related tools and platforms
Experience working collaboratively as part of a cross-functional team
Experience working with marketing performance dashboards with tools such as PowerBI, Tableau, or Google Data Studio
Experience designing, implementing, and analyzing multivariate tests with tools such as Visual Website Optimizer, Adobe Target, or Google Optimize

Samsung is an equal employment opportunity employer.


Samsung has an accommodation process in place and provides accommodations for job applicants with disabilities as appropriate. Assessment and selection materials and procedures can be made available in accessible formats and methods as appropriate. If you require a specific accommodation because of disability or medical need, please let us know when selected to take part in our recruitment process so that reasonable arrangements can be made for the appropriate accommodations to be in place as you move through our process.


We thank you for your interest in working for Samsung. Only candidates selected for an interview will be contacted.


#LI-DJ1


#indhigh

Skills and Qualifications","Samsung Electronics
3.4",Mississauga
58,Data Scientist,"Our organization:
The Alberta Securities Commission is the industry-funded regulator responsible for administering the province's securities laws. It is entrusted with fostering a fair and efficient capital market in Alberta and with protecting investors. As a member of the Canadian Securities Administrators (CSA), the ASC works to improve, coordinate and harmonize the regulation of Canada's capital markets.

The Corporate Finance division is responsible for reviewing the disclosure included in prospectuses and other offering documents; reviewing continuous disclosure by issuers; formulating recommendations for the development of rules, regulatory instruments, policies, and legislative amendments.
The opportunity:
Reporting to the Manager, Compliance, Data & Risk, the Data Scientist will work with other members of the market intelligence team to provide analyses to the ASC divisions. You will have the opportunity to work with regulatory datasets and develop analyses to: help the ASC better understand our capital markets: support proactive compliance: and inform policy development. Analyses may require manipulating large or complex datasets and may require developing or enhancing existing databases. Projects are likely to vary over time, which will give the successful candidate an opportunity to use a variety of methodologies. Candidates should have an interest in learning about market developments and understanding the associated benefits and risks.
Key responsibilities include:
Working with other team members to define the problem or question being answered, identify the data to be used, and decide on an appropriate methodology.
Working with a variety of staff throughout the ASC.
Improving the usability of regulatory data sources.
Responding to ad-hoc requests for data analysis, ASC reports or publications.
Participating in analyses related to systemic and emerging risk for the CSA Systemic Risk Committee (which is led by the ASC) when required.
The ideal candidate will possess:
A degree in finance, economics, mathematics or the physical sciences. Graduate degree preferred.
Two - five years work experience as a Data Scientist.
Experience cleaning, transforming and visualizing large data sets.
Experience with econometrics, statistical models, machine learning or predictive modeling.
Proficiency with Python or R, SQL, and Tableau.
A self-motivated approach and enjoy finding solutions to problems.
Experience with kdb+/q is an asset.
Experience in the financial industry is an asset.
To apply:
Click the Apply For This Job button to submit your resume, cover letter and salary expectations by July 9, 2021. You will be contacted if you are selected for an interview. More information about working at the ASC including our comprehensive Total Rewards package can be found on our website at www.albertasecurities.com.","Alberta Securities Commission
3.6",Calgary
59,Data Scientist,"OPENTEXT - THE INFORMATION COMPANY

As the Information Company, our mission at OpenText is to create software solutions and deliver services that redefine the future of digital. Be part of a winning team that leads the way in Enterprise Information Management.

The Opportunity:
The AI Data Scientist will focus on business analysis, data analysis, and model building in support of the delivery of AI and Analytics to our OpenText teams. This individual will be a professional that is self-motivated and driven to accomplish company goals and who is comfortable multitasking in a fast-paced, dynamic environment.

You are great at:
Working with business teams in all parts of the business to gather conceptual business needs, translate them into clear functional business requirements
Create process models, diagrams, charts, PowerPoint presentations
Work with technical teams and/or study relational database tables to create Technical Data Requirements from the Business Requirements
Build data models in Python or R using a Magellan Notebook
Work with application support, product management, and engineering teams on quarterly upgrades and feature requests for Magellan product suite
Self-motivated and driven to accomplish company goals and who is comfortable multitasking in a fast-paced, matrixed environment
Perform data preparation, linkage, and feature selection
Calculating model accuracy
Reporting and visualizing results/insights
Provide end-user support and training as needed

What it Takes:
Bachelor’s degree in Computer Science, Engineering, Business or equivalent experience
5 + years of proven abilities related to data analysis, reporting, analytics, and data modeling
Experience working with data in databases
Experience with SQL, Python, and R
Excellent listening, interpersonal, written, and oral communication skills
Experience with OpenText Magellan preferred
Experience working in a complex, matrix, fast-paced environment
Attention to detail with emphasis on accuracy and quality
Ability to prioritize work to balance multiple projects and deadlines
The ability to work independently, as part of a team, and cross-functionally within the organization

At OpenText we understand and value diversity in our employees and are proud to be an Equal Opportunity Employer. We hire the best talent regardless of race, creed, color, national origin, ancestry, disability, marital status, sex, age, veteran status or sexual orientation. If you require accommodation at any time during the recruitment process please email accommodationrequests@opentext.com. Applicants have rights under Federal Employment Laws including but not limited to: Family and Medical Leave Act (FLMA) , Equal Employment Opportunity and Employee Polygraph Protection Act","opentext
3.5",Waterloo
60,Data Scientist,"OPENTEXT - THE INFORMATION COMPANY

As the Information Company, our mission at OpenText is to create software solutions and deliver services that redefine the future of digital. Be part of a winning team that leads the way in Enterprise Information Management.

The Opportunity:
The AI Data Scientist will focus on business analysis, data analysis, and model building in support of the delivery of AI and Analytics to our OpenText teams. This individual will be a professional that is self-motivated and driven to accomplish company goals and who is comfortable multitasking in a fast-paced, dynamic environment.

You are great at:
Working with business teams in all parts of the business to gather conceptual business needs, translate them into clear functional business requirements
Create process models, diagrams, charts, PowerPoint presentations
Work with technical teams and/or study relational database tables to create Technical Data Requirements from the Business Requirements
Build data models in Python or R using a Magellan Notebook
Work with application support, product management, and engineering teams on quarterly upgrades and feature requests for Magellan product suite
Self-motivated and driven to accomplish company goals and who is comfortable multitasking in a fast-paced, matrixed environment
Perform data preparation, linkage, and feature selection
Calculating model accuracy
Reporting and visualizing results/insights
Provide end-user support and training as needed

What it Takes:
Bachelor’s degree in Computer Science, Engineering, Business or equivalent experience
5 + years of proven abilities related to data analysis, reporting, analytics, and data modeling
Experience working with data in databases
Experience with SQL, Python, and R
Excellent listening, interpersonal, written, and oral communication skills
Experience with OpenText Magellan preferred
Experience working in a complex, matrix, fast-paced environment
Attention to detail with emphasis on accuracy and quality
Ability to prioritize work to balance multiple projects and deadlines
The ability to work independently, as part of a team, and cross-functionally within the organization

At OpenText we understand and value diversity in our employees and are proud to be an Equal Opportunity Employer. We hire the best talent regardless of race, creed, color, national origin, ancestry, disability, marital status, sex, age, veteran status or sexual orientation. If you require accommodation at any time during the recruitment process please email accommodationrequests@opentext.com. Applicants have rights under Federal Employment Laws including but not limited to: Family and Medical Leave Act (FLMA) , Equal Employment Opportunity and Employee Polygraph Protection Act","opentext
3.5",Waterloo
61,Data Scientist,"Bachelor's Degree
3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
2 years working as a Data Scientist
Experience in as many of the following areas: measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, descriptive analytics, and regression analysis.
Good understanding of supervised and unsupervised learning models
Amazon Advertising is one of Amazon's fastest growing and most profitable businesses. As a core product offering within our advertising portfolio, Sponsored Products (SP) helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through Amazon. The SP team's primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

As a Data Scientist on this team you will:

Solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ML models by tailoring to business needs, and collaborating with Scientists, Engineers, BIE's, and Product Managers.
Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers to produce the required data.
Deliver with independence on challenging large scale problems with ambiguity.
Manage and drive the technical and analytical aspects of Advertiser segmentation; continually advance approach and methods.
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytic capabilities, platforms, and pipelines.
Apply statistical or machine learning knowledge to specific business problems and data.
Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.
Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
Build decision-making models and propose solution for the business problem you defined
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Utilize code (python or another object oriented language) for data analyzing and modeling algorithms.
Why you love this opportunity
Amazon is investing heavily in building a world-class advertising business. This team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth
You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven fundamentally from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video https://youtu.be/zD_6Lzw8raE


PhD in Statistics, Economics or related quantitate field.
Experience in measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, manipulating data & analyzing very large data sets, descriptive analytics, and regression analysis.
Excellent quantitative modeling, good knowledge of ML methods, statistical analysis, and problem-solving skills.
Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data.
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences.
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Experience in advertising is a plus.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/ontario","AMZN CAN Fulfillment Svcs, ULC
3.8",Midtown Toronto
62,Data Scientist,"Data Scientist - ( 210001H9 )

Description

At Stantec, we approach every water, power and industrial process project we undertake—whether at the local, regional, or national level— thoughtfully, and execute it with excellence across all project phases. We partner with our clients to design fit-for-purpose solutions that address their communities’ unique needs throughout the related infrastructure lifecycle. Our experts lead their fields and guide our work with scientific rigor, an innovative spirit, and a vision for growth. We’re a place where you can apply your passion and collaborate with top talent on work that’s critical to our clients, our communities, and the industry at large.

Your Opportunity

Stantec’s Water group has an opportunity for an experienced data scientist who has worked with operational technologies.

Stantec is in the early stages of developing a digital platform to leverage our world class Water engineering a science subject matter expertise called Stantec Insight Analytics (SIA). SIA uniquely combines an analytics toolkit with Stantec’s subject matter expertise to enable transformational asset operation, management, and decision-making in Real Time. The successful candidate will aid with technical strategy, data science and engineering, and development within an Agile software development team.

Stantec’s Digital Solutions team works closely with project managers and clients to develop solutions that enable our clients to have top tier information access and analytics. This journey includes identifying, defining, and developing those products. Several product and service oriented solutions have been developed at version 1.0 and more are being defined. Our goal is to transform the water industry with best in class digital solutions. These solutions cover the complete project and water lifecycle, from planning to operations, and watershed management to wastewater treatment.

The Digital Solutions team is looking for an operational technology data scientist to complement the existing team in achieving our mission over the long term. The position will include performing both product and project consulting work. Responsibilities will include helping build out current and future digital solutions by designing and implementing data analysis techniques. This role requires the implementation of best practices in data science to meet project objectives using a code-based approach. Specifics in this role include defining data requirements to support project objectives, determining quality of input data, quantifying uncertainty of results, and designing traditional and machine learning based approaches for analysis. We are specifically looking for candidates that have worked in industrial, automation, instrumentation, or similar operational technology fields working with control systems. Candidates with experience with Microsoft Azure, streaming analytics, machine learning, and application development are preferred for this position.

Your Key Responsibilities

Support the Stantec Digital Solutions team in developing top tier digital solutions. This requires some travel to attend meetings with clients
Work with remote teams for development and implementation as needed for a variety of digital solutions for analytical dashboards and interfaces. Focus on implementing best practices and developing for reusability
Automating data collection and ETL workflows
Data analytics to generate recommended actions
Ability to understand storyboards, wireframes, and simple prototypes; and, how to develop them into real solutions
Ability to communicate and coordinate with other team members to complete project tasks to meet specific deadlines
You will be receiving direction from Digital Solution leadership in various locations and technical support from remote locations
Candidates must be well organized, self-motivated, and enjoy finding solutions to problems

Qualifications

Capabilities and Credentials

Can work well in a team environment without direct supervision and ability to productively work from home
Possess a hard-working and positive attitude
Ability to participate and collaborate in project team setting and to engage in creative and critical thought
Possesses excellent time-management skills, thorough understanding of task assignment and schedule, budgeting and efficient use of time and available resources
Possess strong interpersonal and communication skills, both written and verbal, along with the ability to prioritize multiple tasks
Ability to design and implement reusable data analysis techniques based on requirements, specifications, or prototypes
Experience working with operational technologies in an industrial, automation, or water treatment context is a must. This includes working with data sets from industrial control systems such as SCADA, PLCs, and DCS
Experience with at least one business intelligence platform such as Microsoft Power BI or Tableau
Experience working with web-based APIs using JSON or XML objects
Experience with machine learning libraries such as TensorFlow and resources such as Azure Machine Learning
Experience with streaming data analytics
Experience with big data tools such as Hadoop, Spark, or DataBricks
Experience working with location data and maps is preferred
Experience with Python, R, or SCALA is preferred
Experience using Azure DevOps is preferred
Experience working in a consultant role is preferred

Education and Experience

Computer Science or Engineering related Bachelor’s degree from an accredited institution. Minimum of 8 years of experience.

Typical office environment working with computers and remaining sedentary for long periods of time. Field work may include exposure to the elements including inclement weather.

This description is not a comprehensive listing of activities, duties or responsibilities that may be required of the employee and other duties, responsibilities and activities may be assigned or may be changed at any time with or without notice.

Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best.

Primary Location : Canada-British Columbia-Burnaby

Other Locations : Canada-Alberta-Calgary, Canada-British Columbia-Vancouver, Canada-Alberta-Edmonton

Job : Applications Development

Organization : BC-1117 Water-CA British Columbia

Employee Status : Regular

Job Level : Manager

Travel : Yes, 10 % of the Time

Schedule : Full-time

Job Posting : Jun 11, 2021, 9:55:03 AM

Req ID: 210001H9

Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","Stantec
3.8",Vancouver
63,Data Scientist,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Calling on a Data Scientist who can seamlessly combine tech know-how with business acumen to go from a promising ML experiment to a shipped product, with real-world impact.

You will join the Canadian Advanced Analytics team delivering decision support and insight to our Insurance Sales team. You will have dual reporting into Advanced Analytics and the sales organization to ensure that you are plugged into the data science community while staying close to our business needs. You will develop and implement analytics enabled solutions to improve business process, generate insights, support business goals, strategy development, and measure the impact of this work.

You must have technical skills in both data and software development. There are 3 core skills we are looking for:

Solid foundation in Data science techniques and concepts

In-depth coding knowledge of in Python and structured data (SQL)

Able to communicate insights that the business can interpret and execute on and drive adoption.

A true greenfield opportunity, you will join the team as we embark on cloud native architecture.

Key Accountabilities

Build end-to-end machine learning solutions to solve complex customer problems

Working in collaboration with Canadian Insurance Sales business to plan, scope, implement and sustain predictive analytics solutions

Focus on Feature Engineering, Model Training and Model Evaluation in addition to data munging / wrangling

Identify the right algorithms and statistical techniques for a specific project as well as the best features for a model.

Make business recommendations with effective presentations of findings at multiple levels of stakeholders including division heads.

Develop measurements and feedback systems

Mentor associates and peers on Data Science best practices

Key Experiences:

2+ years working experience in developing and implementing data science techniques (predictive, prescriptive with proficiency in Python

Advanced working SQL knowledge and experience working with relational databases and SQL

Comfortable writing complex SQL queries to extract and integrate data from multiple database sources

Working knowledge of Salesforce will be an asset

Minimum 1 year of experience in basic software development practices (git, code scan, modular code development) the last 2 years

Experience working with cloud native architecture (PaaS) using Azure stack preferably and experience with Azure ML will be an asset.

Experience with deep learning methodologies either in practice or in academia

Effective and concise oral and written storytelling and insights communication skills

Ability to work on multiple projects in parallel while managing constantly changing deadlines and priorities

Ability to document work and effectively prioritize documentation

BSc/M.S. in a statistical, mathematical, or technical field (i.e., computer science) or equivalent experience

Nice to have

Past experience in distributor-based sales for life insurance /wealth management products, or other financial services industry (e.g., retail banking, credit card, property and casualty insurance)



If you are ready to unleash your potential, it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. As of December 31, 2020, we had $1.3 trillion (US$1.0 trillion) in assets under management and administration, and in the previous 12 months we made $31.6 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an Equal Opportunity Employer

At Manulife /John Hancock , we embrace our diversity. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex (including pregnancy and pregnancy-related conditions), sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will work with applicants who request a reasonable accommodation during the application process . All information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and Manulife/John Hancock policies . To request a reasonable accommodation in the application process, contact recruitment@manulife.com .","Manulife
4.0",Midtown Toronto
64,Data Scientist,"Ready to create innovative solutions and best practices?
Join our team

Have you ever dreamed about building an AI-driven technologically advanced platform capable of helping millions of people and changing their lives for the best? If so, your dream will come true with us!
TELUS is looking for a passionate and talented Data Scientist to join a highly skilled and dynamic Advanced Analytics team. In this role, you will be a key contributor to our next generation Demand Forecasting, and Customer Behavioral & Customer Intents Prediction models.
You will create the most advanced Machine Learning solutions to enable various stakeholders to better anticipate TELUS’ customers needs and help them meet customers’ inquiries in advance.
Customer Experience AI, Data & Analytics Spotlight:
Our team works in a fun, innovative and challenging environment that directly influences the strategic direction and performance of the Customer Experience business
Our teams are responsible for the Demand Forecasting, Customer Intents and Behavioral Prediction, as well as Performance Analytics
We work closely with our stakeholder teams to deliver on our strategic objectives; our key stakeholders and partners include Operations, Marketing, Finance, and Technology Transformation and more
We provide opportunities for you to excel and show your stuff: work on high value and high visibility projects
We have flexible work styles with the ability to work in and out of the office
You will work in a team that actively supports your personal development with progressive training and development tools.

Here’s the impact you’ll make and what we’ll accomplish together
As a Data Scientist, you’re in great company, working alongside some of the brightest and creative Data Scientists, Data Engineers and Data Analysts. You will be part of the journey that brings us to a better understanding of our customers, in order to predict their needs and interaction behaviour.
With your expert knowledge and experience in Machine Learning, you will contribute to the development of state of the art ML & AI driven solutions such as demand forecasting, customer intents prediction and customer behaviour models.
Here's how
Lead the development and implementation of ML & AI and Big Data solutions including predictive modelling, customer impact assessments, etc
Support and evolve the Advanced Analytics and Data Management roadmap by leveraging industry research, best practices and emerging tools/technology
Execute, oversee, and evolve models and algorithms selection to deliver solutions that are relevant and facilitate decision making
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities
Identify opportunities for process/model optimization and refine to improve effectiveness/accuracy and enhance ROI
Collaborate with Data Scientists and Data Engineers within TELUS as well as external Data Science communities

Qualifications
You're the missing piece of the puzzle
You are recognized for addressing business needs via your application of data mining and analysis, predictive modeling, statistics and other advanced analytical techniques
You are sought out for your skills in Machine Learning (Supervised and Unsupervised), Classification, Clustering, Segmentation, Time Series Analysis, NLP, Demand Forecasting and Optimization, with 5 or more years of practical business experience in the above areas
You are capable of delivering technical and complex concepts in a way that is understood by non-technical audiences
You have solid development experience with Python and you are comfortable using various data science libraries such as Scikit-learn, Pandas, Numpy as well as frameworks like TensorFlow, Pytorch, Keras
You are comfortable with Jupyter environment and infrastructure, as well as know what GitHub, Spyder/PyCharm are
You possess advanced knowledge in SQL
You are familiar with at least one of the cloud computing platforms - GCP, AWS, Azure
You are well versed in software and AI development lifecycles
You are a collaborative, creative, open-minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ML-driven models through an iterative approach
Great-to-haves
Masters or PhD degree in a quantitative field such as Math, Statistics, Computer Science, Economics, or Data Science
Data visualization experience: Data Studio, Tableau, PowerBI, Domo
Data environments experience: MS SQL, Oracle
G-Suite experience
Experience with agile methodology and team-based software development workflows (e.g. JIRA)
A bit about us
Our business is connecting Canadians. Our social impact is using our world-leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. When you join our team, you’re helping us make the future friendly. We’re committed to diversity and equitable access to employment opportunities based on ability — your unique contributions and talents will be valued and respected here.

Primary Location: CA-AB-Calgary
Other Locations: CA-AB-Edmonton

Schedule: Full-time","TELUS
3.9",Calgary
65,Data Scientist,"Ready to create innovative solutions and best practices?
Join our team

Have you ever dreamed about building an AI-driven technologically advanced platform capable of helping millions of people and changing their lives for the best? If so, your dream will come true with us!
TELUS is looking for a passionate and talented Data Scientist to join a highly skilled and dynamic Advanced Analytics team. In this role, you will be a key contributor to our next generation Demand Forecasting, and Customer Behavioral & Customer Intents Prediction models.
You will create the most advanced Machine Learning solutions to enable various stakeholders to better anticipate TELUS’ customers needs and help them meet customers’ inquiries in advance.
Customer Experience AI, Data & Analytics Spotlight:
Our team works in a fun, innovative and challenging environment that directly influences the strategic direction and performance of the Customer Experience business
Our teams are responsible for the Demand Forecasting, Customer Intents and Behavioral Prediction, as well as Performance Analytics
We work closely with our stakeholder teams to deliver on our strategic objectives; our key stakeholders and partners include Operations, Marketing, Finance, and Technology Transformation and more
We provide opportunities for you to excel and show your stuff: work on high value and high visibility projects
We have flexible work styles with the ability to work in and out of the office
You will work in a team that actively supports your personal development with progressive training and development tools.

Here’s the impact you’ll make and what we’ll accomplish together
As a Data Scientist, you’re in great company, working alongside some of the brightest and creative Data Scientists, Data Engineers and Data Analysts. You will be part of the journey that brings us to a better understanding of our customers, in order to predict their needs and interaction behaviour.
With your expert knowledge and experience in Machine Learning, you will contribute to the development of state of the art ML & AI driven solutions such as demand forecasting, customer intents prediction and customer behaviour models.
Here's how
Lead the development and implementation of ML & AI and Big Data solutions including predictive modelling, customer impact assessments, etc
Support and evolve the Advanced Analytics and Data Management roadmap by leveraging industry research, best practices and emerging tools/technology
Execute, oversee, and evolve models and algorithms selection to deliver solutions that are relevant and facilitate decision making
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities
Identify opportunities for process/model optimization and refine to improve effectiveness/accuracy and enhance ROI
Collaborate with Data Scientists and Data Engineers within TELUS as well as external Data Science communities

Qualifications
You're the missing piece of the puzzle
You are recognized for addressing business needs via your application of data mining and analysis, predictive modeling, statistics and other advanced analytical techniques
You are sought out for your skills in Machine Learning (Supervised and Unsupervised), Classification, Clustering, Segmentation, Time Series Analysis, NLP, Demand Forecasting and Optimization, with 5 or more years of practical business experience in the above areas
You are capable of delivering technical and complex concepts in a way that is understood by non-technical audiences
You have solid development experience with Python and you are comfortable using various data science libraries such as Scikit-learn, Pandas, Numpy as well as frameworks like TensorFlow, Pytorch, Keras
You are comfortable with Jupyter environment and infrastructure, as well as know what GitHub, Spyder/PyCharm are
You possess advanced knowledge in SQL
You are familiar with at least one of the cloud computing platforms - GCP, AWS, Azure
You are well versed in software and AI development lifecycles
You are a collaborative, creative, open-minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ML-driven models through an iterative approach
Great-to-haves
Masters or PhD degree in a quantitative field such as Math, Statistics, Computer Science, Economics, or Data Science
Data visualization experience: Data Studio, Tableau, PowerBI, Domo
Data environments experience: MS SQL, Oracle
G-Suite experience
Experience with agile methodology and team-based software development workflows (e.g. JIRA)
A bit about us
Our business is connecting Canadians. Our social impact is using our world-leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. When you join our team, you’re helping us make the future friendly. We’re committed to diversity and equitable access to employment opportunities based on ability — your unique contributions and talents will be valued and respected here.

Primary Location: CA-AB-Calgary
Other Locations: CA-AB-Edmonton

Schedule: Full-time","TELUS
3.9",Calgary
66,Senior Clinical Scientist - Oncology - Home Based,"We believe that our people are the future of the industry. We provide a culture in which our employees can enjoy personal satisfaction, professional achievement and have the ability to strategically map out long-term career plans. If you're ready to be a part of something inspiring join us and Discover Your PRA.

Who are we?

We Are PRA.

We are 20,000 employees strong, operating in more than 90 countries. We are committed to saving lives and we are constantly striving to be the best at what we do. Our impact is real and we see it every single day. We are getting life saving drugs into the hands of those who need them most.

Who are you?
You are a leader that isn’t afraid to delegate, but also isn’t afraid to get your hands dirty. You look for new and innovative ways to problem solve. You are the ultimate planner and coordinator and are an excellent communicator. You have a serious passion for clinical development. You never settle for what is, but are always pushing clinical development forward to what it could be. You motivate others to do the same. Most of all, you want to do it in a place where you’re more than an employee number. A place you love working.

Still here? Good. Because if this is you, we’d really like to meet you.
The Sr Clinical Scientist will be accountable for the clinical/scientific execution of the clinical protocol.
Responsibilities

What you will be doing:
May lead or support a study or studies, depending on size/complexity. If lead, accountable for the clinical/scientific execution of the protocol.
As lead, will be responsible for the following:
Clinical point of contact for scientific issues/questions for internal and external stakeholders (e.g., IRB, sites)
Responsible for trial design and endpoint development in collaboration with CD
Leads the Medical Monitoring (MM) team in performing MM activities, including development of the Medical Monitoring Plan (MMP) and review of SAE reports
Sets up/supports SAC, DMC, adjudication committees
Protocols/amendments – collaborates with medical writer, participates in governance committee review
Authors protocol clarification letters
Contributor to study specific documents (e.g., SMP)
Reviews/updates informed consent
Provides scientific input to SM for data management activities (e.g., EDC, DRP, CRFs)
Monitors data issues requiring clinical input
Monitors central lab reports and other external data for safety and critical values
Prepares scientific slides, attends and presents protocol information at Investigator Meeting
Scientific lead on Clinical Trial Team (CTT)
Reviews specs, initiates allocation (randomization) request form and approval schedule in allocation schedule generation system
Coordinates planning of lab, bio specimens and imaging specifications
Co- authors newsletters with SM
Participates in Database lock activities Collaboratively plans CSRs, CTDs/WMAs with medical writing
Supports publications/presentations as needed
Reconciles and review all protocol deviation classifications in SPECTRUM
Assesses and prepares protocol deviation list for CSR
Collaborates with medical writing to develop trial results communication for investigators
Provides scientific assessment for Operational Reviews
Supports SM/MW activities as needed to achieve CTT deliverables.
Provides clinical specifications to SM to support interactions with external vendors (e.g., IVRS, ePRO)
May act as mentor to other CSs
Qualifications
What you need to have:

Educational Requirements
BS/BA in Life Sciences with 7+ yrs clinical research experience
MS/PhD in Life Sciences with 5+ years clinical research experience
If no degree in Life Sciences, must have significant experience in clinical development (>11 years)
Minimum Years of Experience
Minimum 2 years pharmaceutical experience with demonstrated leadership responsibilities required.
Medical monitoring experience required
Oncology experience required
Excellent Excel and PP skills required
Excellent written and oral communication skills
Ability to travel up to 15% (might include international travel)
To qualify, applicants must be legally authorized to work in the Canada or US, and should not require, now or in the future, sponsorship for employment visa status
Position based remote in US or Canada

PRA is an EEO/AA employer and is committed to providing opportunities to minorities, women, veterans and individuals with disabilities.


Options
Apply for this job onlineApply
Share
Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.
Share on your newsfeed
Connect With Us!","PRA Health Sciences
4.0",Remote
67,Data Scientist,"The CTC Personalization & Customer Analytics team is the central hub for engaging consumers with exciting and inspirational loyalty and product offers through better use of customer data, driving incremental sales and profit.

The Promo Analytics and Operations team is accountable for creating a high performance, cross-banner, silo-free source of all customer data enabling quick and efficient customer insights, audience creation, customer journey analyses and advanced customer modelling.

The Data Scientist role provides technical leadership in all facets of the project, from selecting key customer features and interactions to ensuring accurate data blending to deriving new customer attributes through descriptive and predictive analytics through a deep understanding of applying the data science lifecycle to customer modelling. The Data Scientist will be the subject matter expert in combining customer-related data sources, collaborating with teams that produce customer insights, deploy unique personalized offers directly to customers and developing other customer data products.

The dynamic environment requires individuals with a cross functional background, excellent organizational skills, experience working in an agile project environment, advanced analytical ability, strong communication skills to deal effectively with stakeholders and the ability to work effectively in a team as well as independently.

The primary responsibilities of the Data Scientist include:

Efficiently and accurately integrate customer data from a variety of organizational systems.
Derive customer attributes and intents through novel uses of the data at hand and models to describe and predict customer behaviour, as well as a deep understanding of customer behaviour.
Ensure generated insights meet standards of analytical and statistical rigour, highlighting gaps where necessary.
Provide mentorship to team members on data, code, and data science best practices.
Lead the creation of efficient, cost-effective high-availability pipelines.
Work with IT teams to ensure that project needs are met in the next generation of CTC data platforms.
Provide ad hoc analytics and recommendations for action as needed.

Qualifications:

Professional

Post-Secondary Education at the Master’s level, with 2-5 years experience in a business environment.
Extensive knowledge of statistics, predictive analytics and data science techniques to improve customer understanding through creative problem solving and modelling.
Experience leading analytical projects with iterative improvement in a fast-paced environment.
Ability to understand what data means about a customer.

Technical

Strong familiarity with statistical modeling tools and data science libraries. Python & SQL are required.
Experience building dashboards and visualizations in Enterprise-grade BI tools.
Good working knowledge of relational and non-relational databases in big data (Hive, BigQuery, SnowFlake) and/or cloud environments (GCP, Azure).
Intermediate knowledge of standard desktop tools such as Excel and PowerPoint

Interpersonal

Provides a positive influence and excels in a fast-paced team environment with the ability to take on leadership responsibilities while embracing and driving innovative solutions that improve the performance of the team.
Advanced written and verbal communication skills.
Strong interpersonal skills with the ability to embrace and action constructive feedback positively.
Exceptional attention to detail.

Strong ability to:

Work with complex and evolving systems and extensive and varied data.
Manage changing/conflicting priorities and make effective decisions quickly.
Adapt to rapid and continuous change to project requirements and priorities.
Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. CTR Marketing
Ontario-Toronto
Permanent
Full-time
Job Posting
: Jun 21, 2021, 10:42:38 AM","Canadian Tire
3.8",Midtown Toronto
68,Data Scientist,"The CTC Personalization & Customer Analytics team is the central hub for engaging consumers with exciting and inspirational loyalty and product offers through better use of customer data, driving incremental sales and profit.

The Promo Analytics and Operations team is accountable for creating a high performance, cross-banner, silo-free source of all customer data enabling quick and efficient customer insights, audience creation, customer journey analyses and advanced customer modelling.

The Data Scientist role provides technical leadership in all facets of the project, from selecting key customer features and interactions to ensuring accurate data blending to deriving new customer attributes through descriptive and predictive analytics through a deep understanding of applying the data science lifecycle to customer modelling. The Data Scientist will be the subject matter expert in combining customer-related data sources, collaborating with teams that produce customer insights, deploy unique personalized offers directly to customers and developing other customer data products.

The dynamic environment requires individuals with a cross functional background, excellent organizational skills, experience working in an agile project environment, advanced analytical ability, strong communication skills to deal effectively with stakeholders and the ability to work effectively in a team as well as independently.

The primary responsibilities of the Data Scientist include:

Efficiently and accurately integrate customer data from a variety of organizational systems.
Derive customer attributes and intents through novel uses of the data at hand and models to describe and predict customer behaviour, as well as a deep understanding of customer behaviour.
Ensure generated insights meet standards of analytical and statistical rigour, highlighting gaps where necessary.
Provide mentorship to team members on data, code, and data science best practices.
Lead the creation of efficient, cost-effective high-availability pipelines.
Work with IT teams to ensure that project needs are met in the next generation of CTC data platforms.
Provide ad hoc analytics and recommendations for action as needed.

Qualifications:

Professional

Post-Secondary Education at the Master’s level, with 2-5 years experience in a business environment.
Extensive knowledge of statistics, predictive analytics and data science techniques to improve customer understanding through creative problem solving and modelling.
Experience leading analytical projects with iterative improvement in a fast-paced environment.
Ability to understand what data means about a customer.

Technical

Strong familiarity with statistical modeling tools and data science libraries. Python & SQL are required.
Experience building dashboards and visualizations in Enterprise-grade BI tools.
Good working knowledge of relational and non-relational databases in big data (Hive, BigQuery, SnowFlake) and/or cloud environments (GCP, Azure).
Intermediate knowledge of standard desktop tools such as Excel and PowerPoint

Interpersonal

Provides a positive influence and excels in a fast-paced team environment with the ability to take on leadership responsibilities while embracing and driving innovative solutions that improve the performance of the team.
Advanced written and verbal communication skills.
Strong interpersonal skills with the ability to embrace and action constructive feedback positively.
Exceptional attention to detail.

Strong ability to:

Work with complex and evolving systems and extensive and varied data.
Manage changing/conflicting priorities and make effective decisions quickly.
Adapt to rapid and continuous change to project requirements and priorities.
Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience. CTR Marketing
Ontario-Toronto
Permanent
Full-time
Job Posting
: Jun 21, 2021, 10:42:38 AM","Canadian Tire
3.8",Midtown Toronto
69,"Data Scientist, Memberships Modelling","Since being founded in 2011, Prodigy Education has grown from 3,000 local users to more than 100 million registered users worldwide. As one of the fastest-growing EdTech startups in North America, Prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. Anyone with an internet connection is welcome to create a free account for Prodigy’s popular Math Game for grades 1 to 8. Prodigy Education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. For more information visit www.prodigygame.com.

Our passion is our mission - to help every student in the world love learning!

Our Data team is scaling rapidly as we continue to hit our product and growth milestones! The work you do will aid the educational advancement of millions of students. You will have the chance to apply your analytics skills to not only help kids learn but also help our product and leadership teams to make better decisions.
We are looking for a modelling and ML expert to join our growing team. You will have the chance to apply your data analysis, modelling, and coding skills to help our Data, Finance, and Executive teams better understand our business and build the best possible company strategy. You will develop advanced models to analyze our paid memberships, and empower all teams with actionable insights on user conversion, churn, and engagement.
Your Impact:
Work with stakeholders, data scientists, and developers to create useful models to analyze our paid memberships.
Leverage data analytics and quantitative analysis to monitor the model's performance and identify new features to improve KPIs.
Develop a deep understanding of our internal and external users to identify how our models can help solve their pain points.
Iterate upon successful MVPs to ensure the user-experience and code quality matches our internal standards.
Collaborate with key cross-departmental stakeholders to maintain technical product roadmaps, prioritize requests, and ensure that business goals are being met.
Effectively scope projects so that they are lean, but also add enough value to validate your hypotheses and meet business needs.
Help our teams explore and understand our business and our users.
Design and develop a variety of metrics and models to inform the impact of company activities and lines of business.
Work on a variety of giant datasets, from their development and manipulation to visualizing them via polished dashboards.
Communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non-technical backgrounds.
Who You Are:
At least 3 years demonstrated experience with data science and modelling.
Specific experience delivering revenue-related models which leverage analytics and machine learning
Good written and verbal communication skills with the ability to present a strong rationale for product decisions
Applied computational and mathematical model builder.
Expert skills and knowledge of SQL and Python programming languages.
Demonstrated application of model-building and analytics to financially-relevant problems.
A team and customer centric mindset.
Passion for solving hard problems and building a great technical product, balancing speed and depth for greatest value.
Experience in business requirements analysis, design, implementation, and testing of solutions.
Ability to break down large projects into manageable tasks, and leverage agile methodologies such as Scrum and Kanban
Experience using analytics and user research to add significant value to a product
Expertise in working with BI platforms.
Ability to oversee and work simultaneously on different projects with a variety of timelines.
Willingness to learn and work in a hyper-growth company
Love for our mission of helping kids everywhere enjoy learning.


Our Core Technologies:
SQL & Python
Data-related technologies such as data lakes and warehouses, Spark, Databricks, and similar cloud services
Bonus Points For:
Degree(s) in Engineering, Computer Science, Stats, Mathematics, or related disciplines.
Demonstrated ability to solve hard mathematical, algorithmic, and statistical problems.
Expertise in forecasting, time series analysis, user segmentation, financial modelling, and analyzing Stripe or similar transaction data.
Experience working with cloud platforms like AWS, GCP, Databricks.
Experience working with A/B testing and experimentation, and applying statistical concepts.
Significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship.
Experience in the ed tech or SaaS industry
Previous experience scaling in a startup environment
What We Offer:
A culture of transparency, where team members are involved in important conversations
Full health benefits from day one (1) for you and your family, fully covered!
We are a profitable company, with eligibility to participate in stock options for all full-time permanent employees
Learning and development budget for all full time employees to use towards career growth and development opportunities
We recognize 9-5 is not for everyone! We offer flexible working hours that will allow you to schedule your work day with a bit more freedom!

While we operate 100% remotely for the time being, we understand the importance of togetherness. We offer frequent and fun team and company events, to stay connected and in the know.

Please note: During the Covid-19 pandemic, in order to keep all our candidates and team members safe, Prodigy is operating, hiring and onboarding 100% remotely for the time being.

Come as you are. We believe the power of our collective potential will transform education. We are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. We welcome applications from people from all underrepresented groups, including (but not limited to) people of any gender, age, or religion, members of the LGBTQIA2+ community, BIPOC and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of Prodigy Education. If you feel like you don’t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we’d still love for you to apply!

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Education will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require accommodation, please notify us and we will work with you to meet your needs.","Prodigy Game
4.8",Oakville
70,"Data Scientist, Memberships Modelling","Since being founded in 2011, Prodigy Education has grown from 3,000 local users to more than 100 million registered users worldwide. As one of the fastest-growing EdTech startups in North America, Prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. Anyone with an internet connection is welcome to create a free account for Prodigy’s popular Math Game for grades 1 to 8. Prodigy Education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. For more information visit www.prodigygame.com.

Our passion is our mission - to help every student in the world love learning!

Our Data team is scaling rapidly as we continue to hit our product and growth milestones! The work you do will aid the educational advancement of millions of students. You will have the chance to apply your analytics skills to not only help kids learn but also help our product and leadership teams to make better decisions.
We are looking for a modelling and ML expert to join our growing team. You will have the chance to apply your data analysis, modelling, and coding skills to help our Data, Finance, and Executive teams better understand our business and build the best possible company strategy. You will develop advanced models to analyze our paid memberships, and empower all teams with actionable insights on user conversion, churn, and engagement.
Your Impact:
Work with stakeholders, data scientists, and developers to create useful models to analyze our paid memberships.
Leverage data analytics and quantitative analysis to monitor the model's performance and identify new features to improve KPIs.
Develop a deep understanding of our internal and external users to identify how our models can help solve their pain points.
Iterate upon successful MVPs to ensure the user-experience and code quality matches our internal standards.
Collaborate with key cross-departmental stakeholders to maintain technical product roadmaps, prioritize requests, and ensure that business goals are being met.
Effectively scope projects so that they are lean, but also add enough value to validate your hypotheses and meet business needs.
Help our teams explore and understand our business and our users.
Design and develop a variety of metrics and models to inform the impact of company activities and lines of business.
Work on a variety of giant datasets, from their development and manipulation to visualizing them via polished dashboards.
Communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non-technical backgrounds.
Who You Are:
At least 3 years demonstrated experience with data science and modelling.
Specific experience delivering revenue-related models which leverage analytics and machine learning
Good written and verbal communication skills with the ability to present a strong rationale for product decisions
Applied computational and mathematical model builder.
Expert skills and knowledge of SQL and Python programming languages.
Demonstrated application of model-building and analytics to financially-relevant problems.
A team and customer centric mindset.
Passion for solving hard problems and building a great technical product, balancing speed and depth for greatest value.
Experience in business requirements analysis, design, implementation, and testing of solutions.
Ability to break down large projects into manageable tasks, and leverage agile methodologies such as Scrum and Kanban
Experience using analytics and user research to add significant value to a product
Expertise in working with BI platforms.
Ability to oversee and work simultaneously on different projects with a variety of timelines.
Willingness to learn and work in a hyper-growth company
Love for our mission of helping kids everywhere enjoy learning.


Our Core Technologies:
SQL & Python
Data-related technologies such as data lakes and warehouses, Spark, Databricks, and similar cloud services
Bonus Points For:
Degree(s) in Engineering, Computer Science, Stats, Mathematics, or related disciplines.
Demonstrated ability to solve hard mathematical, algorithmic, and statistical problems.
Expertise in forecasting, time series analysis, user segmentation, financial modelling, and analyzing Stripe or similar transaction data.
Experience working with cloud platforms like AWS, GCP, Databricks.
Experience working with A/B testing and experimentation, and applying statistical concepts.
Significant accomplishments that required both technical and strategic capabilities, such as research projects, open source software contributions, and entrepreneurship.
Experience in the ed tech or SaaS industry
Previous experience scaling in a startup environment
What We Offer:
A culture of transparency, where team members are involved in important conversations
Full health benefits from day one (1) for you and your family, fully covered!
We are a profitable company, with eligibility to participate in stock options for all full-time permanent employees
Learning and development budget for all full time employees to use towards career growth and development opportunities
We recognize 9-5 is not for everyone! We offer flexible working hours that will allow you to schedule your work day with a bit more freedom!

While we operate 100% remotely for the time being, we understand the importance of togetherness. We offer frequent and fun team and company events, to stay connected and in the know.

Please note: During the Covid-19 pandemic, in order to keep all our candidates and team members safe, Prodigy is operating, hiring and onboarding 100% remotely for the time being.

Come as you are. We believe the power of our collective potential will transform education. We are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. We welcome applications from people from all underrepresented groups, including (but not limited to) people of any gender, age, or religion, members of the LGBTQIA2+ community, BIPOC and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of Prodigy Education. If you feel like you don’t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we’d still love for you to apply!

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Education will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require accommodation, please notify us and we will work with you to meet your needs.","Prodigy Game
4.8",Oakville
71,Data Scientist / Machine Learning Expert,"THIS IS AN IMMEDIATE VACANCY. WE ARE LOOKING FOR TEAM MEMBERS WHO CAN JOIN US IMMEDIATELY AND WORK 35 HOURS A WEEK. FLEXIBLE SCHEDULE POSSIBLE. ALL WORK IS REMOTE.

We are looking for an enthusiastic and self-motivated addition to our growing Engineering team. The position offers a unique opportunity to be part of a small, fast-growing, challenging environment, that takes on Financial Literacy and Entrepreneurship education around the world.

Responsibilities:

You’ll be working with frontend and backend engineers building company projects
Build end-to-end machine learning solutions to solve complex customer problems
Working closely with Infrastructure architects to design scalable and cost-effective solutions
Develop measurements and feedback systems

Requirements:

A degree in computer science, statistics, or related fields
School transcript required
Strong math and statistics background
High proficiency in Python
Familiarity with Django, Algorithmic trading, or JavaScript
Mandated by the Government to hire only Canadian Citizens or PR Card Holders under the age of 30.

If you're passionate about data science, and are eager to learn and grow, please apply!

Contract length: 10 months

Part-time hours: 35 per week

Job Types: Part-time, Contract

Salary: $18.00 per hour

Benefits:

Work from home

Schedule:

Day shift

Education:

Bachelor's Degree (preferred)

Experience:

Data Mining: 1 year (required)
Statistics: 1 year (required)
Machine Learning: 1 year (required)

Language:

English (required)

Licence/Certification:

Canadian Citizenship or PR Card and you are under 30 (required)

Work remotely:

Yes",Toronto Explore & Learn,Midtown Toronto
72,Data Scientist,"Job Summary
Define, develop and lead a data science program which identifies exploitation opportunities, and provides solutions and capabilities to address them.
Conduct research and recommend potential initiatives to analysts, and branch management and senior executive staff.
Autonomously find, enrich, transform, interpret, and exploit data to create intelligence products.
Act as a Service representative on joint projects related to data science and participate in collaborative efforts where applicable.
Provide mentorship and guidance to fellow Data Scientists and Data Exploitation Analysts, regarding intelligence analysis and associated activities pursued in response to the mandate.
Recommend new data exploitation projects in annual work plans by identifying analytical gaps and suitable solutions.
Regularly update knowledge of academic and industry data science practices and standards.
Effectively communicate and present findings to specialists, management and non-technical audiences. Clearly document methodologies employed in research and data exploitation solutions.
Education

Undergraduate degree in:

Mathematics
Statistics
Computer Science
Computer Engineering
Field of study related to data analytics

The educational program must be from an accredited learning institution recognized in Canada.

If you completed a program outside of Canada you will be required to obtain proof of a Canadian equivalency at your expense through a recognized credential assessment service.

Note: Any higher level of education could be recognized as experience.

Experience
Undergraduate degree and seven (7) years of experience

The candidate must possess seven (7) years of experience in data science, data analytics or data mining. Please note that out of the seven (7) years of relevant experience required, at least four (4) years must have been gained in data science specifically.
The candidate must possess recent and significant experience in the following:

Experience performing complex data exploitation on large volumes of data to provide tactical and strategic insights directly to analysts, business owners, and decision makers.
Experience gathering requirements and identifying opportunities to apply data science towards business objectives.
Experience prototyping and developing data exploitation capabilities using Python, in a Jupyter environment.
Experience visualizing analytics, writing reports, producing functional notebooks, and designing and delivering presentations.
Experience working with one or more of the following technologies: TensorFlow, PyTorch, Spark, Scala.

Candidates must also possess recent and significant experience in at least two (2) of the following:

Experience with supervised and unsupervised machine learning.
Experience in the creation and implementation of algorithms and statistical techniques to resolve data science problems.
Experience with text analytics and natural language processing (NLP).
Experience in the design, creation, and implementation of graph analytics.
Experience with complex data processing for time series and patterns of life analyses.

Recent experience is defined as experience acquired within the last five (5) years.

Significant experience is defined as the depth and breadth of experience that would normally be acquired by a person in a position where the performance of these duties constitutes his or her main functions over that period of time.

Competencies
Communication
Initiative
Innovation
Creativity
Ingenuity
Analytical skills
Coaching
Conditions of Employment

Not Applicable

Notes

The majority of work in our organization must be done in the office and cannot be performed at home.

A written exam will be administered. If successful, you will be invited to an interview. The exam will serve to evaluate your technical knowledge as it pertains to the position.


Reference Links
Salary Grade Breakdown

Security Requirements
Candidates must be eligible to receive an Enhanced Top Secret security clearance. The process involves a security interview, a polygraph, and a background investigation that includes credit and financial verifications. The use of illegal drugs is a criminal offense. Drug use is an important factor considered in your reliability and suitability assessment during the selection process. Therefore it is important not to use any illegal drugs from the time you submit your application.
Others
Important

Applicants must clearly demonstrate in their application how they meet each Education and Experience criteria. Failure to do so will result in the applicant being screened out of the career opportunity.


CSIS is a separate employer and is not subject to the Public Service Employment Act (PSEA). CSIS has its own classification, compensation system, and a different staffing regime. As such, we use a different staffing process and terminology.

CSIS is committed to diversity and inclusion and the equitable participation of all Canadians. Should you require accommodation in relation to a disability, please tell us at the beginning of the selection process. This information will be kept confidential.


The personal information provided in your application is protected under the Privacy Act and will be held in Personal Information Bank SIS/P-PU-025.


We thank all applicants for their interest in CSIS. However, only those who are selected for further consideration will be contacted.","Canadian Security Intelligence Service
4.3",Ottawa
73,Data scientist,"Overview




As an engineering service provider, we serve clients who have specific needs in the areas of machine learning, data analysis and computer vision. As such, we are looking for a capable Data Scientist to join the inference team at Kinsol Research and offer his/her expertise in statistical modeling and machine learning.

Key Responsibilities:



Build statistical models and inference systems using multiple data sources
Create visualizations and documentation to explain complex concepts to software analysts and stakeholders
Provide expertise on quantitative modeling for the broader analytics group
Communicate results and findings derived from data throughout the organization in a clear, concise way
Collaborate with other areas of the company on long-term projects
Learn, implement and share new methodologies and keep up to date with current trends in the area
Qualifications:



PhD/MSc degree in computer science, engineering, applied mathematics, physics or statistics
2+ years of hands-on experience with Python (numpy, scipy, pandas, jupyter)
Practical experience in applying machine learning, especially developing models and inference systems
Experience in scaling up smaller projects and sharing work collaboratively across a wider team
Sufficient data warehouse and non-relational data techniques knowledge to work effectively with engineering partners
Comfortable navigating new codebases in a unix environment
Additional Assets:



Exposure to Amazon Web Services, ability to design decoupled, fault tolerant, highly scalable, highly available system architectures
Experience with agile development and collaborative software practices
Experience with Docker containers and continuous integration practices



Contact Information:




Please send a resume and cover letter in a single PDF to: info@kinsol.io with ATTN:Data Scientist in the subject line.",Kinsol Research,Victoria West
74,in vitro DMPK Associate Scientist or Scientist,"Paraza Pharma Inc. is an innovative company with an aim to significantly improve the efficiency of the drug discovery process from lead identification through lead optimization to development candidates.

With an excellent team of highly creative drug discovery scientists trained in world-reputed laboratories and deep experience in drug discovery and development from pharmaceutical companies such as Merck, Pfizer, Wyeth, Boehringer-Ingelheim, AstraZeneca and Schering-Plough, we offer collaborative opportunities to provide most efficient solutions.

We are currently seeking for an in vitro DMPK Associate Scientist or Scientist for a full time job position.

JOB DESCRIPTION

As a member of the Drug Metabolism and Pharmacokinetic (DMPK) group, the candidate will be in charge of performing standardized protocols, aiming at the screening and profiling of drug candidates on the basis of their in vitro ADME properties. The candidate will also be involved in the validation and/or establishment of new in vitro assays. The work will mainly consist of classical bench work and cell culture and data analysis.

The successful candidate possesses 3 to 5 years of experience in DMPK or in a related field (biology, biochemistry) with a good knowledge of the different biological mechanisms involved in the absorption, distribution, metabolism and excretion of novel chemical entity. Experience in cell culture will be considered an asset. Good communication skills and capacity to deliver results in a stringent schedule while maintaining excellent work quality is essential.

Major Responsibilities

· Culture and treatment of different cell lines.

· Participate actively in compound screening campaigns by performing in vitro assessments involving biological matrices.

· Data analysis and reporting.

· Participate actively in the establishment/improvement of experimental methodologies.

Qualifications

- University degree in biochemistry, biology, pharmacology or related scientific field;

- 3 to 5 years of experience in the industry;

- Demonstrated skills working with cells (hepatocytes, Caco-2, MDCK considered an asset);

- Demonstrated team work spirit with capability to succeed in a fast-paced environment, working on multiple projects with constantly changing priorities and deadlines.

Application deadline: 2021-06-01

Expected start date: 2021-06-01

Job Types: Full-time, Permanent

Benefits:

Assurance Dentaire
Assurance Invalidité
Assurance Maladie Complémentaire
Assurance Vie
Assurance Vision
Congés de Vacances et Compensatoires
Programme d'Aide aux Employés
REER Collectif
Régime d'Achat d'Actions
Stationnement sur place

Schedule:

8 Heures
Du Lundi au Vendredi
Quart de jour

Work remotely:

No","Paraza Pharma, Inc.
4.7",Saint-Laurent
75,"Data Scientist, Shopping","About Pinterest:

Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.

We’re looking for a Data Scientist to join the Shopping team with the goal of building a successful Shopping product at Pinterest. You’ll apply quantitative analysis, data mining and data visualization techniques to shape the strategy of the Shopping experience at Pinterest.

What you’ll do:

Design advanced experiments for Shopping product and Shopping monetization
Perform deep dive analysis to understand and optimize the key levers of our Shopping product team
Partner closely with Eng team to improve shopping optimization and recommendation systems
Design core metrics that serve as the North Stars for team efforts and model trade-off decisions across product areas
Work with product managers and engineers to design data products, prove their value by running experiments and release into production

What we’re looking for:

Ability to manipulate large data sets with high dimensionality and complexity; fluency in SQL and Python or R
4+ years experience doing quantitative analysis or statistical modeling; strong experimentation expertise
Knowledgeable about best practices around data manipulation, building data pipelines, feature engineering and creating dashboards
Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams to quickly turn insights into actions
Excellent communication skills and ability to explain learnings to both technical and non-technical partners.
Experience in Shopping/ecommerce products will be preferred

#LI-KP1


Not Specified
0","Pinterest
4.2",Midtown Toronto
76,Data Scientist,"Data Scientist

Sequence Bio is a dedicated team of scientists, researchers, programmers, and business leaders driven to change the future of healthcare and accelerate the discovery of better, safer medicines and disease treatments. But, we need your help!


We are looking for individuals who are highly motivated, solutions focused, team oriented and passionate about adding value to a fast-paced, growing company committed to benefiting the lives of individuals, families, and communities in Newfoundland and Labrador for generations to come. Want to help make a bigger impact? Apply today!


Overview of the Role

The Data Science and Analytics team’s work is focused on the analysis of data from whole genome genotyping, NGS whole genome sequencing, RNASeq and other omic’s technologies that will be used to help identify the population structure of our cohort - enabling Sequence Bio to search for novel drug targets to accelerate the development of better, safer medicines and disease treatments. This team is also responsible for developing tools and pipelines, implementing external, best practice, solutions into our discovery workflows and supporting all aspects of the analysis of Sequence Bio’s research activities.


Reporting to the Vice President, Research, Data Science and Analytics, the Data Scientist will be responsible for analyzing and structuring all aspects of the genomic and phenotypic data produced as part of our research objectives and play an integral role in supporting and working with the company’s information technology, cohort operations and research teams to maintain a well-founded, innovative and secure IT infrastructure. They will also be responsible for the continued optimization of Sequence Bio’s Research and Analysis platform, which will consist of a broad set of cutting edge tools and algorithms built to exploit Big Data architecture. The Platform will use machine learning methodologies to conduct hypothesis and non-hypothesis-based pattern recognition to discover new biomarkers.


Ideal Candidate

BSc or MSc in Statistics, Mathematics, Computer Science or another quantitative field.
1-3 years hands-on data science and statistics experience.
Experience in the Life Sciences or Health Care industry is considered an asset.
Strong analytical and problem solving skills.
Excellent written and verbal communication skills for coordinating across teams.
Proven experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets; experience working with AWS preferred.
Demonstrated experience working with and creating data architectures.
A drive to learn and grow with a rapidly evolving early stage company.



Responsibilities

Reports to the VP, Research, Data Science and Analytics.
Provide input on bioinformatic tools, solutions and pipelines that Sequence Bio needs to develop or implement as part of Sequence Bio’s research activities.
Implement and optimize algorithms for use by Sequence Bio and its wider community.
Work with scientists, bioinformaticians, statisticians, software engineers, systems analysts and clinical team members to develop, test and improve new genomic analysis techniques.
Organize, support, and collaborate across departments to meet project deliverables and timelines
Ensure team data analysis complies with company and international analysis and quality standards.
Other duties as required by your team lead(s) or the executive team.
Willing to take initiative and create and take on new responsibilities as our company continues to grow.



Working at Sequence Bio

At Sequence Bio, we do things a bit differently. And that makes sense, because when you’re trying to transform drug discovery, you can’t do the same old things again and again. The same goes for how we work. Our culture is evolving and progressive, and the procedures, policies and processes we follow encourage success, foster creativity, and embrace innovation. An appreciation for the latest technology tools, and a commitment to flexible working hours during peak project deployment, is required.


Our Commitment

Ethics, privacy and security excellence is rooted in everything we do at Sequence Bio. We promise to be transparent about our information policies and practices, and to return benefits to Newfoundland and Labrador. All employees must uphold the company's commitment in all they do.


Sequence Bio is proud to be an Equal Opportunity Employer. We recognize the importance and value of a diverse workforce and we are committed to creating an inclusive and respectful environment for all employees. If you require any accommodation to participate in the recruitment and selection process, please reach out to maddie@sequencebio.com and we will work with you to meet your needs.


Apply before July 9th, 2021 5:00 PM Newfoundland Time.",Sequence Bio,St. John's
77,Data Scientist,"Data Scientist

Sequence Bio is a dedicated team of scientists, researchers, programmers, and business leaders driven to change the future of healthcare and accelerate the discovery of better, safer medicines and disease treatments. But, we need your help!


We are looking for individuals who are highly motivated, solutions focused, team oriented and passionate about adding value to a fast-paced, growing company committed to benefiting the lives of individuals, families, and communities in Newfoundland and Labrador for generations to come. Want to help make a bigger impact? Apply today!


Overview of the Role

The Data Science and Analytics team’s work is focused on the analysis of data from whole genome genotyping, NGS whole genome sequencing, RNASeq and other omic’s technologies that will be used to help identify the population structure of our cohort - enabling Sequence Bio to search for novel drug targets to accelerate the development of better, safer medicines and disease treatments. This team is also responsible for developing tools and pipelines, implementing external, best practice, solutions into our discovery workflows and supporting all aspects of the analysis of Sequence Bio’s research activities.


Reporting to the Vice President, Research, Data Science and Analytics, the Data Scientist will be responsible for analyzing and structuring all aspects of the genomic and phenotypic data produced as part of our research objectives and play an integral role in supporting and working with the company’s information technology, cohort operations and research teams to maintain a well-founded, innovative and secure IT infrastructure. They will also be responsible for the continued optimization of Sequence Bio’s Research and Analysis platform, which will consist of a broad set of cutting edge tools and algorithms built to exploit Big Data architecture. The Platform will use machine learning methodologies to conduct hypothesis and non-hypothesis-based pattern recognition to discover new biomarkers.


Ideal Candidate

BSc or MSc in Statistics, Mathematics, Computer Science or another quantitative field.
1-3 years hands-on data science and statistics experience.
Experience in the Life Sciences or Health Care industry is considered an asset.
Strong analytical and problem solving skills.
Excellent written and verbal communication skills for coordinating across teams.
Proven experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets; experience working with AWS preferred.
Demonstrated experience working with and creating data architectures.
A drive to learn and grow with a rapidly evolving early stage company.



Responsibilities

Reports to the VP, Research, Data Science and Analytics.
Provide input on bioinformatic tools, solutions and pipelines that Sequence Bio needs to develop or implement as part of Sequence Bio’s research activities.
Implement and optimize algorithms for use by Sequence Bio and its wider community.
Work with scientists, bioinformaticians, statisticians, software engineers, systems analysts and clinical team members to develop, test and improve new genomic analysis techniques.
Organize, support, and collaborate across departments to meet project deliverables and timelines
Ensure team data analysis complies with company and international analysis and quality standards.
Other duties as required by your team lead(s) or the executive team.
Willing to take initiative and create and take on new responsibilities as our company continues to grow.



Working at Sequence Bio

At Sequence Bio, we do things a bit differently. And that makes sense, because when you’re trying to transform drug discovery, you can’t do the same old things again and again. The same goes for how we work. Our culture is evolving and progressive, and the procedures, policies and processes we follow encourage success, foster creativity, and embrace innovation. An appreciation for the latest technology tools, and a commitment to flexible working hours during peak project deployment, is required.


Our Commitment

Ethics, privacy and security excellence is rooted in everything we do at Sequence Bio. We promise to be transparent about our information policies and practices, and to return benefits to Newfoundland and Labrador. All employees must uphold the company's commitment in all they do.


Sequence Bio is proud to be an Equal Opportunity Employer. We recognize the importance and value of a diverse workforce and we are committed to creating an inclusive and respectful environment for all employees. If you require any accommodation to participate in the recruitment and selection process, please reach out to maddie@sequencebio.com and we will work with you to meet your needs.


Apply before July 9th, 2021 5:00 PM Newfoundland Time.",Sequence Bio,St. John's
78,Data Scientist,"Applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex, high volume data from a variety of sources. Analyzes large quantities of data and presents insights and predictions (e.g., on client behaviors and preferences, new products and services) to support management planning, execution and monitoring of business decisions. Builds and maintains the production execution of Data Science into enterprise systems and architecture.

Key accountabilities include:

Research, design and develop state-of-the-art machine learning and forecasting solutions.
Lead the research, design, and construction of predictive models to enhance understanding of Moneris core business and adjacent opportunities. Work is conducted based on an understanding of specific business priorities and strategies.
Partner with data engineering and data analytics teams to inform the design of data infrastructure for data science
Build and perfect robust statistical techniques to achieve desired accuracy for existing projects and create solutions that help Moneris exceed current performance levels
Participate in creating the structure for production data science workloads across the enterprise including leading on best practices, pipeline controls, and overall monitoring and management of model deployment.
Develop and roll out data science projects in production and lead the implementation of new tools and processes with business critical production accountability

Minimum position requirements:

Degree in Data Science, Statistics, Mathematics, Computer Science, Engineering, or other related fields.
3+ years of experience in data science, statistical modeling, advanced analytics, or software development.
You must be fluent in Python and are able to design and develop sophisticated solutions with minimal supervision.
Strong proficiency with Python and SQL.
Experience with Spark, Databricks, and Azure eco-system is a big plus.
Strong proficiency with the Git, VS Code, Jupyter suite, and data visualization tools and libraries such as Tableau, PowerBI, matplotlib, plotly, etc.
This position requires advanced programming skills in Python. At least 50% of the time will be spent on building new and improving existing solutions in Python or Spark.","Moneris Solutions Corporation
3.7",Etobicoke
79,Data Scientist,"Data Scientist
Montreal, QC, Canada Req #1220

Monday, June 21, 2021

EDF Renewables North America, a subsidiary of EDF Renewables, is a leading North American independent power producer boasting over 30 years of experience across a broad spectrum of services. Our mission is to deliver renewable solutions to lead the transition to a sustainable energy future.
Scope of Position:
The Data Scientist will lead and participate in the development, validation and delivery of algorithms, statistical models and reporting tools in the context of EDFR’s Wind Energy Team. The employee will solve complex analytical problems and develop automated tools to streamline established wind assessment methodologies. This position will interact with internal customers and stakeholders to ensure project success while ensuring deadlines are met. The incumbent must be comfortable with project management as well as designing, creating, and deploying the data architecture to deliver solutions.


Ideal candidates will possess a combination of business knowledge, technical skills, and people skills to define and guide data strategy for the Resource Assessment team and maximize user adoption of any new tools or models put forth.


Working conditions:
Approximately 95% of time is spent in the office environment, utilizing computers, servers, peripheral equipment, phones, and general office equipment. Approximately 5% of the time is spent traveling outside of the office to other EDF Renewables locations or vendor locations located in the US, Canada and Mexico, for the purpose of project related work, and to attend conferences, trade shows, and professional development events.

Responsibilities:

60% Data Science Activities:
Contribute to R&D efforts in the energy assessment field using pre-construction and operational data.
Collaborates with business partners to understand their problems and goals, develop predictive modeling, statistical analysis, data reports and performance metrics.
Use programming skills to explore, examine and interpret large volumes of data in various forms.
Develops and uses algorithms and statistical predictive models and determines analytical approaches and modeling techniques to evaluate scenarios and potential future outcomes.
Performs analyses of structured and unstructured data to solve multiple complex business problems utilizing advanced statistical techniques and mathematical analyses and broad knowledge of the organization and industry.
Interacts with internal and external peers and managers to exchange complex information related to areas of specialization.
Conducts data analysis and research, designs algorithm, recommends ongoing improvements to existing applications to help find new information for business decisions.
25% Resource Assessment Efficiency, Methodology, and Research Initiatives:
Maintain ownership of EDFR’s automated Wind Resource Assessment Methodology code library
Collaborates with team members to ensure such a tool continually meets the group’s needs
Optimize performance of tools where appropriate for efficiency gains and increased robustness.
Brings data science techniques and machine learning algorithms to bear in both pre-construction development analyses and post-construction operational analyses.
Integrates analysis tools to leverage existing databases and applications that store turbine data, met data, wind farm production data, and energy estimate results
Develops innovative and effective data-driven algorithms and applications for energy assessment using advanced statistical and predictive modelling techniques.
Provides training/maintenance/bug-fixes/updates for in-house proprietary software packages and develops new modules to meet ongoing increasing needs from the energy assessment team.

10% Resource Assessment Project Work:
Estimates energy production for wind projects under development
Designs turbine layouts to optimize energy production and minimize construction costs
Analyzes and solves resource assessment and development challenges
Analyzes data to identify and evaluate new sites for future projects
Communicates site characteristics, energy production potential, and risks to members of the Senior Management Team and Regional Developers
Supports the key project development functions for all projects, including financial feasibility analysis, permitting, engineering, due diligence, project legal review, etc.

5% Other duties as assigned

Qualifications:
Bachelor’s Degree in mathematics, statistics, computer science, engineering, or related field required.
Master’s Degree or PhD, a plus.
Strong interest in Renewable Energy and the environment
Minimum of 3 years’ experience providing advanced analytics within a business setting preferred.
1 year of data science implementation.
Able to facilitate discussions between small groups of technical leaders, recognize issues of conflict and inconsistency between data requirements, and pursue a resolution of these issues
2 or more years supporting progressively complex projects in predictive modeling, data analytics, machine learning, and big data technologies.
Minimum 2 years’ experience in SAS or SQL or other programming languages such as Python, Fortran or other MVC languages.
Ability to work with large data sets from multiple data sources.
Strong knowledge of advanced analytics tools and languages to analyze large data sets from multiple data sources.
Anticipates and prevents problems and roadblocks before they occur.
Demonstrates the ability to communicate technical ideas and results to non-technical clients in written and verbal form.
Ability to work cooperatively as part of a team, as well as independently under own initiative
Effective communications skills that enable successful advocacy and alignment with a long-term vision
Self-starter, motivated, able to manage multiple priorities and tasks in a dynamic environment with a good understanding of software development standards and best practices.

Other details

Job Function

I03

Pay Type

Salary","EDF Renewables
4.0",Montreal
80,Data Scientist,"Who we are
At Criteo, our culture is as unique as it is diverse. With offices around the world, our incredible team of 2,600 Criteos collaborates to create an open & inclusive environment. We work together to achieve our goals, push boundaries, and be impactful. All of this supports us in our mission to power the world’s marketers with trusted & impactful advertising.

We are looking for a highly motivated Data Scientist to contribute to the design and implementation of our Commerce Insights product, with a solid understanding of data science and machine learning algorithms. The Commerce Insights product has a wide range of data science challenges. The ideal candidate will have an extensive experience working with data, analyzing large data sets, with outstanding skills to identify and quantify opportunities for optimizations. You must thrive in a start-up environment, be proactive, detail oriented and eager to learn and keep-up with an evolving product landscape. You must have good judgement in identifying the right approach to a problem.
How You'll Make An Impact
You will contribute to the design and implementation of solutions to problems we encounter in building the Commerce Insights product.
Contribute to the development of a platform which collects and processes large amounts of data used in Commerce Insights product.
Gather and analyze data to extract valuable information relevant to prediction models.
Identify key prediction problems and propose innovating solutions.
Report, visualize and communicate results.
Contribute to the exploration and creation of new scientific understanding.
Work closely to satisfy stakeholders on other Product as well as other R&D teams to net our clients optimal performance results.

What We're Looking For
BS/MS in Data Science, Computer Science, Statistics, or a related field.
2+ years of experience dealing with big datasets using tools that run on Hadoop.
2+ years of programming experience, in Python or another language (C#, Java, C++ or other scripting languages are all good).
Experience developing and extending systems of moderate complexity
A passion for shipping quality high-performance code
A strong sense of ownership and a dislike for passing the buck
A problem solver, a fixer, and a creative technologist. We believe data analytics is a talent and a passion, not just a skill. Be resourceful.
A strong communicator and a team player who can work efficiently with others

Bonus Skills
Practical experience writing Map/Reduce, Spark or Hive/Presto or using a machine learning frameworks like TensorFlow.
Familiarity with Java, or Scala
Experience working with product owners to understand and implement business requirements
A demonstrated track record of taking initiative and acting as a leader
Experience working well in a very fast-paced and continuously changing environment

At Criteo, we are committed to creating an environment where all Criteos feel a sense of belonging. We nourish our diversity by listening to all cultures within Criteo - and there are many. We are proud to be a global team and conscious that it takes people with different perspectives, thoughts and cultures to succeed.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent.","Criteo
4.0",Vancouver
81,Data Scientist,"The Company You’ll Join

At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they’ve managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You’ll Work With

Our mission is to enable data-driven decisions and products across Carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. This is a foundational role in Carta’s fast-growing Data Organization, working on one of the world’s most valuable data sets at one of the fastest-growing FinTech companies of all time. The team consists of experts in product analytics, machine learning and data engineering. We partner with each other and Cartan’s across the company to solve impactful problems. Our team strongly believes that being helpful accelerates results and we support one another to be successful at Carta.

The Problems You’ll Solve

As a Data Scientist, ML at Carta, you’ll partner with domain experts across the company to analyze and explore Carta’s proprietary data set. You will build statistical models that power new products and accelerate Carta’s business. Examples of responsibilities will include:

Perform exploratory analyses to understand the dynamics of private markets and ownership
Develop machine learning models to power new financial products and to extract trends from performance of existing products
Automate monitoring of data distributions to detect and flag anomalies
Partner with product managers, engineers, and business teams to incorporate data-driven insights into decision-making
Own, coordinate, and solve complex, cross-functional problems that extend beyond the traditional boundaries of product, analytics, and data science
The Impact You’ll Have

You will own significant projects directly aligning with Carta’s company-wide initiatives of data products and data quality. Your work will empower leaders across the company to make good product decisions and optimize operational efficiency. Additionally, you will have the opportunity to set best practices for integrating our ML models into production helping Carta’s current and future data scientists.

About You

Candidates must have a strong foundation in statistics, be proficient in SQL and Python, and have an analytical mindset. You have a strong bias towards simplicity, are excited by “zero to one” projects, and can efficiently communicate findings to leadership. Example traits that we value:

2+ years of industry experience solving complex data problems with descriptive and predictive models
Proficiency with modern programming languages (Python, R, SQL, etc.) and datastores (Redshift or similar)
A deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance
Strong written and verbal communication skills, with a particular emphasis on data visualization
A collaborative attitude and a helpful personality","Carta
3.9",Waterloo
82,Data Scientist,"The Company You’ll Join

At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they’ve managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You’ll Work With

Our mission is to enable data-driven decisions and products across Carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. This is a foundational role in Carta’s fast-growing Data Organization, working on one of the world’s most valuable data sets at one of the fastest-growing FinTech companies of all time. The team consists of experts in product analytics, machine learning and data engineering. We partner with each other and Cartan’s across the company to solve impactful problems. Our team strongly believes that being helpful accelerates results and we support one another to be successful at Carta.

The Problems You’ll Solve

As a Data Scientist, ML at Carta, you’ll partner with domain experts across the company to analyze and explore Carta’s proprietary data set. You will build statistical models that power new products and accelerate Carta’s business. Examples of responsibilities will include:

Perform exploratory analyses to understand the dynamics of private markets and ownership
Develop machine learning models to power new financial products and to extract trends from performance of existing products
Automate monitoring of data distributions to detect and flag anomalies
Partner with product managers, engineers, and business teams to incorporate data-driven insights into decision-making
Own, coordinate, and solve complex, cross-functional problems that extend beyond the traditional boundaries of product, analytics, and data science
The Impact You’ll Have

You will own significant projects directly aligning with Carta’s company-wide initiatives of data products and data quality. Your work will empower leaders across the company to make good product decisions and optimize operational efficiency. Additionally, you will have the opportunity to set best practices for integrating our ML models into production helping Carta’s current and future data scientists.

About You

Candidates must have a strong foundation in statistics, be proficient in SQL and Python, and have an analytical mindset. You have a strong bias towards simplicity, are excited by “zero to one” projects, and can efficiently communicate findings to leadership. Example traits that we value:

2+ years of industry experience solving complex data problems with descriptive and predictive models
Proficiency with modern programming languages (Python, R, SQL, etc.) and datastores (Redshift or similar)
A deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance
Strong written and verbal communication skills, with a particular emphasis on data visualization
A collaborative attitude and a helpful personality","Carta
3.9",Waterloo
83,Senior Data Scientist (Machine Learning),"Mastercard's Cyber & Intelligence organization develops and delivers world-class security products and services for customers across the globe. NuData Security predicts fraudulent transactions by identifying good users from bad, based on their online behaviour. By analyzing over 38 billion behaviours annually, NuData harnesses the power of behavioural and biometric analysis to empower its clients to predict fraud and verify the user behind the device. This allows clients to predict fraud before a critical decision, reduce customer insult, and investigate bad actors efficiently.

Role
We are looking for a Senior Data Scientist with a minimum of 5 years of experience in a related field to join our team in the Vancouver office. The position will be technical in nature where you will provide guidance on the various statistical methods and algorithms used in modeling work by our team, and provide mentorship to others in this area. This is a key role within the team responsible for developing models to support various NuData products, and you’ll have exciting responsibilities, including:


Analyzing complex, high-volume data from varying sources and identifying key regularities, patterns and trends.
Prototyping and developing machine learning models in collaboration with an agile, high-functioning team.
Spotting new opportunities in data collection, feature creation, feature selection, model tuning and evaluation practices, and taking those ideas from the first concepts to live product integrations.
Implementing effective monitoring and benchmarking for model performance comparison.
Leveraging new research in data modelling to identify opportunities, pioneering algorithms and systems that become key commercial products.
Maintaining model development pipelines, libraries and machine learning infrastructure.

All About You
Ideally, you are:

Statistically adept. You have studied in a quantitative field (i.e. mathematics, statistics, economics, data science) at a doctoral or master’s level. You have the depth of knowledge required to identify appropriate techniques, follow and create formal proofs, define apt performance measures and adeptly explore or transform data.
Someone with a strong foundational knowledge of principles underlying common statistical learning techniques such as linear regression, support vector machine, tree-based methods, bagging and boosting methods.
A strong problem solver with critical thinking skills who can formulate a problem into solution. Able to challenge assumptions and validate modeling solutions from a statistical inference perspective.
Capable of writing complex SQL queries to process data. Proficient with manipulating and analyzing data to gain meaningful insights using tools such as Pandas for Python.
Experienced in creating algorithms and applying machine learning models to solve real business problems. You have the vision to see what the next generation model looks like and can iterate over production models to generate a competitive edge in the market.
A capable coder, able to write well-abstracted, production-quality code in Python (preferred), R, Java and/or C++. You’re experienced in using cloud services (e.g. AWS, Microsoft Azure and/or Google Cloud), and machine learning tools (e.g. scikit-learn, Tensorflow and/or Keras).
Experienced working with large data sets. You understand the benefits of batch processing and parallelization and know how to design a pipeline to scale-out machine learning workflows. You have experience working with distributed data processing frameworks such as Apache Spark.
An effective communicator in visual, verbal and spoken channels, able to identify a narrative in complex data and convey clear, actionable findings to different types of audiences.
Experienced in architecting end-to-end solutions for production deployment (considered an asset but not required).

It also helps if you are:

Collaborative. We do our best work as a team, which means sharing, being open to giving and receiving support and constructive input.
Evidence-based. We work to eliminate assumptions and test our hypotheses, and we value rigour.
Responsible. We offer the opportunity to drive major projects that protect consumers every day, internationally. We are looking for colleagues who care about that.
Motivated. We’re a team of data scientists with personal and collaborative side projects, and we’re looking for someone who shares our enthusiasm.
Innovative. Data Science is a continuously growing field. We like our team to keep pushing for new ideas and methods. We are looking for someone who is creative and not just always satisfied with the status quo.

Due to COVID-19, most of our employees are working from home. We’ve implemented a virtual hiring process and continue to interview candidates by phone or video and are onboarding new hires remotely. We value the safety of each member of our community because we know we’re all in this together.

Mastercard is an inclusive Equal Employment Opportunity employer that considers applicants without regard to gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

If you require accommodations or assistance to complete the online application process, please contact reasonable.accommodation@mastercard.com and identify the type of accommodation or assistance you are requesting. Do not include any medical or health information in this email. The Reasonable Accommodations team will respond to your email promptly.","MasterCard
4.3",Vancouver
84,Staff AI Research Scientist - ATG,"Company Description

ServiceNow is making the world of work, work better for people. Our cloud‑based platform and solutions deliver digital workflows that create great experiences and unlock productivity for employees and the enterprise. We're growing fast, innovating faster, and making an impact on our customers' and employees' lives in significant and important ways. With over 6,900 customers, we serve approximately 80% of the Fortune 500, and we're on the 2020 list of FORTUNE World's Most Admired Companies.®

We're looking for people who are ready to roll up their sleeves and help us build on our incredible momentum, our diverse, engaged workforce, and our purpose to make the world of work, work better.

Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.

Job Description

The Advanced Technology Group (ATG) at ServiceNow is a customer-focused innovation group building intelligent software and smart user experiences using existing and emerging data and AI technologies to enable end-to-end, industry leading work experiences for customers. We are a group of researchers, applied scientists, engineers and product managers with a dual mission. We build and evolve the AI platform, and partner closely with business units to build products and end-to-end AI-powered work experiences for customers. In equal measure, we lay the foundations, research, experiment and de-risk AI technologies that unlock new work experiences in the future.

Team

ServiceNow carries out fundamental research to push the limits of what AI can do for enterprises. You will be part of the Element AI research group within the ServiceNow Advanced Technology Group.

Role

You will do fundamental research on low-data machine learning with a focus on natural language processing and multimodal representations, within our “low-data learning” research program. You will have a role of knowledge generation and transfer, as well of maintaining our scientific credibility within the academic community.

What you get to do in this role:

Research scientists have the responsibility to set up their own research agenda within the topics of the research team, supervise interns, collaborate with their colleagues and the global AI community.

Research scientists are also responsible to be on top of the latest trends and discoveries and of sharing their knowledge with their colleagues through internal communications and collaborative projects.

Research scientists are also responsible to act as scientific advisors for other teams in need for their expertise and contribute to the products of the company.

Qualifications

In order to be successful in this role, we need someone who has:

A PhD in machine learning, deep learning, computer science, artificial intelligence or a related field.
A getting-things done mindset with a desire to push the boundary of fundamental knowledge
Experience in natural language understanding and optionally on multimodal representation learning, reinforcement learning, graphs, time series, computer vision, etc.
Experience and mastery of scientific programming with Python and Numpy, and optionally also with Java, JavaScript, or R.
Experience and mastery of deep learning programming in Pytorch and optionally with Tensorflow.
Experience contributing to research communities and/or efforts including publishing papers at top international conferences such as (NeurIPS, ICLR, ICML, ACL, CVPR, etc.)
Desire to work in a diversified team.

When applying please provide:

CV
Cover letter
Research statement

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at +1 (408) 501-8550, or [email protected]om for assistance.

For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.","ServiceNow
4.3",Montreal
85,Data Scientist,"RESPONSIBILITIES:
Develop state-of-the-art computer vision algorithms for object detection, classification, and face recognition.
Prototype hardware and software solutions for object detection, classification, and face recognition.
Develop and implement scalable and efficient modeling algorithms that can work with large-scale data in production systems.
Collaborate with product management and engineering groups to develop new products and features.
SKILLS AND QUALIFICATIONS:
PhD or MS degree in Computer Science, Electrical Engineering, Statistics, Applied Math, or other related fields.
Expertise in deep learning, deep neural networks, convolutional neural networks, Artificial Intelligence and/or related techniques.
Proficient in one or more programming languages such as Python and Java.
Familiarity with one or more neural network frameworks such as TensorFlow, Caffe or MXNet.
Strong analytical and quantitative problem solving ability.
Excellent communication, relationship skills and a strong team player.

Preferred Qualifications
Experience with big data techniques (Hadoop, MapReduce, Spark).
Experience with relational (SQL) and NoSQl Databases.
compensation:
TBD

How to apply:
Please send your resume to hr@awakedata.com",Awakedata,Burnaby
86,Research Programmer - Data Scientist,"Canada’s Michael Smith Genome Sciences Centre (GSC)

Today’s Research. Tomorrow’s Medicine.

The GSC is a department of the BC Cancer Research Institute and a high-throughput genome sequencing facility. We are leaders in genomics, proteomics and bioinformatics in pursuit of novel treatment strategies for cancers and other diseases.

Among the world’s first genome centres to be established within a cancer clinic, for more than two decades our scientists and innovators have been designing and deploying cutting-edge technologies to benefit health and advance clinical research.

Among the GSC’s most significant accomplishments are the first publication to demonstrate the use of whole-genome sequencing to inform cancer treatment planning, the first published sequence of the SARS coronavirus genome and major contributions to the first physical map of the human genome as part of the Human Genome Project.

By joining the GSC you will become part of an exceptional and diverse team of scientists, clinicians, experts and professionals operating at the leading edge of clinical research. We look for people who share our core values—science, timeliness, respect—to join us on our mission to use genome science for the betterment of health and society.

Summary

Job Reference No: RP_R00008_ 2021_05_19

Dr. Aly Karsan and the Karsan lab team at Genome Sciences Centre (GSC) are seeking a Research Programmer to join a Marathon of Hope Cancer Centre research project. The team will be working with other research programmers at the Karsan lab for developing data analysis pipelines for various next-generation sequencing (NGS) data such as but not limited to scRNA-Seq, targeted sequencing, ATAC-Seq, and BS-Seq, for the study of cancer evolution. We seek candidates with strong analytical and programming skills to research, develop, and improve our research pipelines.

The role is ideally suited for detail-oriented individuals with a strong interest in data analysis, research, and scientific programming within a high throughput academic setting. The Karsan lab has a history of strong publications and can offer great experience in research with full access to the GSC’s world-class compute cluster. Additionally, the Karsan Lab has a diverse computational biology core for knowledge sharing, collaboration, and support.

Duties/Accountabilities
Design and implement bioinformatic data pipelines to meet objectives of the project
Work with other project team members to develop and test code, and implement analysis
Evaluate and incorporate third-party software into pipelines
Produce thorough but concise written documentation of experiments, algorithms, validations, and other procedures as required.
Qualifications
Graduation from a recognized Bachelor of Science Program in Computer Science or relevant program. A Master’s degree in a relevant field would be a strong asset.
Two (2) years of recent related experience or an equivalent combination of education, training, and experience.
Core Skills and Abilities
Expertise with scientific programming and able to provide links to code samples via GitHub
Familiarity with molecular and cellular biology
Excellent verbal and written communication skills
Demonstrated ability to interpret results
Comfortable working in a Unix environment, including experience with shell scripting and common command-line tools
Established ability to efficiently organize work assignments and establish priorities
Demonstrated interpersonal skills including the ability to work effectively with others in a team environment.
Additional Assets
Familiarity in statistical analysis using modern computational tools (experience with any relevant tools will be considered, but R and Python are preferred)
Familiarity in next-generation sequencing datasets
Understanding of cancer biology
Functional knowledge of distributed version control systems, such as SVN or GIT
Apply

Please submit a detailed cover letter and resume to bcgscjobs@bcgsc.ca, using Research Programmer – Data Scientist, Karsan Lab in the subject line of your email.

This posting will remain online until filled.

Important!

We believe that diversity and inclusivity are essential for the advancement of human knowledge and science.

We welcome all applicants and provide all employees with equal opportunity for advancement, regardless of race, colour, ancestry, place of origin, political belief, religion, marital status, family status, physical or mental disability, sex, sexual orientation, gender identity or expression, age, conviction of a criminal or summary conviction offence unrelated to their employment.

All qualified candidates are encouraged to apply; however, Canadian citizens and permanent residents will be given priority.

Due to COVID-19 restrictions, the position would require working remotely on a temporary basis. This will be re-evaluated once plans to return to the office are made.","BC Cancer Agency
3.6",Vancouver
87,Data Scientist,"Dawn InfoTek Inc. is a professional IT consulting team that partners with major financial institutions, investment firms and government sectors. We have been dedicated in delivering cutting-edge consulting services and recruiting all levels of IT positions for our clients.

We are looking for a meticulous and enthusiastic Data Scientist to join our dynamic team to work at our bank client.

Type: Contract / Permanent
Location: Toronto

Requirements

Must-have:

Excellent computing development skills, particularly statistical and database modeling tools (i.e., SQL, Python, SAS, R, Access/VBA, etc.); well-developed ability to adapt to various programming languages and environments.
1 year of hands-on experience in quantitative analysis and machine learning; exposure to quantitative analysis related to credit risk management and modeling is preferred.
In-depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte-carlo simulation and bootstrapping techniques.
Well-developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses.
Ability to efficiently manage multiple priorities to ensure timely delivery.
Attention to details, independence, and ability to effectively collaborate in teamwork.
Flexibility and creativity in problem solving.

Nice-to-Have:

1 + years of experience in hands-on quantitative/statistical analysis, preferably related to the non-retail credit risk area in a major financial institution. - candidates with this experience will take priority in the interview process.

For immediate consideration, please apply as soon as possible to this posting by submitting your Resume along with your Availability Date

Referrals are more than welcome! We thank all applicants for your interest and referral. However, only qualified candidates selected for an interview will be contacted. Must reside in Toronto area.

For further information on our company, please visit: www.dawninfotek.com

Contract length: 12 months

Job Types: Full-time, Contract

Salary: $50.00-$60.00 per hour

Benefits:

Work from home

Schedule:

Monday to Friday

Experience:

Computing skills like SQL, Python, SAS, R, Access/VBA, etc.: 1 year (required)
quantitative analysis and machine learning: 1 year (required)
regression modeling, monte-carlo simulation: 1 year (required)
quantitative/statistical analysis: 1 year (required)

Work remotely:

Temporarily due to COVID-19","Dawn InfoTek Inc.
4.0",Midtown Toronto
88,Data Scientist,"Dawn InfoTek Inc. is a professional IT consulting team that partners with major financial institutions, investment firms and government sectors. We have been dedicated in delivering cutting-edge consulting services and recruiting all levels of IT positions for our clients.

We are looking for a meticulous and enthusiastic Data Scientist to join our dynamic team to work at our bank client.

Type: Contract / Permanent
Location: Toronto

Requirements

Must-have:

Excellent computing development skills, particularly statistical and database modeling tools (i.e., SQL, Python, SAS, R, Access/VBA, etc.); well-developed ability to adapt to various programming languages and environments.
1 year of hands-on experience in quantitative analysis and machine learning; exposure to quantitative analysis related to credit risk management and modeling is preferred.
In-depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte-carlo simulation and bootstrapping techniques.
Well-developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses.
Ability to efficiently manage multiple priorities to ensure timely delivery.
Attention to details, independence, and ability to effectively collaborate in teamwork.
Flexibility and creativity in problem solving.

Nice-to-Have:

1 + years of experience in hands-on quantitative/statistical analysis, preferably related to the non-retail credit risk area in a major financial institution. - candidates with this experience will take priority in the interview process.

For immediate consideration, please apply as soon as possible to this posting by submitting your Resume along with your Availability Date

Referrals are more than welcome! We thank all applicants for your interest and referral. However, only qualified candidates selected for an interview will be contacted. Must reside in Toronto area.

For further information on our company, please visit: www.dawninfotek.com

Contract length: 12 months

Job Types: Full-time, Contract

Salary: $50.00-$60.00 per hour

Benefits:

Work from home

Schedule:

Monday to Friday

Experience:

Computing skills like SQL, Python, SAS, R, Access/VBA, etc.: 1 year (required)
quantitative analysis and machine learning: 1 year (required)
regression modeling, monte-carlo simulation: 1 year (required)
quantitative/statistical analysis: 1 year (required)

Work remotely:

Temporarily due to COVID-19","Dawn InfoTek Inc.
4.0",Midtown Toronto
89,Data Scientist,"About Praemo:
Founded by industry experts and focused on the appropriate application of leading-edge analytic technologies like AI within industrial operations, we believe there is a simpler, more cost, time and operationally effective way to harvest insights from the Industrial and Manufacturing data sets that already exist.

Praemo is an advanced data and analytics company that builds solutions utilized by a wide range of industrial operations. From discrete manufacturing to consumer-packaged goods to mining and process plants, our technology, RazorTM fills a critical gap. Utilizing an organization’s operational and IoT (Internet of Things) data as-is, where-is, and applying AI (artificial intelligence) tools like ML (Machine Learning), RazorTM transforms existing, under-utilized data into context relevant insights. These insights alert industrial operators to any anomaly with the potential to harm performance in time to prevent it.

Responsibilities:
Build machine learning based products/solutions, which provide descriptive, diagnostic, predictive, or prescriptive models based on data
Independently develop end-to-end applications
Develop and maintain performant and scalable applications
Work closely with and incorporate feedback from Engineering teams
Maintain a customer-centric point-of-view for applications
Requirements:
BS in Computer Science, Systems Engineering, Computer Engineering, or related fields
3+ years of practical experience in machine learning is mandatory
General knowledge of Linux
Strong skills in Python (analytic packages such as Keras/Tensorflow/SciPy in particular)
Any experience with provisioning tools such as Ansible or Saltstack would also be helpful
DevOps experience is a plus
Redis experience is a strong asset
Preferred Qualifications:
PhD or Master’s degree in a machine learning discipline
Experience with Git or other version control software
Knowledge of Agile development methodology
Background in User Experience Design
Experience leading engineering teams and projects
Experience utilizing GPU technology
Some mechanical and industrial process knowledge
Previous startup experience","Praemo
5.0",Kitchener
90,Junior Data Scientist/Analyst,"Company Description


We are a global architecture, engineering, planning, and technology firm defining the cities of tomorrow.

By connecting design and technology, we change how people experience their built environment. We work across disciplines to create the intelligent systems, sustainable buildings, and efficient infrastructure that shapes the way people live, move, learn, and heal.

With over 3,000 employees and 60+ offices around the world, we understand what it takes to work locally and scale globally.

At IBI, we’re defining the cities of tomorrow.



Job Description


The Data Scientist is responsible for modeling complex enterprise scenarios, discovering enterprise insights and identifying opportunities in the use of statistical, algorithmic, mining and visualization techniques. In addition to advanced analytic skills, this role is also proficient at integrating and preparing large, varied datasets, architecting specialized database and computing environments, and communicating results in a way that is customized to the target audience.

This is an exciting role for someone seeking a challenging and dynamic role in enterprise analytics and an amazing opportunity to collaborate within IBI Group globally towards Connected and Smarter environment and operations. Working in close collaboration with buildings, land planning, infrastructure design and planning, transportation, and geomatics departments across IBI Group, the Data Scientist demonstrates the capability to turn data into critical information and knowledge that can be used to make sound decisions. The successful candidate possesses a combination of keen business focused, advanced analytical, problem solving and programming capabilities to quickly develop and validate through models.


Most Of The Things You'll Work On:

Works in collaboration with all IBI Group departments and external clients to discern and identify sources, develop data roadmap strategies and requirements, conduct analytical processes, and validates findings.
Understands the broader objectives, while leading the smaller initiatives to drive the work and outcomes.
Develops innovative and effective approaches to solve analytical problems and communicates results and methodologies.
Develops experimental design approaches and models to validate findings or test hypotheses.
Monitors and tracks performance decision systems and models (e.g. AI and statistical models).
Curates and establishes business objectives through technical writing and presentations with colleagues and external clients for the purposes of business development and strategic interests.
Supports team members in data analytics methodology and coding best practices.


Qualifications


You'll Need To Have:

Minimum Bachelor’s Degree in Mathematics, Statistics, Computer Science, Engineering, or related field; Master’s Degree preferred.
Completion of a Data Science or Data Analytics program in addition to the above Bachelor’s Degree.
Minimum of 1 to 2 years of experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas.
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources (in-house and external open sources) is required.
Proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms and developing operational models.
Demonstrated ability in predictive analysis and deriving conclusions.
Demonstrated ability to propose solutions to business problems by leveraging pattern detection over potentially large datasets.
Experience with data visualization and Business Intelligence tools such as PowerBI and Tableau.
Strong analytical programming skills in Python (Keras, PyTorch, Scikit-learn, Tensorflow, Weka, Spacy, Numpy, etc), data management (MS SQL, Oracle).
Experience with any statistical modeling (SAS, SPSS, R) will be an asset.
Experience with mapping tools such as QGIS and Carto will be an asset.
Experience with UX/UI will be an asset.
Experience with web development (Django, Python, Java) will be an asset.
A strong passion for empirical research and for answering hard questions with data is required.
Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner through technical writing and presentations.

Additional Information


We are currently in a work from home model during COVID-19, but when we do return to the office we're located at 55 St. Clair Ave West, this office is steps away from St. Clair station and is easily accessible by bike, TTC and car. Occupying 7 floors, with over 700 employees, it is the largest office at IBI Group. The floors are open concept and represent our collaborative approach to projects.

BI Group provides a competitive benefit package and pays association dues and licensing fees.

As an Equal Opportunity Employer, we are proud to support the growth and equality of our people through initiatives like our Mentorship Program, Global Women’s Network, and Diversity & Inclusion Council. We welcome applications from all suitably qualified candidates regardless of age, race, disability, gender reassignment, marriage and civil partnership, pregnancy and maternity, religion or belief, sex and sexual orientation. We thank all applicants for their interest. However, only those selected for an interview will be contacted.

As part of IBI Group's selection process, candidates may be requested to consent to background checks relevant to the role under consideration for, prior to receiving a job offer. These could include: work references, education and credential confirmation, employment verification, identity check, credit report, criminal offence and driver’s license record. #ibi

We request applicants submit RESUME AND PORTFOLIO highlighting relevant work experience. Please limit PDF files to 10MB","IBI Group
3.5",Midtown Toronto
91,Junior Data Scientist/Analyst,"Company Description


We are a global architecture, engineering, planning, and technology firm defining the cities of tomorrow.

By connecting design and technology, we change how people experience their built environment. We work across disciplines to create the intelligent systems, sustainable buildings, and efficient infrastructure that shapes the way people live, move, learn, and heal.

With over 3,000 employees and 60+ offices around the world, we understand what it takes to work locally and scale globally.

At IBI, we’re defining the cities of tomorrow.



Job Description


The Data Scientist is responsible for modeling complex enterprise scenarios, discovering enterprise insights and identifying opportunities in the use of statistical, algorithmic, mining and visualization techniques. In addition to advanced analytic skills, this role is also proficient at integrating and preparing large, varied datasets, architecting specialized database and computing environments, and communicating results in a way that is customized to the target audience.

This is an exciting role for someone seeking a challenging and dynamic role in enterprise analytics and an amazing opportunity to collaborate within IBI Group globally towards Connected and Smarter environment and operations. Working in close collaboration with buildings, land planning, infrastructure design and planning, transportation, and geomatics departments across IBI Group, the Data Scientist demonstrates the capability to turn data into critical information and knowledge that can be used to make sound decisions. The successful candidate possesses a combination of keen business focused, advanced analytical, problem solving and programming capabilities to quickly develop and validate through models.


Most Of The Things You'll Work On:

Works in collaboration with all IBI Group departments and external clients to discern and identify sources, develop data roadmap strategies and requirements, conduct analytical processes, and validates findings.
Understands the broader objectives, while leading the smaller initiatives to drive the work and outcomes.
Develops innovative and effective approaches to solve analytical problems and communicates results and methodologies.
Develops experimental design approaches and models to validate findings or test hypotheses.
Monitors and tracks performance decision systems and models (e.g. AI and statistical models).
Curates and establishes business objectives through technical writing and presentations with colleagues and external clients for the purposes of business development and strategic interests.
Supports team members in data analytics methodology and coding best practices.


Qualifications


You'll Need To Have:

Minimum Bachelor’s Degree in Mathematics, Statistics, Computer Science, Engineering, or related field; Master’s Degree preferred.
Completion of a Data Science or Data Analytics program in addition to the above Bachelor’s Degree.
Minimum of 1 to 2 years of experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas.
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources (in-house and external open sources) is required.
Proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms and developing operational models.
Demonstrated ability in predictive analysis and deriving conclusions.
Demonstrated ability to propose solutions to business problems by leveraging pattern detection over potentially large datasets.
Experience with data visualization and Business Intelligence tools such as PowerBI and Tableau.
Strong analytical programming skills in Python (Keras, PyTorch, Scikit-learn, Tensorflow, Weka, Spacy, Numpy, etc), data management (MS SQL, Oracle).
Experience with any statistical modeling (SAS, SPSS, R) will be an asset.
Experience with mapping tools such as QGIS and Carto will be an asset.
Experience with UX/UI will be an asset.
Experience with web development (Django, Python, Java) will be an asset.
A strong passion for empirical research and for answering hard questions with data is required.
Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner through technical writing and presentations.

Additional Information


We are currently in a work from home model during COVID-19, but when we do return to the office we're located at 55 St. Clair Ave West, this office is steps away from St. Clair station and is easily accessible by bike, TTC and car. Occupying 7 floors, with over 700 employees, it is the largest office at IBI Group. The floors are open concept and represent our collaborative approach to projects.

BI Group provides a competitive benefit package and pays association dues and licensing fees.

As an Equal Opportunity Employer, we are proud to support the growth and equality of our people through initiatives like our Mentorship Program, Global Women’s Network, and Diversity & Inclusion Council. We welcome applications from all suitably qualified candidates regardless of age, race, disability, gender reassignment, marriage and civil partnership, pregnancy and maternity, religion or belief, sex and sexual orientation. We thank all applicants for their interest. However, only those selected for an interview will be contacted.

As part of IBI Group's selection process, candidates may be requested to consent to background checks relevant to the role under consideration for, prior to receiving a job offer. These could include: work references, education and credential confirmation, employment verification, identity check, credit report, criminal offence and driver’s license record. #ibi

We request applicants submit RESUME AND PORTFOLIO highlighting relevant work experience. Please limit PDF files to 10MB","IBI Group
3.5",Midtown Toronto
92,Data Scientist,"Position in Data Science Using Dynamic Data-Driven Modeling and AI/ML
Job Description and Responsibilities:

The selected candidate will be responsible for researching, designing, developing, and programming to implement algorithms for (a) signal processing and time series data analysis using both deterministic and statistical methods; (b) data-driven modeling to model the linear or nonlinear relationship between multivariate time series data that are often dynamically correlated (not static); (c) feature extraction (both time and frequency domain) and clustering / classification of multivariate time series data. The successful candidate will work closely with a multi-disciplinary team of engineers to apply the developed algorithms to solve practical problems in various sectors of industry, and assist them in validation and verification as well as technical documentation of the solution.

Desired Education Level and Background:

Ph.D. or Master’s degree preferably in Electrical Engineering, or otherwise, in Computer Science or Applied Mathematics with relevant experience and research interests

Required Skills and Qualifications:

A proven track record and solid expertise in the following fields:

System identification for data-driven modeling of dynamic systems
Artificial Intelligence and Machine Learning (AI/ML) for modeling input/output (or cause/effect) relationship between time series data
Linear and nonlinear statistical regression modeling and analysis
Time and frequency domain signal processing and time series data analysis
AI/ML for clustering and classification of time series data
Feature extraction and dimensionality reduction methods for time series data
Strong background in linear algebra (vector and matrix data manipulation)
Working knowledge of optimization techniques and toolboxes is an asset
Technical documentation and presentation

Candidates must have proven experience of efficient, proficient computer programming and implementation of signal processing, time series analysis and data-driven modeling methods (system identification, AI/ML, and statistical methods) in Python. Knowledge of MATLAB/Simulink programming and toolboxes in the aforesaid domains is considered a valuable asset. Experience in Java and C++ is not required but considered beneficial. The selected candidate must be innovative and highly organized, and must have very good personal and interpersonal skills including problem solving, analytical thinking, learning, and team work and communication skills. Professional proficiency in English language is essential. Knowledge of French language is considered an asset.

GlobVision, throughout its 24+ years of existence, has repeatedly demonstrated commitment to diversity, equity, and inclusion as core and unwavering values of the company. They are not only central to the company’s culture but considered as a mechanism by which we leave an endurable impact on our society. We strongly believe that the fusion of varied perspectives results in more innovative solutions to complex, challenging problems in our increasingly diverse and connected world.

***Please note, this position is available for Canadian residents only, and those selected for an interview will be contacted.***

Job Type: Full-time

Benefits:

Dental care
Disability insurance
Life insurance

Schedule:

Monday to Friday

Experience:

Machine Learning: 1 year (preferred)

Work remotely:

No",GlobVision Inc.,Montreal
93,Data Scientist,"We're transforming the Cyber Security industry

About Us:

F8th uses machine learning that can identify users and fraudsters in real-time via 100s of patterns of how an individual uses their mouse, keyboard, touchscreen and other inputs. It continuously analyzes typing speed, movement speed, clicking speed, acceleration, and more, and then builds a behavioural profile.

Job Description:

Excellent SQL skills, fluency in Python, and experience with at least one statistical package (R, Pandas/NumPy/SciPy/matplotlib, Stata, Matlab)
Deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance
Create and apply model and algorithm testing strategies to measure conduct multivariate testing and A/B testing to measure effectiveness of models and make ongoing changes
Collaborate and lead the teams in feature extraction, data representation, and automatic data pipeline and collection design, as well as data quality assurance monitoring
Functional, end-to-end, integration, regression, automated/manual testing

Requirements:

Bachelor’s/Master's degree in data science, computer science, applied math, statistics or a related technical field. MS/PhD degree in CS or related areas is preferred.
3+ years experience in software development and machine-learning
Hands-on 3+ years of experience on machine learning, text analysis, data mining, and NLP
Knowledge of Scala, Python, C#, C++, Java or Typescript with 2-3 years of experience
Experience with SQL and NoSQL databases
Experience using PyTorch & popular NLP libraries such as FairSeq, AllenNLP, HuggingFace or SpaCy
Experience with one or more back-end programming languages such as C++ and Python
Familiarity working with large data sets and big data platforms such as Hadoop, PySpark, and Kubernetes
Deep knowledge of advanced statistical techniques and concepts, machine learning techniques, and expertise in their applications
Excellent communications skills with the ability to share insights and expectations with clients, stakeholders and colleagues, both locally and remotely

What We Offer You:

Start-up lifestyle at a Cyber Security company
Experience working closely with the founders of the company

Note:

Kindly mention the job title in the subject of your email

Expected Start Date: 2021-07-01

Job Types: Full-time, Permanent

Benefits:

Employee stock purchase plan

Schedule:

8 hour shift
Monday to Friday

Work remotely:

Yes",F8th,Midtown Toronto
94,Senior Product Data Scientist,"This position is open to the US and Canada. Any applications outside of those locations will not be considered.




Coffee Meets Bagel Coffee Meets Bagel's mission is to give everyone a chance at love. The app curates quality matches with fuller profiles that result in real conversations. Globally, CMB has generated millions of real dates and thousands of lasting relationships. Coffee Meets Bagel was named one of the Top 10 Dating apps by Time Magazine and the Best Dating App for Women by Refinery29. It has also been voted the #1 recommended dating app for singles looking for relationships.

Job description Each day, our users visit our app with the hope of connecting with someone. These interactions generate millions of data points that can be used to help us better understand our customers’ experiences. We need you to ask and answer the questions that will transform this data into a better understanding of what our customers find delightful, and what they find painful, so that you can help drive changes that further our vision of helping singles form meaningful connections with other amazing singles! The Senior Product Data Scientist will be responsible for partnering with our product and growth teams to provide the facts needed to make better decisions and to help push our products and services to better serve our customers. You will be responsible for building a strong understanding of our ecosystem, working with the product team to determine which projects are the most important, and being willing to use the right tool (a scripted model, a dashboard, a presentation) to find and explain relevant information and insight that will help the company operate better.
Responsibilities
Work cross-functionally with product, design, finance, and engineering teams to provide data-driven insights that will help define the product & marketing roadmap and drive significant increase in core business KPIs (growth, revenue, engagement).
Create internal dashboards to monitor the health of the product and business KPIs (growth, revenue, engagement).
Deliver ad-hoc analyses and reports to support business needs, investigate, triage and resolve metrics-based issues without heavy guidance.
Assist in feature development from ideation to execution, including helping with user research, determining the best way to test new product features, and running deep analysis of feature performance post launch.
Create and share compelling presentations that motivates and inspires the team to build with conviction.
When necessary, build models in R, Python, or other systems that help us better measure and understand the results of experiments or user flows.
Qualifications
Bachelors in a quantitative field (e.g. mathematics, statistics, computer science, engineering, physics, quantitative social science) and 4+ years post-collegiate work experience as an analyst or data scientist; or a Masters/PhD in a quantitative field with 2+ years work experience as an analyst or data scientist.
Experience applying statistics to rigorously analyze data and derive insights to solve ambiguous problems.
1+ years designing and evaluating experiments or quasi-experiments
High proficiency in SQL & business intelligence tools (e.g., Mode, Tableau, etc).
Basic Proficiency in a scripting language like Python, R, or Julia
Capable of condensing data and telling a persuasive story to technical and non-technical audiences.
Self-starter who can thrive in a dynamic, fast-paced environment, drive change through influence, and collaborate effectively with a variety of cross-functional stakeholders. Excited and hungry to try new tools and processes to achieve results.
A serious passion for using data to build delightful products for our customers.
Competency with developer tools like Git and Bash is a plus


Please make sure to mark CMB as ""safe"" as our emails tend to go to Spam.","Coffee Meets Bagel
4.6",Midtown Toronto
95,Data Scientist,"Data Scientist
Location: Montreal, Ottawa & Toronto

We Are:
The people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.

You Are:
An expert at solving real-world challenges with data, analytics, AI/ML and creativity. Yes, creativity! You know the theory and you have hands-on expertise from studies, experience and/or self-taught projects. And you’re all about helping clients scale data into value.

What You’ll Do:

Provide hands-on technical thought leadership, solve large & complex business problems and drive actionable insights for clients
Prototype & scale AI/ML solutions in production cloud environment to meet business needs
Stay abreast of AI/ML technologies, academic researches & hands-on techniques
Participate in development of innovative solutions for clients across functions & industries


What We’re Looking For:

At least 5 years embracing challenges with data science lifecycle in enterprise setting
At least 3 years developing & implementing AI/ML models, including professional experience with recommender engine, natural language processing, optimization & operational research, computer vision and deep & classical machine learning
At least 3 years working with data science tools: e.g. Python, R, Spark, SQL, Plotly, Flask & Git
At least 3 years designing & operating tools & services in cloud environments: e.g. GCP, Azure, AWS & Databricks
At least 2 years orchestrating and maintaining AI/ML models in a production environment using Data & ML Ops tools: e.g. Docker, Kubernetes, MLFlow, Jenkins & CircleCI
At least 5 years storytelling with data and communicating findings to a non-technical audience

Bonus Point If:

Graduate degree in data science or related disciplines: e.g. Applied Mathematics, Statistics, Computer Science, Economics, Engineering and Physics
A blend of data science capability, consulting expertise and industry experience
Drive to learn and master new technologies and techniques","Accenture
4.1",Mississauga
96,Data and Applied Scientist,"Empower Microsoft customers to browse and communicate with confidence and trust and protect them from phishing and social engineering threats. That is what inspires us, drives our work, and pushes us to challenge the status quo every single day.
We are anapplied research team bringingimpact driven research in theSecurity and Compliance suite for O365 customers. We explore cutting edge techniques in diverse disciplines that protect our customers from social engineering attacks at scale, while advancing state of the art in the process.
As a Senior Applied Researcher your work will impact over half a billion Microsoft customers. You will develop new capabilities that help the team to scale and work smarter. You will have the opportunity to analyze vast datasets and have a pulse on the latest research to positively influence our product roadmaps. You will be able to prototype and experiment in completely new areas. Your research will delight customers and demonstrate Microsoft’s thought leadership in the security space. By working with teams across the broader group, you will need the right balance of passion, customer empathy, technical depth, and partnering skills.
If you enjoy being on the cutting edge of applied research in security, come join us! We‘re looking for someone passionate about leading and pushing forward cutting-edge research for solving complex, highvolumeproblems related to social engineering.

#SCMVAN
#SCMRJOBS
#SCMJOBS
Responsibilities
Incollaborationwithadiverseteam(includingengineersandresearchers),defineandexecute deep learning-basedresearchtowards real world problems
Collaborate with some of the world’s best researchers at Microsoft Research to drive fundamental research into real world security products impacting over half a billion people in over a hundred countries around the world.
Communicate internally and externally through academic and industry conferences, publications, open-source releases and other mindshare venues such as blogs, media interviews, etc.
Explore bold research ideas, design and conduct scientific experiments, learn and iterate on further improvements of the research undertheumbrellaofresponsibleAIprinciples.
Qualifications
Required:
Track record in research areas in deep learning, such as graph neural networks, knowledge graphs, NLP, computer vision, responsible AI as evidenced by at least 2 publications in academic conferences and/or open code contributions OR 4+ years of relevant industry experience realizing cutting-edge research into product innovation.
Hands on experience with deep learning frameworks such as PyTorch, Tensorflow, etc.
Excellent written and verbal communication skills and the ability to simplify and explain complex ideas.
Excellentresearchskillswiththeabilitytobreaklong term research goals into achievable milestones. Ability to clearly articulate the problems and explore related solutions.
Teamplayer,confidentandenthusiastic;Proven partner engagement and cross-team collaboration skills
Preferred:
Proven publication record in top-tier venues. Examples include but are not limited to ICML, NeurIPS, ICLR, EMNLP, ACL, NAACL, KDD, AAAI, etc.
Experience with large-scale data processing tools
Moderate software engineering skills for developing quick and accurate prototypes
Experience in safety and ethical aspects of AI.
Expert knowledge in security, reputation systems, anti-fraud systems,phish detection technologies, and social engineering research

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
97,Data Scientist,"Job Overview


SomaDetect is a high-growth technology startup in the dairy industry that is looking to expand its development team. We have a diverse team that strives to develop fiercely innovative solutions, with a focus on quality to create products that put farmers first. SomaDetect is now a fully remote company, with team clusters in Buffalo, NY, and across Canada (southern Ontario, Ottawa, Fredericton, and Halifax). This is a remote position.


We are looking for a Data Scientist that will join our existing team and participate in the development of predictive models that leverage massive amounts of “image” data. The Data Scientist will collaborate with a team of multidisciplinary engineers and researchers to tackle challenges related to the analysis/modeling of dairy data. This role will require someone that is well versed in the fundamentals of computer vision and machine learning. The ideal candidate will also have the experience and problem-solving abilities necessary to extract insights and discover patterns within messy, real-world data sets.


This role focuses on work in real-time with multiple sensor data, data acquisition, analysis, and modeling for building smart solutions for the dairy industry. This role utilizes deep learning on a fast GPU machine to facilitate the prediction and estimation operations.


Responsibilities and Duties



Develop deep learning models for computer vision problems (image classification).
Responsible for enhancing the image data collection procedures collaboratively with our operational teams for building the relevant predictive models.
Responsible for processing, cleansing, and verifying the integrity of IMAGE data used for model development.
Responsible for developing processes and tools to monitor and analyze the data quality and model performance.
Evaluate new sensor models.
Build tools and framework for multiple cameras and sensor calibration.
Develop various computer vision algorithms that are efficient and robust.
Play an active role in end-to-end product development/deployment lifecycle.
Work collaboratively with other software developers and engineers to integrate algorithms into a complete product.
Test the AI products in the field and refine the products by learning and applying new algorithms.
Thoroughly test and objectively evaluate the scope of validity of any R&D deliverables.



Qualifications & Requirements



Experience with OpenCV and Deep Learning frameworks: TensorFlow or PyTorch or Caffe
Experience with deep learning algorithms: CNN, RNN, and LSTM
Experience in computer vision algorithms and 2D sensor data
Proficient programming skills in Python (must have), R (nice to have)
Strong of computer vision fundamentals
Knowledge and experience in statistical and data mining techniques using time series datasets, Bayesian Probability, Markov Models (HMM).
Experience in using AWS (S3, Sage Maker)
Excellent oral and written communication
Works effectively in small teams
Ph.D. or master’s degree in computer science, Data Science, Bioinformatics, Engineering, or equivalent experience
3+ years of relevant experience in the computer vision and deep learning field
Experience in working in an agile environment, using project management and reporting tools (e.g., Confluence, Jira etc)



We appreciate all expressed interest in this position; however, only the candidates selected for an interview will be contacted.",SomaDetect,Quebec
98,Data Scientist,"Job Overview


SomaDetect is a high-growth technology startup in the dairy industry that is looking to expand its development team. We have a diverse team that strives to develop fiercely innovative solutions, with a focus on quality to create products that put farmers first. SomaDetect is now a fully remote company, with team clusters in Buffalo, NY, and across Canada (southern Ontario, Ottawa, Fredericton, and Halifax). This is a remote position.


We are looking for a Data Scientist that will join our existing team and participate in the development of predictive models that leverage massive amounts of “image” data. The Data Scientist will collaborate with a team of multidisciplinary engineers and researchers to tackle challenges related to the analysis/modeling of dairy data. This role will require someone that is well versed in the fundamentals of computer vision and machine learning. The ideal candidate will also have the experience and problem-solving abilities necessary to extract insights and discover patterns within messy, real-world data sets.


This role focuses on work in real-time with multiple sensor data, data acquisition, analysis, and modeling for building smart solutions for the dairy industry. This role utilizes deep learning on a fast GPU machine to facilitate the prediction and estimation operations.


Responsibilities and Duties



Develop deep learning models for computer vision problems (image classification).
Responsible for enhancing the image data collection procedures collaboratively with our operational teams for building the relevant predictive models.
Responsible for processing, cleansing, and verifying the integrity of IMAGE data used for model development.
Responsible for developing processes and tools to monitor and analyze the data quality and model performance.
Evaluate new sensor models.
Build tools and framework for multiple cameras and sensor calibration.
Develop various computer vision algorithms that are efficient and robust.
Play an active role in end-to-end product development/deployment lifecycle.
Work collaboratively with other software developers and engineers to integrate algorithms into a complete product.
Test the AI products in the field and refine the products by learning and applying new algorithms.
Thoroughly test and objectively evaluate the scope of validity of any R&D deliverables.



Qualifications & Requirements



Experience with OpenCV and Deep Learning frameworks: TensorFlow or PyTorch or Caffe
Experience with deep learning algorithms: CNN, RNN, and LSTM
Experience in computer vision algorithms and 2D sensor data
Proficient programming skills in Python (must have), R (nice to have)
Strong of computer vision fundamentals
Knowledge and experience in statistical and data mining techniques using time series datasets, Bayesian Probability, Markov Models (HMM).
Experience in using AWS (S3, Sage Maker)
Excellent oral and written communication
Works effectively in small teams
Ph.D. or master’s degree in computer science, Data Science, Bioinformatics, Engineering, or equivalent experience
3+ years of relevant experience in the computer vision and deep learning field
Experience in working in an agile environment, using project management and reporting tools (e.g., Confluence, Jira etc)



We appreciate all expressed interest in this position; however, only the candidates selected for an interview will be contacted.",SomaDetect,Quebec
99,Data Scientist,"What you'll do
Responsibilities

In this role, you would report to the VP Engineering. Responsibilities will include:

Conceiving and developing data driven solutions for clients
Creating and presenting results and findings to clients
Collaborating with developer resources to build data pipelines and operationalize solutions
Data cleaning & reshaping
What you'll need
Qualifications
Masters or Ph.D in Econometrics, Financial Economics, Mathematics, Statistics, Physics, Computer Science, Data Science, Engineering or equivalent experience
2-5 years of experience in a Data Science role
Experience in one or more programming languages (Preferably Python)
Experience with one or more data science frameworks (e.g. Numpy, Scikit-learn, Scipy, Pandas)
Strong understanding of data and business
Ability to work autonomously and in a team
Working in a fast-paced environment
Ability to solve complex problems
Strong communication skills

Nice to haves:
Past experience with one or more business intelligence/analytics platforms (Teradata, Microstrategy, Cognos)
Analytical experience related to the food and beverage industry
Past experience working with time series data
We're looking for
Core Skills
Jupyter Forecasting Python Statistical Modeling Statistics Interpreting Data Problem Solving Science","Fiddlehead
4.1",Moncton
100,Data Scientist,"Maxa AI offers an AI-powered SaaS solution for commercial performance that runs alongside a company’s ERP system. Maxa deals with SME to X-large enterprises in all industries, as well as affiliate partners.

We are currently looking for a Data Scientist to join our Montreal based team.

About us:
We deliver business performance technology with python and SQL.
We move fast with infinite capacity; our technology lives in the cloud.
We eat business system data and time series for breakfast.
We like math, science and engineering degrees.
We love stories about failures even more.


You Have: *
At least 5 years of experience as a Data Scientist.
A few interesting stories about challenging real-world datasets you’ve tackled.
Used a combination of advanced statistics and machine learning to create and or validate predictive insights.
A love for complex time-series data.
A passion for conversations about decision-trees, regression and other types of ML algorithms applied to table data and time series (and make geek jokes about them)",Maxa AI,Montreal
101,Data Scientist,":


The Data Scientist will join the Advanced Analytics team focused on creating transformational analytics-enabled capabilities across all of Acosta’s businesses. This can range from using statistical methods, data-mining and machine-learning techniques, or generating novel approaches uniquely suited the challenge. We value complementary and divergent experiences to bring many points of view on how to approach solve a problem. Although our datasets range in size, you can expect to work with very large datasets regularly in this role.


The incumbent(s) in this position should exhibit the following Acosta values:
People Minded – Must show dignity and respect to all people
Integrity – Must exemplify the highest degree of ethical behavior
Results Oriented – Must show passion, pride and commitment to succeed
Trust – Must be honest, sincere and confident
Teamwork – Must build trusting relationships
Innovation – Must progress through a combination of creativity, common sense and vision
Balance – Must maintain an optimistic attitude and keep perspective on what is important in life.


Essential Functions:

Development of analytical capabilities to serve diverse business use cases, in active collaboration with product management and technology counterparts.
Cross-functional, internal and external consulting, including discovery/structuring of business problems, and exploratory analysis of candidate methods to identify promising approaches for development.
Creation and maintenance of solution documentation, including data transformation, models, and solution integration.
Ownership and lifecycle management for analytics capabilities working in a production environment, including computational performance, accuracy/validity, and extension to new uses.
Other duties as assigned


Qualifications:


Job Requirements:

Graduate Degree
Master's degree preferred
4 – 7 years of experience with programming languages like Python (preferred), R or SAS to write complex code and implement into a production environment. Must be able to develop independently and guide others within the development team.
Practical experience with development, tuning, and maintaining Machine Learning capabilities at scale.
Experience generating linear and/or logistic regression models. Must be able to generate complex analytic models on a large scale with no guidance. Must be able to guide others in the same.
Experience with Linear / Integer Programming and/or other optimization techniques. Must be able to generate complex solvable optimization models on a large scale with no guidance. Must be able to guide others in the same.
Experience with data science in Microsoft Azure or cloud environments using Spark or alternative parallel computation capabilities highly desired.
CPG, Sales and/or Retail experience highly desired



Knowledge, Skills and Abilities Requirements:

An understanding of different data sources, their proper uses, and their limitations. Must be able to identify data that is unclean and/or misapplied and must be able to recommend the proper methodology to fix any issues.
Excellent written and verbal communication skills that allows story telling. Must be able to clearly speak English and must be able to communicate very technical procedures to a non-technical audience.
Strong analytical and problem-solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information residing in large datasets.
Ability to consult across various business functions to explain analytic functions and how they can be used to drive a business.
Intellectual curiosity is critical.



Acosta Sales & Marketing is an Equal Opportunity Employer




By submitting your application you agree with and accept the Acosta Privacy Statement and Terms of Conditions.

US: http://acosta.jobs/privacy-policy-us/

Canada: http://acosta.jobs/privacy-policy-ca/
#AcostaServices


Job: Information Technology
Schedule: Full-time
Job Type: Standard
Shift: Day Job
Job Posting: May 12, 2021, 4:29:43 PM","Mosaic North America
3.7",Midtown Toronto
102,Data scientist,"Summary

Koïos Intelligence Inc., established in 2017, is the realization of the vision of an experienced and multidisciplinary team coming from a wide range of scientific, academic and professional backgrounds. Powered by machine learning, operations research and business analytics, Koïos delivers personalized solutions that create a synergy around in-house client systems. In this role, the candidate will work with a multidisciplinary team to design, develop & create analytical solutions through applications of Data Mining, Machine Learning. The ideal candidate will help the team to develop ML applications and take advantage of emerging technologies around Data Science. The candidate will be expected to be hands-on as well as guide and mentor new modellers in the team.

Responsibilities
Understand business needs and apply Machine Learning/Big Data technology to solve real-world business problems
Ability to build and optimize deep architectures using machine learning techniques

Implement state-of-the-art of natural language processing and be familiar with BERT and transformers architectures
Data mining, working with structured and unstructured data
Manipulate high-volume, high-dimensionality data from varying sources to highlight patterns, anomalies, relationships, and trends
Present analysis and recommendations to the target audience

Minimum Qualifications

MSc (Science, Technology, Engineering, Mathematics) degree with 2 years of experience. Moderate working knowledge of modelling/research/analytics or actuarial required. Relevant statistical analysis work experience required.

Work Experience & Knowledge

Relevant work experience in research and/or advanced analytic work (e.g. predictive modelling) in the insurance industry preferred.

Job Specific, Technical Skills & Competencies

Computer Proficiency: Ability to read/revise/review a statistical software program (e.g. Python, R, Java, C++ an advantage)
Ability to create advanced programs from scratch. Leading the Business: Problem Solving & Decision Making.
Risk Taking, Innovation. Results Orientation. Business Perspective. Seeks Opportunities to Learn.
Business Acumen: Understanding and knowledge of key business knowledge areas (e.g. product, enterprise, industry, claim process and competitors).
Ability to leverage business knowledge to determine approaches to execution.
Critical Thinking: Ability to take action in solving problems while exhibiting judgment and a realistic
Statistics: Understanding of advanced statistics underlying data models. Ability to apply new statistical procedures to work. Demonstrates strong ability and knowledge of database principles, data profiling, statistics and data modelling and can apply this knowledge in new or complex situations.

Preferred Qualifications

2+ years of experience in one or more of the following:

Machine Learning Libraries, TensorFlow, PyTorch, Cuda, CuDNN, Dlib, Machine Vision, and Natural Language Processing
4+ years of experience in programming with Python, R, C++ or Java
1+ years of experience in handling data and working with database tools, e.g., SQL, NoSQL, MongoDB, Hadoop or Spark
Proven ability to work creatively and analytically in a problem-solving environment
Excellent communication (written and oral) and interpersonal skills
Experience with contributing to open source project","Koïos Intelligence
5.0",Montreal
103,Data Scientist II,"Bachelor’s Degree in any quantitative discipline such as Statistics, Mathematics, Quantitative Finance or Operational Research
At least 5 years of experience working in Analytics / Data Science / Forecasting environment
Experience in working with databases and SQL in a business environment
Demonstrated use of analytical packages and scripting languages such as R, Python, SAS and SPSS.
Prior experience in design and execution of science/analytical projects.
Worked extensively in large scale databases and data warehouse.
Amazon.com’s Customer Trust and Partner Support (CTPS) mission is to make Amazon the safest and most trusted place worldwide to transact online. Amazon runs one of the most dynamic e-commerce marketplaces in the world, with nearly 2 million sellers worldwide selling hundreds of millions of items in ten countries. CTPS safeguards every financial transaction across all Amazon sites. As such, CTPS designs and builds the software systems, risk models and operational processes that minimize risk and maximize trust in Amazon.com. CTPS organization is looking for a Data Scientist for its Forecasting and Planning Research team. The team is being grown to provide insights about its CTPS planning and provide analytical solutions to help drive operational efficiencies, uncover the hidden risks and trends, reduce investigation errors and bad debt, improve customer experience and predict & recommend the optimizations for future state of CTPS operations.

As a DS-II, you will be responsible for modeling complex problems, discovering insights and identifying opportunities through the use of statistical, machine learning, algorithmic, data mining and visualization techniques. You will collaborate effectively with internal stakeholders and cross-functional teams to solve problems, create operational efficiencies, and deliver successfully against high organizational standards. The candidate should be able to apply a breadth of tools, data sources and analytical techniques to answer a wide range of high-impact business questions and present the insights in concise and effective manner. Additionally, you are an effective communicator capable of influencing and driving major decisions through data-driven insights. This is a high impact role with goals that directly impacts the bottom line of the business.

Responsibilities:

Use time series/ML forecasting techniques to forecast CTPS investigations for improved long term and short term capacity planning.
Employ the appropriate algorithms to discover patterns of risks, abuse and help reduce bad debt
Design experiments, test hypotheses, and build actionable models to optimize CTPS operations
Solve analytical problems, and effectively communicate methodologies and results
Build predict models to forecast risks for product launches and operations and help predict workflow and capacity requirements for CTPS operations
Draw inferences and conclusions, and create dashboards and visualizations of processed data, identify trends, anomalies
Work closely with internal stakeholders such as business teams, engineering teams, and partner teams and align them with respect to your focus area
Experience in statistical techniques such as classification, clustering, regression, statistical inference, collaborative filtering, and natural language processing, experimental design, social networking analysis, feature engineering, etc.
Experience in creating forecasting using time-series and causal models.
Experience/knowledge of advanced machine learning techniques such as GBM, random forest, etc.
Experience in e-commerce / on-line companies in fraud / risk control functions
Coding skills in one of the modern languages Java, Python, R
Experience with visualization technologies such as Tableau
Compelling communication and influencing skills and participation in winning the support of management and influence the course of major strategic decisions","AMZN CAN Fulfillment Svcs, ULC
3.8",Vancouver
104,"Data Scientist, Analytics & Insights","Data Scientist, Analytics & Insights
Mississauga, ON, Canada Virtual Req #635

Thursday, June 10, 2021






Are you looking for more than a job? At World Vision Canada we offer challenging careers that change the lives of children all over the world and it will change yours too. Come and be part of a team of 400 Canadians with a vision for the world: Life in all its fullness for every child.

You will experience Christian faith in action helping to make real and lasting change in the lives of the world’s most vulnerable children. Join the World Vision Canada team and be part of a powerful and effective force for good:

For Children. For Change. For Life.



Position: Data Scientist, Analytics & Insights
Reports to: Manager, Analytics & Insights
Position Term: Full time permanent
Deadline: Until filled
Location: Remote within Canada


Job purpose
The Data Scientist, Analytics & Insights is responsible for discovering insights and identifying opportunities to optimize experiences and help guide and inform key business decisions using statistical, algorithmic, mining and visualization techniques. In addition to advanced analytic skills, this role is also proficient at integrating and preparing large, varied data-sets, architect of specialized database and computing environments, and communicating results.



This role would act as a general consultant to the business on analytics initiatives, and designs and implements end-to-end solutions through the use of well-established and leading edge techniques; the Data Scientist will determine the appropriate solution to address the business problem at hand, extract and manipulate the data from various sources, execute and deploy the solution collaborating with other areas of the organization as needed, and communicate results back to the business in a clear and timely manner.

This role supports the core mandate of the Data Science & Advanced Analytics department, which is to create lasting Customer-Focused Analytics Solutions covering all data domains (customer, financial, operations, impact, third party), and enable Insights-led Decision Making across the organization.


Duties and responsibilities
Consults with business partners and identifies appropriate research approach/design to address the business problem at hand.
Provides in-depth customer analysis and insight, helping to guide and inform decisions to optimize marketing initiatives, research customer personas, segments, and journeys, and highlighting trends as necessary.
Mines internal and external data to develop research results that emphasizes actionable recommendations and insights to support business decisions and marketing optimization.
Extracts and validates structured and unstructured data from various sources, proactively identifying new data sources to integrate into data analytics models.
Manipulates large data sets from multiple sources, performing big data analytics where possible to understand emerging trends, patterns, or insights through the use of statistical analysis.
Creates predictive models that inform key business decisions and executes models from design through to deployment, ensuring accuracy of data and that models are viable, repeatable, and scalable; reports on model results once applied.
Educates the organization on advanced analytics approaches and techniques used, such as testing hypotheses and predictive modelling, helping the organization understand the principles and the underlying logic behind the process.
Leads model governance planning and execution process.
Takes initiative to find better methodologies and approaches to produce accurate, timely and actionable insights for WVC internal stakeholders and donor audiences.
Develops clear and comprehensive presentations of analytics results that emphasizes actionable recommendations and insights to support the development of new strategies and tactics.

Qualifications
3 to 5 years of relevant advanced analytics experience; experience working in an Agile environment an asset.
Bachelor’s degree in mathematics, statistics or computer science or related field.
Master’s degree preferred; certification in machine learning and/or big data an asset.
Solid knowledge of statistical techniques with a focus on customer and digital data, and analytical modelling and other advanced analytics techniques (such as statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms).
Proficient in the use of statistical packages; strong programming skills (such as Hadoop, MapReduce or other big data frameworks, Java), and statistical modelling (like SAS, Python or R)
Experience developing and using machine learning algorithms.
Demonstrates the following data scientist qualities: clarity, accuracy, precision, relevance, depth, breadth, logic, significance, and fairness.
Proven ability to think strategically and to come up with solutions to loosely defined business problems.
Strong interpersonal skills; a strong team player and collaborative with other departments
Curious mindset; demonstrated analytical and communication skills, and commitment to life-long, hands-on learning.

We bring life-saving support in times of disaster. We help poor communities to take charge of their futures. We provide small loans and training that boost family livelihoods. We work with policy makers to change the way the world is run. Our Christian faith teaches us that every child, regardless of gender, faith or race, is a precious gift to the entire world - and that their wellbeing concerns us all. We shall never rest while children suffer in situations that can be changed.

Canada's Top 100 GTA's Top 10

Our Core Values: We are committed to the Poor. We are Christian. We are Stewards. We value People. We are Partners. We are Responsive.
Qualified candidates must be able to demonstrate a commitment to the core values and mission of the World Vision partnership.

World Vision Canada takes our Safeguarding responsibilities seriously and we provide an environment that is safe for our child and adult beneficiaries. We have strong recruitment procedures to make sure the safest and most suitable people work with the children in our programs. We provide our staff and volunteers with ongoing supervision, support and training in their work with child and adult beneficiaries.


World Vision Canada welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.

Thank you for your interest; however only those applicants selected for an interview will be contacted.

Other details

Job Family

Resource Development & Fundraising

Job Function

Individual Contributor

Pay Type

Salary

Telecommute %

100","World Vision Canada
3.4",Mississauga
105,Data Scientist,"About Peritus.ai


Peritus is dedicated to building AI assistants to make tech workers more productive to achieve our vision of zero touch customer service. Our patented cloud-first Knowledge Engine uses advanced NLP and machine learning to enable continuous learning from content, discussions, case management, and agile development systems. We embrace a human-in-the-loop philosophy to train data sets, refine recommendation quality, and learn from implicit user feedback.


Use Cases

The Peritus Knowledge Engine is currently being deployed for the following use cases at large technology vendors:


Customer Self-Service: AI-assisted search and forum question-answering automation to avoid new support cases.
Support Automation: Assisted problem solving that accelerates resolution time and shifts-left new knowledge to make the team smarter.
Services Automation: Build and integrate custom solutions faster by automating code reuse and lower risk of daily CI/CD releases.
The Peritus Technology Platform

Starting with assisting tech users in quickly finding a needle in the haystack, vision extends to assist human reasoning for complex answers across dynamic sources of information. The company’s technology platform ingests unstructured content, systems of record, and product telemetry at high volume & velocity into an industry specific knowledge graph. We use reinforcement learning and a normalized ontology for people, products, and problems to assist human reasoning during problem solving and actively learn from implicit feedback. Peritus has been granted two patents pertaining to reinforcement learning and using a knowledge graph applied to customer service.

Our team is proudly global with locations in the U.S (Bay Area), India (Bangalore), and Canada. Peritus venture investors include The Hive, IdeaSpring, and Benhamou Global Ventures.


About the role


As part of the Canadian engineering team, execute the Machine Learning/Artificial Intelligence technology roadmap to solve the challenges of dealing with structured, semi-structured and unstructured data in the context of a technology problem.


Responsibilities
Advance the Machine Learning capabilities of the product.
Analyze, select and implement Machine Learning/AI algorithms that improve the relevance of related incidents, accuracy of resolutions and routing of incidents.
Experiment with multiple algorithms simultaneously to identify the optimal algorithm.
Improve accuracy by incorporating implicit and explicit feedback from users.
Understand the data by interacting with the Subject Matter Experts.
About you
You have a Master’s / PhD in Computer Science, Machine Learning or equivalent field.
Your experience in building products from scratch using machine learning is a big plus.
You have proven experience in developing algorithms using Python and/or Java, C++ or Scala in one or more of the following fields: machine learning, data analytics, information retrieval.
You have experience applying statistics, probability, and machine learning to real business problems.
You have experience in Natural Language Processing such as topic extraction, building knowledge graph (ontology).
You have experience with Deep Learning frameworks (TensorFlow), applications, or services.
You are smart, get things done, have great energy and thrive in a fast paced early-stage startup environment.
You have passion for creating customer value by applying cutting edge innovations in data science & technology.

Please send your resume to jobs@peritus.ai.",Peritus.ai,Montreal
106,Data Scientist,"About Us

Backed by a 50-year legacy of engineering excellence, reliability and industry-leading customer service, Telesat has grown to be one of the largest and most successful global satellite operators. Telesat works collaboratively with its customers to deliver critical connectivity solutions that tackle the world’s most complex communications challenges, providing powerful advantages that improve their operations and drive growth.

In addition to our state-of-the-art global, geostationary satellite fleet, Telesat Lightspeed, our Low Earth Orbit network scheduled to begin service in 2022, will revolutionize global broadband connectivity by delivering a combination of high capacity, security, resiliency and affordability with ultra-low latency and fiber-like speeds.

Telesat also provides industry-leading technical consultation and support services to satellite operators, insurers and other industry stakeholders around the globe.

Privately held and headquartered in Ottawa, Canada, with offices and facilities around the world, Telesat’s principal shareholders are Canada’s Public Sector Pension Investment Board and Loral Space & Communications Inc. (NASDAQ: LORL). For more information, visit www.telesat.com.

PURPOSE OF JOB

The Senior Data Scientist will be responsible of studying real-time and historical data residing in the data platforms to drive insights and B.I. by implementing ML/AI techniques. The candidate will be primarily focused on examining metadata for different use cases and assessing, developing and implementing ML/AI models using advanced statistical and modeling techniques.

MAIN RESPONSIBILITIES:

The role has 2 primary responsibilities:

Data Science:

Research, develop, and implement machine learning algorithms and artificial intelligence into a variety of services and use cases.
Monitor the latest trends and techniques in machine learning and artificial intelligence to drive innovation.
Collaborate with other teams and share knowledge and ideas to drive optimal business decisions

Data Visualization:

Apply advanced and modern data visualization techniques to enable a digital experience
Create self-serve dashboards to empower stakeholders and various business segments

EDUCATION & EXPERIENCE REQUIRED

Specialized Knowledge, Skills and Abilities

5+ years’ experience in data science with proven experience in ML and AI
Advanced understanding of machine learning, neural networks and deep learning
Expert in Python (Pandas, PySpark, etc.)
Proficiency in machine learning frameworks like scikit-learn, TensorFlow, PyTorch, or Keras
General knowledge of data consumer hubs (Databricks, BigQuery, Snowflake, Synapse)
Experience in studying complex data sets and strong knowledge in data visualization (PowerBI, Tableau)
Excellent communication (verbal, written, presentation) and interpersonal skills
Ability to work under pressure and meet strict deadlines
Master’s degree is an asset – Software Engineering, Computer Science or Mathematics with specialization in statistics, data analytics, or related discipline preferred.

DECISION MAKING & SUPERVISION:

Decision Making

In this role, the incumbent will unleash the power of machine learning and artificial intelligence to positively impact and recommend business decisions tied to LightSpeed.

Supervision Exercised

There will be no supervision of other team members expected for this position.

WORKING CONDITIONS:

The successful candidate must be able to work in Canada and obtain clearance under the Canadian Controlled Goods program (CGP).","Telesat
3.2",Ottawa
107,Associate Data Scientist,"PointClickCare is the leading North American cloud-based healthcare software for the acute and long-term and post-acute care markets. For over 20 years, the company has held the same vision – to help the world care for vulnerable populations. Since its inception, PointClickCare has grown exponentially with over 1,700 employees today all working towards impacting the lives of millions. Recognized by Forbes as one of the Top 100 Private Cloud Companies and acknowledged by Waterstone Human Capital as Canada’s Most Admired Corporate Culture, PointClickCare leads the way in creating cloud-based software. With its recent acquisition of Collective Medical, PointClickCare solidifies its position as a high growth healthcare software provider, serving over 21,000 long-term and post-acute care providers and over 1,300 hospitals. Their shared mission to support vulnerable populations is allowing PointClickCare and Collective Medical to connect disparate points of care at scale faster than anyone else in the market.

For more information on PointClickCare, please connect with us on Glassdoor and LinkedIn.

Position Type:
Co-op Student (Starting Sept 2021)

Reporting to the Vice President, Data Intelligence, the Associate Data Scientist will be responsible for understanding, interpreting, manipulating, grouping and correlating our data with the goal of turning our vast amounts of meaningful insights for PointClickCare internally and for existing and new customer bases externally.

Key Responsibilities:
Analyzing and understanding PointClickCare's data thoroughly
Developing a full understanding of our customers' challenges and need for data, in addition to our own internal needs
Translate business needs into requirements to build analytic plan for data models, approach and methodology
Perform data preparation activities necessary for feature engineering
Using Machine Learning, develop predictive models and visualization tools to deliver new insights and analytics products to our organization
Analyze and evaluate model for accuracy, algorithmic fairness and interpretability
Seek feedback on relative purpose, value and performance of completed analytics products

Experience Required:
Coursework or practical experience with data mining and building algorithms
Some experience in the evaluation of data/data sets work products involving data analysis and research
Proficient computer skills including use of Microsoft Office products or equivalent software and the ability to learn corporate software programs
Basic analytical, data mining, data modeling and data management skills, and ability to utilize data to drive strategic business directions
Practical ability to visualize data, communicates effectively about data, and utilizes data effectively
Strong problem solving and logical skills
Ability to think creatively and to work well both as part of a team and as an individual contributor.
Demonstrate ability to work with minimal direction, with the ability to coordinate complex activities.
Meticulous attention to detail
Excellent written and verbal communication skills and the ability to interact with a variety of customers and stakeholders.
Some exposure with a range of business intelligence and analysis tools SAS, SQL Server Reporting Services, SPSS, R, MicroStrategy, or Tableau is an asset
Statistical programming experience (SAS, R, Python) is an asset

It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.

When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it. If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com","PointClickCare
4.3",Remote
108,Data Scientist,"Company Information


Name of Hiring Company: Nuvoola AI


Nuvoola AI is an artificial intelligence firm based in Quebec, Ontario, and New Brunswick. We are market leader in Artificial Intelligence (AI) computer vision, implementing virtual guard solutions, with facial, license plate and character recognition, leveraging natural language interaction for various market and industries. We thrive at optimizing business processes and solving complex operational problems. We are a recognized and talented team partnering with the best in the industry and take serious proud of helping our customer reduce their operating cost, be more competitive while improving their overall efficiency.


We offer a stimulating, high technology work environment and state-of-the-art projects, coupled with professional development and continuing education with access to international conferences and sophisticated work equipment.


Nuvoola AI subscribes to the principle of equal access to employment and promotes the diversity of the workforce.


Please apply via https://www.nuvoola.com/company#careers


Job Title: Data Scientist


Sector

Management
Finances and Administration
Natural and Applied Science + Related Fields
Health
Sales & Services
Supply chain, Transportation, and Related Fields
Natural Resources, Agriculture
Public Utilities – Fabrication & Services


Number of Opening: 1


Designated Work Area:

Montreal or Chambly (QC), Ottawa (ON), Caraquet (NB), Remote




Job Description:


Are you passionate about creating sustainable solutions using AI and cloud technologies?


Join the Nuvoola AI team as a Data Scientist to solve interesting business challenges. We are looking for individuals that master a whole range of skills and talents going from being able to handle the raw data, analyzing that data with the help of statistical techniques, to sharing his/her insights with his peers (and customers) in a compelling way. The candidate should be capable of figuring new ways of answering business needs where current BI formulas do not exist, should also be focused on predicting future results vs traditional BI views of current/past KPIs.


If you are looking for a team environment and a fun place to work, with emerging technologies and projects, Nuvoola AI is the place for you. Come and join us!




Primary Responsibilities:




Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business decisions.
Applies scripting and programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings and recommendations in a simple, clear way to drive action.
Makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices.
Helps define the strategic direction that Nuvoola AI should take with respect to AI.
Influences stakeholders on the best approaches to use for deep learning.
Identifies cloud infrastructure needs for deep learning.
Evaluates and makes recommendations for new tools, techniques, and technologies to develop and support evolving operational needs in the AI space.
Designs and develops custom data models and algorithms for the Nuvoola AI product line.
Institutionalizes and develops the practice of data scientist within Nuvoola AI.
Popularize complex solutions so that they are clear and understandable for non-experts.
Promotes data science at Nuvoola AI, its customers and to the external community.
Acts as a liaison between our University partners and Nuvoola AI (University of Moncton & ETS). Works closely and supervises the future holders of a doctorate working on our innovating projects with such key partners. Will physically work at those facilities when required.



Essential Skills & Qualifications




University Degree in Computer Science, Math, or related field or equivalent. Masters or PhD preferred.
5+ years of work experience directly related to quantitative analysis with proven results.
3+ years of work experience across a broad set of data science skills, including traditional statistical methods, machine learning and Natural Language Processing.
3+ years of experience with time-series analysis, forecasting, and anomaly detection
Strong knowledge and hands-on experience with R, Python, SQL and C.
Excellent oral and written communication skills (English and French)
Excellent analytical, interpersonal and communication skills, including strong presentation skills.
Dynamic, positive attitude, practical, takes initiative to solve problems.
Excellent time management, organizational and collaborative skills.



Diplomas:

High School
Professional Training
Bachelor’s degree
Master
PhD
Required / Privileged



Level in French

Bilingual
Fluent
Good
Average
School level
Required / Privileged



Level in English

Bilingual
Fluent
Good
Average
School level
Required/ Privileged



Number of Years of Experience: 3 to 5 years

Requited / Privileged



Duration of Contract

Fixed Duration (temporary)
Undetermined Duration (permanent)



Starting Date (Day/Month/Year): April 2021


Remuneration (Mandatory)

Annual
Monthly
Weekly
Hourly


Amount ($ CAN):

From____$______ To _____$______


The information on the salary is:

Confidential
Public



Additional Information:





Why work at Nuvoola AI:



Stimulating work environment and state-of-the-art projects,
Professional development and continuing education with access to international conferences,
Benefits after 3 months in position providing excellent coverage,
Open work environment and sophisticated work equipment.



Nuvoola subscribes to the principle of equal access to employment and promotes the diversity of the workforce.","Nuvoola
3.6",Fort-Chambly
109,Data Scientist,"Company Information


Name of Hiring Company: Nuvoola AI


Nuvoola AI is an artificial intelligence firm based in Quebec, Ontario, and New Brunswick. We are market leader in Artificial Intelligence (AI) computer vision, implementing virtual guard solutions, with facial, license plate and character recognition, leveraging natural language interaction for various market and industries. We thrive at optimizing business processes and solving complex operational problems. We are a recognized and talented team partnering with the best in the industry and take serious proud of helping our customer reduce their operating cost, be more competitive while improving their overall efficiency.


We offer a stimulating, high technology work environment and state-of-the-art projects, coupled with professional development and continuing education with access to international conferences and sophisticated work equipment.


Nuvoola AI subscribes to the principle of equal access to employment and promotes the diversity of the workforce.


Please apply via https://www.nuvoola.com/company#careers


Job Title: Data Scientist


Sector

Management
Finances and Administration
Natural and Applied Science + Related Fields
Health
Sales & Services
Supply chain, Transportation, and Related Fields
Natural Resources, Agriculture
Public Utilities – Fabrication & Services


Number of Opening: 1


Designated Work Area:

Montreal or Chambly (QC), Ottawa (ON), Caraquet (NB), Remote




Job Description:


Are you passionate about creating sustainable solutions using AI and cloud technologies?


Join the Nuvoola AI team as a Data Scientist to solve interesting business challenges. We are looking for individuals that master a whole range of skills and talents going from being able to handle the raw data, analyzing that data with the help of statistical techniques, to sharing his/her insights with his peers (and customers) in a compelling way. The candidate should be capable of figuring new ways of answering business needs where current BI formulas do not exist, should also be focused on predicting future results vs traditional BI views of current/past KPIs.


If you are looking for a team environment and a fun place to work, with emerging technologies and projects, Nuvoola AI is the place for you. Come and join us!




Primary Responsibilities:




Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business decisions.
Applies scripting and programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings and recommendations in a simple, clear way to drive action.
Makes strategic recommendations on data collection, integration and retention requirements incorporating business requirements and knowledge of best practices.
Helps define the strategic direction that Nuvoola AI should take with respect to AI.
Influences stakeholders on the best approaches to use for deep learning.
Identifies cloud infrastructure needs for deep learning.
Evaluates and makes recommendations for new tools, techniques, and technologies to develop and support evolving operational needs in the AI space.
Designs and develops custom data models and algorithms for the Nuvoola AI product line.
Institutionalizes and develops the practice of data scientist within Nuvoola AI.
Popularize complex solutions so that they are clear and understandable for non-experts.
Promotes data science at Nuvoola AI, its customers and to the external community.
Acts as a liaison between our University partners and Nuvoola AI (University of Moncton & ETS). Works closely and supervises the future holders of a doctorate working on our innovating projects with such key partners. Will physically work at those facilities when required.



Essential Skills & Qualifications




University Degree in Computer Science, Math, or related field or equivalent. Masters or PhD preferred.
5+ years of work experience directly related to quantitative analysis with proven results.
3+ years of work experience across a broad set of data science skills, including traditional statistical methods, machine learning and Natural Language Processing.
3+ years of experience with time-series analysis, forecasting, and anomaly detection
Strong knowledge and hands-on experience with R, Python, SQL and C.
Excellent oral and written communication skills (English and French)
Excellent analytical, interpersonal and communication skills, including strong presentation skills.
Dynamic, positive attitude, practical, takes initiative to solve problems.
Excellent time management, organizational and collaborative skills.



Diplomas:

High School
Professional Training
Bachelor’s degree
Master
PhD
Required / Privileged



Level in French

Bilingual
Fluent
Good
Average
School level
Required / Privileged



Level in English

Bilingual
Fluent
Good
Average
School level
Required/ Privileged



Number of Years of Experience: 3 to 5 years

Requited / Privileged



Duration of Contract

Fixed Duration (temporary)
Undetermined Duration (permanent)



Starting Date (Day/Month/Year): April 2021


Remuneration (Mandatory)

Annual
Monthly
Weekly
Hourly


Amount ($ CAN):

From____$______ To _____$______


The information on the salary is:

Confidential
Public



Additional Information:





Why work at Nuvoola AI:



Stimulating work environment and state-of-the-art projects,
Professional development and continuing education with access to international conferences,
Benefits after 3 months in position providing excellent coverage,
Open work environment and sophisticated work equipment.



Nuvoola subscribes to the principle of equal access to employment and promotes the diversity of the workforce.","Nuvoola
3.6",Fort-Chambly
110,Data Scientist,"Description

We are looking for a Data Scientist who will work with a cross-functional team of product, engineering, and customer success leaders to mine customer and end-user data, build predictive models, develop data dashboards and visualizations, and conduct analytical studies in order to help improve our products and drive better outcomes for our customers.

The ideal candidate should be passionate about behavioral data at scale, has a strong analytical and consultative mindset, a deep understanding of databases, visualization, and statistical and machine learning modeling techniques, and the ability to thrive in a dynamic, fast-paced environment. This role will drive high impact to the company through engagement performance optimization, natural language processing, to persona analysis.

Company Description

Viafoura partners with over 600 global media brands, helping them to engage, convert and monetize their digital audiences. With best-in-class engagement and content moderation solutions — including real-time conversations, live blogs, community chat, personalization tools, and AI-powered moderation — Viafoura helps companies create active, civil, and loyal online communities reaching 500 million users every month, and generating massive scale real-time data.

Advanced data analytics also offer customers access to unique and valuable insights into their audience's behaviors and preferences. As a result, the Viafoura solution drives higher registrations and subscriptions as well as better-targeted content and advertising.

Responsibilities



Formulate and lead guided, multifaceted analytic studies against large volumes of data
Interprets and analyzes data using exploratory mathematic and statistical techniques based on the scientific methods
Take ownership of end to end data analysis, reporting, and insights
Identify high potential but underexposed product and feature opportunities
Work with data partners (CDPs, DMPs, ad tech) to help develop integrated products
Works closely with engineering and product teams to develop a strategy for long term data products
Identify data gaps and present solutions through collaboration with engineering and product owners
Implement the strategies and set up A/B test experiments to support best practices
Qualifications
Master's or Phd degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar)
Experience taking ownership of end to end analytical products
3+ years of hands-on experience in statistical modeling and analysis
3+ years experience writing Python and complex SQL queries in a business environment
2+ years of AWS suite experience
1+ years experience building machine learning models
1+ years experience with Quicksight or other visualization tools / open-source libraries
Preferred Qualifications
Analytical mindset and ability to see the big picture and influence others
Detail-oriented and must have an aptitude for solving unstructured problems
Ability to work effectively in a multi-task, high volume environment
Experience with commonly used DMPs, CDPs, and ad technology
Experience with natural language processing, sentiment analysis, semantic pattern detection, and machine learning
Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations
Experience building natural language processing and/or recommendation systems in production
A/B test experience
Job Benefits
Competitive Compensation
Comprehensive benefits
Professional Development
Full remote work option","Viafoura
4.3",Remote
111,Expert Data Science,"At CN, we work together to move our company—and North America—forward. Be part of our Information & Technology (I&T) team, a critical piece of the engine that keeps us in motion. From enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value-added tasks. You will be able to develop your skills and career in our close-knit, safety-focused culture working together as ONE TEAM. The careers we offer are meaningful because the work we do matters. Join us!

Job Summary

You will be part of a team that spans across all business domains. You will provide advanced analytical insights using data analysis and machine learning techniques. You will collaborate with teams across the company, exploring various data sources to help identify new opportunities while driving the adoption of AI. As an expert data scientist, you will combine your knowledge of machine learning and software development skills to automate model development, training, and deployment. You will leverage your experience in building reusable algorithms, functions, and libraries to use in model development for predictive and prescriptive analytics.

Story telling is critical to the change management practice of putting the model into real live environment. Success will be dependent on hypothesis generation, exploration of data, using AI to discover insights, to developing automation pipelines and visual – analytics all being explained to our stakeholder’s community.

The Data & Analytics team is helping CN to create a data-driven culture where everyone can make better decisions, grounded in trusted data, and augmented by the power and scale of analytics. Using advanced data platforms, and AI tooling, decisions can happen at just the right moment, impacting the environment, safety and operational excellence for our customers and team members, while always keeping an eye on the future, ready to explore...

We are highly innovative, and passionate, we believe anything is possible, by embracing people culture, using the right technology, and having an agile mindset, we will drive the highest value to customers…

Interested in working with a team of data innovators, and being part of a culture of transformation, creativity, and teamwork? If so, we would love to connect with you!




Main Responsibilities

Work with structured and unstructured raw data to design and develop innovative predictive models, metrics, and dashboards to uncover actionable insights
Visualize and report data findings creatively in a variety of visual formats that provide insights to the organization
Influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset
Support and evolve the Advanced Analytics and Data Science roadmap by leveraging industry research, best practices, and emerging tools/technology
Collaborate on end-to-end automation efforts required to bring models to production
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities



Requirements

Experience in the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques with hands-on work experience
7-8 or more years of hands-on work and practical business experience in Machine Learning and AI, including classification, clustering, time series analysis, NLP, demand forecasting and optimization
Excellent communication skills and capable of breaking down technical and complex concepts in a way that is understood by non-technical audiences



Education/Certification/Designation

Masters or PhD degree in a quantitative field such as Math, Statistics, Computer Science, Economics, or Data Science



Technical Skills/Knowledge

Solid development experience with Python and comfortable using various data science libraries such as Scikit-learn, Pandas, NumPy as well as frameworks like TensorFlow, Pytorch, Keras and have applied these skills towards solving actual business matters
Comfortable working in and with a Jupyter like environment and infrastructure, and familiar with GitHub, Data bricks
Have advanced knowledge in SQL and Apache Spark
Expert level experience with at least one of the cloud computing platforms – Azure, AWS, GCP
Familiar with Tableau and/or Power BI visual analytics purposes
Well versed in software and AI development lifecycles, including ML Ops
Have agile experience and have a bias for action, removing blocks to get results fast

Assets

Experience with SAFe agile methodology and work in a fast-paced environment
Having Azure or other cloud certifications, For example Azure Data Lake, Data Bricks



About CN

As a leading North American transportation and logistics company, CN is a true backbone of the economy. With a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. We transport US$200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000-mile network spanning Canada and mid-America. CN is the only Canadian company listed in the Transportation and Transportation Infrastructure sector of the Dow Jones Sustainability World Index (DJSI). Launched in 1999, the DJSI World represents the gold standard for corporate sustainability. At CN, we work as ONE TEAM, focused on safety, sustainability, and our customers, providing operational and supply chain excellence to deliver results.


CN is an employment equity employer and we encourage all qualified candidates to apply. We thank all applicants for their interest, however, only candidates under consideration will be contacted. Please monitor your email on a regular basis, as communication is primarily made through email.","Canadian National Railway
3.3",Edmonton
112,Data Scientist,"You’re more than just a statistician made to sound sexy. You’re a happy, hands-on, passionate analyst who can write code and knows math.

Reliance Foundry Co. Ltd. is a Surrey-based, rapidly growing metal products company. With 95 years of experience in the cast metals industry, we now service our Global customers by providing traditional site furnishing and castings in new and innovative ways. We are an agile small business with limitless growth plans that extend far beyond simple metal products. Today, we are looking for enthusiastic, motivated and talented people to join our team.

We are looking for a Lead Data Scientist to develop comprehensive machine learning models for various smart-city and related IoT products. You will be in charge of managing and orchestrating large amounts of raw, real-time data. We will rely on you to build exceptional data products to extract and deliver valuable business insights for our customers.

In this role, you should be highly analytical with a knack for analysis, math, maybe some physics, and certainly statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research.

Your goal will be to help our customers analyze trends that matter to them and to empower their decision-making process with actionable data.

Key Responsibilities:

Work within our digital products team to establish optimal data collection process and techniques.
Undertake preprocessing of structured and unstructured data.
Analyze large amounts of information to discover trends and patterns to deliver valuable insights.
Build predictive models and machine-learning algorithms.
Present information using awesome data visualization techniques that cut through the noise.
Propose solutions and strategies to business challenges.
Collaborate with engineering and product development teams.

Required Qualifications/ Preferences:

Proven experience as a Data Scientist, preferably in a lead role.
Direct experience developing and training machine learning models.
Deep knowledge of SQL and Python; familiarity with Jupyter, JavaScript, C, C++, or Java is an asset.
Experience using business intelligence tools (e.g. AWS QuickSight, Tableau) and data frameworks (e.g. Hadoop).
Analytical mind and business acumen.
Strong math skills (e.g. statistics, algebra).
Problem-solving aptitude.
Excellent communication and presentation skills. You can summarize the complex into the simple.
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred.

Attractive Qualifications:

Happy! You were born with this special gene whereby your glass is always Full.
Hustle Factor: You don’t get discouraged by objections, and you get persistent when it comes to reaching your goals.
Passionate: You’re all about solving real problems, not just “pitching.”
Results-driven: You’re able to think on your feet and love overcoming obstacles.
Adaptability: You are open to feedback and coaching and ready to take your skills to the next level.
Organization: You know how to allocate your time effectively.
Empathetic: You’re a good listener who knows how to get a real sense of customer’s needs.
Customer Focused: You’re always thinking about how to add value for the Customer.
Ability to accomplish multiple tasks simultaneously with speed and accuracy.

Why should you apply?

Full time position with a competitive benefits package, and salary structure.
Reliance Foundry celebrates successes with fun company gatherings, luncheons, and other perks!
We believe in an environment that encourages a positivity while pursuing high standards.

Please submit resumes via email complete with personal cover letter and wage requirements to:

Jazz Gill, HR Manager
Reliance Foundry Co. Ltd.
Surrey, British Columbia (B.C.), Canada
e-mail: recruitment@reliance-foundry.com

No telephone inquiries or agencies, please.
Applications will be assessed to determine a short list of candidates to be interviewed. We appreciate all interest, but only qualified candidates will receive responses.","Reliance Foundry
5.0",Surrey
113,DATA SCIENTIST,"WHO WE ARE

At Leger, we know Canadians. With over 30 years of experience, we are THE most accurate market research firm in Canada. Joining our company means joining a team of 600 passionate people who are committed to their work. We are the largest Canadian-owned market research and analytics company, with 8 offices across Canada and the United States.

WHY YOU WILL LOVE WORKING WITH US

We are the benchmark in our industry, and we offer important strategic advice to our clients. We distinguish ourselves through our company culture, our transparent management, our dynamic attitude and our flat company structure. Our team is the basis of our success and as they say, birds of a feather flock together. If you want to join us and make a difference, our team is waiting for you!

YOUR ROLE AS A DATA SCIENTIST

Provide effective, relevant and innovative insights to our clients through data modelling
Advise our internal & external clients on the data and models to use to meet their business needs
Use your skills in big data mining and modelling i.e., machine learning algorithms, advanced statistical analyses, etc.
Share your knowledge and expertise with your coworkers

Joining our team as a data scientist means taking the values of quality, customer service, innovation, collaboration and commitment to heart. It means being passionate about data, various statistical analyses and storytelling. It also means sharing your knowledge, providing advice and contributing to the growth of the team. Above all, it means growing and evolving in a stimulating and friendly environment.

YOUR RESPONSIBILITIES

Data mining and modelling from various sources (survey data, CRM, operational data, etc.)
Perform advanced statistical analysis: segmentation, MaxDiff, conjoint analysis, factor analysis, TURF, etc. and apply the various techniques to the market research industry
Develop predictive models, classification models, marketing attribution models, etc.
Process structured and unstructured data (social media, videos, etc.)
Propose and develop effective business intelligence solutions aligned with client needs (internal & external)
Develop marketable tools such as simulators, dashboards and predictive models
Advise research teams on service proposals, deliverables, which models and analyses to use, which data to use, interpretation of results, etc.

WHAT YOU NEED TO SUCCEED

Requirements

Graduate degree in a quantitative field such as computer science, engineering, physics, statistics, applied mathematics or equivalent
Strong knowledge of programming languages with emphasis on machine learning and advanced analytics techniques (R and Python)
Practical experience in SQL and database coding
Fluency in French and English is essential
At least 2 years of experience in business intelligence and data modelling
Knowledge of statistical techniques and data mining

Skills

Practical experience with large databases
Collaborative spirit and ability to effectively communicate complex ideas to clients and coworkers
Excellent analytical and problem-solving skills, with the capacity to identify the causes of problems and provide recommendations quicklyExperience in market research and marketing
Rigorous and accurate data processing with a keen eye for detail
Ability to work under tight deadlines and manage multiple projects

BENEFITS

Paid vacation
Group insurance
Employee Recognition Program
Leger University, training, mentorship, and continuing education
Employee Assistance Program (EAP)
Profit-Sharing Program (PSP)
Pension plan
Flex Program: Hybrid Work Model
Overall health allowance
and more!

THE PERKS OF WORKING WITH US

At Leger, our people are at the heart of our success. Being part of our team means:

Working in a friendly, respectful, and positive environment. Happiness at work is one of our top priorities!
Enjoying flexible benefits and other perks that foster a culture of well-being.
Developing your skills and thriving professionally with our learning and mentorship opportunities.
Multiple opportunities for long-term growth. More than one-third of our permanent employees have been with Leger for at least 10 years.
Making new friends and connections across Canada and the United States.
and much more!

If you want to be part of a great team and you think you are the motivated, talented and ambitious person we are looking for, submit your application!

WE THANK ALL APPLICANTS. HOWEVER, ONLY THOSE SELECTED FOR AN INTERVIEW WILL BE CONTACTED.

Leger is an equal opportunity employer. It prohibits discrimination based on age, colour, disability, national origin, race, religion, sex, sexual orientation, and any other legally protected class in accordance with applicable federal, provincial and local laws. Leger is committed to creating and maintaining an inclusive and accessible workplace. If you are contacted for an interview and require accommodation during the interviewing process, please let us know.","Leger
4.0",Midtown Toronto
114,Data Scientist,"Company Description


Cardinal Path, part of dentsu, is a leading digital analytics and digital marketing firm focused on delivering insight, understanding and outcomes that create competitive advantage for our clients. We engage at the strategic, business, and technical levels to generate tangible and quantifiable value for our partners. Our clients include brands such as Bridgestone, Johnson and Johnson, Pfizer, Asics and hundreds of others. Cardinal Path’s mission is: To know. To Share. To be our Partners’ competitive advantage. And our company culture reflects the importance of our people’s’ expertise, wellness and happiness in everything we do.



Job Description


The Data Science Consultant (Data Engineer) will have proven expertise in system architecture, database design, data integrations, and be an expert in SQL and Python. Experience with delivering in big data platforms such as Google BigQuery, Microsoft Azure SQL DB/Synapse, or Amazon Redshift is essential. Expertise with traditional RDBMS platforms such as SQL Server or Oracle and NoSQL and Hadoop environments would complement. Data integration experience using ETL platforms such as AirFlow, Talend, Alteryx, or Fivetran is important.

Experience in the digital data and analytic ecosystem and intermediate knowledge in Web Analytic tools (Google Analytics or the Adobe Marketing Cloud), and API expertise is a major plus!!

Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles
Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts
Participate in product roadmap discussions and identifying key areas for improvement of products and services
Collect client project requirements, focusing on needs & impacts and necessary technical outcomes
Create solution designs to solve for clients business and technical needs while keeping within budget
Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following Cardinal Path's documentation standards
Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards
Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security
Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models
Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps.


Qualifications

Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development
Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required
Experience with relational database systems including SQL Server, Oracle, MySql, Postgres
Advanced skills in data scripting and database development technologies (SQL, Python, R)
Deep knowledge of ETL tools and how they can be applied to a big data environment
Familiarity with analyzing digital marketing, advertising and ecommerce data
Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics
Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI
Experience with cloud platforms such as AWS, Azure, and Google Cloud
Familiar with NoSql database technologies such as MongoDB
Knowledge of technologies such as Spark, Hadoop, and Airflow



Additional Information


We know through experience that different ideas, perspectives and backgrounds foster a stronger and more creative work environment that delivers better business results. We strive to create workplaces that reflect the clients we serve and where everyone feels empowered to bring their full, authentic selves to work. We are committed to working with our candidates from all ability levels throughout the recruitment process to ensure that they have what they need to be at their best.

If you need accommodation during the application or interview process, please contact Canada.Recruitment@dentsuaegis.com or to begin a conversation about your individual accessibility needs throughout the hiring process.

#LI-MZ1","Cardinal Path
3.4",Midtown Toronto
115,Data Scientist - NLP,"What is the opportunity?

As a data scientist in the NLP space you are part of a team responsible for developing RBC’s NLP platform supporting a variety of projects. You will be part of the innovation and technology team at RBC, working on building technology components that RBC developers and businesses leverage to deliver business value. You will be working on projects using latest advancements in Natural Language Processing (NLP) to enable adoption and reuse across the enterprise. The position will involve research in a practical setting while building production systems and models.


We want vocal futurists that can advocate their vision, who will be excited about creative problem-solving as part of a cross-functional team; will obsess over writing smart, simple clean code; will tirelessly strive to deliver the best solution supporting the user experience and will have the drive and desire to keep learning the latest.


What will you do?

Work with modern open source and vendor packages to support use cases in semantic understanding & conversational AI.
Own the end-to-end cycle from understating the business problem, data discovery and extraction, model development and evaluation, to production deployment.
Stay up to date with latest research and apply it in practical settings to define strategy and deliver business value.
Perform code reviews and ensure a high level of code quality.
Provide technical mentorship within the organization to streamline adoption of NLP components.
Keep developer experience in mind when building tools and services for others to use.
Work in a cross-functional, collaborative team aimed at delivering high-value, high quality, and scalable NLP/ML solutions.


What do you need to succeed?

Must-have

Master’s or PhD degree in Mathematics, Statistics or Computer Science with a focus on AI/ML areas
2+ years of work experience in a data science and machine learning
Expert understanding of NLP tasks such as classification, NER, text generation, and topic modeling with practical experience using NLP libraries such as Gensim, SpaCy
Hands-on experience and expertise with different AI/ML frameworks such as Keras, Pytorch, TensorFlow, SparkML, Scikit-Learn
Solid experience in deploying production level AI models


Nice to Have

Experience with deep neural networks architectures in particular transformer models
Familiar with container-type environments: Docker, Openshift
3+ years of experience in advanced software engineering practices including Agile techniques


What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.

A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Work in a dynamic, collaborative, progressive, and high-performing team
Flexible work/life balance options
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with business partners


Learn more about RBC Tech Jobs

Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Toronto
Address: 88 Queens Quay West
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel(%): 0
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 06/25/2021
Platform: Technology and Operations
Req ID: 368717
Ad Code(s):","RBC
4.1",Midtown Toronto
116,Data Scientist - NLP,"What is the opportunity?

As a data scientist in the NLP space you are part of a team responsible for developing RBC’s NLP platform supporting a variety of projects. You will be part of the innovation and technology team at RBC, working on building technology components that RBC developers and businesses leverage to deliver business value. You will be working on projects using latest advancements in Natural Language Processing (NLP) to enable adoption and reuse across the enterprise. The position will involve research in a practical setting while building production systems and models.


We want vocal futurists that can advocate their vision, who will be excited about creative problem-solving as part of a cross-functional team; will obsess over writing smart, simple clean code; will tirelessly strive to deliver the best solution supporting the user experience and will have the drive and desire to keep learning the latest.


What will you do?

Work with modern open source and vendor packages to support use cases in semantic understanding & conversational AI.
Own the end-to-end cycle from understating the business problem, data discovery and extraction, model development and evaluation, to production deployment.
Stay up to date with latest research and apply it in practical settings to define strategy and deliver business value.
Perform code reviews and ensure a high level of code quality.
Provide technical mentorship within the organization to streamline adoption of NLP components.
Keep developer experience in mind when building tools and services for others to use.
Work in a cross-functional, collaborative team aimed at delivering high-value, high quality, and scalable NLP/ML solutions.


What do you need to succeed?

Must-have

Master’s or PhD degree in Mathematics, Statistics or Computer Science with a focus on AI/ML areas
2+ years of work experience in a data science and machine learning
Expert understanding of NLP tasks such as classification, NER, text generation, and topic modeling with practical experience using NLP libraries such as Gensim, SpaCy
Hands-on experience and expertise with different AI/ML frameworks such as Keras, Pytorch, TensorFlow, SparkML, Scikit-Learn
Solid experience in deploying production level AI models


Nice to Have

Experience with deep neural networks architectures in particular transformer models
Familiar with container-type environments: Docker, Openshift
3+ years of experience in advanced software engineering practices including Agile techniques


What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.

A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Work in a dynamic, collaborative, progressive, and high-performing team
Flexible work/life balance options
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with business partners


Learn more about RBC Tech Jobs

Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Toronto
Address: 88 Queens Quay West
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel(%): 0
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 06/25/2021
Platform: Technology and Operations
Req ID: 368717
Ad Code(s):","RBC
4.1",Midtown Toronto
117,Data Science,"Job Category: Engineer
Job Type: Full Time
Job Location: CanadaUSA
Location : Multiple Locations
Description

We are looking for data scientists who can develop best in class predictive models, machine learning models, and deep learning models and at the same time, they should be able to explain the decisions taken by the models automatically through plain simple English language. Also, facilitate product solutions and enhance user experience with analytical insights and addressing the problem statements encountered by users

Responsibilities
Work with deep data and analytics skills with strong business acumen to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results.
Experience using statistical computer languages R, Python, SLQ, etc to manipulate data and draw insights from large data sets
Experience working with and creating data architectures
Knowledge of a variety of machine learning techniques clustering, decision tree learning, artificial neural networks, etc and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts regression
Demonstrate and Document working prototype on test datasets and real-world scenarios.
Innovate to come up with new solutions and improve existing solutions.
Be an enthusiastic and motivated member of the team.
Maintain knowledge of new technologies in the field of Computer Vision and Machine Learning.
Required Skills
Python, Linux OS
Has hands-on knowledge on setting up Docker containerization and running application on ECS,EKS
Very good exposure in setting up Analytical tools such as RStudio, MLFLOW, Databricks, Jupyter etc.
Very good practical knowledge of using and implementing AWS services EC2,S3,ECS,AWS sagemaker.
Mathematical optimization, discrete-event simulation, rules programming, and predictive analytics.","Cyber Chasse
4.1",Canada
118,Data Scientist,"Transforming the Future with the Convergence of Simulation and Data

Data Scientist:

Do you like a challenge, are you a complex thinker who likes to solve problems? If so, then you might be the new Altairian we are searching for. At Altair, your curiosity matters. We pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients' success, as well as our own.


Job Summary:

The goal of the data scientist is to provide impactful analytics for clients using available data. The data scientist works alongside project managers, ETL professionals, relationship managers and sales managers to serve a diverse group of clients. The role is client-facing and calls for a mixture of technical, business and people skills.

Data scientists apply data analysis and statistical techniques to various data sets to develop predictive models and apply other machine learning techniques. As a consultant, they are also critical in the phases prior to modelling: defining the project, hands-on data extraction, and data quality. After modelling, data science consultants are responsible for the presentation and deployment phases, and performing the tasks that lead to successful implementation of predictive analytics for our clients. – Location Greater Toronto Area, CA




What You Will Do:


• Requirements capture,

Data preparation and analysis,
Knowledge discovery,
Predictive analysis,
Business analysis and interpretation,
Reporting and scoring,
ROI analysis,
Strategic deployment of analytics,
Provide maximum business value to Altair clients through analytics deployment,
Working in close collaboration with Altair sales professionals and serving as knowledgeable trusted advisors to clients and industry partners,
Provide a spectrum of custom, rapidly deployable, solutions which include B2B and B2C data-driven decision support capabilities
Conduct presentations to senior level clients when required



What You Will Need:

Basics:

Strong quantitative background (applied mathematics/statistics, engineering, physics, applied sciences) with MSc or PhD.
2+ years working as a Data Scientist.
Deep knowledge understanding of data mining techniques (e.g. decision trees, regression analysis, time series analysis, clustering, association rules, etc.).
Strong analytical and problem-solving skills.
Good working knowledge of programming languages and platforms such as SAS and/or SQL (e.g. SQL Server, Oracle, DB2), Matlab, R or Python.
Excellent written and oral communication skills.
Be able to work independently as well as in a team environment.



How You Will Be Successful:

Envision the Future
Communicate Honestly and Broadly
Seek Technology and Business “Firsts”
Embrace Diversity and Take Risks



What We Offer:

Competitive Salary
Comprehensive Benefit Package
Outstanding Work/Life Balance
Flex Time
Group RSP
Employee Stock Purchase Program
Paid Vacation & Paid Holidays
Paid Time Off for Community Service
Collaborative environment
Charitable Matching Program



Why Work with Us:

Altair is a global technology company that provides software and cloud solutions in the areas of product development, high-performance computing (HPC) and artificial intelligence (AI). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.




Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing and artificial intelligence (AI).




For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com.


Ready to go? #ONLYFORWARD


At our core we are explorers; adventurers; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. We are the original trailblazers that make the impossible possible; discovering new solutions to our customer’s toughest challenges.


Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair's history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.","Altair Engineering
4.2",Midtown Toronto
119,Data Scientist,"Core Responsibilities

1. Develops queries and performs extensive programming to access, transform, and prepare data for statistical modeling.

2. Performs deep dive diagnostic, predictive, and prescriptive analytics to support data-driven business decision making.

3. Identifies and diagnoses data inconsistencies and errors, documents data assumptions, and forages to fill data gaps.

4. Engages with internal stakeholders to understand and probe business processes in order to develop hypotheses. Brings structure to requests and translates requirements into an analytic approach.

5. Guides test design, research design, and model validation. Provides statistical consultation services. Serves as the analytics expert on cross functional teams for large strategic initiatives and contributes to the growth of the Vanguard analytic community.

6. Prepares and delivers insight presentations and action recommendations. Communicates complex analytical findings and implications to business partners.

7. Participates in special projects and performs other duties as assigned.


Qualifications

Minimum of three years related work experience in analytical roles. Experience with data wrangling required - Programming skills to access, transform and prepare large scale data for statistical modeling. Experience utilizing statistical and machine learning methods required.
Undergraduate degree in Analytics, Applied Mathematics, Economics, Statistics or related analytical field of study or equivalent combination of training and experience. Graduate degree preferred.

About Vanguard

We are Vanguard. Together, we’re changing the way the world invests.

For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.

We want to make success accessible to everyone. This is our opportunity. Let’s make it count.

Inclusion Statement

Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”

We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.

When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.

Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.","Vanguard
3.5",Midtown Toronto
120,Data Scientist,"Transforming the Future with the Convergence of Simulation and Data

Data Scientist:

Do you like a challenge, are you a complex thinker who likes to solve problems? If so, then you might be the new Altairian we are searching for. At Altair, your curiosity matters. We pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients' success, as well as our own.


Job Summary:

The goal of the data scientist is to provide impactful analytics for clients using available data. The data scientist works alongside project managers, ETL professionals, relationship managers and sales managers to serve a diverse group of clients. The role is client-facing and calls for a mixture of technical, business and people skills.

Data scientists apply data analysis and statistical techniques to various data sets to develop predictive models and apply other machine learning techniques. As a consultant, they are also critical in the phases prior to modelling: defining the project, hands-on data extraction, and data quality. After modelling, data science consultants are responsible for the presentation and deployment phases, and performing the tasks that lead to successful implementation of predictive analytics for our clients. – Location Greater Toronto Area, CA




What You Will Do:


• Requirements capture,

Data preparation and analysis,
Knowledge discovery,
Predictive analysis,
Business analysis and interpretation,
Reporting and scoring,
ROI analysis,
Strategic deployment of analytics,
Provide maximum business value to Altair clients through analytics deployment,
Working in close collaboration with Altair sales professionals and serving as knowledgeable trusted advisors to clients and industry partners,
Provide a spectrum of custom, rapidly deployable, solutions which include B2B and B2C data-driven decision support capabilities
Conduct presentations to senior level clients when required



What You Will Need:

Basics:

Strong quantitative background (applied mathematics/statistics, engineering, physics, applied sciences) with MSc or PhD.
2+ years working as a Data Scientist.
Deep knowledge understanding of data mining techniques (e.g. decision trees, regression analysis, time series analysis, clustering, association rules, etc.).
Strong analytical and problem-solving skills.
Good working knowledge of programming languages and platforms such as SAS and/or SQL (e.g. SQL Server, Oracle, DB2), Matlab, R or Python.
Excellent written and oral communication skills.
Be able to work independently as well as in a team environment.



How You Will Be Successful:

Envision the Future
Communicate Honestly and Broadly
Seek Technology and Business “Firsts”
Embrace Diversity and Take Risks



What We Offer:

Competitive Salary
Comprehensive Benefit Package
Outstanding Work/Life Balance
Flex Time
Group RSP
Employee Stock Purchase Program
Paid Vacation & Paid Holidays
Paid Time Off for Community Service
Collaborative environment
Charitable Matching Program



Why Work with Us:

Altair is a global technology company that provides software and cloud solutions in the areas of product development, high-performance computing (HPC) and artificial intelligence (AI). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.




Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing and artificial intelligence (AI).




For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com.


Ready to go? #ONLYFORWARD


At our core we are explorers; adventurers; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. We are the original trailblazers that make the impossible possible; discovering new solutions to our customer’s toughest challenges.


Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair's history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.","Altair Engineering
4.2",Midtown Toronto
121,Data Scientist,"Patagona Technologies is a software development company working with the Canadian Department of National Defence on studying and combating online disinformation. We are looking for a Data Scientist to contribute to the development of various machine learning models on social media network data. You will work side-by-side with a Computational Social Scientist to apply these models to various real-world case studies to demonstrate and validate our systems. You will apply social network analysis approaches to various research contexts.

Responsibilities

Develop techniques to expand training datasets while limiting bias within those datasets.
Develop processes and tools to monitor and analyze model performance and data quality.
Gather and process data at scale, write scripts and queries, and work with APIs.
Work with the team to provide research support using qualitative and quantitative methods.
Contribute to reports and studies for publication.

Qualifications

Experience using Python to manipulate data and draw insights from large data sets.
Experience working with relational data using SQL.
Experience visualizing and presenting data to stakeholders.
Experience working with cloud services for data processing and ETL pipelines.
Excellent written and verbal communication skills for communicating with a team and writing for publication.
Knowledge and experience in statistical and data mining techniques for social network analyisis.
Knowledge of common machine learning techniques and their real-world advantages/drawbacks.
Familiarity with data analytics and computational social science methods (in particular network analysis and natural language processing).
Strong problem solving skills and proactive in filling in own knowledge gaps through learning and asking questions.

Special Consideration will be given to candidates with:

Written language skills in French, Russian and Chinese.
Prior experience studying online disinformation or other social media analysis work.

Job Type: Full-time

Pay: $75,000.00-$83,000.00 per year",Patagona Technologies,Kelowna
122,Machine Learning Engineer / Data Scientist,"CATCHY INTRO


Honestly, we’ve been brainstorming this “catchy intro” for about 20 minutes and everything that we throw at the wall is either too serious, or just downright lame, with no authenticity behind it. Which is absolutely hilarious, considering everyday TerraSense strives for authenticity. So that’s it. That’s what you get. Our not-so-super-catchy, not-super-lame, but not-super-corporate intro. Authentic. Hey, come work here and help us on this journey.


WHY WORK WITH US?


Our two main products target the Utilities and Defense sectors. Besides understanding how to use machine learning to predict maintenance for transmission lines, or how to take the metadata from two sensors and fuse them together, we actually do appreciate the soft skills too. We strive to foster a culture of success, innovation, respect, and did we mention authenticity? That’s right, if you hate what the CTO is saying, we fully expect you to step up and tell him he’s wrong (or that you disagree). The Product Manager does all the time and she still hasn’t been fired.


WHAT YOU WOULD BE DOING...


... on the development team for our MIST product, working to create and deploy aerial surveillance with artificial intelligence. The product will utilize edge computing, computer vision and deep learning algorithms. Okay so we hope that you got this far and are slightly intrigued by our culture and what you would be doing. Here comes the hard part. This role requires you to be a Canadian Citizen or Permanent Resident having resided in Canada for at least 10 years as well as a criminal record and credit check. You will be required to work locally with flexibility on work hours. These are hard requirements with no negotiation, so please do not apply to this particular role if you don’t meet these requirements. We will have other roles that come up without such stringent requirements, but there is no wiggle room on this one.


QUALIFICATIONS



Excellent knowledge of Python
2 years of experience in building and shipping great software
Experience with deploying ML on the edge or in the cloud
Strong knowledge of ML frameworks (eg. TensorFlow, PyTorch, CUDA)
Knowledge of computer vision models, frameworks, and tools
Eligible for security clearance and to work in Canada
Bonus: Experience with Docker, video analytics, and/or GUI development a plus
Bonus: Networking and cybersecurity experience



COMPENSATION



Competitive salary and stock options based on experience, competency and length of service
5 weeks paid vacation
Training and professional development allowance, and extended medical and dental
Beer Tuesdays at our neighbourhood microbrewery (post Covid!)


NON - COMPENSATION CONSIDERATIONS



Accountability: We truly do work hard, play hard and expect everyone to self manage...meaning we don’t track hours.
Flexibility: If your best time to work is from 10pm to 2am then we want to support that so we try to enable team communication by committing to M-Th 10am-2pm “office hours.” The rest is up to you.",TerraSense Analytics Ltd,Kelowna
123,Data Scientist,"We are looking for a great Data Scientist to join Wysdom.AI – a fast-growing Conversational AI company helping businesses offer their customers natural language AI solutions that deliver automated customer service and support over chat, through smart devices, search, or on the phone.

Wysdom offers a comprehensive Conversational AI Optimization suite helping businesses increase customer satisfaction, contain costs, and maximize revenue generation. We use a proprietary suite of analytics, optimization and testing tools, and offer services through a team of experienced conversational AI specialists who ensure clients maximize their conversational AI ROI. Brands around the world fully outsource their conversational AI needs to Wysdom.

We do all the work for enterprises as their business evolves, from set-up to optimization. Our customer’s only job is to tell us what matters to their customers and what matters to them. We’ll take it from there, while providing the ongoing insights on how Wysdom is shaping the experience of the enterprise’s customers.

The Wysdom platform is built on a state-of-the-art NLP infrastructure, complemented with the tools, data and people to ensure successful operation of the suite of Wysdom products.

We are growing our team — please join us as a Data Scientist based in our Richmond Hill headquarters.

But what will I actually be doing?

The day-to-day will involve writing queries, building dashboards, and preparing analytical reports about product performance for our clients and the Wysdom.AI team. You will work with SQL, Tableau, and Python and ML Frameworks/libraries (among other tools) to create stunning visuals showing how Wysdom.AI is making their customers’ experience even better. There will also be opportunities to improve our AI processes and drive real change in our platform through developing tools and processes to streamline AI training and analytics.

In this role, you will:

Build and maintain efficient Tableau dashboards and reports for a variety of Wysdom customers
Maintain and help optimize Tableau Server instances for our clients
Conduct an ad-hoc analysis as requested to dig into product performance
Assist in building out automated processes using Python to enhance analytics at Wysdom.AI
Continually improve our insights products through performance improvements, new metrics, and visualizations
Beyond theses day-to-day responsibilities, your sense of curiosity and analytical mindset, will challenge you to dig deeper into the ways in which we can continually improve our solution, our success rate, and the customer experience.

About You

Degree in Computer or Data Science, Statistical Analysis, Math and Engineering
2-3 years of experience with data visualization tools, specifically Tableau and experience setting up and managing Tableau Server
Experience programming with Python and with Machine Learning frameworks/libraries e.g. Scikit-learn, Pandas, Matplotlib, Seaborn, Tensor flow, or Pytorch would be an asset
Experience with ETL tools: Tableau ETL, Airflow
Advanced SQL querying skills (Experience with NoSQL, specifically MongoDB is an asset)
Experience using Excel/Google Sheets
Source Control: Git
Strong problem solving, quantitative and analytical abilities
Knowledge of API’s/ Web Services Integration

About Wysdom.AI

Wysdom.AI is a venture-funded start-up and is led by an experienced team of serial entrepreneurs with a history of building great teams and products. We offer a terrific work environment in all our offices, full company-paid benefits from your first day, and a stock option program, to ensure you participate in the growth we see ahead. Head here to read more about what it’s like to work at Wysdom.

MZjvkjiUoM","Wysdom.AI
4.2",Richmond Hill
124,Data Scientist,"We are looking for a great Data Scientist to join Wysdom.AI – a fast-growing Conversational AI company helping businesses offer their customers natural language AI solutions that deliver automated customer service and support over chat, through smart devices, search, or on the phone.

Wysdom offers a comprehensive Conversational AI Optimization suite helping businesses increase customer satisfaction, contain costs, and maximize revenue generation. We use a proprietary suite of analytics, optimization and testing tools, and offer services through a team of experienced conversational AI specialists who ensure clients maximize their conversational AI ROI. Brands around the world fully outsource their conversational AI needs to Wysdom.

We do all the work for enterprises as their business evolves, from set-up to optimization. Our customer’s only job is to tell us what matters to their customers and what matters to them. We’ll take it from there, while providing the ongoing insights on how Wysdom is shaping the experience of the enterprise’s customers.

The Wysdom platform is built on a state-of-the-art NLP infrastructure, complemented with the tools, data and people to ensure successful operation of the suite of Wysdom products.

We are growing our team — please join us as a Data Scientist based in our Richmond Hill headquarters.

But what will I actually be doing?

The day-to-day will involve writing queries, building dashboards, and preparing analytical reports about product performance for our clients and the Wysdom.AI team. You will work with SQL, Tableau, and Python and ML Frameworks/libraries (among other tools) to create stunning visuals showing how Wysdom.AI is making their customers’ experience even better. There will also be opportunities to improve our AI processes and drive real change in our platform through developing tools and processes to streamline AI training and analytics.

In this role, you will:

Build and maintain efficient Tableau dashboards and reports for a variety of Wysdom customers
Maintain and help optimize Tableau Server instances for our clients
Conduct an ad-hoc analysis as requested to dig into product performance
Assist in building out automated processes using Python to enhance analytics at Wysdom.AI
Continually improve our insights products through performance improvements, new metrics, and visualizations
Beyond theses day-to-day responsibilities, your sense of curiosity and analytical mindset, will challenge you to dig deeper into the ways in which we can continually improve our solution, our success rate, and the customer experience.

About You

Degree in Computer or Data Science, Statistical Analysis, Math and Engineering
2-3 years of experience with data visualization tools, specifically Tableau and experience setting up and managing Tableau Server
Experience programming with Python and with Machine Learning frameworks/libraries e.g. Scikit-learn, Pandas, Matplotlib, Seaborn, Tensor flow, or Pytorch would be an asset
Experience with ETL tools: Tableau ETL, Airflow
Advanced SQL querying skills (Experience with NoSQL, specifically MongoDB is an asset)
Experience using Excel/Google Sheets
Source Control: Git
Strong problem solving, quantitative and analytical abilities
Knowledge of API’s/ Web Services Integration

About Wysdom.AI

Wysdom.AI is a venture-funded start-up and is led by an experienced team of serial entrepreneurs with a history of building great teams and products. We offer a terrific work environment in all our offices, full company-paid benefits from your first day, and a stock option program, to ensure you participate in the growth we see ahead. Head here to read more about what it’s like to work at Wysdom.

MZjvkjiUoM","Wysdom.AI
4.2",Richmond Hill
125,Data Scientist,"About Guestlogix:

We take the stress out of travelling for passengers. With our platform, airlines can deliver content that lets passengers tailor their trip uniquely for themselves. This includes items and services for travelers throughout their whole trip, like priority boarding or lounge access, a tour of the Eiffel Tower if you’re in Paris, or a personalized whiskey tour if you’re in Dublin.

This approach to the travel experience transforms how airlines provide value to their passengers and drives ancillary revenue through every stage of the customer journey. The vision for our platform will deliver on this promise by leveraging AI to offer an extensive inventory of personalized, high-demand and custom curated content - including offers for pre, during and post travel - through an intuitive, customer centric interface delivering benefits for passengers and airlines. And we need your help to make this vision a reality.

Who we are looking for:

Guestlogix’s vision for the future? A personalized, AI driven travel platform for a seamless and stress free travel experience for every single traveler. You will be a massive part of that future achievement.

Our Delivery team at Guestlogix is looking to add a Data Scientist. You’ll join a small, agile delivery team composed of product managers, designers, and developers all committed to delivering a great product collaboratively.

What you will do here:

Create cutting edge technology. You will bring your data skills and experience to bear on building a SaaS platform that makes passengers’ lives easier and stress free. You will produce scalable, well tested, and reusable enterprise grade code and models.
Solve problems. This is a role for someone who sees a problem and can identify the steps needed to resolve it and take action in a creative but stable way.
Collaborate. Our small polyskilled teams work closely up and down our tech stack and across disciplines to build the best platform possible for our customers and passengers.

What you will need to excel here:

A passion to create technology that will make the lives of passengers all over the world better.
Real-world experience applying machine learning and NLP to solve problems for users.
Specific experience in using information extraction and knowledge graphs is a plus.
Experience writing code working in a variety of languages such as R, Python, and SQL.
Comfort and familiarity with agile and lean techniques and the desire to continuously improve how we deliver products.
Effective communication skills where you listen with the intent of truly understanding and are concise, articulate and candid when communicating - both verbally and in writing.
A drive for excellence and a passion for creating cool stuff, breaking down barriers and completely changing the game.

Join us on our journey to make air travel a great experience again. Our crew enjoys a remote-first way of working. You will have the flexibility and autonomy to innovate within small teams to build our first to market platform, using modern tools and methods. As if that is not enough, we provide you with a competitive salary and benefits, and provide you with the flexibility to manage work and life, along with virtually unlimited developmental opportunities to grow your skills and learn together on our journey.


LJV17o1eG6","Guestlogix
2.6",Remote
126,Data Scientist,"About Guestlogix:

We take the stress out of travelling for passengers. With our platform, airlines can deliver content that lets passengers tailor their trip uniquely for themselves. This includes items and services for travelers throughout their whole trip, like priority boarding or lounge access, a tour of the Eiffel Tower if you’re in Paris, or a personalized whiskey tour if you’re in Dublin.

This approach to the travel experience transforms how airlines provide value to their passengers and drives ancillary revenue through every stage of the customer journey. The vision for our platform will deliver on this promise by leveraging AI to offer an extensive inventory of personalized, high-demand and custom curated content - including offers for pre, during and post travel - through an intuitive, customer centric interface delivering benefits for passengers and airlines. And we need your help to make this vision a reality.

Who we are looking for:

Guestlogix’s vision for the future? A personalized, AI driven travel platform for a seamless and stress free travel experience for every single traveler. You will be a massive part of that future achievement.

Our Delivery team at Guestlogix is looking to add a Data Scientist. You’ll join a small, agile delivery team composed of product managers, designers, and developers all committed to delivering a great product collaboratively.

What you will do here:

Create cutting edge technology. You will bring your data skills and experience to bear on building a SaaS platform that makes passengers’ lives easier and stress free. You will produce scalable, well tested, and reusable enterprise grade code and models.
Solve problems. This is a role for someone who sees a problem and can identify the steps needed to resolve it and take action in a creative but stable way.
Collaborate. Our small polyskilled teams work closely up and down our tech stack and across disciplines to build the best platform possible for our customers and passengers.

What you will need to excel here:

A passion to create technology that will make the lives of passengers all over the world better.
Real-world experience applying machine learning and NLP to solve problems for users.
Specific experience in using information extraction and knowledge graphs is a plus.
Experience writing code working in a variety of languages such as R, Python, and SQL.
Comfort and familiarity with agile and lean techniques and the desire to continuously improve how we deliver products.
Effective communication skills where you listen with the intent of truly understanding and are concise, articulate and candid when communicating - both verbally and in writing.
A drive for excellence and a passion for creating cool stuff, breaking down barriers and completely changing the game.

Join us on our journey to make air travel a great experience again. Our crew enjoys a remote-first way of working. You will have the flexibility and autonomy to innovate within small teams to build our first to market platform, using modern tools and methods. As if that is not enough, we provide you with a competitive salary and benefits, and provide you with the flexibility to manage work and life, along with virtually unlimited developmental opportunities to grow your skills and learn together on our journey.


LJV17o1eG6","Guestlogix
2.6",Remote
127,Data Scientist,"This is an exciting opportunity to join our client's Innovation and Strategy team at the ground level! You will be part of their innovation hub located in downtown Toronto where your desire for impact will only be matched by your inate ability to collaborate with other like minded individuals to come up with creative solutions to retail data science problems.

In this role, you'll have the chance to roll up your sleeves and apply data science methods and analytics to real-world business situations. The Data Scientist will play a key role in enhancing advanced analytics and machine learning capabilities within the organization. You will be responsible for the building, training, scoring and monitoring of machine learning models. You will work closely with various stakeholders throughout our business to understand business needs and develop solutions through machine learning or other advanced analytics/predictive modeling techniques.

Job Requirements

MS/PHD or equivalent in Computer Science, Engineering, Statistics, Mathematics, or related technical field
Experience in developing machine-learning algorithms, statistical and mathematical optimization models, and simulation and visualization tools
Strong understanding of regression modeling, time series analysis, cluster analysis, machine-learning concepts such as supervised and unsupervised learning, classification, random forest, neural nets, etc.
Ability to identify predictive attributes of data sets and perform feature engineering to improve machine learning results
Experience with manipulating big data sets via SQL able to process, filter and present large quantities of data
Experience in one or more programming languages (e.g. Python, R, Scala, etc.)
Experience with Databricks, Tableau and AutoML tools an asset","Vaco
3.7",Midtown Toronto
128,Sr Data Scientist,"Position Summary:

The successful candidate will assist in leveraging customer, digital and transportation datasets to create insights on pricing, marketing and customer travel behavior. The Sr. Data Scientist will assist the Director of Data Analytics and other key stakeholders to bring actionable data driven solutions to 407 ETR. They will have the expertise and knowledge to mentor more junior members while also having the business acumen to understand how to frame a business problem and deliver insight that is actionable. This position is part of a highly collaborative and energetic team in a start-up minded environment.

Position Responsibility:

Assemble and analyze data to understand customer behavior from existing 407 ETR data, external data sources and emerging sources.
Building Pricing models and optimization using python, gurobi or the like.
Undertake analysis of target customer groups (segments) for specific marketing and pricing programs and assess opportunities and strategies for marketing.
Ad hoc analysis and modeling of data.
Lead project-based work with key business stakeholders.
Strong Mentoring and leadership skills to support and coach junior members on statistical techniques and experimental design.
Strong experience building customer analytic models like: price elasticity, attrition, lifetime value, churn and segmentation.
Ability to understand business stakeholder’s issues and create valuable insight.
Raise awareness and action of data science within the company to help focus on fact-based decisions.
Support the Department along with the Information Technology Management Department in planning the structure and storage of new customer related data fields.
Represent the department in committees within the organization.

Qualifications:

A University degree in Engineering, Statistics, Mathematics, or Computer Science.
Graduate degree in Statistics or Operations Research preferred.
Minimum 10 years working experience with data science techniques: clustering, regression models, classification, anomaly detection and other machine learning techniques.
Well-developed business analysis, research and creative problem-solving skills.
Organizational skills and time management skills; planning and project management, and ability to meet multiple deadlines.
Strong communication skills and work ethic.
Highly collaborative team player with an entrepreneurial spirit.
Experience with Python, Tableau and AWS cloud.

Note: This job description is not intended to be all-inclusive. Employee may perform other related duties as negotiated to meet the ongoing needs of the organization.

Accommodations for disabilities or other grounds protected by human rights legislation are available upon request for candidates taking part in all aspects of the employment selection process.","407 ETR
4.0",Woodbridge
129,Data Scientist,"Company Description


At thinking Capital, we’re changing the landscape of financial technology! We are looking for a talented Data Scientist to join our incredible team.

Thinking Capital belongs to the Purpose Financial family of businesses. Thinking Capital is a subsidiary of Purpose Financial, a diversified financial services platform focused on addressing historically underserved segments of the market. Purpose is backed by OMERS, TorQuest Partners and Allianz.

Simply put, our mission is to empower Canadian small businesses through innovative financial services. At the heart of our offering is our digital experience, which is powered by our proprietary software platform, our real time connections to a multitude of data sources and our advanced data science models. We are squarely in the corner of owners and entrepreneurs, providing for them, and at the right moment, the financial support they need to grow and thrive.



Job Description


You have spent countless hours over the years solving hard problems in mathematics, statistics and computer science. You thrive on extracting useful information from large messy data sets. You know that a data set that satisfies all the requirements of a specific statistical procedure is a rarity indeed – and you know what to do about it. You have followed your passion for all things quantitative and are turning it into your profession.

At ThinkingCapital we encourage everyone to trust themselves, stop holding back and use your acquired knowledge to influence your future. Everyone in the team is an integral contributor to our products, working with our customers to collaborate and design the best solutions.

Our open work culture provides the opportunity for you to contribute to all aspects of our business: customer engagement, product ownership, software, QA, devops and 24/7 cloud service deployment.

As a key member of our team your passion for data will help us design, develop and deploy our integrated cloud services that help small businesses succeed.

What you'll do:

Application of machine learning to an automated financial services platform
Design of sophisticated algorithms that work on large datasets in real-time
Learn and adapt emerging machine learning methodologies to real problems
Identifying, assessing, and monitoring credit risk trends, communicating adherence to authorized risk tolerance parameters and support Senior Management decision-making.
Diagnosing, documenting and reporting drivers of unexpected changes to portfolio/origination composition and credit performance. Communicating your findings including future impacts to losses and proposed recommendations to Senior Management as required.


Qualifications


You bring strong knowledge and real-world experience:

• Machine learning and artificial intelligence

Statistical methodology (eg linear & logistic regression, time series models, hypothesis testing, etc)
Python (Pandas), R (tidyverse) and SQL
Algorithms, data structures, and computational mathematics
Experience with analytics for large messy data sets
Obtaining data from web sites via scraping, apis and third parties
Proficiency with Linux command-line
Working autonomously and being highly resourceful
A masters degree in statistics or equivalent

We value data scientists who can demonstrate personal or business projects that have solved real problems big or small with data sets that you have obtained. You found the right data, scraped it off a web site or used an api to get it. Stored it, munged it, found all the anomalies and figured out what to do about them. You asked statistical questions of the data, found out that the data did not satisfy the requirements of the methodology you used, and figured out what to do about that. You derived useful information from the data and demonstrated value from the project.


Additional Information


Why you should join us:

Outstanding people:
Surround yourself with a high-performing, energetic and passionate group of people dedicated to the Thinking Capital Mission.

FinTech Revolution:
Be part of a team that is revolutionizing the financial system and redefining how Canadian small businesses access capital.

Fast-Paced Environment:
Take on complex projects in an innovative, start-up-like environment.

Amazing Culture:
Benefit from an amazing working environment offering you the flexibility to do your best work

Diversity of thought:
Join a team that values diversity and collaboration.","Thinking Capital
3.7",Midtown Toronto
130,Data Scientist,"Company Description


At thinking Capital, we’re changing the landscape of financial technology! We are looking for a talented Data Scientist to join our incredible team.

Thinking Capital belongs to the Purpose Financial family of businesses. Thinking Capital is a subsidiary of Purpose Financial, a diversified financial services platform focused on addressing historically underserved segments of the market. Purpose is backed by OMERS, TorQuest Partners and Allianz.

Simply put, our mission is to empower Canadian small businesses through innovative financial services. At the heart of our offering is our digital experience, which is powered by our proprietary software platform, our real time connections to a multitude of data sources and our advanced data science models. We are squarely in the corner of owners and entrepreneurs, providing for them, and at the right moment, the financial support they need to grow and thrive.



Job Description


You have spent countless hours over the years solving hard problems in mathematics, statistics and computer science. You thrive on extracting useful information from large messy data sets. You know that a data set that satisfies all the requirements of a specific statistical procedure is a rarity indeed – and you know what to do about it. You have followed your passion for all things quantitative and are turning it into your profession.

At ThinkingCapital we encourage everyone to trust themselves, stop holding back and use your acquired knowledge to influence your future. Everyone in the team is an integral contributor to our products, working with our customers to collaborate and design the best solutions.

Our open work culture provides the opportunity for you to contribute to all aspects of our business: customer engagement, product ownership, software, QA, devops and 24/7 cloud service deployment.

As a key member of our team your passion for data will help us design, develop and deploy our integrated cloud services that help small businesses succeed.

What you'll do:

Application of machine learning to an automated financial services platform
Design of sophisticated algorithms that work on large datasets in real-time
Learn and adapt emerging machine learning methodologies to real problems
Identifying, assessing, and monitoring credit risk trends, communicating adherence to authorized risk tolerance parameters and support Senior Management decision-making.
Diagnosing, documenting and reporting drivers of unexpected changes to portfolio/origination composition and credit performance. Communicating your findings including future impacts to losses and proposed recommendations to Senior Management as required.


Qualifications


You bring strong knowledge and real-world experience:

• Machine learning and artificial intelligence

Statistical methodology (eg linear & logistic regression, time series models, hypothesis testing, etc)
Python (Pandas), R (tidyverse) and SQL
Algorithms, data structures, and computational mathematics
Experience with analytics for large messy data sets
Obtaining data from web sites via scraping, apis and third parties
Proficiency with Linux command-line
Working autonomously and being highly resourceful
A masters degree in statistics or equivalent

We value data scientists who can demonstrate personal or business projects that have solved real problems big or small with data sets that you have obtained. You found the right data, scraped it off a web site or used an api to get it. Stored it, munged it, found all the anomalies and figured out what to do about them. You asked statistical questions of the data, found out that the data did not satisfy the requirements of the methodology you used, and figured out what to do about that. You derived useful information from the data and demonstrated value from the project.


Additional Information


Why you should join us:

Outstanding people:
Surround yourself with a high-performing, energetic and passionate group of people dedicated to the Thinking Capital Mission.

FinTech Revolution:
Be part of a team that is revolutionizing the financial system and redefining how Canadian small businesses access capital.

Fast-Paced Environment:
Take on complex projects in an innovative, start-up-like environment.

Amazing Culture:
Benefit from an amazing working environment offering you the flexibility to do your best work

Diversity of thought:
Join a team that values diversity and collaboration.","Thinking Capital
3.7",Midtown Toronto
131,Data Scientist,"About the Opportunity

Apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management
Assist us to drive innovation, enabling new underwriting paradigms, distribution models, and data management
Build and implement solutions that enable operational units, to improve quality and speed of core processes, in order to generate incremental revenue or reduce expenses
Proactively research new ways of modeling data to unlock actionable insights or improve processes
Effectively interpret modeling results, distill actionable insights and present them to partners
Collaborate across functions, and with clients to use analytics to influence business decisions
Work with existing data science groups and collaborate with internal partners, to leverage capabilities in big data technology

About You

Undergraduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics with 3 years’ experience OR Graduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, with 1+ years’ experience
Insurance or financial services background would be an asset
Actuarial examinations or designation would be an asset
Expertise in advanced predictive analytic techniques
Strong experience with Python or R
Working knowledge of SQL (familiarity with multiple languages considered an asset)
Experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining
Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure, etc.)
Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc.), natural language processing, and deep learning frameworks (ex. TensorFlow, Pytorch, etc.) would be assets
Excellent communication skills, ability to interpret modeling results, and convey them to partners
Fast-learner with a drive to make a difference
Ability to thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines



How to Apply

Click the “Apply Now” button and follow the instructions to submit your resume. Please note that we only accept documents in MS Word or Rich Text formats. When referencing this job, quote #29411.




You must currently reside within the Greater Toronto Area and be permitted to work in Canada to be considered for this opportunity. A recruiter will be in touch with you if your profile meets our client’s requirements for this role.","Vaco Lannick
3.9",Midtown Toronto
132,Research Data Scientist,"Deepcell is an early-stage Stanford spin-off company that has developed a platform capable of performing diagnostic and screening tests based on a simple blood draw.
With the power of AI, microfluidics and genetics, we will change how prenatal screenings and liquid biopsies are done. Deepcell technology has won multiple prestigious awards and is backed by top-tier venture capitalists in Silicon Valley including Andreessen Horowitz and Bow Capital.
Responsibilities
Work with large, complex and ever growing data sets
Research and develop and advance the state of the art of techniques to solve machine learning problems at Deepcell including supervised and unsupervised learning
Build and prototype analysis pipelines iteratively to provide insights at scale. Develop comprehensive knowledge of Deepcell’s objectives and related functions, advocating for changes where needed for product development
Work in close collaboration with Engineering, product, bio science and bioinformatics teams
Publish and patent
Minimum Qualifications
PhD in Computer Science, related technical field or equivalent practical experience
Experience in Computer Vision, Machine Learning, Algorithmic Foundations of Optimization, Data Mining, or Machine Intelligence (Artificial Intelligence)
Programming experience in Python and TensorFlow
Contributions to research communities/efforts, including publishing papers in machine learning (JMLR, ICLR, NeurIPS, ICML, ACL, CVPR, ECCV, AAAI)
Interest in solving impactful problems and applications to biotechnology
Effective communication with engineers and scientists from different disciplines
Preferred Qualifications
Relevant work experience, including full time industry experience or as a researcher in a lab
Stellar publication record
Ability to design and execute on research agenda with the understanding and care to transfer to development and production",Deepcell,Mountain View
133,Data Scientist 3,"Zynga is a leading developer of the world’s most popular social games that are played by people around the world every single day. To date, more than 1 billion people have played our games across Web and mobile, including Words With Friends, FarmVille, Zynga Poker, Merge Dragons, Empires & Puzzles, Toon Blast, and CSR.

Zynga’s Programmatic Ads Platform team uses our outstanding and expansive data to acquire high-value users for our gaming portfolio. We strive for a better understanding of our players which translates into challenges and features that delight them.

Here’s where you would come in: identify and formalize problems related to campaign and bidding optimization. Design and develop systems and machine learning models to optimize campaigns at scale and low-latency. Be innovative, be creative, use every bit of that key commodity – data. Millions of people play Zynga games every day, so our data is tremendously rich, and we have a lot of it!

This role will be responsible for communicating findings to your peers – both technical and non-technical. Your solutions to difficult problems will need to be demonstrably impactful, visual, and maintainable. You will collaborate with engineering teams to build campaign bidders and optimizers. You will collaborate with User Acquisition Managers, Product Managers, and Engineers to deliver business impact.

Responsibilities:

Design and implement scalable systems and models to experiment with campaigns and creatives across channels and acquire users at scale

Work with large amounts of data to find and realize opportunities to acquire and re-target users profitably delivering unambiguous business metric impact

Craft effective campaign strategies to acquire users across a multitude of user acquisition channels

Drive and empower user acquisition team to make quantitatively informed, evidence-based decisions - through custom visualizations, and ETLs to augment user data

Design, test, verify and implement machine learning models with Zynga’s games that impact millions of users. Models may include but not limited to LTV modeling, campaign bid recommendations, budget allocation, clustering/segmentation, forecasting, fraud detection, and/or reinforcement learning

Build services and applications that improve effectiveness of campaigns, creatives, ad networks, and/or user segments.


Required Skills and Experience:

B.S. or B.A. in Math, Statistics, Comp Sci, Engineering, or other quantitative field required; Masters, MBA or PhD preferred

3-5+ years of relevant work experience in data science or analytics role in a Machine Learning team

Proficient in Python/Java/C/C++/C#/Go; Demonstrated experience in deploying models or systems in high throughput or low-latency environments

Strong experience in SQL

Proven experience with some of the following: machine learning, predictive modeling, deep learning

Experience in analyzing large datasets, preferably in a Hadoop or Spark environment, and deploying production-ready systems at scale

Strong written and oral communication skills

Strong passion for gaming and performance marketing!

Familiarity with OpenRTB, mobile programmatic ad tech, performance marketing, and/or user acquisition landscape is a big plus

Ability to build and maintain simple software services and systems at scale; experience in deploying services in at least one cloud provider (AWS, Google Cloud or Azure) is a big plus


What we offer you:
Competitive salary, bonus plan, Zynga RSU’s (Restricted Stock Units), ESPP (Employee Stock Purchase Plan)
RRSP Company Match Contribution
Extended Health coverage, dental, disability, critical illness, EAP, and life insurance
Virtual mental health and neurodiversity support programs
Goodlife fitness annual membership
Open vacation policy
Family planning support program
Generous paid maternity/parental leave
Subsidized Back-up child care
Zynga happy hours and frequent employee events
Casual dress every single day
Culture of diversity and inclusion including employee resource groups
Work with cool people and impact millions of daily players


Zynga is an equal opportunity employer. We are proud of our broad community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome job-seekers, players, employees, and partners from all backgrounds. Join us!

We will consider all qualified job-seekers with criminal histories in a manner consistent with applicable law.

Zynga is committed to providing reasonable accommodation to applicants with disabilities. If you need an accommodation during the interview process, please let us know
#LI-LM1","Zynga
4.6",Toronto
134,Data Scientist - JTM,"Jumio Transaction Monitoring (JTM) is disrupting a $7.5 billion compliance software market by offering an innovative platform and incorporating new data sources for our bank and fintech partners to monitor their transactions for suspicious behavior helping make the financial system safer while maximizing the value and utility of critical compliance resources.
We are looking for a data scientist at JTM. In this role, you will get to work alongside various experts in customer success, product and engineering. You will analyze datasets to discover patterns, build and test models and implement them to improve our transactional monitoring system.
Responsibilities:

Mine and analyse data from databases to create features, generate insights, drive optimization and improvement of product development.
Develop data models and algorithms to improve the current AML rule based system.
Develop processes and tools to monitor and analyse model performance and data accuracy in production.
Implement end-to-end machine learning solutions in a production environment
Keep pace with the state-of-the-art technologies in machine learning

Experience and Qualifications:

Bachelor’s degree in Mathematics, Statistics, Computer Science, Engineering
3+ years of industrial experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas; or equivalent 2+years of industry experience with Master’s degree
Experience with data scripting languages (e.g., SQL, Python, R etc.)
Hands-on experience with machine learning frameworks such as Scikit-learn, Tensorflow and Pytorch
Knowledge of classical machine learning techniques (clustering, decision trees, artificial neural networks)
Knowledge of time series approaches (ARIMA, Kalman filters, sequence modeling etc)
A strong passion for empirical research and for answering hard questions with data is required.

Great to have Experience and Qualifications:

Graduate degree in statistics, computer science, machine learning or related quantitate field.
Industrial experience in finance
Familiarity with SaaS development in cloud ecosystems like AWS (e.g., Sagemaker)

Job Type: Full-time","Jumio Corporation
3.8",Montreal
135,Data Scientist - JTM,"Jumio Transaction Monitoring (JTM) is disrupting a $7.5 billion compliance software market by offering an innovative platform and incorporating new data sources for our bank and fintech partners to monitor their transactions for suspicious behavior helping make the financial system safer while maximizing the value and utility of critical compliance resources.
We are looking for a data scientist at JTM. In this role, you will get to work alongside various experts in customer success, product and engineering. You will analyze datasets to discover patterns, build and test models and implement them to improve our transactional monitoring system.
Responsibilities:

Mine and analyse data from databases to create features, generate insights, drive optimization and improvement of product development.
Develop data models and algorithms to improve the current AML rule based system.
Develop processes and tools to monitor and analyse model performance and data accuracy in production.
Implement end-to-end machine learning solutions in a production environment
Keep pace with the state-of-the-art technologies in machine learning

Experience and Qualifications:

Bachelor’s degree in Mathematics, Statistics, Computer Science, Engineering
3+ years of industrial experience solving analytical problems using relevant quantitative and qualitative research and analytics experience, in related business areas; or equivalent 2+years of industry experience with Master’s degree
Experience with data scripting languages (e.g., SQL, Python, R etc.)
Hands-on experience with machine learning frameworks such as Scikit-learn, Tensorflow and Pytorch
Knowledge of classical machine learning techniques (clustering, decision trees, artificial neural networks)
Knowledge of time series approaches (ARIMA, Kalman filters, sequence modeling etc)
A strong passion for empirical research and for answering hard questions with data is required.

Great to have Experience and Qualifications:

Graduate degree in statistics, computer science, machine learning or related quantitate field.
Industrial experience in finance
Familiarity with SaaS development in cloud ecosystems like AWS (e.g., Sagemaker)

Job Type: Full-time","Jumio Corporation
3.8",Montreal
136,"Data Scientist, Machine Learning","The Company You'll Join

At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they've managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.
The Team You'll Work With

Our mission is to enable data-driven decisions and products across Carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. This is a foundational role in Carta's fast-growing Data Organization, working on one of the world's most valuable data sets at one of the fastest-growing FinTech companies of all time. The team consists of experts in product analytics, machine learning and data engineering. We partner with each other and Cartan's across the company to solve impactful problems. Our team strongly believes that being helpful accelerates results and we support one another to be successful at Carta.
The Problems You'll Solve

As a Data Scientist, ML at Carta, you'll partner with domain experts across the company to analyze and explore Carta's proprietary data set. You will build statistical models that power new products and accelerate Carta's business. Examples of responsibilities will include:

Perform exploratory analyses to understand the dynamics of private markets and ownership
Develop machine learning models to power new financial products and to extract trends from performance of existing products
Automate monitoring of data distributions to detect and flag anomalies
Partner with product managers, engineers, and business teams to incorporate data-driven insights into decision-making
Own, coordinate, and solve complex, cross-functional problems that extend beyond the traditional boundaries of product, analytics, and data science

The Impact You'll Have

You will own significant projects directly aligning with Carta's company-wide initiatives of data products and data quality. Your work will empower leaders across the company to make good product decisions and optimize operational efficiency. Additionally, you will have the opportunity to set best practices for integrating our ML models into production helping Carta's current and future data scientists.
About You

Candidates must have a strong foundation in statistics, be proficient in SQL and Python, and have an analytical mindset. You have a strong bias towards simplicity, are excited by ""zero to one"" projects, and can efficiently communicate findings to leadership. Example traits that we value:

2+ years of industry experience solving complex data problems with descriptive and predictive models
Proficiency with modern programming languages (Python, R, SQL, etc.) and datastores (Redshift or similar)
A deep understanding of modern statistical and machine learning models, when to apply them, and how to evaluate their performance
Strong written and verbal communication skills, with a particular emphasis on data visualization
A collaborative attitude and a helpful personality","Carta
3.9",Waterloo
137,Digital Data Scientist,"Digital Data Scientist-MON17852

Description

BOMBARDIER

Bombardier is a global leader, creating innovative and game-changing planes. Our products and services provide world-class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. We are a global organization focused on working together with a team spirit.

In your role, you will:

Work on challenging and research-based initiatives using advanced machine learning methods focusing on tangible outcomes

Nurture strong working networks with internal and external stakeholders to access large variety of data sources and enhance A.I. value creation

Prepare and integrate large and various types of data (structured/non-structured)

Implement machine learning models, data mining methods, and statistical analysis

Leverage visualization tools/packages to create powerful representations of results

Produce data-driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to stakeholders

Collaborate with the development team to deploy production-scale solutions

Challenge status-quo for data ecosystem and collaboratively innovate solutions to enable A.I. across teams

Quickly learn new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises

Articulate software and hardware requirements for A.I. solutions to non-practitioners.

Qualifications

As our ideal candidate,

You have a Masters in Computer Science, Statistics, or data science relevant fields and an Engineering background is desired

You have strong data profiling, cleaning, mining and technical documentation skills

You possess a minimum of 3 years of experience in developing machine learning models for real business problems

You possess a minimum of 3 years of experience with NLP and text analytics methods and packages

You have experience deploying A.I. solutions within business functions to improve business competitiveness.

You have experience with MLOps to build end-to-end pipeline and deploying models in production

You possess experience with big data technologies, primarily in machine learning and statistics function

Above average expertise in one or more programming language - Java, C#, Ruby, Python

You have experience designing and implementing AI/data science algorithms/systems and managing the associated data by leveraging, connecting and operationalizing large scale enterprise data solutions and applications using best-known data management and analytics platforms (e.g. Azure / AWS)

You have Experience working in an Agile development environment implementing AI/data science algorithms leveraging state-of-the-art programming languages and libraries

Bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected Characteristics to apply.

Whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone.

Join us at https://bombardier.com/en/careers/career-opportunities

Your ideas move people.

Job: Project/Program Management
Primary Location: CA-QC-Montreal Dorval
Organization: Aerospace
Schedule: Full-time
Employee Status: Regular

Job Posting: 21.05.2021, 5:29:38 PM

Unposting Date: Ongoing","Bombardier
3.4",Dorval
138,Data Scientist II,"TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us.

Department Overview

What does TD stand for? For starters, we believe in visionary leadership and insights. We believe in using every resource at our disposal to better serve our clients, and for almost every department, that begins with data.

As part of our Data and Analytics team, you'll be a fundamental part of crafting business processes enterprise-wide by analyzing vast amounts of past and present data.

TD's vision for the future? Tailored, customized banking products, services and experiences for every single customer. If you've been in business as long as we have, you know there's no such thing as one size fits all, and a diverse, inclusive Data Analytics team is a massive part of that future achievement.

Job Description

About this Role

While you are a natural leader, you don't mind getting your hands dirty. And in your role, you will simultaneously work to create data related solutions to drive business results, while working with senior leadership to communicate timelines and progress and identify business opportunities. You are not only a functional expert, you also possess broad managerial experience and specialized knowledge of regulatory and industry frameworks, using that knowledge to inform development cycles and develop industry leading analytic solutions. Most of all, your work ethic and thought leadership inspires your team to innovate with purpose, execute with speed, collaborate to deliver world-class data solutions and ultimately become leaders themselves.

We are looking for someone to work as part of a trailblazing team of data scientists who create groundbreaking analytical solutions that improve our core work enterprise wide.

As a Data Scientist II, these are the essential qualifications of this role:

Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become core work you're doing
Work closely with business owners to find opportunities and serve as an ambassador for data science
Design and deliver enterprise analytic solutions for customers
Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques
Build complex statistical models that learn from and scale to petabytes of data.
Analytical thought leadership and staying ahead of developments in data mining and the application of data science
Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size
Generally accountable for a significant business management area that typically has enterprise wide impact or accountability
Enterprise or functional expert, requiring broad managerial and deep specialized knowledge at the enterprise, business, regulatory and industry levels

Job Requirements

What can you bring to TD? Tell us about your most relevant experience, credentials and knowledge for this role, as well as these essential requirements and attributes:
Undergraduate degree or technical certificate
Seven (7) or more years of relevant experience

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Job Family

Advanced Analytics & Modelling

Job Category - Primary

Enterprise Data & Analytics

Job Category(s)

Enterprise Data & Analytics

Hours

37.5

Business Line

TD Wealth

Time Type

Full Time

Employment Type

Regular

Country

Canada

**Province/State (Primary)

Ontario

City (Primary)

Toronto

Work Location

TD Centre - South - 79 Wellington Street West

Job Expires

24-Jun-2021","TD Bank
4.0",Midtown Toronto
139,Data Scientist,"There has never been a better time to join Extreme, after three acquisitions extending our portfolio and go to market strategy, we have seen enormous opportunity and growth within the regions. Aside from being a Technology Leader in the Gartner Magic Quadrant, we also adamantly promote an internal culture that truly embraces diversity, inclusion and equality in the workplace. Having Diversity and Inclusion as part of our core values and beliefs, we’re proud to foster an environment where every Extreme employee can thrive because of their differences, not despite them.

Responsibilities:

Working under the guidance of the leader of the Portfolio Intelligence team, provide analytics and insight to the executive leadership team.
Collaborate with subject matter experts across the company to build impactful data analysis and visualization.
Using statistical modelling and AI techniques, provide leadership in business plan creation and forecasting.
Working with the Product Management organization, improve the business plan and financial modelling process.
Take a leadership role in the definition of Customer Success metrics in our Cloud offerings.
Design and maintain data visualizations in Tableau.

Required Qualifications:

Completed degree in a quantitative discipline (Engineering, Statics, Finance, Mathematics, Economics)
Master of Business Administration an asset.
ML/AI competency an asset.
Advanced statistical methods and predictive modelling.
Excellent writing and communication skills.
Executive presentation skills.
Familiarity with data visualization software and techniques.
Experience with Tableau an asset.

Required Qualifications:

Completed degree in a quantitative discipline (Engineering, Statics, Finance, Mathematics, Economics)
Master of Business Administration an asset.
ML/AI competency an asset.
Advanced statistical methods and predictive modelling.
Excellent writing and communication skills.
Executive presentation skills.
Familiarity with data visualization software and techniques. Experience with Tableau an asset.
Ability to work with large datasets and provide concise analysis and insights
Capable of independent research and learning.

Location: Position is based in Toronto, Ontario area - it is not budgeted for relocation. Qualified local candidates (or those moving to the area on their own) are encouraged to apply.


Extreme Networks, Inc. (EXTR) creates effortless networking experiences that enable all of us to advance. We push the boundaries of technology leveraging the powers of machine learning, artificial intelligence, analytics, and automation. Over 50,000 customers globally trust our end-to-end, cloud-driven networking solutions and rely on our top-rated services and support to accelerate their digital transformation efforts and deliver progress like never before. For more information, visit Extreme's website or follow us on Twitter, LinkedIn, and Facebook.


We encourage people from underrepresented groups to apply. Come Advance with us! In keeping with our values, no employee or applicant will face discrimination/harassment based on: race, color, ancestry, national origin, religion, age, gender, marital domestic partner status, sexual orientation, gender identity, disability status, or veteran status. Above and beyond discrimination/harassment based on “protected categories,” Extreme Networks also strives to prevent other, subtler forms of inappropriate behavior (e.g., stereotyping) from ever gaining a foothold in our organization. Whether blatant or hidden, barriers to success have no place at Extreme Networks.

#LI-ME1","Extreme Networks
3.5",Montreal
140,Data Scientist,"Design, develop, test, advocate, evangelize and build data-driven products that help our customers improve business decisions. You will provide insight into analytic practices, design and lead iterative learning and development cycles.
Responsibilities
Understanding and worked with database systems.
Understanding and worked with machine learning algorithms.
Perform feature analysis.
Develop ontology for key market segments.
Develop outcome/event taxonomy for key business models.
Build utility code and handle miscellaneous support tasks.
Documenting software projects and maintaining project documentation.
Working in a team environment as well as working alone.
Qualifications
Experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning.
Python programming skills with two (2) years or more of Python experience.
Good verbal and written communication skills.
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Master's degree or six (6) years related work experience delivering quality code on time.
Tools we use...
Confluence
JIRA
Spark
Azure
Python
Keras
Bit bucket
Jupyter Notebook
Scala
PostGres
Nice to haves...
Experience in some subset of the following: Java, R, Python, SQL, Scala, Spark.
Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.
Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, supervised learning, recommendation and optimization algorithms.","Cerebri AI
3.9",Midtown Toronto
141,Data Scientist,"Duties/Responsibilities:

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements/Qualifications:

Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred",thinkCOMPASS,Concord
142,Data Scientist,"Duties/Responsibilities:

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements/Qualifications:

Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred",thinkCOMPASS,Concord
143,Data Scientist,"Duties/Responsibilities:

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams

Requirements/Qualifications:

Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred",thinkCOMPASS,Concord
144,Data Scientist,"Rôle et Responsabilités:
Extraire et analyser les données se trouvant dans les bases de données de l’entreprise afin d’optimiser et d’améliorer le développement des produits, les techniques de marketing et les stratégies commerciales.
Évaluer l’efficacité et l’exactitude des nouvelles sources de données et techniques de collecte de données.
Élaborer des algorithmes et des modèles de données personnalisées à appliquer aux ensembles de données.
Utiliser une modélisation prédictive pour accroître et optimiser l’expérience des clients, les revenus générés, le ciblage publicitaire et d’autres résultats opérationnels.
Élaborer un cadre de tests A/B pour l’entreprise et mettre à l’essai la qualité du modèle.
Coordonner différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats.
Élaborer des processus et des outils pour le contrôle et l’analyse du rendement des modèles et de l’exactitude des données.

Exigences et requis:
Titulaire d’une maîtrise ou d’un doctorat en statistique, informatique, analyse des systèmes de gestion ou autre domaine connexe.
Au moins 6 ans d’expérience en science des données ou en statistiques appliquées.
Solides aptitudes pour le développement de produits et la résolution de problèmes.
Expérience dans l’utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler les données et extraire des renseignements de grands ensembles de données.
Expérience dans la manipulation d’ensembles de données et l’élaboration de modèles statistiques.
Expérience avec diverses techniques d’apprentissage automatique (Forêt d'arbres décisionnels, gradient boosting, machines à vecteur de support, réseaux de neurones, réseaux bayésiens, etc.) et de leurs avantages et inconvénients dans le monde réel.
Expérience avec les techniques et concepts statistiques sophistiqués (MLG/régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation conforme, etc.).
Expérience dans l’utilisation et la création d’architectures de données.
Expérience dans l’utilisation de services Web : Redshift, S3, Azure, Spark, DigitalOcean, etc.
Expérience dans l’analyse de données provenant de: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Expérience dans la visualisation et la présentation de données pour des intervenants, à l’aide de : Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
Expérience de direction d’initiatives axées sur le service client.
Excellentes aptitudes pour la communication verbale et écrite en vue de la coordination des équipes.",Services Conseils IntelliSoft inc.,Montreal
145,"Data Scientist, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Toronto; Ottawa; Vancouver

Learn from deep subject matter experts through mentoring and on the job coaching
Be encouraged to deepen your technical skills…whatever those may be.
Be empowered to lead and have impact with clients, our communities and in the office.


Are you passionate about solving complex analytical problems, learning about the latest in cutting-edge AI and continuing to develop your analytical and business development skills? If you answered yes, then we have an opportunity waiting for you!

What will your typical day look like?


As a Data Scientist, you would take a hands-on role in delivering advisory services to high growth organizations with a diverse team consisting of data scientists, data architects, software developers, information designers, and business/industry leaders. You will responsible for performing statistical modelling, computations, and data ETL to deliver best-of-breed analytical solutions for clients’ business problems. You will work with large amounts of data on a granular level, from structured and unstructured data sources and participate in various structured and ad-hoc analysis projects. You will also perform data analysis and communicate insights on client projects, and provide support in planning, data collection, and assist in pitches and proposal bids.

About the team


Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Enough about us, let’s talk about you


You are someone with:

Data analysis experience using (one or more): Python, Could ML (AWS, GCP, Azure), or similar tools
1+ years (Consultant) or 3+ years (Senior Consultant) relevant work experience with applying analytics or working with data in any industry
Strong experience with statistical analytical techniques, data mining, and predictive models is required
Database and programming languages experience and data manipulation and integration skills using (one or more) SQL, Oracle, Hadoop, NoSQL Databases, or similar tools is required
Experience with social media analytics and/or natural language processing and/or optimization is an asset Knowledge using either AWS, Azure or GCP
Strong experience with Machine Learning Project management experience is an asset
Ability to work with data with significant ambiguity, develop creative approaches to analytical problems, and interpret data and results from a business/industry perspective
Enthusiastic about solving complex problems with a variety of analytical tools
Professional services, consulting, or advisory experience is an asset
Strong oral and written communication skills
Interest in continuing to develop analytical and business development skills
BA/BSc degree in Computer Science, Applied Mathematics, Statistics, or related field is required.
Advanced degree (MA/MSc, equivalent or higher) is preferred.


Join Deloitte and bring back that loving feeling, and love the company you keep. This position may require frequent travel to serve clients across North America. Candidates must be able to enter the USA to work on client assignment.

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 52 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Midtown Toronto
146,Data Scientist / Engineer,"Mobile data connectivity drives economic growth and brings vast social benefits to the world, but two-thirds of the world's population is unable to access this valuable resource. Our mission is to make affordable mobile communications available to every human on earth.

We are founded by early Product and Growth team executives from Facebook, and backed by world-leading VCs including Google Ventures, Social Capital, SV Angels, Macquarie Capital, and Compound.

We partner with some of the greatest institutions in the world including Linkedin, Supercell, Twitter, Microsoft, Verizon Wireless, Singtel, and T-Mobile.

SUMMARY

As a Data Scientist / Engineer at LotusFlare, you will play a vital role in redefining connectivity on a global scale. You will work on products bringing connectivity to more than 10 million people across the globe. You will advocate data-fueled products that help our customers to make data-driven decisions. You will provide insight using leading analytics practice and ultimately produce new and creative analytic solutions that will become part of our core products including experimentation platform (Velocity), analytics platform (Periscope), and data platform. You are a strategic thinker who can form hypotheses, synthesize disparate information to validate those hypotheses, and provide actionable insights for the product team to scale user base.

RESPONSIBILITIES

Participate in building models that will scale products with millions of users globally
Partner with cross-functional teams including engineering, UX/UI, sales, marketing, and customer success to build growth strategies and manage complex, cross-functional projects
Analyze diverse sources of data to devise actionable insights
Deep understanding of the B2C consumer markets and core metrics in the markets
Work with Product Managers to develop, execute, and test different growth experiments that have a significant impact on conversion across all funnels (acquisition, activation, retention, engagement, and monetization)

REQUIREMENTS

Undergraduate degree in quantitative fields including Engineering, Math, Statistics from top tier institute or relevant field (MS or PHD is preferred)
Candidate must have the ability to independently build data pipelines, develop data models, and recommend growth strategies to product and executive teams
3 - 5 years of previous experience in building ETLs, analyzing consumer insights, creating metrics
Experience with SQL and/or NoSQL database
Experience with data visualization, dashboards, and reports
Experience with scripting languages such as Python
Candidate must be able to effectively synthesize disparate quantitative and qualitative data sets to make data-driven decisions
Eager to learn new programming languages and tools when needed
Strong desire to work in a fast-paced startup environment
Obsessive around moving critical business metrics and products
Strong communication skills, attention to detail, and ability to manage multiple projects and stakeholders
Great oral and written communication skills in English

IyRrQ3FNkE","LotusFlare, Inc.
4.3",Midtown Toronto
147,Data Scientist,"We are looking to hire a Data Scientist.

Missions

TASKS AND RESPONSIBILITIES

Your day-to-day missions:
Collect needs and specify the models to be implemented
Identify best practices to integrate AI in the Firm's context
Create software solutions using AI technologies
Implement, test and deliver functionalities according to our standards
Deploy AI solutions to end-users

In this position, you will be guided by members of the Amer BI Center who will be committed to providing you with the tools and advice that you need to successfully reach your goals.
You will be client-facing, from collecting business requirements to identify and implement solutions bringing value and efficiency gains for the group.

Environment:
Very vibrant position, many challenges for you to meet
A team that fosters exchange and teamwork.
Projects on a human scale, sense of mutual support, high level of skills

Profile

What if it was you?
You have completed a Master's degree with a Mathematics/CompSci/Engineering specialization (software development or data science/analytics focus) and you are interested in machine learning.
A first experience in Data Science using Python is preferred.
You are fluent in English and a working understanding of French.

ABOUT YOU
Fast learner: you are able to own over your work quickly
Team player: you have a sense of responsibility
Proactive: you feel comfortable taking initiatives
Flexible: you enjoy working in a fast-paced environment, with rapidly changing priorities
Result-oriented and analytical : you have a problem-solving mindset

TECHNICAL SKILLS
Required:
Programming Tools: Python, Pandas, Numpy, Scikit-Learn, Git, Jupyter Notebook
Databases : PostgreSQL, Elasticsearch, Oracle
Servers: Unix & Windows
Would be a plus:
Knowledge of ETL tools : Pentaho Data Integration, Talend, Informatica
Knowledge of BI tools: Power BI, Tableau, Grafana
Knowledge of DevOps tools: Docker, Kubernetes, Jenkins
Sharing a GitHub or StackOverFlow account

======================================================================================

Data Scientist

Missions

TÂCHES ET RESPONSABILITÉS

Vos missions au quotidien:
Recueillir les besoins et préciser les modèles à mettre en œuvre
Identifier les meilleures pratiques pour intégrer l'IA
Créer des solutions logicielles en utilisant les technologies d'IA
Mettre en œuvre, tester et fournir des fonctionnalités conformément à nos normes
Déployer des solutions d'IA auprès des utilisateurs finaux

À ce poste, vous serez guidé par les membres du Centre Amer BI qui s'engageront à vous fournir les outils et les conseils dont vous avez besoin pour atteindre vos objectifs avec succès.
Vous serez en contact avec les clients, de la collecte des besoins de l'entreprise à l'identification et à la mise en œuvre de solutions apportant de la valeur et des gains d'efficacité pour le groupe.

Environnement
Un poste très dynamique, de nombreux défis à relever
Une équipe qui favorise l'échange et le travail d'équipe.
Projets à taille humaine, sens de l'entraide, haut niveau de compétences

Profil

Et si c'était vous?
Vous avez obtenu un master avec une spécialisation en mathématiques/compSci/ingénierie (développement de logiciels ou sciences des données/analyse) et vous êtes intéressé par l'apprentissage automatique.
Une première expérience en science des données en utilisant Python est préférable.
Vous parlez couramment l'anglais et avez une bonne compréhension du français.

À PROPOS DE VOUS
Apprentissage rapide : vous êtes capable de maîtriser rapidement votre travail
Joueur d'équipe : vous avez le sens des responsabilités
Proactive : vous vous sentez à l'aise pour prendre des initiatives
Souplesse : vous aimez travailler dans un environnement en évolution rapide, avec des priorités qui changent rapidement
Orienté vers les résultats et analytique : vous avez un esprit de résolution de problèmes

LES COMPÉTENCES TECHNIQUES
Obligatoire
Outils de programmation: Python, Pandas, Numpy, Scikit-Learn, Git, Jupyter Notebook
Bases de données : PostgreSQL, Elasticsearch, Oracle
Serveurs : Unix & Windows
Ce serait un plus
Connaissance des outils ETL : Pentaho Data Integration, Talend, Informatica
Connaissance des outils de BI : Power BI, Tableau, Grafana
Connaissance des outils DevOps: Docker, Kubernetes, Jenkins
Partager un compte GitHub ou StackOverFlow","CGI
3.8",Montreal
148,Senior Big Data Developer,"Req Id: 298498


At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we advance how Canadians connect with each other and the world.


If you’re ready to bring game-changing ideas to life and join a community that values, professional growth and employee wellness, we want you on the Bell team.


Bell’s forward-thinking Customer Operations team is creating the ultimate service experience for our residential, wireless and small business consumers. We lead strategic development and execution of day-to-day operations, develop tools and processes to drive service enhancements, manage customer loyalty and retention, and leverage big data and artificial intelligence to create intellectual property.


We have been building our Business Intelligence team and have made tremendous strides in creating the BEST BI environment this industry has seen! As a result, we've been able to provide strategic guidance and intelligence that has contributed to Bell's success. If you want to work with the latest & greatest BI tools like, Best in Class Teradata, SAS and Hadoop all within an Agile Methodology environment, then this may be the role for you!


Our people are empowered to make big things happen and are supported by growth, training and personal development opportunities.


About the Role:

The Big Data Developer will be a key member of the Bell Business Intelligence Big Data Team and work on the Hadoop platform. The Big Data Developer will work closely with Hadoop Administrators, Data Scientists, and business stakeholders. This position will be responsible for, but not limited to:

Develop high-performance data processing pipelines
Partner with Business Analysts and internal customers to improve our data coverage and analytic capabilities;
Ability to take initiative to research, learn and recommend emerging technologies
Aim for defect-free programming, create and maintain quality code, provide support during testing cycles and post-production deployment, engage in peer code reviews.
Advanced and extensive knowledge of the business (or organization), technical environment, standards, processes, procedures, programming languages and operating systems.
Readiness and motivation (as senior or lead developer and valued subject matter expert) to address and resolve highly complex and multifaceted development-related issues, often independently.
Experience developing and using virtualization, container-based and cloud platforms such as Kubernetes, OpenShift, Swarm, Docker, etc.


Skills :

Experience working with Apache Spark, Kafka and other big data technologies
Experience in developing Big Data ingestion frameworks or experience in working with ingestion tools
Demonstrated analytical and problem solving skills, particularly those that apply to a ""Big Data” environment.
Experience with data pipeline E.T.L. tools, such as: Talend (added advantage)
5 years or more experience with multiple mainstream programming languages such as Python, Java, C++, C#, Go, etc.


Competencies:

Strong Communication skills
Self-Motivated
Willingness to learn
Excellent planning and organizational skills


Candidates will be required to complete a coding test as part of the interview process.


#LI-AD1

#Tech

#BigData

#BusinessIntelligence


Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.


Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Don Mills || Canada : Ontario : Don Mills || Canada : Quebec : Verdun
Application Deadline: 06/30/2021


Please apply directly online to be considered for this role. Applications through email will not be accepted.


At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.


Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.


Created: Canada, ON, Don Mills


Bell, one of Canada's Top 100 Employers.","Bell Canada
3.9",Don Mills
149,Data Scientist - 05/12/21,"Acerta’s machine learning platforms leverage automotive assembly and vehicle data to detect the earliest indicators of future product failures. We help automakers optimize quality, safety, and reliability throughout the entire product life cycle, from the assembly line to the finish line.




As an integral part of the data science team at Acerta, you will productize, deploy, maintain, and monitor machine learning models running behind Acerta’s LinePulse and AutoPulse products. Our LinePulse SaaS platform enables automakers to identify anomalies in production data for enhanced testing, accelerated root cause analysis, and improved manufacturing output. Acerta’s AutoPulse SaaS platform enables predictive maintenance of connected and autonomous vehicles based on production, maintenance, and on-road data.


Requirements:

Minimum of 3 - 5 years of data science experience using python
Strong ML and statistics background
2+ years of software development experience
Experience with keras, tensorflow, and sklearn.
Experience with time-series and operations data is an asset
Previous Kaggle experience or similar is a plus
Ability to work in a fast-paced agile environment
Experience using Git in a team environment
Flexibility to adjust to changing priorities, requirements, and schedules
Familiarity with working on remote linux instances
Available in office full-time (KW)



Responsibilities:

Own significant product requirements and drive them from development to deployment
Tune and monitor machine learning models deployed for customers.
Research and apply state of the art in model interpretation and explainability
Package development in Acerta’s Codebase



We thank all applicants for their interest; only those candidates selected for an interview will be contacted.

Acerta is committed to fostering a diverse and inclusive workplace. We strongly encourage applicants from all backgrounds and walks of life.","Acerta Analytics Solutions Inc
4.1",Kitchener
150,Data Scientist (Portfolio Modelling),"Closing Date (MM/DD/YYYY):

06/30/2021

Worker Type:

Permanent

Language(s) Required:

English

Term Duration (in months):

Data science and statistical modelling expertise needed
Use your extensive knowledge of risk management and finance in areas such as credit risk, allowance for credit losses, economic capital, and stress testing to support our portfolio management team.

What you’ll do:

Unlock insights from complex and diverse groupings of internal and external data or developed models to tell a story

Use advanced analytics techniques to enable enlightened decision-making

Choose appropriate ways to tell the story through words, visualization, and interpretation

What we’re looking for:

Analytical thinker who can design and develop strategies that give users the information they need to make informed decisions

Creative thinker with research, analytical, and problem solving skills

Confident communicator who can translate knowledge for others

Relationship-builder comfortable making recommendations for improvement

What you’ll need:

A bachelor’s degree in agriculture, finance, business, economics, mathematics, statistics or computer science and at least four years of experience (or an equivalent combination of education and experience)

In-depth understanding of statistics and mathematics combined with business domain knowledge

Highly proficient in visualization and analytics tools including but not limited to SAS, MS Power BI, AWS environment and tools, R, Python

A passion for analysis, insights and storytelling

-If you are an FCC employee, use your Workday portal to apply.

-If you are an FCC employee On Leave, contact Human Resources for instructions on how to apply.","Financement agricole Canada
4.3",Regina
151,Data Scientist - Innovation & Attributes,"Synopsis of the role

As a Data scientist, in this role, you will work closely with business stakeholders to understand their goals and determine how data can be used to achieve those goals. You will be tasked with designing data modeling processes, create algorithms and predictive models to extract the data the business needs, help analyze the data and share insights with peers.


Who is Equifax?


At Equifax, we believe knowledge drives progress. As a global data, analytics and technology company, we play an essential role in the global economy by helping employers, employees, financial institutions and government agencies make critical decisions with greater confidence.

We work to help create seamless and positive experiences during life’s pivotal moments: applying for jobs or a mortgage, financing an education or buying a car. Our impact is real and to accomplish our goals we focus on nurturing our people for career advancement and their learning and development, supporting our next generation of leaders, maintaining an inclusive and diverse work environment, and regularly engaging and recognizing our employees. Regardless of location or role, the individual and collective work of our employees makes a difference and we are looking for talented team players to join us as we help people live their financial best.


The Perks of being an Equifax Employee?


We offer excellent compensation packages with market competitive pay, comprehensive healthcare packages, schedule flexibility, work from home opportunities, paid time off, and organizational growth potential.


Grow at your own pace through online courses at Learning @ Equifax.


What You’ll Do


As a Data Scientist at Equifax, you will work directly with both internal stakeholders and external clients to deliver innovative decision science models & attributes that leverage Equifax’s vast data assets. These include decision areas covering the credit lifecycle, geodemographic & marketing attributes, ratings & fraud models, as well as any new areas where data driven decision making can be informed by predictive modelling including advanced modeling techniques and machine learning when applicable.

Build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees and neural network

Develop new tools, advanced analytical techniques and products as part of the innovation team

Project management including defining business and technical requirements, resource planning and analytic solution design

Working alongside key clients as part of co-innovation projects and effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the so what of the analysis

Creation of recommendations, market insights and dashboards following completed analysis and Quality control of all analytical output

Qualifications

Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics

3+ years’ Data Science experience with expert knowledge of R, Python, SAS or SQL in a large data environment

3+ years’ experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks

Proven hands-on experience designing and building analytical solutions to solve real world problems, with limited direct supervision required

Creativity & idea generation and the ability to extract business insights from analysis & transform this into an easy to understand story

Extra Points for any of the Following

Master’s level degree in a business-related field/MBA

Experience working in a cloud environment such as GCP an asset

Experience in working with Credit Data

Background in financial services, telecommunications or utilities favorable

Success Attributes of an Equifax employee; does this describe you?

Accountability

Curiosity

Collaboration

Think and act differently

Trust

Ownership

Decide-Execute-Ship


We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

If this sounds like somewhere you want to work, don’t delay, apply today - we’re looking for you!

Primary Location:

CAN-Toronto-5700 Yonge

Function:

Function - Data and Analytics

Schedule:

Full time","Equifax
3.7",Midtown Toronto
152,"Data Scientist, International Analytics","About the Role
The Analytics team is looking for experienced Data Scientists to guide measurement, strategy, and tactical decision-making as we expand our logistics platform into new countries. We are looking to hire in several countries across a variety of teams and levels to accelerate growth in our current international markets (Canada and Australia) and lead the strategy and execution of new market launches (more coming!) Data Scientists at DoorDash work to uncover insights and turn them into relevant recommendations, driving decisions for the entire organization. Analytics is integral to all operational areas at DoorDash.
As a Data Scientist at DoorDash, you'll use your quantitative background to mentor other scientists and dive into large datasets to guide decision-making. We tackle a multitude of exciting challenges including customer acquisition, balancing supply and demand, fraud and support, marketing, marketplace efficiency, and more. If you enjoy finding patterns amidst chaos, are excited to build a market from 0 to 1, and have experience using analytics to affect revenue, growth, operations or beyond, we’re looking for someone like you! You’re excited about this opportunity because you will… Use quantitative analysis and the presentation of data to see beyond the numbers and understand what drives our business Build full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools Produce recommendations and use statistical techniques and hypothesis testing to validate your findings Provide insights to help business and product leaders understand marketplace dynamics, user behaviors, and long-term trends Identify and measure levers to help move essential metrics and make recommendations Work backwards from understanding and sizing problems to ideating solutions Report against our goals by identifying essential metrics and building executive-facing dashboards to track progress Be excited to travel (when it’s safe!) to meet with business partners and the team in each market We’re excited about you because you have… A degree in Math, Physics, Statistics, Economics, Computer Science, or similar domain 5+ years of experience in data analytics, consulting, or related quantitative role Experience working with funnel optimization, user segmentation, cohort analyses, time series analyses, regression models, etc Expertise of SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau) The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way The determination to initiate and lead projects to completion in a scrappy environment Prior experience working abroad or in international expansion preferred but not required Fluent English required, proficiency in additional languages a plus Why You’ll Love Working at DoorDash We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies. We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day. We are learners - Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility. We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits. About DoorDash
DoorDash is a technology company that connects customers with their favorite local and national businesses in all 50 US states, Canada, and Australia. Founded in 2013, DoorDash empowers merchants to grow their businesses by offering on-demand delivery, data-driven insights, and better in-store efficiency, providing delightful experiences from door to door. By building the last-mile delivery infrastructure for local cities, DoorDash is bringing communities closer, one doorstep at a time. Read more on the DoorDash Engineering blog or at www.doordash.com . Our Commitment to Diversity and Inclusion
We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.","DoorDash
4.0",Midtown Toronto
153,Product Data Scientist,"The Company You’ll Join

At Carta we create owners and make private markets liquid.

We live in a world where some people live on the equity stack and enjoy exponential wealth growth and preferential tax treatment; others live on the debt stack and may work their entire lives for a company and retire only with the cash they’ve managed to save from their paychecks. Our contribution to solving the wealth inequality problem is moving people from the debt stack (payroll) to the equity stack. By making it as easy to issue equity to employees as it is to put them on payroll, we can create more owners.

At Carta, we are helpful, transparent, fair, and kind. We are relentless executors, unconventional thinkers, and masters of our craft.

To learn more, here is what one of our investors wrote about leading our Series F.

The Team You’ll Work With

Our mission is to enable data-driven decisions and products across Carta by collecting accurate data, building scalable infrastructure and delivering advanced analytics. We believe in building a strong data foundation to ensure data quality and to promote self-service across the company. In addition, the data team works on developing proprietary data products using Carta’s rich and unique dataset. The team is split between Data Science/ Machine Learning, Data Analytics, and Data Engineering. We like to partner with each other and with Cartans across the company to get our work done. We constantly think about how we can improve and grow.

The Problems You’ll Solve

As a member of this team, you will partner with business and product teams to use data to accelerate decision making. You will make sure our internal customers have access to consistent metrics and understand their definitions, partner with the rest of the data team to enable self service access to the data they need, and work on reporting and analysis to improve our products. Examples of responsibilities include:

Partner with business and product teams across the organization to understand business problems and help build data solutions
Work with Data Engineering team to build and implement data pipelines for new data sources
Build ML models and deeper analytics with Data Science team using SQL and/or Python to generate insights
Promote self service for business users and their data requests through Looker or other methods
Structure and build ETL infrastructure for new products and business lines
The Impact You’ll Have

By partnering with teams within Carta and providing data solutions, you will elevate our decision making and improve our products, operations and business direction. As you continue to build out our analytics toolkit, you will empower others in the organization to make data driven decisions.

About You

Successful candidates in this role are excellent communicators who are always looking for opportunities to use data to make decisions. You have at least 5+ years of analytics experience either in product analytics or data science. You are a self starter who can build relationships across the company, understand how to prioritize your work, is able to partner with members of your team, and understands when data can and should be used to improve Carta. You have excellent attention to detail, are able to communicate with both business and technical team members and don’t mind writing documentation.

Preferred Tech Stack (experience working with the following tools):

SQL (postgres, redshift)
Python
Looker
AWS / Sagemaker
Airflow
Dbt

Example of problems you will solve include:

Working across multiple teams to standardize, document and generate core metrics for our business and our product
Re-evaluate Explores in Looker to make sure they are easy to understand and use
Provide training sessions to teach members of other teams to use Looker
Generate insights into how new features can impact a product release
Work with business partners and/or product managers to instrument new initiatives and come up with metrics to measure them
Collaborate with the rest of the data team to come up with new products based on data

We are an equal opportunity employer and are committed to providing a positive interview experience for every candidate. If accommodations due to a disability or medical condition are needed, connect with us via email at recruiting@carta.com. As a company, we value fairness, helpfulness, transparency, leadership and build our teams around these values. Check out our careers page to get to know us better as you think about your next step at Carta.","Carta
3.9",Waterloo
154,Data Scientist,"At Metricsflow, we work to shape the future of data attribution for a new kind of relationship between customers and companies. Advocating for privacy-first practices and a smarter, deeper, and non-invasive customer learning, Metricsflow innovates using machine learning and AI technology to equip businesses with the right tools. If you are passionate about the internet and how data is treated, you’ve found the right place.


Metricsflow is seeking an exceptional individual to serve as a Data Scientist. The successful candidate will work closely with the product and engineering team to translate technological and customer requirements into valuable features that ensure a great user experience.


Responsibilities:

Work with structured and unstructured raw data to design and develop innovative predictive models, metrics, reports, and dashboards to uncover actionable insights
Deliver results to drive the projects end to end, not limited to model training, but also including building data pipelines and integrating with engineering systems
Research industry best practices for features to be implemented in the Metricsflow reporting application, with a focus on Data Science features including data preparation, machine learning, user identification
Implement scalable, efficient processes for large scale data analyses, model development and deployment.



Requirements:

3+ years in data scripting languages e.g Python
Hands-on experience in the application of predictive modeling, artificial neural networks, time-series analysis, clustering and classification techniques, and other advanced analytical techniques
Experience using CI/CD tools
Good design and problem-solving skills and an ability to innovate and solve challenging technical problems
Knowledge of the software development lifecycle and Agile methodologies
Excellent organization and time management skills",Metricsflow Inc,St. John's
155,"Operations Research Scientist/Data Scientist - Vancouver, Canada/Remote","Operations Research Scientist/Data Scientist - Vancouver, Canada/Remote-FIT00030

Description


Fujitsu has been consistently named as FORTUNE ‘World’s Most Admired Companies’ year after year, Fujitsu is a leading multinational Information and Communication Technology (ICT) company at the forefront of driving enterprise-scale digital transformation initiatives in organizations and communities around the world. Offering a full range of technology products, solutions and services, Fujitsu’s commitment to R&D continues to deliver cutting-edge technologies, particularly in the fields of artificial intelligence, optimization, operations research, IoT, blockchain, and supercomputing. Combined with its core offerings in IT infrastructure and cloud transformation, this has enabled Fujitsu to develop vast international business operations employing over 130,000 people in 100 countries worldwide in all business sectors at the heart of the global economy. Additionally, Fujitsu’s strong orientation towards the environment, sustainability, and social/societal impact has ensured it continues to be named to the Dow Jones Sustainability World (DJSI World), the world’s leading Socially Responsible Investment (SRI) index, year after year.




Fujitsu Intelligence Technology




Fujitsu Intelligence Technology Limited (FITL) is an emerging center of excellence and innovation hub within Fujitsu’s global operations for data science, artificial intelligence, optimization, quantum-inspired computing, and digital transformation. Located in Vancouver, Canada, and operating as a gateway to Fujitsu’s profound global engineering and innovation ecosystem, FITL is positioned as a digital transformation catalyst, working to grow Fujitsu’s AI and Digital Annealer business solutions both in North America and globally to support Fujitsu’s mission of making the world more sustainable through building trust in society with innovative solutions.

Fujitsu Intelligence Technology is comprised of a diverse team of data scientists, operations research scientists, software engineers along with a strong management support group committed to help businesses navigate and adapt to the digital world. We are committed to developing the talent of our resources through mentoring, collaboration, and education with internal or external stakeholders to shape them to become leaders in the digital transformation ecosystem. We value transparency and fairness in everything we do and look for people that are able to adapt quickly, stay ambitious, and be passionate about new technology.

We are looking for an Operations Research Scientist that would be working closely with the team in our Vancouver, BC office. Please note that remote work is an available option for this role.


Position Summary

We're looking for an experienced Operations Research Scientist to join Fujitsu's AI and optimization team to help solve real-world challenges facing society and businesses across different industries, including manufacturing, healthcare, pharmaceutical, oil and gas, and financial services.




As an Operations Research Scientist, you are passionate about solving problems that make a difference to people, business, and society. You will play a crucial role in identifying and developing innovative advanced analytics solutions & services to support business outcomes. In this position, you will be working in a fast-paced, collaborative team environment to solve customer problems through data, using best-of-breed open source and proprietary AI and Operations Research technologies such as Fujitsu’s Next Generation Quantum Inspired Digital Annealer, a dedicated architecture for solving complex combinatorial optimization problems.




Responsibilities

A successful candidate will perform the following:

Collaborate with our clients and internal stakeholders to understand business processes, identify opportunities, and propose approaches to challenges in a consultative manner
Design, develop and lead the implementation of cloud or onpremises analytics solutions
Acquire, explore, analyze, visualize, cleanse, and transform large sets of data from various external or internal sources
Select and apply appropriate algorithms, methods, and tools
Create scalable data pipelines and machine learning systems
Clearly and objectively communicate progress, results and insights to clients
Investigate, define, select, and promote the use of processes, tools, frameworks, and best practices
Share ideas and expertise with colleagues in a collaborative team environment

Qualifications



Basic Qualifications

Master’s or PhD Degree in a quantitative field such as Operations Research, Data Science, Computer Science, Quantitative Finance, Math, Physics or a related Engineering degree
Minimum seven (7) years of experience in building models and developing algorithms for optimization, machine learning, statistics, mathematical programming, and simulation in industry and/or academia.
Minimum five (5) years of work experience in managing and analyzing largescale structured and unstructured data using a data and analytics programming language, preferably Python
Expert skills in Operations Research such as linear programming, metaheuristics, heuristics, quadratic programming
Experience with analytics, and optimization frameworks and packages such as Numpy, Scipy, Pandas, Gurobi, CPLEX, Xpress, Simulated Annealing
Proven ability to communicate complex concepts and insights verbally and in writing to colleagues and clients with varying degrees of technical knowledge
Proven ability to efficiently work in a team
Excellent analytical and problemsolving skills
Excellent interpersonal skills
Ability to articulate complex technical concepts to nontechnical stakeholders
Ability to work effectively in highpressure situations
Ability to lead and deliver project against tight timelines
Organized, articulate, team player, open to collaborative workstyles and able to manage multiple deliverables for different projects at any given time
Familiarity and willingness to work in crosscultural and geo-diverse teams



Preferred Qualifications

Experience in designing and building production analytics solutions
Experience in Data Science using machine learning frameworks and packages such as Scikitlearn, Keras, PyTorch, TensorFlow
Consulting or experience in a clientfacing role
Experience with discrete event simulation
Experience with Big Data technologies such as Hadoop and Spark
Experience with visualization platforms such as Tableau and PowerBI
Experience with relational databases, SQL and data modeling
Job Type Experienced
Job Administration
Primary LocationBC-Vancouver
Travel Yes, 20 % of the Time","Fujitsu
3.5",Vancouver
156,"Data Scientist: Pricing, Fraud, Monetization","Data Scientist: Pricing, Fraud, Monetization
London, ON, Canada Req #43

Thursday, January 28, 2021

ABOUT THIS POSITION


Digital Extremes is currently seeking a Data Scientist: Pricing, Fraud, Monetization to join our team. You will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. As a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action. As an ideal candidate, you will also have experience with free to play games.
RESPONSIBILITIES
Identify opportunities, advocate and direct changes to regional pricing, fraud prevention, vendors and customized offers ensuring positive player value and sentiment.
Collaborate with Insight, Marketing and Development teams to improve the player purchasing experience
Working closely with the Finance team ensuring proper management of VAT, sales tax, financial tracking and chargebacks
Manage relationships and data pipeline with third party vendors
Use iterative experimental approaches, statistical methods and modelling to measure the effectiveness of changes
Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team
Conduct ad hoc data analysis based on current team needs and management priorities
REQUIREMENTS
Excellent organizational, communication and interpersonal skills
Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other)
Minimum 3 years of experience using Data Science techniques
A passion for video games and understanding of gaming culture
Experience with regional pricing, custom offers and fraud of digital goods
In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks
Experience in the gaming industry, specifically Free to Play gaming is a plus
Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling
Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action
Excellent organizational, communication and interpersonal skills
Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas
ABOUT DIGITAL EXTREMES
Founded in 1993 by James Schmalz, Digital Extremes ranks as one of the world's top independent video game development studios. Originating with the co-creation of Epic Games' multi-million unit selling Unreal® franchise including Unreal and Unreal Tournament, Digital Extremes went on to develop Dark Sector®, BioShock® for the PlayStation®3, the BioShock 2 multiplayer campaign, and The Darkness® II. The studio has reached its greatest critical and commercial success with the free-to-play action game, Warframe®, boasting a global community of 50 million registered players on PC, PS4™, Xbox One and Nintendo Switch™. For more information about Digital Extremes, visit www.digitalextremes.com. To sign up for Warframe, visit www.warframe.com.


WHY WORK AT DIGITAL EXTREMES


Our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. Developing new and existing talent is our long-term focus. We are honored that our work environment has been consistently recognized as one of “Canada’s Top 100 Employers”. We summon you to join our elite team!


The rewards of a career with Digital Extremes include:
Competitive salary with bonus opportunities
Excellent benefits and paid time off
Matching RRSP plan
Employee Assistance Program (EAP)
Professional development and career support
Fitness and parking/transit subsidies
Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff
All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more
JOIN US


Digital Extremes is an equal opportunity employer committed to diversity and inclusion. We welcome and encourage applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the recruitment process. We thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted.


Other details

Pay Type

Salary","Digital Extremes
3.5",London
157,Data Analyst/Engineer,"Telus is building the TV Experience of the future! If you want to be part of the most exciting journey, join our team! We are going to reinvent how entertainment is brought to people, through technology, content and exciting user experience. We shall use the most modern and advanced technologies, creating small, independent and cohesive teams with diverse skills - to reach a commonly agreed target: rebuild entertainment!

Responsibilities

Identify strategic data requirements for the enterprise.
Analyze structural requirements for new software and applications.
Migrate data from legacy systems to new solutions.
Determine how an enterprise’s data will be stored and utilized.
Assess the enterprise’s internal and external data and design blueprint to manage the available data.
Create an inventory of enterprise’s data and store data in an easily accessible format.
Design and develop complex database management systems and separate public data from private ones.
Collaborate with enterprise’s management needs to create data models in line with the organizations need.
Research to collate new data and update the company’s database from time to time.

Requirements

7+ Years of Proven work experience as Data Scientist, Data Analyst or similar role.
In-depth understanding of database structure principles.
Experience in independently managing complex projects.
Experience gathering and analyzing system requirements.
Knowledge of data mining and segmentation techniques.
Expertise in MySQL, SQL Server, and Oracle.
Familiarity with data visualization tools (e.g. Tableau, D3.js, and R).
Excellent analytical, quantitative, and interpersonal skills, with impeccable attention to detail.
Ability to learn new technologies quickly.
Ability to work independently and with a cross-functional geographically spread team.
Ability to interface with multiple cross-functional teams and external partners.

Prior experience in TV architecture is a plus.

Job Types: Full-time, Temporary

Salary: $75.00-$80.00 per hour

Application question(s):

How many years of experience do you have as a Data Scientist or Data Analyst?
How many years of experience with MYSQL, SQL and Oracle do you have

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process","TELUS International Inc.
3.8",Edmonton
158,Senior Data Scientist - RACE21,"Closing Date: June 30, 2021


Reporting to the Manager of Data Science, the Senior Data Scientist at RACE21™ brings deep understanding of big data and helps in building and enabling big data analytics solutions.


They apply complex and most current modelling techniques to existing data sets in order to find optimization and / or improvement opportunities relevant to the context of the product being developed and business problem(s) at hand.


Must-Have Experience (derived from hands-on experience on projects that went into production) in the following domains:

Operations Research
Mixed Integer Programming
Linear Programming
Constrained Optimization


Responsibilities:

Be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures
Designs, develops, and implements end-to-end cloud-based machine learning production pipelines (data exploration, sampling, training data generation, feature engineering, model building, and performance evaluation)
Collects, parses, manages, analyzes and visualizes large sets of data using multiple platforms
Identifies opportunities across business operations to reduce cost, improve safety, sustainability, and efficiency
Extracts and visualizes insights from the available data sets and provides reports and guidelines for improving operations
Prepares documentations of the models, designs and techniques for data and product development teams
Translates complex functional and technical requirements into detailed architecture, design, and high performing software
Codes, tests, and documents new or modified data systems to create robust and scalable applications for data analytics
Ensures all automated processes preserve data by managing the alignment of data availability and integration processes
Works with fellow Data Scientists and Engineers to ensure that all data solutions are consistent
Ability to architect highly scalable distributed systems using different tools (considered an asset, but not required)
Develops standards and processes for integration projects and initiatives
Is prepared to communicate data science insights to internal clients and stakeholders


Qualifications:

Computer Science degree or equivalent education and experience
Master’s or PhD Degree in Information Technology, Computer Science, or a related quantitative discipline (preferred but not required)
A minimum of 3 years’ experience in data science
Proficient in Python for data processing, statistical analysis, machine learning and visualization and skilled in writing SQL queries
Experienced in applied data science within business operations and industry environments
Familiar with data modeling and different data structures and algorithms
Experienced as a Data Scientist within an Agile team or other rapid development methods and environments (preferred but not required)
Excellent problem solving, critical thinking, and communication skills
Experience in developing presentations and communications to be shared with internal and external stakeholders
Brings a high energy and a passionate outlook to the role and can influence those around them in a collaborative and informative manner
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Knowledge of simulation and optimization techniques is (considered an asset but not required)


At Teck, we value diversity. Our teams work collaboratively and respect each person’s unique perspective and contribution.


Qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically.


We wish to thank all applicants for their interest and effort in applying for the position; however, only candidates selected for interviews will be contacted.


Your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. Teck respects the privacy of all applicants and the confidentiality of personal information.


Teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, and zinc, as well as investments in energy assets. Headquartered in Vancouver, Canada, its shares are listed on the Toronto Stock Exchange under the symbols TECK.A and TECK.B and the New York Stock Exchange under the symbol TECK.


The pursuit of sustainability guides Teck’s approach to business. Teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. In 2019, Teck was named to the Dow Jones Sustainability World Index (DJSI) for the tenth straight year, indicating that Teck’s sustainability practices rank in the top 10 per cent of the world’s 2,500 largest public companies in the S&P Global Broad Market Index.","Teck Resources Limited
4.1",Vancouver
159,Data Scientist/Analytics Engineer,"What does your dream company look like? If it's a fun, hyper-growth startup where people look forward to coming to work Monday mornings, keep reading...
RenoRun: We are market leaders, as the fastest-growing materials supplier, delivering to Canadian and US cities. To contractors, renovators and craftsmen, RenoRun is the single materials provider because they get quality materials, from anywhere, anytime, simply and reliably. We're truly disrupting the way construction professionals purchase and receive their materials.
The proof is in the pudding! We have recently closed one of Canada's largest Venture-Backed Series A's for 2019 and are in search of AMAZING talent to help propel the company on to the next.

So if you're looking for impact, look no further. Come join RenoRun!

We are looking for a Data Scientist/ Analytics Engineer to join our Data team. You'll be an integral part of connecting the team to business and ensuring a win-win for all!

Your typical day includes:
Building - You will help build and maintain the data infrastructure at the heart of the company.

Partnering - You will work closely with business stakeholders to understand their data needs and build out the required solutions.

Ownership - From cleaning and transforming raw data into business logic to helping stakeholders build reports, you will have a hand in making sure the right data is getting to the right people at the right time.

Improvement - You'll be constantly looking for ways to improve the modelling and data pipelines to reflect reality and increase efficiency.

Must haves:
2-4 years experience working in analytics engineering, data science, or similar roles
Experience writing SQL and Python
Experience working with data visualization software (Looker preferred)
Experience in data modelling and working with data warehouses (DBT, Snowflake for example)

Nice to haves:
Bachelor's or equivalent in a relevant field (Stats, Math, Comp Sci.)
Experience working in a start-up environment
Experience building/working with data pipelines and ETL tools & processes (Fivetran, Stitch for example)
Experience building/working with predictive models and machine learning algorithms

Perks:
Competitive compensation packages including equity
Unlimited vacation
Comprehensive health, dental & vision insurance
Incredible work environment and culture
Plenty of snacks
Dog friendly office

Why You Should Work With Us:
We know building and renovation. We are industry leaders.

We make puns. We have fun.

We cut to the point because we value people's time.

We are culture-driven. We care a lot. And we say it.

Thank you for your interest in RenoRun!

For more information visit www.renorun.com
At RenoRun, we strive to build a workforce composed of individuals with diverse identities, backgrounds, abilities, and minds that will help us to grow, not only as a company, but also as individuals. RenoRun is an Equal Opportunity Employer .","RenoRun Inc.
4.2",Montreal
160,Data Scientist/Analytics Engineer,"What does your dream company look like? If it's a fun, hyper-growth startup where people look forward to coming to work Monday mornings, keep reading...
RenoRun: We are market leaders, as the fastest-growing materials supplier, delivering to Canadian and US cities. To contractors, renovators and craftsmen, RenoRun is the single materials provider because they get quality materials, from anywhere, anytime, simply and reliably. We're truly disrupting the way construction professionals purchase and receive their materials.
The proof is in the pudding! We have recently closed one of Canada's largest Venture-Backed Series A's for 2019 and are in search of AMAZING talent to help propel the company on to the next.

So if you're looking for impact, look no further. Come join RenoRun!

We are looking for a Data Scientist/ Analytics Engineer to join our Data team. You'll be an integral part of connecting the team to business and ensuring a win-win for all!

Your typical day includes:
Building - You will help build and maintain the data infrastructure at the heart of the company.

Partnering - You will work closely with business stakeholders to understand their data needs and build out the required solutions.

Ownership - From cleaning and transforming raw data into business logic to helping stakeholders build reports, you will have a hand in making sure the right data is getting to the right people at the right time.

Improvement - You'll be constantly looking for ways to improve the modelling and data pipelines to reflect reality and increase efficiency.

Must haves:
2-4 years experience working in analytics engineering, data science, or similar roles
Experience writing SQL and Python
Experience working with data visualization software (Looker preferred)
Experience in data modelling and working with data warehouses (DBT, Snowflake for example)

Nice to haves:
Bachelor's or equivalent in a relevant field (Stats, Math, Comp Sci.)
Experience working in a start-up environment
Experience building/working with data pipelines and ETL tools & processes (Fivetran, Stitch for example)
Experience building/working with predictive models and machine learning algorithms

Perks:
Competitive compensation packages including equity
Unlimited vacation
Comprehensive health, dental & vision insurance
Incredible work environment and culture
Plenty of snacks
Dog friendly office

Why You Should Work With Us:
We know building and renovation. We are industry leaders.

We make puns. We have fun.

We cut to the point because we value people's time.

We are culture-driven. We care a lot. And we say it.

Thank you for your interest in RenoRun!

For more information visit www.renorun.com
At RenoRun, we strive to build a workforce composed of individuals with diverse identities, backgrounds, abilities, and minds that will help us to grow, not only as a company, but also as individuals. RenoRun is an Equal Opportunity Employer .","RenoRun Inc.
4.2",Montreal
161,Data Scientist - Canada,"At Shift Technology, we're transforming insurance with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk and accurately identifying suspected fraud, making internal teams more effective and improving financial performance.

Since our launch in 2014 in Paris, we've raised over $320M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Mexico, Hong-Kong, and Sao Paulo, and currently work with more than 80 of the world's leading insurers. If you are excited about joining a fast-growing insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

Shift Technology offers a unique opportunity to brilliant candidates to accelerate their careers in data science

Data scientists work on a broad range of subjects, acquiring a lot of technical and professional experience in data science, data engineering, coding, business understanding and client interactions; skills invaluable in any career.

Our company is small enough that each person's achievements have an impact on overall performance, yet big enough to be a world leader in our domain.

We are a fast growing company, the best contributors will grow to managerial or product tech lead positions much more rapidly than in bigger companies

YOUR ROLE

The data science team is in charge of technically delivering the Shift products to clients, the key role in the success of our projects with clients. It is a hands-on job, expect to be doing everything you can imagine from the technical side in an AI company:

Implementation of the data engineering , usually from client extracts to the insertion of the data in our data stores (SQL, ElasticSearch)

Developing, testing, tuning models and putting them in production for tasks such as fraud detection and automation detection in complex environments.

Automate key business tasks by implementing them in our production process framework in C#

Conduct meetings with clients and interact with external stakeholders, whether it is direct user feedback, presenting business cases or defining the roadmap of evolutions for that client

You will actively participate in the definition and development of our suite of products on fraud detection, anti-money laundering and claim automation, working on various data types such as structured data, free text, documents and images.

WHAT WE ARE LOOKING FOR

As a result of the range of the role, we are looking for people with diverse skills and proficiencies to help make our customers successful.We are open to people not having exactly all of the required skills, but in each one of those they must be willing to build expertise.

As a result, we expect data scientists to be:
Code-savvy , either by having a degree in computer science and/or having developed some apps with actual users, or by willing to spend a lot of time practicing. Writing scripts for models and notebooks is not enough at Shift, we thrive on people who can write maintainable, production-quality code that will run everyday without breaking.

AI-savvy , either by having a degree in machine learning and/or statistics or be looking to work on those subjects. Having a clear understanding of statistics and machine learning problems, tasks and common resolutions is important to communicate internally and explain to the client how the product is working.

Client facing . You will need to be comfortable, clear and professional when talking to clients during meetings and by email. Expect to talk with a client every other day and grow your communicational and presentational skills!

Business smart . We don't expect candidates to know the insurance sector, but we want people who can learn and master the business aspects of our products

English speakers . We are an international company with offices in many countries and 40+ nationalities, the Shift working language is English.

EEO Statement

At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria. Shift is proud to be an Equal Opportunity Employer.",Shift Technology,Midtown Toronto
162,Data Scientist - Canada,"At Shift Technology, we're transforming insurance with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk and accurately identifying suspected fraud, making internal teams more effective and improving financial performance.

Since our launch in 2014 in Paris, we've raised over $320M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Mexico, Hong-Kong, and Sao Paulo, and currently work with more than 80 of the world's leading insurers. If you are excited about joining a fast-growing insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

Shift Technology offers a unique opportunity to brilliant candidates to accelerate their careers in data science

Data scientists work on a broad range of subjects, acquiring a lot of technical and professional experience in data science, data engineering, coding, business understanding and client interactions; skills invaluable in any career.

Our company is small enough that each person's achievements have an impact on overall performance, yet big enough to be a world leader in our domain.

We are a fast growing company, the best contributors will grow to managerial or product tech lead positions much more rapidly than in bigger companies

YOUR ROLE

The data science team is in charge of technically delivering the Shift products to clients, the key role in the success of our projects with clients. It is a hands-on job, expect to be doing everything you can imagine from the technical side in an AI company:

Implementation of the data engineering , usually from client extracts to the insertion of the data in our data stores (SQL, ElasticSearch)

Developing, testing, tuning models and putting them in production for tasks such as fraud detection and automation detection in complex environments.

Automate key business tasks by implementing them in our production process framework in C#

Conduct meetings with clients and interact with external stakeholders, whether it is direct user feedback, presenting business cases or defining the roadmap of evolutions for that client

You will actively participate in the definition and development of our suite of products on fraud detection, anti-money laundering and claim automation, working on various data types such as structured data, free text, documents and images.

WHAT WE ARE LOOKING FOR

As a result of the range of the role, we are looking for people with diverse skills and proficiencies to help make our customers successful.We are open to people not having exactly all of the required skills, but in each one of those they must be willing to build expertise.

As a result, we expect data scientists to be:
Code-savvy , either by having a degree in computer science and/or having developed some apps with actual users, or by willing to spend a lot of time practicing. Writing scripts for models and notebooks is not enough at Shift, we thrive on people who can write maintainable, production-quality code that will run everyday without breaking.

AI-savvy , either by having a degree in machine learning and/or statistics or be looking to work on those subjects. Having a clear understanding of statistics and machine learning problems, tasks and common resolutions is important to communicate internally and explain to the client how the product is working.

Client facing . You will need to be comfortable, clear and professional when talking to clients during meetings and by email. Expect to talk with a client every other day and grow your communicational and presentational skills!

Business smart . We don't expect candidates to know the insurance sector, but we want people who can learn and master the business aspects of our products

English speakers . We are an international company with offices in many countries and 40+ nationalities, the Shift working language is English.

EEO Statement

At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria. Shift is proud to be an Equal Opportunity Employer.",Shift Technology,Midtown Toronto
163,Senior Data Scientist,"Les candidats référés ne doivent pas postuler directement pour ce poste.
Toutes les références de candidats doivent d’abord être soumises dans Workday par un collègue de Loblaw actuel.

Lieu:

1 Presidents Choice Circle, Brampton, Ontario, L6Y 5S5

C’est toute une décision que de se joindre à une entreprise. Nous offrons des perspectives d’emploi à des personnes qui, comme vous, sont travaillantes, dynamiques et fiables.

Pourquoi ce role est-il important?

The Data, Insights and Analytics division at Loblaw is looking for a Data Scientist to join our fast-growing team. The team will look for your expertise in Optimization in helping build production-ready data science solutions. The ideal candidate must have expertise in the development of optimization algorithms, modern analytical programming and heuristics. The candidate would also thrive working in an agile development environment alongside talented data/software engineers and possess a flair for communicating optimization solutions, ideally with a retail pricing context.

What You'll Do:

Act as one of the Optimization subject manager experts within the Data, Insights & Analytics team, establishing and managing a priority work roadmap
Collaborate with the business to translate problem statements and then d esign and test analytical modules for modeling and optimization platforms
Be a strong individual contributor who can quickly extract data and hash out working prototypes leveraging cloud technology to solve business needs
Develop powerful business insights from data using a range of analytical techniques including, but not limited to building predictive models that learn from and scale to massive data sets and the production of interactive data visualizations
Support the organization in adapting Optimization best practices and delivery methods
Partner with our Data & Software Engineering departments to build world-class web-based analytical solutions
Document and present methodology inside and outside the company
Strictly adhere to legal and compliance guidelines; regarding access and exposure to sensitive and confidential information

What You'll Bring:

Graduate degree in Operations Research, Industrial Engineering, Applied Mathematics, Computer Science or Systems Engineering with focus on optimization methods
Experience in retail and/or CPG pricing, promotions and assortment is a big plus
Excellent oral and written communication skills
Superb analytical and critical thinking capability; to not only manipulate massive, complex datasets, but also to derive meaningful interpretations & conclusions
Experience writing production grade code using scientific computing packages (e.g., R, Apache Spark's Machine Learning Library MLlib, NumPy, Scipy Sklearn)
Expertise in Python or other modern programming languages
Expertise in using CPLEX, Gurobi and or Numerical Algorithm Groups solvers
Expertise in object-oriented programming
Well-organized and capable of handling multiple mission-critical projects simultaneously while meeting deadlines
A desire and ability to take initiative, multi-task and work in a collaborative, fast-paced environment
Capability to liaise with all levels across the enterprise on projects and ad-hoc requests
Experience in Short-release lifecycle (agile processes including scrum)

Comment R é ussir:

Chez Loblaw, nous recherchons toujours des personnes formidables pour continuellement renforcer notre culture. Nous croyons que les gens formidables façonnent nos valeurs, sont authentiques, bâtissent la confiance et créent des liens.

Si cela vous ressemble et que vous êtes ouvert d’esprit, que vous avez une bonne attitude face aux changements et que vous aimez les défis d’un environnement de travail aux détails dynamiques, postulez aujourd’hui.

En outre, nous croyons que la conformité aux lois consiste à faire ce qu'il faut. Le respect de la loi fait partie de notre Code de conduite; il renforce ce que nos clients et nos parties prenantes attendent de nous.

Type d'emploi:

Temps plein

Role:

Poste régulier

Loblaw considère que la diversité culturelle du Canada est une source de fierté nationale et un symbole de force. Nous nous sommes donné comme priorité de refléter la diversité croissante du Canada dans les produits que nous vendons, les gens que nous embauchons et notre culture d’entreprise. Des accommodements sont disponibles sur demande pour les postulants et collègues atteints d’un handicap.

Remarque : Si vous avez accès à Libre-service de l’employé (ESS) dans Workday, veuillez postuler à cet emploi en utilisant l’application Workday.","Loblaw Companies Limited
3.6",Brampton
164,Data Scientist,"Data Scientist, 48Hour Discovery

Founded in 2017, 48Hour Discovery (48HD) is a Canadian biotechnology company with headquarters in Edmonton, AB and satellite sites in San Diego, California and Seoul, South Korea. The 48HD genetically-encoded platform technology offers rapid discovery of pharmaceutical leads in the peptide / macrocycle therapeutic space to major pharmaceutical companies (example: https://tinyurl.com/yyvv626v ).

We are currently seeking a creative and motivated data scientist to join our team. The ideal candidate will have strong prior knowledge of chemistry, biochemistry and experience with machine learning that involves chemical/molecular structures. This candidate will combine the knowledge of Machine Learning and chemical/molecular structures to develop automate, reusable models for predictive analytics in the peptide/macrocycle space.

Primary Responsibilities

This is a key position in developing the platform to discover future pharmaceutical leads while driving the adoption of AI. All applicants must be prepared to provide demonstrated experience in the following:

Extensive knowledge in chemistry and/or biochemistry including chemical/molecular structures.
Work with structured and unstructured raw data to design and develop innovative predictive models using machine learning techniques.
Visualize and report data findings creatively in various visual formats that provide insights.

Additional consideration will be given to individuals with experience in the following:

Work with Next Generation Sequencing (NGS) data.
Data collected from phage display experiments.
Bioinformatics background.

Qualifications

MSc or PhD in Computer Science, Machine Learning, Artificial Intelligence, Statistics, Mathematics, Engineering, Computational Biology, Molecular Biology, Chemistry, Biochemistry or a related discipline, with (at minimum) graduate-level courses in machine learning, or equivalent practical experience.
Minimum 2 years in implementing Machine Learning software.
Extensive knowledge in chemistry and/or biochemistry. Familiar with chemical/molecular structure.
Strong research experience in machine learning, preferably in deep neural network architectures.
Proficient in deep learning frameworks like PyTorch and scientific computing packages. Able to implement an algorithm as described in an academic paper using these frameworks in quality code.
Strong computer science background, with experience in object-oriented programming, systems design, data structures and algorithms. Proficient in Python and/or R, with an interest in learning new languages.
Familiarity with source control (Git) and Unix systems.
Efficient written and verbal communication skills with the ability to present to a wide range of audiences.

This full-time position has a term length of 18 month, with the possibility of extension, and offers a comprehensive benefits package. Salary will be commensurate with experience and qualifications.

Job Type: Full-time

Salary: From $70,000.00 per year

Benefits:

Extended health care

Schedule:

Monday to Friday

Work remotely:

No",48Hour Discovery Inc,Edmonton
165,Bilingual Data Science Associate,"Company presentation

World leader in gases, technologies and services for Industry and Health, Air Liquide is present in 80 countries with approximately 65,000 employees and serves more than 3 million customers and patients. Oxygen, nitrogen and hydrogen have been at the core of the company’s activities since its creation in 1902. Air Liquide’s ambition is to be the leader in its industry, delivering long-term performance and acting responsibly.

Entity and activity description

Founded in 1911, Air Liquide Canada has over 2,200 employees and serves over 80,000 customers in Canada’s aeronautics, automobile, agri-food, chemical, defense, electronics, energy, metallurgy, metal fabrication, mining and healthcare industries from our sites located in key industrial regions from coast to coast.

Missions and Responsibilities

The R&D Data Science group at Air Liquide has an opening for a Data Scientist. The researcher will have the opportunity to work on challenging problems focusing on customers, patients and operations. The researcher will also interact with multi-disciplinary teams composed of Business, IT and Digital resources that define operating models, and build digital solutions.

Duties and Responsibilities

Collaborate with the business to define needs and challenges, translate them into functional specifications, and develop solutions to address them.
Work with IT and external organizations to obtain online/offline data. Clean, and analyze the data.
Develop solutions relying on machine learning methods such as clustering, regression, classification, time series and deep learning.
Test and verify the performance of solutions with prototypes developed in R, Python, or similar development environments.
Support the development of industrial tools and their deployment in the business units.
Train team members and the business, thus ensuring sustainability of the solutions for Air Liquide.
Publish research in internal reports, at conferences and peer-reviewed journals

Competencies and Profile

Master in Computer Science or related field
3 years of relevant experience is preferred
A strong background and experience in statistics and machine learning
Strong programming skills in Python or R
Ability to write production level, modular code
Demonstrates strong process and operational safety behavior at all times
Excellent communication and interpersonal skills (written and oral)
Ability to work in a multi-disciplinary and international team

Preferred

Experience in AWS, Azure, and SQL

Thank you for your interest. Please note that only applicants selected for an interview will be contacted For more information on our company, visit us online at www.airliquide.ca

Missions et Responsabilités

Vous aurez l’opportunité de travailler sur des problèmes complexes centrés sur les clients, patients et les opérations. Vous travaillerez au sein d’une équipe multi-disciplinaire composée de profils d’experts en science des données et de recherche opérationnelle. Vous serez également en interaction avec les équipes opérationnelles, des TI et du Digital qui travaillent à identifier des modèles opérationnels et à construire des solutions digitales.

Développer des solutions basées sur les approches d'apprentissage automatique (machine learning): analyse par groupe (clustering), régression, classification, séries temporelles et apprentissage profond (Deep Learning)
Tester et vérifier la performance des solutions à l’aide de prototypes développés en R, Python ou des environnements de développement similaires
Soutenir le développement d’outils industriels et leur déploiement dans les unités commerciales
Collaborer avec les opérations afin de définir les besoins, les traduire en spécifications fonctionnelles et développer des solutions pour y répondre
Travailler en collaboration avec les TI et les organisations externes afin d’obtenir des données en ligne/hors ligne. Nettoyer et analyser les données.
Former les membres de l’équipe et les opérations, afin d’assurer la durabilité de ces solutions pour Air Liquide

Profil et compétences

Maîtrise en science des données
3 années d'expérience pertinente
Une expérience en statistiques et d’apprentissage automatique (machine learning)
Capacité à produire du code modulaire et déployable en production
Solides compétences en Python ou R
Fait preuve d’un comportement axé sécurité opérationnelle à tout moment
Excellentes capacités de communication (écrite et orale) et en relations interpersonnelles
Capacité à travailler dans une équipe multi-disciplinaire et internationale

Préféré

Expérience sur AWS, Azure et SQL

Nous vous remercions de votre intérêt pour Air Liquide. Notez que seuls les candidats présélectionnés seront contactés. Pour plus d'informations sur notre entreprise, visitez-nous en ligne à www.airliquide.ca

Job Types: Full-time, Permanent

Schedule:

8 hour shift
Monday to Friday

Ability to commute/relocate:

Montréal, QC (preferred)

Education:

Master's Degree (preferred)

Experience:

Data Science: 4 years (preferred)
Machine learning: 3 years (preferred)","Air Liquide
3.8",Montreal
166,Data Scientist (Portfolio Modelling),"Closing Date (MM/DD/YYYY):

06/30/2021

Worker Type:

Term (Fixed Term)

Language(s) Required:

English

Term Duration (in months):

12

Data science and statistical modelling expertise needed
Use your extensive knowledge of risk management and finance in areas such as credit risk, allowance for credit losses, economic capital, and stress testing to support our portfolio management team.

What you’ll do:

Unlock insights from complex and diverse groupings of internal and external data or developed models to tell a story

Use advanced analytics techniques to enable enlightened decision-making

Choose appropriate ways to tell the story through words, visualization, and interpretation

What we’re looking for:

Analytical thinker who can design and develop strategies that give users the information they need to make informed decisions

Creative thinker with research, analytical, and problem solving skills

Confident communicator who can translate knowledge for others

Relationship-builder comfortable making recommendations for improvement

What you’ll need:

A bachelor’s degree in agriculture, finance, business, economics, mathematics, statistics or computer science and at least four years of experience (or an equivalent combination of education and experience)

In-depth understanding of statistics and mathematics combined with business domain knowledge

Highly proficient in visualization and analytics tools including but not limited to SAS, MS Power BI, AWS environment and tools, R, Python

A passion for analysis, insights and storytelling

-If you are an FCC employee, use your Workday portal to apply.

-If you are an FCC employee On Leave, contact Human Resources for instructions on how to apply.","Farm Credit Canada
4.3",Regina
167,"Scientist, Data",":


The Data Scientist will join the Advanced Analytics team focused on creating transformational analytics-enabled capabilities across all of Acosta’s businesses. This can range from using statistical methods, data-mining and machine-learning techniques, or generating novel approaches uniquely suited the challenge. We value complementary and divergent experiences to bring many points of view on how to approach solve a problem. Although our datasets range in size, you can expect to work with very large datasets regularly in this role.


The incumbent(s) in this position should exhibit the following Acosta values:
People Minded – Must show dignity and respect to all people
Integrity – Must exemplify the highest degree of ethical behavior
Results Oriented – Must show passion, pride and commitment to succeed
Trust – Must be honest, sincere and confident
Teamwork – Must build trusting relationships
Innovation – Must progress through a combination of creativity, common sense and vision
Balance – Must maintain an optimistic attitude and keep perspective on what is important in life.


Essential Functions:

Development of analytical capabilities to serve diverse business use cases, in active collaboration with product management and technology counterparts.
Cross-functional, internal and external consulting, including discovery/structuring of business problems, and exploratory analysis of candidate methods to identify promising approaches for development.
Creation and maintenance of solution documentation, including data transformation, models, and solution integration.
Ownership and lifecycle management for analytics capabilities working in a production environment, including computational performance, accuracy/validity, and extension to new uses.
Other duties as assigned


Qualifications:


Job Requirements:

Graduate Degree
Master's degree preferred
4 – 7 years of experience with programming languages like Python (preferred), R or SAS to write complex code and implement into a production environment. Must be able to develop independently and guide others within the development team.
Practical experience with development, tuning, and maintaining Machine Learning capabilities at scale.
Experience generating linear and/or logistic regression models. Must be able to generate complex analytic models on a large scale with no guidance. Must be able to guide others in the same.
Experience with Linear / Integer Programming and/or other optimization techniques. Must be able to generate complex solvable optimization models on a large scale with no guidance. Must be able to guide others in the same.
Experience with data science in Microsoft Azure or cloud environments using Spark or alternative parallel computation capabilities highly desired.
CPG, Sales and/or Retail experience highly desired


Knowledge, Skills and Abilities Requirements:

An understanding of different data sources, their proper uses, and their limitations. Must be able to identify data that is unclean and/or misapplied and must be able to recommend the proper methodology to fix any issues.
Excellent written and verbal communication skills that allows story telling. Must be able to clearly speak English and must be able to communicate very technical procedures to a non-technical audience.
Strong analytical and problem-solving skills with the ability to collect, organize, analyze, and disseminate significant amounts of information residing in large datasets.
Ability to consult across various business functions to explain analytic functions and how they can be used to drive a business.
Intellectual curiosity is critical.


Acosta Sales & Marketing is an Equal Opportunity Employer


By submitting your application you agree with and accept the Acosta Privacy Statement and Terms of Conditions.

US: http://acosta.jobs/privacy-policy-us/

Canada: http://acosta.jobs/privacy-policy-ca/


Job: Information Technology
Schedule: Full-time
Job Type: Standard
Shift: Day Job
Job Posting: May 12, 2021, 9:52:09 AM","Mosaic North America
3.7",Midtown Toronto
168,Data Scientist (Shopping Experience),"At Loblaw Digital, we know that our customers expect the best from us. Whether that means building the best, most innovative online shopping experiences, or designing an app that will impact the lives of people across the country, we’re up for the challenge. Loblaw Digital is the team responsible for building and operating the online businesses of Canada’s largest and most successful retailer. Based in downtown Toronto, we are an entrepreneurial, fast-paced, and collaborative team working towards transforming the way Canadians shop by creating leading eCommerce experiences in the online grocery shopping, beauty, pharmacy, loyalty, and apparel spaces, and we’re only just getting started! To achieve these goals, we are looking for talented and passionate individuals who want to collaborate and solve challenging problems and make significant and lasting impact on Canadians.

The impact you’ll make

As a Data Scientist on our team, you will build data-science products that power a best-in-class personalized shopping experience, driven by an abundance of data from the Loblaw enterprise. This work could be in the domains of product recommendations, personalized search, and personalized messaging, to name a few.

You will work with stakeholders within Loblaw Digital to determine the best ways to surface these personalized experiences within customer shopping journeys, and leverage your collective domain expertise to design business-logic guardrails around your model output. You will design experiments to measure the effectiveness of your product in driving customer engagement and value, through key business metrics such as clickthrough rate and attributed sales.
What you'll do
Build robust, scalable, high-performance ML solutions based on massive structured and unstructured datasets from various sources
Work with Engineering and Data Platform teams to build and deploy your ML models into production
Work cross-functionally with business teams — Product, Trading, Marketing, Supply Chain, Web Analytics etc. — to source data, establish requirements, and define success
Does this Sound like you?
MS or PhD in a STEM field — especially computer science — or equivalent work experience in a Data Scientist or closely related role
A portfolio including work in the domain of data science and ML
Creative, resourceful, and productive problem-solver
Able to work independently and collaboratively
Passion for building ML solutions to fluid, open-ended problems
Experience in software development best practices
Comfortable with advanced SQL querying
Proficient in Python and familiar with a compiled language
Experience with big-data tools, e.g. Spark, Beam, Kafka.
Experience with dataviz tools such as Tableau, Looker, etc.

How you’ll succeed

At Loblaw Digital, we seek great people to continually strengthen our culture. We believe great people model our values, are authentic, build trust and make connections. We’re able to keep innovating because our colleagues are passionate about their work and excited about the future of eCommerce. You will get to work with some of the best digital minds and will have the support of world class technologies to craft products our customers will love!

Loblaw Digital recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. Accommodation is available upon request for applicants with disabilities in the recruitment and assessment process and when hired. In addition, we believe that compliance with laws is about doing the right thing. Upholding the law is part of our Code of Conduct – it reinforces what our customers and stakeholders expect of us.","Loblaw Digital
3.6",Midtown Toronto
169,Data Scientist - Telematics,"This role will start off as work from home, gradually you will be required to work in the Montreal office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive impactful decisions. The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. This team is exploring the frontiers of the insurance business such as how to harness the data from connected cars to deliver new types of products to customers. This exciting role is at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

As a Data Scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work.

What you’ll do

Transformation of very large and complex datasets into meaningful conclusions and recommendations

Build high performing machine learning and statistical models on very large datasets

Develop novel algorithms and innovative data-driven solutions to solve business problems

Implement and help enhance existing ML pipeline, framework and modelling packages used by the team

Building and maintaining good quality code and help iteratively develop software to increase efficiencies

Show strong interest and understanding of the assigned business domain

What you need to succeed

As a data-scientist, you will need the following skills and experience to succeed in the role:

University Degree in Computer Science, Math, Statistics, Physics, Actuarial Science or related field or equivalent. Masters or PhD strongly preferred

1-2 years of programming experience preferably in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.

3-5 years of experience of building machine learning models for business applications

Advanced level understanding of machine learning fundamentals and model development principles (Generalization, Bias-Variance Tradeoff, GLMs, NLMs, etc.)

2-3 years experience with ML/AI technologies, such as scikit-learn, Keras. TensorFlow, PyTorch

Experience mining IoT sensor data or Telematics data will be considered an asset

Experience with Big Data Technologies such as Spark, Databricks, Scala will be considered an asset

What sets you apart

A growth mindset with versatile skills and able to work through problems from first-principles.

A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data.

Experience at all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment.

Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.

Experience working as part of an Agile Team

The best problems in the industry are yet to be articulated. We need someone who is creative and self-motivated

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","Aviva
3.7",Montreal
170,Process Data Scientist,"Reference : R2601779

Position Title : Process Data Scientist - Vaccines

Department: Data Science, Manufacturing Technology

Location: Sanofi Pasteur Limited, Toronto

Sanofi Pasteur: The world’s leading vaccine company

Sanofi Pasteur, the vaccines division of Sanofi, is the largest company in the world devoted entirely to human vaccines. Our driving goal is to protect people from infectious diseases by creating safe and effective vaccines. Our company distributes more than 1 billion doses of vaccine each year, making it possible to vaccinate more than 500 million people across the globe. Sanofi Pasteur offers the broadest range of vaccines in the world, providing protection against 20 bacterial and viral diseases.

Sanofi is dedicated to supporting people through their health challenges. We are a global biopharmaceutical company focused on human health. We prevent illness with vaccines, provide innovative treatments to fight pain and ease suffering. We stand by the few who suffer from rare diseases and the millions with long-term chronic conditions. With more than 100,000 people in 100 countries, Sanofi is transforming scientific innovation into healthcare solutions around the globe.

Mission:

The Data Science team operates with a customer-focused mindset to apply data analytics capabilities to deliver tangible benefits. The team actively works on improving data infrastructure and analytics capabilities to enable process monitoring, improve process understating and enhance decision making.

Process Data Scientistwill lead the way to support applied analytics and tech transfer activities for new vaccine manufacturing processes. This individual will play a key role during tech transfer operations to extract value out of analogous manufacturing processes by analyzing process data and working in partnership with subject matter experts to have a deep understanding of the production processes. The right candidate will identify and employ data engineering, data visualization and advanced analytics capabilities, including statistics and machine learning techniques to provide the right Data Science solutions to the business.

Key Responsibilities:

Take initiatives and drive for results with minimum supervision; high level of maturity to work with different facets of the business including Quality, Manufacturing Operations, Automation, Project Management and Supply Chain.

Partner with stakeholders from multiple sites and departments to identify opportunities for applying machine learning and process modelling techniques to solve complex business challenges such as maximizing yield, write-off avoidance, reducing process variability and predictable supply.

Extremely comfortable in storytelling in relation to data and processes, i.e., proven ability to explain manufacturing process through a data analytics mindset.

Exploit opportunities to leverage data from other manufacturing sites in the network to develop applied data analytics solutions such as real-time process monitoring, data visualization and process modelling solutions.

Partner with Data Infrastructure team to apply re-usable and efficient data engineering solutions when applying process analytics.

Promote a strong quality mindset with a focus on data integrity, validation and data governance.

Key Requirements:

MSc. or PhD in process or industrial engineering with data science or process modelling background or a similar technical field.

Must have a minimum 3 years (PhD) or 5 years (MSc) of relevant process modelling/process diagnostics experience in manufacturing or industrial settings.

Strong experience in delivering insights through mathematical modelling and data visualization.

Proficient in using classification, clustering, dimensionality reduction, ensemble methods, neural networks and deep learning methods.

Experience using tools such as Python, SQL, R, KNIME, SIMCA, JMP, R-Shiny and QlikSense.

Experience with implementing ETL processes for aggregating and contextualizing data.

Strong knowledge in working with data historian systems, including PI Asset Framework (AF) & PI Event Frames – infrastructure, Manufacturing Execution System (MES) and IoT solutions.

Experience with developing business requirements, and ability to influence and communicate with a diverse group of stakeholders from multiple levels of management.

Ability to deliver projects with complex requirements and a strong customer focus.

Ability to succeed in a team-oriented environment under very dynamic and fast-paced working conditions.

Experience with Big Data ecosystem such as AWS or Microsoft Azure is a plus.

Travel :

The candidate should be willing and able to travel to the USA as needed.

Applications received after the official close date will be reviewed on an individual basis.

Sanofi is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. We welcome and encourage applications from all qualified applicants. Accommodations for persons with disabilities required during the recruitment process are available upon request.

Thank you in advance for your interest.

Only those candidates selected for interviews will be contacted.

Follow Sanofi on Twitter: @SanofiCanada and on LinkedIn: https://www.linkedin.com/company/sanofi

Sanofi, Empowering Life

#GD-SP #LI-SP

At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.","Sanofi
3.9",Midtown Toronto
171,Senior Data Scientist,"What is the opportunity?

As a Senior Data Scientist, you will develop, design, and implement organization-wide cutting-edge AIOps(AI for IT Operations) solutions at RBC Technology Infrastructure. Leveraging leading edge technologies and various data sets, you will build machine learning based products to facilitate informed decision-making and business process optimization in order to minimize outages and reduce downtime of RBC services which save considerable amount of costs and also improve user experience.


What will you do?

Work on challenging and research-based initiatives using advanced machine learning methods focusing on tangible outcomes
Collaborate proactively with various business and operation units to identify business opportunities and designing innovative solutions to optimize processes and promote informed decision-making
Prepare and integrate large and various types of data (structured/non-structured)
Implement machine learning models, data mining methods, and statistical analysis
Leverage visualization tools/packages to create powerful representations of results
Produce data-driven insights to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives
Collaborate with the development team to deploy production-scale solutions
Quickly learn new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises


What do you need to succeed?

Must-have

PhD. or Masters in Computer Science, Statistics, or relevant fields.
Expert in Python programming to write production-ready codes. Strong data profiling, cleaning, mining and technical documentation skills
2+ years of experience in developing machine learning models for real business problems
2+ years of experience with NLP and text analytics methods and packages
Experience with big data technologies – parallel processing techniques and Apache Spark, NoSQL/SQL databases
Proficient in Linux environment, shell scripting, and Git


Nice-to-have

Strong knowledge and experience of different deep neural networks architectures (RNN, CNN, GAN, seq2seq/Transformers) and transfer learning
Experience with MLOps to build end-to-end pipeline and deploying models in production
Familiar with container-type environment: Docker, Openshift
Experience in graph analytics and time-series analysis


What’s in it for you?


We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Ability to make a difference and lasting impact
Work in a dynamic, collaborative, progressive, and high-performing team
A world-class training program in financial services
Flexible work/life balance options
Opportunities to do challenging work
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with clients
Access to a variety of job opportunities across business and geographies


Learn more about RBC Tech Jobs

Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Toronto
Address: 330 Front Street W
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel(%): 0-25
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 05/14/2021
Platform: Technology and Operations
Req ID: 349413
Ad Code(s):","RBC
4.1",Midtown Toronto
172,Data Scientist II,"About Us

The Kraft Heinz Company is one of the largest food and beverage companies in the world, with eight $1 billion+ brands and global sales of approximately $25 billion. We’re a globally trusted producer of high-quality, great-tasting, and nutritious foods for over 150 years. Our brands are truly global, with products produced and marketed in over 40 countries. These beloved products include condiments and sauces, cheese and dairy, meals, meats, refreshment beverages, coffee, infant and nutrition products, and numerous other grocery products in a portfolio of more than 200 legacy and emerging brands.

We spark joy around mealtime with our iconic brands, including Heinz, Kraft, Bull's-Eye, HP, Lea and Perrins, Quero, ABC, Master, Banquete, Plasmon, Orlando, Benedicta, Honig, Pudliszki, Wattie’s among others.

No matter the brand, we’re united under one vision: To sustainably grow by delighting more consumers globally . Bringing this vision to life is our team of 39,000+ food lovers, creative thinkers, and high performers worldwide. Together, we help provide meals to those in need through our global partnership with Rise Against Hunger. We also stand committed to responsible, sustainable practices that extend to every facet of our business, our consumers, and our communities. Every day, we’re transforming the food industry with bold thinking and unprecedented results. If you share our passion – and are ready to create the future, build a legacy, and lead as a global citizen – there’s only one thing to do: join our table and let’s make life delicious!

Our Culture of Ownership, Meritocracy & Collaboration

We're not afraid to think differently. Embrace new ideas. Dream big. We empower our people at every level – from entry-level intern to senior leader – to own their work. We share a responsibility to think like Owners – to be mindful of the collective and sustained success of Kraft Heinz – which we apply to every situation, every day. As part of Kraft Heinz, you're supported to grow and achieve. You’re expected to bring your authentic self to work every day, to lead with humility, and drive outstanding performance at every level – and you’ll be rewarded. You’re given opportunities to leave a mark and build a legacy. But you won’t do it alone. You’re supported by passionate teammates along the way, and our collective, collaborative spirit fuels our incredible progress.

Job Description

The Data Scientist II role is a key driver in developing and maintaining advanced analytics tools to help business make quicker and better decisions to maximize the business’ competitive advantage.

This role will help maximize the ROI on our large annual investments in data and technology by discovering hidden insights from data, developing models & dashboards and improving faster decision making that will drive business results.

We are looking for someone with a strong background in Statistics or Mathematics who can translate business problems to mathematical terms to drive business value. The Data Scientist is responsible for developing models, ensuring the models are up to date to meet changing business requirements and unlock new business opportunities. This role works closely with the Principal Data Scientist to develop new and maintain existing analytics solutions.

Why Should You Join the Team?

Data Science team is a new team and is instrumental in guiding Advanced Analytics journey at Kraft Heinz Canada. The team works as a startup - and as a part of this highly energetic team you will not only work on developing models but also get the unique opportunity to gain hands on experience to define data science framework at Kraft Heinz. Overall, if you are passionate about data and would like to apply theoretical concepts to solve practical business problems, develop cutting edge algorithms and intelligent tools to show how data science can bring business value, all while working with a friendly team, this is going to be your dream team to enrich your data science career. The sky is not the limit in terms of enhancing your knowledge and working on a variety of projects with the Data Science team at Kraft Heinz Canada!

Responsibilities:

Model and Tool Development:

Develop, manage, maintain & optimize machine learning models by working closely with Data Engineering, ML Engineer and Business stakeholders to deliver end-to-end solution.
Use of problem-solving skills, advanced Analytics methodologies (ML/AI) to find hidden data insights to unlock new business opportunities
Assist Data Science team with development of complex tools, models or database builds as well as analytic requests

Visualization:

Own Data Science Visualization Framework, Tableau environment for assigned function (permissions, tracking of usage, optimization, etc.)
Adopt visualization best practices to develop dashboards

Team Player:

Leadership in the cross-functional advanced analytics reporting and KPI development
Working with ML Engineer to ensure integrity & governance, rituals and routines of new Data Sources in Snowflake database & Azure Blob storage

Project Management:

Provide inputs/stories and assist in prioritization of Data Engineering sprints
Complete User Acceptance Testing on new releases

Qualifications:

Must Have

Master’s degree in engineering, operations research, statistics, mathematics, or econometrics
Experience in programming languages – SQL, Python or R
Fundamental knowledge on cloud computing technologies
3 – 5 years’ experience with development of large scale supervised, unsupervised ML models and forecasting models
Experience working with database systems and analytical tools, strong design sense for data visualization
Strong communication & problem-solving skills and a strong team player
Knowledge on version control system such as Git
Knowledge on Agile methodologies


Good to have

Knowledge on Open Source Python Visualization such as Bokeh or Streamlit etc.
Experience in working with Azure ML and Azure Devops
Experience in dashboard development in Tableau
Experience in development of Heuristic Models
Experience in working with Agile teams and using tools such as Jira

Kraft Heinz is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified candidates will be considered for our opportunities, regardless of race, religion, faith, creed, age, ethnicity, marital status, gender identity, sexual orientation, or disability. Job seekers with disabilities who require accommodation during the recruitment process or would like more details about accessibility should contact: accessibility@kraftheinzcompany.com .

IND123

#LI-Location

Toronto, ON

Location(s)
Don Mills","Kraft Heinz Company
3.8",Don Mills
173,Senior Data Scientist,"Hiring in the US and Canada Only

At Urbint, our mission is to make communities more resilient. We do this by pairing external data with artificial intelligence to identify areas of high risk and prevent catastrophic loss for utilities and infrastructure operators across the country. We are a team of close-knit engineers, entrepreneurs, and data geeks who obsess over problem-solving, new technologies, and making a positive impact in our communities.

We encourage people from underrepresented groups to apply.

Job Summary

At Urbint, the machine learning team does not work on making consumers spend more or on maximizing clicks. That is all fine; we work on reducing carbon emissions, reducing infrastructure risk and avoiding fatalities. We find meaning and excitement solving these problems, and we hope you do, too.

We are looking for a Senior Data Scientist to join our high visibility, high impact Machine Learning team to help with this mission. The ML team collaborates with a diverse, broader-mission team to deliver value for our customers. Members of the Machine Learning team have the option to major/minor in areas from a large data science specialization spectrum: Technical Product Management, People Management, Data Story-Telling, Applied ML, ML Research, AutoML (Algo/Performance) and MLOps (DE, SRE). This is a great role for someone who enjoys variety and is also looking to expand their skill set in a structured fashion.

What You'll Do

You will major in Applied ML (customer-facing) and minor in AutoML, focused on delivering value to customers.
You will translate business problems into data science problems, and develop solution frameworks (for repeatability/scaling) with focus on speed to value.
You will own key portions of OKRs that help maximize team productivity.
You will have strong communication and organizational skills.

You will convey complex ideas & trade-off decisions to business stakeholders.
You will provide guidance to your team on task level prioritization and cross team coordination.
You may support other teams during ideation with customers.

Overall, you will be responsible for delivering ML products that deliver measurable business value for customers.

Who You Are

3+ years of experience in data science/machine learning roles.
Experience solving concrete, real-world machine learning problems.
Well-versed in Python or R (and willing to continue to learn the Python ecosystem).
Comfortable writing production-ready code.
Demonstrated problem-solving skills and experience maximizing team productivity.
Experience leveraging AutoML technologies.
Up to date with what's under the hood of some of the advanced ML tools available.

Nice to Have

Experience with startup or Agile environments.
Experience building AutoML tools.
Track record of creating excellent slack emojis and memes.

Benefits

Mission-Driven - Some companies use AI to serve better digital ads and trade stocks; we seek to make our communities safer and more resilient
100% Distributed - work from anywhere
Distributed work monthly stipend
Competitive compensation package
Best in Class Medical Coverage - 100% benefits and premiums paid
Health Perks - Wellness reimbursement
Educational Allowance - up to $1000 /yr
Weekly lunch stipend

We're an equal opportunity employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","Urbint
3.7",Ontario
174,Scientifique de données / Data Scientist,"Qui sommes-nous :
BusPatrouille est une entreprise spécialisée dans la technologie de sécurité. À titre de principal fournisseur international de dispositifs visant à faire respecter le bras d'arrêt des autobus scolaires, notre mission principale est d'améliorer la vie des élèves où qu'ils se trouvent.

La technologie de BusPatrouille a été déployée sur un plus grand nombre d'autobus et a été utilisée pour délivrer un plus grand nombre de constats d'infraction relatifs au bras d'arrêt des autobus scolaires que toute autre technologie des autres entreprises existantes à l'échelle mondiale. Notre technologie exclusive transforme les autobus scolaires en autobus intelligents équipés de caméras vidéo, de GPS, de télémétrie, de traitement de données et d'archivage. De cette manière, nous permettons aux comtés et aux districts scolaires d'améliorer la sécurité des enfants.

BusPatrouille est en pleine croissance. Nous sommes donc à la recherche d'un ou d'une scientifique de données pour intégrer notre service de veille stratégique (BI). Si vous aimez travailler dans un environnement dynamique avec des collègues talentueux, ce poste est pour vous.

Responsabilités :
Le poste de scientifique de données a une grande influence et nécessite de travailler en étroite collaboration avec les clients ainsi qu'avec les équipes des ventes et de l'exploitation afin d'aider à prendre des décisions fondées sur les données de manière à stimuler une croissance efficace de BusPatrouille. Si vous aimez la communication narrative et le fait d'influencer les décisions opérationnelles au moyen des chiffres, nous voulons faire votre connaissance!

Il s'agit d'un poste de premier plan qui vous permettra d'interagir régulièrement avec les chefs d'entreprise, de définir la feuille de route de l'équipe et de recenser les besoins pour fournir des solutions innovantes. La personne idéale est autonome, très analytique, curieuse et a de la facilité à plonger dans de grands ensembles de données afin d'en tirer des enseignements. Notre environnement évolue rapidement et requiert une personne enthousiaste, flexible, soucieuse du détail, analytique et à l'aise pour travailler avec plusieurs équipes et des priorités concurrentes.

Mettre en pratique d'excellentes compétences en matière d'analyse et de résolution de problèmes pour prendre des décisions d'affaires dans un environnement dynamique afin de fournir des avantages aux clients et des analyses de performance.

Travailler de manière indépendante et en collaboration avec d'autres scientifiques, des ingénieurs, des concepteurs, des développeurs en veille stratégique (BI) et des gestionnaires de produits sur des projets complexes qui génèrent de la valeur pour BusPatrouille.

Posséder d'excellentes aptitudes à la communication et être capable de structurer un scénario convaincant pour présenter une narration à l'aide de données exploitables.

Être capable de conceptualiser des problématiques ou des occasions d'affaires, de formuler des hypothèses et des objectifs, de définir des indicateurs clés de performance et de faire des recommandations adéquates.

Construire des modèles prescriptifs et prédictifs de calibre international pour résoudre des problèmes commerciaux dans un environnement qui évolue rapidement.

Tirer parti des données internes et externes pour synthétiser des idées intéressantes qui expliquent les tendances sous-jacentes de l'écosystème de l'application automatisée des lois.

Repérer les possibilités d'automatisation pour favoriser l'évolutivité et améliorer tant l'efficacité que la productivité de l'équipe élargie.

Posséder de solides compétences en communication écrite et verbale, avec la capacité de synthétiser efficacement des idées (notamment la théorie des modèles, les compromis de sélection et les limites) pour les présenter à la haute direction ou à des clients.

En temps voulu, embaucher, former, encadrer et diriger une solide équipe d'analyse de données pour BusPatrouille.

Exigences :
Un diplôme d'études supérieures (de préférence un doctorat) en économie, en finance, en statistique ou dans un autre domaine quantitatif.

Plus de trois ans d'expérience pertinente.

Une expérience avérée de la manipulation d'un large éventail de sources et de systèmes de données pour fournir des analyses et des visualisations qui ont des répercussions sur l'activité.

Une solide compréhension théorique et une expertise concrète des bases de données, des structures de données, des mégadonnées, de l'apprentissage automatique et des méthodes (le partitionnement en k-moyennes [K-Means], la forêt d'arbres décisionnels, les algorithmes d'amplification de gradient [Gradient Boosting], etc.).

Une expertise dans les approches analytiques de pointe (par exemple, l'analyse des bases de données, l'analyse numérique, la visualisation des données) et les plateformes (par exemple, Redshift, MySQL, PostgreSQL, Amazon, Tableau).

Une grande maîtrise de SQL, R ou Python.

Des compétences analytiques exceptionnelles et un sens aigu des affaires.

D'excellentes compétences en communication, avec la capacité d'influencer les décideurs et d'obtenir un consensus au sein des équipes.

Une curiosité intellectuelle, une grande autonomie et un esprit d'équipe.

Rémunération et avantages :
Un salaire concurrentiel.

Des avantages sociaux complets, notamment une assurance soins médicaux, soins dentaires et soins de la vue.

Un poste de direction au sein d'une entreprise qui se développe rapidement et qui est investie d'une mission.

L'occasion de travailler avec une équipe très performante.

L'occasion de contribuer à la création d'une entreprise vouée à la sécurité des enfants.

Nous sommes à la recherche de membres essentiels de l'équipe de BusPatrouille qui nous aideront dans notre quête pour accroître la sécurité des enfants. Ce poste joue un rôle important dans notre entreprise et constitue une formidable opportunité pour les personnes qui seront retenues. Nous offrons un milieu de travail inclusif, diversifié, enthousiaste, intègre et profondément engagé. Venez nous aider à assurer la sécurité des enfants.

Who we are:
At BusPatrol, our mission is to create a culture of responsibility and awareness on the road. We are devoted to making the journey to and from school safer. We develop partnerships, deploy Safety Tech, and manage the entire program. We have equipped thousands of buses across North America with our innovative technology

BusPatrol America cares about student safety. We educate motorists every day by helping to enforce the law and work with school officials to improve safety.

Responsibilities:
The Data Scientist is a high-impact role that will work closely with our Customer, Sales, and Operations teams to help drive data-driven decisions that accelerate BusPatrol's efficient growth. If storytelling and impacting operational decisions through numbers is exciting to you, we want to hear from you!

This is a high visibility role that will drive predictive analytic insights and best practices as BusPatrol expands its global footprint. The ideal candidate is a self-starter, highly analytical, curious, and comfortable diving deep into large data sets to unearth insights. Our environment is fast-paced, and requires someone who is enthusiastic, flexible, detail-oriented, analytical, and comfortable working with multiple teams and competing priorities.

Apply excellent analytical and problem-solving skills to drive business decisions in a dynamic environment to deliver customer benefit and performance analytics

Work both independently and collaboratively with other scientists, engineers, designers, BI developers, and product managers on complex projects that deliver value to BusPatrol

Excellent communication skills and ability to structure a compelling storyline to present a narrative using actionable data-driven insights

Ability to conceptualize business issues or opportunities, formulate hypotheses and goals, define KPIs and make appropriate recommendations

Build world class prescriptive and predictive models to solve business problems in a fast-moving environment

Leverage internal and external data to synthesize nuggets of insights that explain underlying trends in the automated enforcement ecosystem

Identify and deliver automation opportunities to drive scalability, improve efficiency and productivity of the broader team

Strong written and verbal communication skills with ability to effectively synthesize insights (including model theory, selection tradeoffs, and limitations) to executives and/or customers

Knowledge and skill requirements:
Strong theoretical understanding and applied expertise with databases, data structures, big data, machine learning, and methods (K-Means, Random Forest, Gradient Boosting, etc.)

Expertise with industry-leading analytics approaches (e.g., database analytics, digital analytics, data visualization) and platforms (e.g., Redshift, MySQL, PostgreSQL, Amazon, Tableau)

Expert proficiency in SQL, R, and/or Python

Exceptional analytical skills and strong business acumen

Outstanding communication skills with the ability to influence decision makers, build consensus with teams, and explain complex analytical concepts to people from other fields

Intellectually curious, self-starter, team player

Education/Experience:
S. (PhD preferred) in a quantitative field, such as economics, applied statistics, computer science, or mathematics

3+ years' experience applying data science methods (including statistical modelling and machine learning techniques) to business problems in the commercial world

Compensation and benefits:
Competitive salary

Comprehensive benefits including medical, dental and vision insurance

An opportunity to work with a high performing team and travel

An opportunity to help build a company dedicated to children's safety

We're looking for a valued partner to add to our team. This is an important role for us, and a great opportunity for the right candidate. Our environment is inclusive, diverse, ignited, built on integrity, and deeply committed. Come and help us keep our children safe.","BusPatrol
3.8",Montreal
175,Data Scientist/Engineer,"Pitstop is looking for a Data Scientist / Developer with exceptional ability to interpret and understand data and a passion for algorithms that provide impactful and reliable results. The Data Scientist / Developer will develop, deploy and validate predictive algorithms which analyze a continuous stream of telematics data (IOT) gathered by automotive sensor nets, as well as other related data. We seek creative candidates with a background in engineering, physics, mathematics and experience with contemporary machine learning techniques. The ideal candidate is someone who is focused on creating business value through good design and building the next generation of our predictive vehicle insights. He or she will have strong coding and software architecture skills and a self-driven attitude to fail fast and succeed faster.

Responsibilities

Collaborate with cross-functional teams (Sales, Marketing, Engineering) to define, design, and ship new features
In collaboration with others, design, build and validate predictive algorithms for vehicle prognostics
Perform exploratory analyses and develop procedures for feature extraction in preparation for algorithm analyses
Participate in software integration work to implement algorithms in production. Work on bug fixing and improving architecture performance
Write documentation and present the results of work to others on the team
Requirements

Undergraduate or Master's degree in Engineering, Physics, Computer science or equivalent
Good knowledge of statistics, experimental design, and probability
3+ years of experience in Python, R or similar scripting language
1+ years experience shipping high-quality software to enterprise customers
Experience with SQL (PostgreSQL or similar)
Understanding and experience with machine learning techniques such as Regression, Naive Bayes, Random Forests, Perceptrons, SVM, Deep Learning
DevOps experience (Amazon, Google, Docker, Jenkins)
Nice to have's

Previous startup experience (preferably in an early-stage startup)
Knowledge of automotive data, automotive physics or experience in the industry
Experience with version control systems (Git, CVS or SVN)
Knowledge of other programming languages including node js, C++
Experience with big data frameworks such as Spark, Hadoop.

Pitstop is an Equal Opportunity Employer:
We are actively seeking to create a diverse work environment because we believe differences make us stronger, and that our diversity is something to celebrate.","Pitstop
4.1",Midtown Toronto
176,"Data Scientist, Fall 2021 Student Opportunities","We're now accepting applications for our 2nd round recruitment of Data Science roles.


What is the opportunity?
Who wouldn't want to be a part of a fantastic team of Data Scientists? At RBC, our Data Science teams offer the opportunity to leverage RBC’s data assets to develop innovative solutions in support of RBCs big data strategy. This position is an essential part to the bank as you develop next-generation applications to meet our customers’ needs. By joining the RBC team as a Data Scientist, you will have the opportunity to analyze, design and implement data solutions to assist all business customers.

What will you do?

Utilize the latest technologies available, designing and building data solutions to meet business needs
Be an active contributor to not only your individual team, but to the RBC development community
Constantly seek out better ways to do things, new tools, new technologies, new processes
Work on transformational projects delivering new value
Work as part of an agile team responsible for end-to-end delivery of business needs
Deploy production-scale solutions using the Hadoop Ecosystem, transforming statistical and machine learning models from single node architecture to parallel processing grid technology
Use business domain knowledge to independently lead the analytics process to identify valuable and innovative insights
Promote analytics across the enterprise to enable RBC to become a data-driven organization


What do you need to succeed?

Must-have:

Programming skills in one or more of the following languages: Python or R
Experience utilizing SQL scripts/querying
Proficient in building statistical and algorithmic models with complex and large datasets, including but not limited to: supervised statistical learning, clustering, natural language processing, recommendation systems, times-series analysis, experimental design (A/B testing), data visualization, deep learning
Ability to data extract, transform, and load processes with a variety of data types
Ability to perform complex data analysis on large volumes of data and present findings to stakeholders


Nice to have:

Experience with big data technologies, primarily in machine learning and statistics function
Exposure to Apache Spark, Hadoop and Public Cloud technologies, data serialization (JSON, Avro, Parquet, ORC)
Experience with big data processing tools like Spark and Hive, GitHub functionality and workflow experience/exposure
Experience with messaging (Kafka, Solace, RabbitMQ) & working on Agile projects


What’s in it for you?
We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients succeed. We care about each other, reaching our potential, making a difference to our communities and achieving success that is mutual. Visit people.rbc.com


Continued career advancement opportunities
Exposure to strong mentorship and leadership examples
A world-class training program in financial services
Opportunities to be a valuable member of a close-knit, collaborative team that encourages networking
A comprehensive Total Rewards Program including bonuses and flexible benefits
Competitive compensation


We encourage you to apply as soon as possible as we accept applications on a rolling basis, but please note that the formal application deadline is May 31, 2021. Should you be selected to progress, someone from our team will reach out directly to provide instructions on next steps. Otherwise, feel free to check for progress updates by logging in to your RBC profile. If the status has not changed, it denotes the fact that your application is still under review.
While there is no one date when our employees will return, we can confirm that the majority of Fall Work Integrated Learning | Co-op positions will start working remotely, however may transition to working at an RBC office as essential service restrictions are lifted.

TAD2021


Learn more about RBC Tech Jobs","RBC
4.1",Midtown Toronto
177,Data & Applied Scientist 2,"Are you passionate about building best image and video experience on the web and help billions of internet users find the most relevant and enjoyable image/video content on the web through recommendation and search? Do you want to work with a group of talented data and applied scientists and distributed system engineers to grow your experience/career in wide range of area including engineering skills, recommendation, computer vision, natural language processing, machine learning, deep learning, big data mining, and information retrieval etc? Our product depends on talents from diversified technical background. If so, this data scientist position on Bing Multimedia Team may be a great fit for you!

Bing multimedia team is looking for a talented machine learning scientist to help us build products and next generation of recommendation and ranking algorithms to make impact to power millions and millions of users. And it is a fun and fast paced team.
Responsibilities
As data & applied scientist, you will have wide range of responsibilities and opportunities to learn and make impact, which includes but not limited to

Analyze the problem through all data available to you including large scale crawled data and user engagement data etc.
Define problem and metrics to address various problems include relevance, authority, attractiveness, diversity, and freshness etc
Design and train ML system and model architecture
Collect data for training
Define ML engineer life cycle and drive project forwards through iterative release
Collaborate with other data & applied scientist as well as distributed system engineer and program manager
Potentially mentor other engineers and proactively seeks mentorship from others
Qualifications
Required Qualifications:


Master or above degree in Computer Science, Engineering, Applied Mathematics, or related fields
3+ years Recommendation, machine learning / computer vision / natural language processing experience and results in academy or industry.
3+ years of experience with general purpose programming language (C/C++/C#/Java/Python etc.)
Good communication skills and ability to work in collaborative environment.
Good design and problem-solving skills and an ability to innovate and solve challenging technical problems
Passion and self-motivated
Embrace engineering excellence and delivering quality results at scale.

Preferred Qualifications:

Ph.D. in Computer Science, Applied Mathematics, related fields
Publications in major ML/IR/NLP/CV conferences. Examples: ICML, NIPS, SIGIR, ACL, EMNLP, CVPR, KDD
Prior Tech lead or dev lead

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
178,Data Scientist – Revenue management,"Intelcom est un important fournisseur de plateforme de livraison au Canada. Pour soutenir sa transformation technologique et permettre la prise de décision basée sur les données, Intelcom est actuellement à la recherche d'un Expert en sciences des données - Gestion des revenus.

Dans le cadre de l'implantation d'une nouvelle plateforme de gestion des revenus, l’Expert en sciences des données est chargé de construire des modèles de données, des simulations et de soutenir l'utilisation de ceux-ci par les utilisateurs. Les résultats obtenus serviront à alimenter la stratégie de tarification et à faire évoluer l'expérience utilisateurs au fil du temps.

Vos responsabilités :

Analyser et visualiser les opérations commerciales et les données du marché.
Comprendre le problème de l'entreprise, identifier les principaux défis, formuler le problème d'apprentissage automatique et fournir des solutions.
Construire des modèles de données et des simulations et incorporer ces modèles dans la plateforme de gestion des revenus
Collaborer largement avec les parties prenantes, la direction du programme et les membres de l'équipe de développement de logiciels afin de s'assurer que les solutions répondent aux besoins de l'entreprise.
Compétences professionnelles :

Trois ans d’expérience dans un poste similaire en gestion des revenus (la prévision de la demande, la gestion du rendement, la tarification, les enchères, etc) idéalement dans le domaine de la logistique, du transport ou de la distribution
Deux ans ou plus d'expérience en tant qu'Analyste de données dans un contexte commercial ou scientifique
Diplôme en informatique, mathématiques ou physique
Compétences avancées en programmation Python
Conception orientée objet
Expérience du travail avec de grands ensembles de données de manière performante : optimisation du code, opérations vectorielles, exécution parallèle.
Tests unitaires
Analyse de données à l'aide de pandas et numpy
Visualisation de données à l'aide de matplotlib et seaborn : histogrammes, diagrammes de dispersion, cartes thermiques.
Analyse et visualisation de données de géolocalisation.
Bilinguisme
Situé à Griffintown (Montréal), accessible par les transports en commun (station de métro Lucien-L'Allier), notre culture encourage la créativité et l'innovation, ainsi que le partage des connaissances et l'entraide. Vous rejoindrez le train au bon moment pour nos prochaines grandes étapes. Votre travail aura un impact réel et significatif sur le succès de l'entreprise.","Intelcom Express
3.2",Montreal
179,Data Scientist/Time Series,"Reporting directly to the Director of Data Science, this role is pivotal in implementing advanced time series solutions to deliver high quality results to clients.

You will be interacting with multi-function teams, including data integration, model development and other consulting functions to implement best practice and thought leadership.

This role also works very closely with client project sponsors to ensure client satisfaction and business requirement fulfillment.

Duties and Responsibilities

Implement currently available time series forecasting models
Develop customized forecasting algorithms required by specifications of each project
Prototype, simulate and benchmark accuracy of algorithms
Develops production-ready codes in R
Works with main stakeholders including but not limited to: Account Executives, Management, Project Managers and Consulting Teams
Performs various other duties as delegated or assigned.

Required Knowledge, Skills, and Experience

The successful incumbent will have:

Graduate degree in a Statistics, Math Computer Science or Engineering program;
Proficient in time series analysis and forecasting
Fundamental knowledge of supervised and unsupervised Machine Learning
Experience with data preprocessing, anomaly/outlier detection
Advanced programming skills in R language is mandatory;
Knowledge of pharmaceutical industry is an asset;
Capability to adapt in fast changing environment and eager to learn
The ability to travel and work outside regular business hours as required;
Proven, motivated self-starter with the ability to lead by example and approach and solve business problems;
Experience working in cross-functional teams with the agility to learn new software applications and technologies;
Demonstrated time management, problem solving and decision making competencies;
Ability to work autonomously and in teams to effectively prioritize multiple projects and associated deliverables;
Proven excellent communication, including presentation, hands on analytical with business savviness and customer relationship abilities;
Proven ability to comprehend, analyze and research problems of a complex nature, make decisions and/or present recommendations;

Preference for fast paced, rapid start-up culture demonstrating the values of results, teamwork, energy, agility, respect, and can-do environment","Scarsin
3.7",Markham
180,Senior Data Scientist,"Funded by NEC X’s Corporate Accelerator Program in Silicon Valley, we are spinning out an eCommerce Insights start-up in Toronto. Using award winning NEC research technology in Princeton, we are building our team in Toronto to take our journey to the next level.

We are looking for an experienced Data Science/AI Researcher with a passion for text and aspect-based opinion mining. You have several years of experience working with various aspects of text mining, data mining and opinion mining. You'll be joining as our Data Scientist and as such, you will be playing a key role in building our product and executing on our development roadmap.

Join us in changing the world of eCommerce and Insights through AI.

What's In It For You:

- Great work life balance
- Join as an early team member, work directly with founders
- Work on large scale data problems using ML/AI and text analysis

What You’ll Work On:

The Data Scientist will work with a team of technologists to add features, improve performance, test and get the solution ready for a commercial launch.

Who You Are:

M.S./PhD in computer science or related field. Broad knowledge in machine learning (ML) and deep learning algorithms.
Hands-on experience developing text analytics, sentiment analysis, opinion mining, NLP and aspect-based opining mining.
Proficient in Python.
Extensive experience using deep learning libraries such as PyTorch and data analytics tools such as pandas and SQL.
Detail oriented – please include the square root of 225 on your application somewhere.
Requirements include excellent spoken and written English communication skills.
Experience with mining of reviews, especially in the eCommerce domain is a big asset.
You have a passion for presenting data in creative and visual ways.

The role:

Use Python and the vast array of AI/ML libraries to analyze data and build statistical models to solve specific business problems.
Improve upon existing methodologies by identifying new data sources, testing model enhancements, and fine-tuning model parameters.
Experience leading large-scale data projects  and pushing production quality code, including deploying and assessing efficacy of a wide array of Machine Learning models in production environments.
Experienced in handling large data sets and databases using SQL in a business environment.
Most importantly: Continually advance our technology in the areas of text analytics, sentiment analysis, opinion mining, NLP and aspect-based opining mining.

What We Offer:

Competitive compensation
Flexible working hours

Job Type: Full-time

Salary: $118,809.00-$144,170.00 per year

Schedule:

Monday to Friday

Experience:

NLP, Sentiment & Text Analytics: 5 years (preferred)
Python: 5 years (preferred)
Aspect Based Opinion Mining: 1 year (preferred)
Machine Learning: 5 years (preferred)

Work remotely:

Yes",eCommerceInsights.AI,Midtown Toronto
181,Machine Learning Engineer/Data Scientist,"About the role:

We are looking for a Machine Learning Engineer who will be responsible for the development of algorithms that will be used as the basis for our mathematical models to automate trading platforms for sports betting markets. We are looking for a Data Scientist who will be responsible for developing unique approaches to complex modeling and inference problems which combines market and trading knowledge with math approach to recognize patterns and trends in betting markets.

Our ideal candidate should have:

Degree/Diploma in Computer Science/Software Engineering/Statistics or equivalent
3+ years of relevant experience with R or Python (NumPy, SciPy, Pandas, etc)
2+ years of relevant experience as Software Developer, preferably using Microsoft .NET Framework (C# or VB.NET)
Strong background in statistics
Experience with Machine Learning algorithms and Probabilistic Models
Experience using cloud computing platforms such as EC2 (AWS)
Experience with modern R packages and technologies such as dplyr, tidyR, data.table, shinyR
Domain experience in on-line gaming industry, financial markets or other 2-sided markets is a plus
Experience with Stan, Neural Networks or Deep Learning on large problems, Hadoop, MapReduce or High Performance Computing is a plus
Experience in SQL and SQL server is also a plus

We offer:

An environment passionate about growth and learning
Competitive salary with bonus
Fitness subsidy program
Workplace that is conveniently located along the Yonge/Sheppard line

What we are looking for:

This is a key role within the team and would suit someone who is passionate about working with data/data science. We are looking for someone with strong background in statistics, modelling and algorithms (machine learning or other) and who has the ability to convey complex information through data visualization. A thorough understanding and passion for sports and sports betting markets is ideal. Experience with cloud computing as well as python is a plus.

The above is intended to describe the general nature and level of work being performed. They are not intended to be an exhaustive list of all responsibilities, duties and skills required.

Crescendo Technology thanks all candidates applying but only those selected for an interview will be contacted. Selected candidates may be asked to complete an on-line technical assessment.

Crescendo Technology is an equal opportunity employer which values diversity in the workplace and we encourage candidates to apply directly and provide a copy of an updated resume. Should you require an accommodation for the recruitment/interview process, please do not hesitate to reach out to us.

To apply please send your resume with cover letter preferred to hr@crescendotechnology.com

Job Features
Job Category
Development","Crescendo Technology
1.0",Midtown Toronto
182,Senior Data Engineer,"Introduction
Have you heard about the IBM Garage? It's a cross-functional team that delivers a unique client co-creation experience to accelerate client transformation. We use Enterprise Design Thinking, our industry-leading IBM Garage Methodology and IBM's multidisciplinary experts in full speed from the start. We design, develop, test, and deliver solutions. Startup speed. Enterprise scale. We apply user-centric approaches to ensure all features add value for the user and achieve desired client impact.

Your Role and Responsibilities
We are looking for a big Data Engineer to join our entrepreneurial team as the Subject Matter Expert on building big data solutions with great scalability. Led by a solution architect, you will provide expertise and leadership to help design IBM Data Science and AI solutions that will help our clients drive technology benefits and business outcomes across industries. You will work with cutting edge technologies such as Watson, as well as Open Source approaches with a passionate team of people who are driving the innovation and digital transformation to cross-industry enterprise clients with the adoption of IBM Data Science and AI. An ideal candidate will also be familiar with Design Thinking, DevOps, big data engineering skills on architecture and solutions with best practices.
Key Responsibilities:
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical requirements and support their data infrastructure needs.
Provide the ability to work within agile development methodology and collaborate effectively with multi-disciplinary teams
Build modern enterprise solutions which support scaling, development, test and data quality evaluation big data solutions based on the requirements.
Understand data architecture, build large-scale data processing systems supporting data transformation, data structures, metadata, dependency and workload management. and optimizes data flow.
Have experience on big data process including collecting, parsing, manipulating, managing, analyzing and visualizing large sets of data to turn information into insights using multiple platforms.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Have expertise in data persistence solutions, experience with the latest (NoSQL) database technologies, and experience with building complex SQL queries using various (NoSQL or RDBMS) databases such as MongoDB or DB2
Experience in software engineering with object-oriented design, coding and testing patterns on large-scale data infrastructures
Use DevOps best practices such as continuous integration, continuous delivery in the production implementation.
IBMReferred_NorthAmerica


Required Technical and Professional Expertise

Develop code using Python, Scala, R languages
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools
5+ years design & implementation experience with distributed applications
5+ years of working experience in database architectures and data pipeline development
Demonstrated knowledge of software development tools and methodologies
Computer Science with software engineering and Math background desired
Demonstrated ability to adapt to new technologies and learn quickly

Preferred Technical and Professional Expertise

Experience with big data tools: Hadoop, Spark, Kafka, etc.
Familiar with big data solutions with experience on Hadoop based technologies such as MapReduce, Hive MongoDB or Cassandra.
5+ years design & implementation experience with distributed applications
5+ years of working experience in database architectures and data pipeline development
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Knowledge of cloud technologies such as Kubernetes, Cloud Foundry, PaaS, and IaaS (SoftLayer)

About Business Unit
IBM has a global presence, operating in more than 175 countries with a broad-based geographic distribution of revenue. The company’s Global Markets organization is a strategic sales business unit that manages IBM’s global footprint, working closely with dedicated country-based operating units to serve clients locally. These country teams have client relationship managers who lead integrated teams of consultants, solution specialists and delivery professionals to enable clients’ growth and innovation. By complementing local expertise with global experience and digital capabilities, IBM builds deep and broad-based client relationships. This local management focus fosters speed in supporting clients, addressing new markets and making investments in emerging opportunities. Additionally, the Global Markets organization serves clients with expertise in their industry as well as through the products and services that IBM and partners supply. IBM is also expanding its reach to new and existing clients through digital marketplaces.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","IBM
3.9",Ottawa
183,DATA SCIENTIST,"The quantitative research team is looking for an entry/mid level Data Scientist in the field of time series analysis and pattern recognition to help with modelling work related to infrastructure optimization. You will be working with team of data scientists responsible for providing insights into client device management for cost savings and performance management. This is a fantastic opportunity to rapidly learn and advance in a growing company.

REQUIREMENTS
2+ years practical data science or engineering work experience out of school, in quantitative domains.
Strong quantitative background: B.Sc. or M.Sc. preferred.
Familiarity with technical tools for analysis: Python, R, SQL, Spark.
Experience with software design concepts. Previous software engineering background is a plus.
Ability to structure a project from idea to experimentation to prototype to implementation.
WHAT WE EXPECT?
Enthusiastically tackling problems with a love for teaching and celebrating the successes of others.
Ability to synthesize information and consider problems from new perspectives.
Desire to share information with others and contribute to our top notch learning environment.
Self-starter that is focused and driven with amazing follow-through.
Driven to delivery quality solutions.",Temetrix,Ottawa
184,Data Scientist,"About the role:
We are looking for a Data Scientist to join our team. In addition to collecting data and transforming data into usable format for models, the Data Scientist will be supporting back-end infrastructure and deploying models and pipelines into production stacks.

Our ideal candidate should have:

Expertise in R and other statistical programming languages (3+ years)
Experience in Frequentist and Bayesian Statistical methods (2+ years)
Experience working with Machine Learning algorithms, Probabilistic Models, and/or other statistical modelling approaches (2+ years)
Experience with modern R packages such as dplyr, ggplot2, data.table, etc
Experience in front-end R technologies for data products such as ShinyR, Flexdashboard
Ability to write complex SQL queries
Working knowledge of software engineering fundamentals and workflows
Experience working with container orchestration platforms such as Kubernetes or Docker Swarm
Cloud Computing Experience
Authority to legally work in Canada

We offer:

An environment passionate about growth and learning
Competitive salary with bonus
Fitness subsidy program
Free beverages in the office
Workplace that is conveniently located along the Yonge/Sheppard line

What we are looking for:
This is a key role within the team and would suit someone who has a strong passion for working with data and data science. An individual with software engineering background is ideal. Great communication and reporting skills required both orally and in written format. Individual must have initiative to work independently and effectively with team members. Interest in sports or betting markets a plus.

The above is intended to describe the general nature and level of work being performed. They are not intended to be an exhaustive list of all responsibilities, duties and skills required.

Crescendo Technology thanks all candidates applying but only those selected for interview will be contacted. Selected candidates will be asked to complete an online technical assessment.

Crescendo Technology is an equal opportunity employer which values diversity in the workplace and we encourage candidates to apply directly and provide updated resume. Should you require accommodation for the recruitment/interview, please do not hesitate to reach out to us.

Reference ID: Data Scientist

Application deadline: 2021-06-14

Job Types: Full-time, Permanent

Additional pay:

Bonus pay

Benefits:

Casual dress
Dental care
Disability insurance
Extended health care
Life insurance
Vision care
Wellness program

Schedule:

Monday to Friday

COVID-19 considerations:
Due to current pandemic, WFH options are available. Gloves, masks and hand sanitizers are made available at the office.

Experience:

R programming: 3 years (preferred)
Frequentist and/or Bayesian statistical: 2 years (preferred)
Machine Learning: 2 years (preferred)

Work remotely:

Temporarily due to COVID-19","Crescendo Technology Ltd.
3.7",Midtown Toronto
185,AI Scientist,"Paige is a software company helping pathologists and clinicians make faster, more informed diagnostic and treatment decisions by mining decades of data from the world's experts in cancer care. We are leading a digital transformation in pathology by leveraging advanced Artificial Intelligence (AI) technology to create value for the oncology clinical team.

We are the first company to develop clinical grade AI tools for the pathologist, which resulted in our receiving FDA breakthrough designation for our first product. Paige has also received FDA-clearance for our digital viewer, FullFocus™. We have also established multiple relationships with biopharma, laboratory, and equipment manufacturers that enables Paige to develop an ecosystem ready to help patients receive better diagnoses and treatment.

We're looking for AI Scientists to join us. In this role you'll be part of a team of world-leading experts in machine learning, computer vision and pathology.

In this role you'll conduct publishable deep learning research using some of the largest digital pathology datasets in the world. You'll be working to save lives by improving the accuracy of cancer detection, classification, and treatment outcome.

Recent graduates and PhD candidates who will defend soon are welcome to apply!

This position is fully remote for candidates based in Canada.

Key Responsibilities:
Work with our AI Scientists and Engineers to develop and assess deep neural network models

Author top-tier journal and conference papers on your research at Paige

Attend conferences to present your work.

Requirements:
Highly motivated

PhD degree in computer science or related field

Publication record in venues such as CVPR, ICCV, NeurIPS, TPAMI, ICLR IJCV, MICCAI, etc.

Expertise in deep learning, especially for computer vision

Strong Python coding skills

Computer vision expertise

Knowledge of deep learning toolboxes

You are authorized to work in Canada",Paige,Ontario
186,Data Scientist,"Minimum Qualifications

Master’s degree in mathematics, statistics, computer science or a related field, or equivalent experience

Preferred Qualifications

3 years of experience working with large data sets
3 years of experience with statistical and data mining tools and methods
3 years of experience with statistical packages, such as R or SAS
3 years of experience working with big data in a Hadoop environment
3 years of experience with linear models (linear regression, generalized linear regression, logistic regression) and nonlinear modeling techniques (decision trees, smoothing methods, ensemble methods)
3 years of experience providing predictive and prescriptive analytics in a business setting
3 years of experience working with SQL or other query languages
Ph.D. in mathematics, statistics, computer science or a related field required, or equivalent experience
Proficiency in the Microsoft Office suite
Knowledge of SQL
Fluency in at least one scripting language
Knowledge of statistical methodologies for modeling and business analytics
Knowledge using analysis tools (e.g., R, SAS, Weka)
Knowledge of data visualization tools

Job Summary

The Data Scientist is responsible for performing data mining, predictive modeling and forecasting to provide actionable insights and strategic direction for business leaders.

The Data Scientist delves into the recesses of large data sets of structured, semistructured and unstructured data to discover hidden knowledge about our business and to develop methods to leverage that knowledge within our line of business.

Responsibilities

Develop predictive and prescriptive statistical or behavioral models from large sets of structured and unstructured data
Identify methods that allow continuous and automated statistical testing to enhance the predictability of deployed models
Communicate results to clients, team members and business leaders
Collect data for ad hoc and statistical analysis
Own the of deployment of applicable models for business projects
Communicate complex analyses, conclusions and solutions clearly to all audiences
Work with project managers to develop detailed project timelines

Disclaimer

This is an outline of the primary responsibilities of this position. As with everything in life, things change. The tasks and responsibilities can be changed, added to, removed, amended, deleted and modified at any time by the leadership group.

The Company has policies to support applicants with disabilities, including, but not limited to, policies regarding the provision of accommodations that take into account an applicant‘s accessibility needs due to disability. For more information, please call us at (800) 411-JOBS or email us at Job@MyRocketCareer.com.","Rock FOC Technology
4.5",Windsor
187,Senior Data Scientist,"Wattpad is a global multiplatform entertainment company whose vision is to entertain and connect the world through stories. Since 2006, we’ve been on a mission to use the power of community and technology to unleash the full potential of stories to the world. Every month 90 million people around the world spend over 23 billion minutes on Wattpad to share and discover stories they can’t find anywhere else. Our brand banner includes: Wattpad, Wattpad Labs, Wattpad Studios, Wattpad Books and Wattpad Brand Partnerships. We’re proudly based in Toronto, but our reach is global. Come build the future of entertainment and storytelling, and write your next chapter with us!

Wattpad is seeking a Senior Data Scientist to join our StoryDNA team. You will help guide and drive aspects of our technical strategy that use machine learning to model our story content and metadata. This senior role will be working across Engineering, Data and Product leadership to help guide the evolution of the technical architecture, infrastructure and best practices used within our Data organization. This role assumes a deep familiarity with both applied research and bringing models to production. The ideal candidate will have a deep interest in social-mobile experiences, a passion for exploring innovative approaches to open-ended problems, and developing solutions to both internal and user-facing product-centric problems.
What you will be doing:
Working cross-functionally to identify problems and turn data into knowledge, which can be actioned into product features or business decisions
Designing experiments, inventing new algorithms, preparing datasets, and creating prototype implementations focusing on applications to various challenging business problems
Engaging with teams across the department to help evolve and guide their data science practices, technology strategy, architectures, and infrastructure
Working closely with product teams to understand their needs and intersecting business strategies to develop a cohesive data science roadmap
Creating strategies that improve our ability to run experiments as an organization
Presenting work within Wattpad as well as in scientific and engineering communities
Collaborating and mentoring other data scientists, establishing best practices, and encouraging knowledge sharing between team members
Work with the team to break down large complex data science projects into manageable phases/deliverables
Building and delivering machine learning models into production
What we’re looking for:
Quantitative background with a graduate degree in Computer Science, Mathematics, Statistics, or related field
5+ years of experience in a quantitative role with knowledge of statistical machine learning, deep learning, and natural language computing
Experience in algorithm development, and adapting existing algorithms to novel applications
Comfort working with complex, high-dimensional data
Ability to work within ambiguity and collaborate with the team to drive insights in a changing environment
Fluency with Python, and familiarity with one or more deep learning software frameworks such as TensorFlow,PyTorch, or JAX
Experience with large-scale data processing tools (Apache Spark, Apache Flink or Apache Beam)
Development experience involving data pipelines, distributed systems, and performance analysis is a plus
Our ideal candidate is highly motivated, self-driven, with a deep curiosity and passion for knowledge discovery
What we offer:
Competitive salary
Career development; we believe in mentorship and supporting you to achieve your goals
Health benefits, fully covered on us!
RRSP Contributions
Generous vacation and Parental Leave Top-up
$200/month Transit and Home Office Allowance, choice of hardware, flexible hours, hybrid office and remote work options
Corporate discount for gym membership for you and your family
Downtown Halifax, NS location, with easy access to transit
Summer Fridays with afternoons off!
And a whole lot more!
**Update: Wattpad is still actively hiring for this role! We are a robust and growing business; our search for new talent continues.**

Due to the current state with COVID-19, Wattpad will conduct all interviews in a distributed manner using applicable third party software where needed and using visual interface tools such as Google Hangouts and Zoom. Our intention is to respect everybody's need for safety and adherence to social distancing.

We also want to respect our team's personal needs and capacity for professional commitments during this time; consequently our pace for the interviewing process might be impacted.

About Wattpad

Who are we? Entrepreneurs and Do-ers. Our vision is to entertain and connect the world through stories, and our mission is to use the power of community and technology to unleash the full potential of stories to the world.
What does that mean? We are visionaries, community builders, passionate problem solvers, storytellers, coffee snobs (tea drinkers, too!), curious by nature, and culturally diverse.
What are we obsessed with? Our users. Solving complex problems and maximizing flow. Learning constantly. Building the next great storytelling product. Finding the greatest stories ever told. Dogs (and cats), coffee, and good snacks.
How do we work? Autonomously, collaboratively, respectfully. Balancing with work, family, and play...and all while having a great time.

Culture and Diversity

Wattpad is an equal opportunity employer. We do not discriminate. Period.

Wattpad welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process. We have taken a leadership position on creating a culture and an organization that truly values diversity. We are committed to fostering a global team that reflects the diversity of the Wattpad community. At Wattpad, we believe cultural fit doesn’t mean culturally identical, and diversity of thought helps us to challenge one another to think big and think differently. We consider employment applicants without regard to age, race, colour, national origin, citizenship, religion, creed, sex, sexual orientation, veteran status, marital status, disability status or any other protected status.

If you have any special needs or accessibility requirements, please let us know. We will do our utmost to accommodate, in accordance with applicable local legislation.","Wattpad
4.0",Halifax
188,"Data Scientist, Supply Chain/Customer Profitability",": 1152275



Who we are

As the Working and Learning Company, we at Staples Canada, are dynamic, inspiring partners to our customers and the communities in which we live. At Staples, we inspire people to work smarter, learn more and grow every day. We look for people who are curious, approachable and passionate, and who enjoy finding solutions.

If that’s you, let’s work, learn and grow together.

We are building an inclusive and diverse team

Staples Canada is creating an inclusive and diverse work environment. We welcome, value and thrive on perspectives and contributions from backgrounds that vary by race, gender, sexual orientation, gender identity or expression, lifestyle, age, educational background, national origin, religion or physical ability. If you have a disability or special need that requires accommodation, please let us know.

Some of what you will do

As the Data Scientist, Supply Chain/Customer Profitability you will be responsible for applying advanced analytical methodology to drive business-critical decisions at STAPLES Canada. You will perform statistical analysis, build models, and leverage machine learning to solve complex business problems. This role will implement and execute internal reporting focused on driving increased process efficiency and reducing cost in the customer’s post-purchase experience. You will work to optimize the balance between delivery cost and customer experience at STAPLES Canada. In this role, you will have the opportunity to help drive data technology decisions at one of Canada’s largest online retailers.

Specifically, you will:

Build, validate, and maintain comprehensive data sets
Deploy machine learning models to dynamically accommodate for order costs and improve the post-purchase customer experience
Solve complex supply chain and customer support challenges, and become the go-to resource for all post-purchase data at STAPLES Canada
Develop and implement feedback mechanisms for profitability models
Provide quantitative research and analysis to identify process improvement
Communicate business intelligence related to our fulfillment centers, transportation network, and customer service team
Develop dashboards and reporting in Looker and distribute on a regular cadence


Some of what you need
4-6 years experience with big data technologies and machine learning
Post-secondary education is required
Previous hands-on AI/ML experience required
Understanding of server-less computing concepts, ideally within Google Cloud Platform
Expert working knowledge of SQL, Python, and/or Node.js
Experience with data mining, cleansing, and ETL
Familiarity with the Segment customer data platform
Comfortable developing reporting in BI tools like Looker or Tableau
Curious
Approachable
Passionate
Problem solver
Some of what you will get
Associate discount
Health and Dental benefits
RRSP/DPSP
Performance bonuses
Learning & Development programs
And more...
Additional Information
Office environment
Option to work remotely
Travel required, 10% within Canada and USA
Job eCommerce
Location(s) CA-ON-Richmond Hill
Schedule Full-time
:
:
:
Employment Statement
Staples Canada is an equal opportunity employer committed to diversity and inclusion and we encourage applications from all qualified candidates, including those with disabilities.","Staples Canada
3.6",Richmond Hill
189,Ingénieur senior de données / Senior Data Engineer,"Ingénieur senior de données

﻿(an English message will follow)

Vous avez envie de participer aux plus grands projets de transformation numérique avec des passionnés d’innovation ? Vous souhaitez participer à la réalisation de grands changements d’importance et à des projets qui changent des vies ? Avec LGS, les possibilités sont infinies. Nous sommes une entreprise locale, d’envergure internationale, propulsée par la puissance du capital intellectuel d’IBM.

Votre développement professionnel et votre bien-être nous tiennent à cœur et les possibilités de carrière sont multiples. Mentorat, formations illimitées et esprit qu’équipe font partie de notre ADN.

Travailler au sein d’une entreprise québécoise d’envergure internationale procure de nombreux avantages : horaire de travail flexible, environnement de travail de qualité, rémunération compétitive, compte mieux-être, télémédecine, studio virtuel de cours en ligne et bien plus !

Le Centre d’innovation client Québec (CIC Québec) emploie un grand nombre de jeunes professionnels qui sont supervisés et encadrés par des employés plus expérimentés dans un environnement favorable à l'apprentissage en continu, en plus d’être un lieu où la diversité et les talents de l’international sont mis de l’avant.

Le CIC Québec a des bureaux à Montréal, Gatineau, Rimouski et Québec et fait partie du réseau mondial d’IBM.

Vous êtes intéressé ? Venez nous rencontrer, nous avons plusieurs emplois disponibles !

Joignez notre équipe en tant que Ingénieur senior de données

Ce que vous ferez

Capacité à travailler directement avec le client afin de comprendre ses besoins et d’y répondre;
Excellentes aptitudes en communication orale et écrite;
Participation à des équipes travaillant dans un processus Agile/Scrum ou Waterfall en s’assurant que les histoires/tâches sont bien définies et que toute l’information et les outils garantissant le succès sont à la disposition;
Collaboration avec le gestionnaire de projet et les intervenants du projet pour s’assurer que nous respectons nos engagements;
Capacité à travailler de façon autonome sur des tâches et à fournir un travail de qualité supérieure;
Capacité à travailler en équipe et faire preuve d’ouverture aux commentaires et à la rétroaction;
Capacité à apprendre rapidement et à s’adapter à un environnement dont le rythme est rapide;
Traitement des données, conception et modélisation des données et déploiement du modèle;

Dont vous aurez besoin

5+ années d’expérience sur Python
3+ années d’expérience avec Azure (Azure Data warehouse, Databricks, Data factory)
Connaissance approfondie de SQL, des pipelines de données ""Big data"", des architectures et des ensembles de données.
Expérience profond avec de grands ensembles de données, des outils de gestion des pipelines de données et des flux de travail.
Expérience de la construction de grands ensembles de données complexes et de mécanismes de livraison pour soutenir l'analyse avancée et l'analyse des insights.

Chez LGS, nous offrons des solutions d’affaires, des services professionnels et des ressources à valeur ajoutée. Notre expertise touche principalement : l’infonuagique, les services applicatifs, l’analyse cognitive & l’Intelligence Artificielle et les services d’appoint.

Ce qui nous distingue? La force de notre capital intellectuel mondial et l’affiliation de nos pratiques à l’expertise d’IBM. Notre ADN est local, mais notre portée est internationale.

*******************************

Senior Data Engineer

Do you want to be part of the biggest digital transformation projects with people who are passionate about innovation? Do you want to be a part of making big changes and working on projects that change lives? With LGS, the possibilities are endless. We are a local company with a global reach, propelled by the power of IBM's intellectual capital.

Your professional development and well-being are important to us and the career opportunities are endless. Mentoring, unlimited training and team spirit are part of our DNA.

Working for a Quebec-based international company offers many advantages: flexible work hours, a quality work environment, competitive compensation, a wellness account, telemedicine, a virtual studio for online courses and much more!

Client Innovation Center Quebec (CIC Québec) is home to a large number of young professionals who are supervised and mentored by more experienced employees in a continuous learning environment, as well as being in place where diversity and international talent is at the forefront.

CIC Québec offices are located in Montreal, Gatineau, Rimouski and Quebec City and is part of IBM’s global network.

Join our team as a Senior Data Engineer!

What you will do

Ability to work with the client directly to understand and meet their requirements;
Excellent verbal and written communication abilities: must effectively communicate with technical and non-technical teams;
Participate in teams working in an Agile/Scrum or Waterfall process and ensure the stories/tasks are well defined and have all the information and tools to be successful;
Work with the Project Manager and project stakeholders to ensure we meet our commitments;
Ability to work independently on tasks and deliver with a high-level of quality;
Ability to work in teams and be open to comments and feedback;
Ability to learn quickly and to adapt to a fast-paced environment;
Data processing, data design and modeling, deploying the model

What you need to have

5+ years Python experience
3 + years experience with Azure (Data warehouse, Databricks, Data factory)
Deep knowledge of SQL, “Big data” data pipelines, architectures and data sets
Experience working with large data sets, data pipeline and workflow management tools
Experience building large, complex big data sets and delivery mechanisms to support advanced analytics and insights analysis;

#CIC #IBMJOBS

Type d'emploi : Temps Plein, Permanent

Avantages :

Assurance Dentaire
Assurance Maladie Complémentaire
Programmes de Bien-être

Horaire :

Du Lundi au Vendredi

Mesures COVID-19:
COVID-19 Update: En raison de COVID-19, nous avons mis en place des modalités de travail alternatives pour assurer la sécurité de tous nos employés. Comme le travail à distance, la formation virtuelle, les entretiens vidéo et l'accès aux webinaires.",LGS IBM Client Innovation Center Québec,Montreal
190,"Data Scientist, Fraud Operations","Dapper Labs is at an inflection point in our journey and it might be the perfect time for you to join us. Less than 6 months ago we launched NBA Top Shot on the new Flow blockchain and it is already on track to be the fastest-growing marketplace in history. Over $200 million in sales in the past 30 days and counting – we need to scale our systems to handle the demand!

We're looking for engineering-minded data scientists – to build out our fraud operations team. You'll join a small team that's scaling rapidly and build sustainable foundations for the future.



Our data pipeline currently include Segment and Tableau. Most of our backend systems are in Go, frontends in React. We use vanilla postgres as well as Kafka event-driven architecture in NBA Top Shot.



We believe in an open digital future: one where people own the assets they pay for and have full transparency into the software they're using. We believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they're helping create. Crypto, or blockchain, is the technology that enables this future. Blockchains are public computers that anyone can access, everyone can trust, and no-one can block or take down. Currencies and collectibles are only scratching the surface of what's possible.



Titles or years of experience don't matter to us – impact, authenticity, and values alignment do. We are now a remote-first team and open to hiring anywhere in the world.



About the role:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity
Create predictive models to understand user-level fraud risk
Consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality
Research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities
Innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the Dapper product team and our finance department
Bonus points if you have the following:
You have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made
You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply
You have a bachelor's degree in a highly quantitate field (Computer Science, Machine Learning, Statistics, Mathematics), and a master's degree preferred
You have 5+ years working experience in data science and or machine learning. Strong knowledge of SQL and python programming and graph databases
You are naturally curious and passionate about fraud prevention: if something seems off, you want to investigate what's going on and solve the true problem
You are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions

More about Dapper Labs:

Dapper Labs is the world's first blockchain entertainment company. We are the creators of industry-leading experiences including CryptoKitties and NBA Top Shot, as well as Dapper Wallet, the simplest way to manage your assets and use the blockchain. We are also the original developers behind Flow, a new decentralized blockchain designed from the ground up for scalability and ease of use.

Our mission at Dapper Labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. We have raised over $350M from leading VCs including Fred Wilson (USV) and Chris Dixon as well as Venrock, Samsung, Google Ventures, Coatue, NBA players, and global artists, among others. Dapper Labs partners include the NBA and NBPA, the NFL-PA, Ubisoft, Warner Music, Turner, Dr. Seuss, Genies, and the UFC, as well as 100+ others.

Visit our website to learn even more about Dapper Labs, including information about benefits and perks.",CryptoKitties,Vancouver
191,Data Scientist - Commercial Analytics,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it’s up to you.

The Role

As a Data Scientist for the Commercial Analytics team, you will work with Veeva Engineers, Consultants, and fellow Data Scientists to support analysis and analytical data deliverables.

Your role will be to generate and own the mathematical and behavioral models that will help drive the generation of impactful insights and suggestions for our clients. Our ideal candidate is multi-talented, with the capabilities to develop statistical, machine learning, and optimization models but they are also able to be client-facing, to understand the business needs of our clients (both within and outside of Veeva), and present complex statistical and machine learning models to the stakeholders.

This is a great opportunity for someone who is excited about using their deep Data Science expertise to help shape the ML offerings of the Veeva business. This role is based in the Veeva Toronto Office - 20 Toronto St, Toronto, ON
What You’ll Do
Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner
Design, develop and assess highly innovative models for clustering, anomaly detection, and more
Build and run analysis of models and algorithms in order to assess performance and identify the best algorithms to present to customers
Ensure models and algorithms support our customers and help them drive towards more intelligent and effective engagement with their customers
Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning, and retrieval processes) on large data sets to identify trends
Work closely with the data warehouse product team to ensure the architecture is effectively developed to support algorithms that are reproducible for many clients while being able to tailor said models for individual clients
Build models to help our Business Consulting and Strategy teams work with customers on how to better understand healthcare behavior to improve patient outcomes
Provide subject matter expertise and advice on model design, data collection, and/or model evaluation to technical and non-technical audiences
Contribute to developing and executing the team’s research agenda, including writing white papers and presenting at conferences
Collaborate with data engineers to access data and explain data requirements
Collaborate with analytics consultants to communicate findings to senior leaders and business partners
Communicate analyses and results, along with implications, to technical and non-technical audiences
Demonstrate impeccable ethics and judgment when dealing with confidential data
Share research insights both inside and outside the organization to become a thought leader in this space
Requirements
Ph.D. in Economics, Machine Learning, Applied Statistics, Applied Mathematics, Physics, Engineering, Computer Science or other quantitative disciplines with at least 1+ year of relevant industry experience, or an equivalent M.S. with 4 years of relevant demonstrable research experience
Advanced in-depth specialization and experience in data analysis techniques such as: classification, pattern recognition, clustering, feature analysis, NLP, fuzzy matching, sentiment analysis, A/B testing, active/adaptive learning
Proficient in R or Python
Ability to manipulate large data sets and develop statistical models, and accurately determine cause and effect relationships
Excellent SQL/Spark skills
Intellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes, and recommend solutions, even in situations with non-standard problems
Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to other team members and clients
Must be comfortable with changing requirements and priorities
Must be results-oriented and able to move forward without complete information and with minimal supervision
Nice to Have
Experience with commercial aspects of the Life Sciences industry
Experience working with Software as a Service and/or enterprise products
Experience with AWS
Hands-on experience building models with deep learning frameworks (Tensorflow or similar)
Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.



Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
192,"Research Associate / Scientist, Biology","Français plus bas

RESEARCH ASSOCIATE / SCIENTIST, BIOLOGY

NuChem Sciences, a synthetic chemistry and biology contract research organization, is expanding and looking for candidates to fill positions as a Research Associate and Scientist for its biology department. NuChem provides a variety of services to support biotech and pharmaceutical industries to identify and optimize pre-clinical candidates in the area of small molecule drug discovery. Visit www.nuchemsciences.com

At NuChem Sciences, we are a dynamic team consisting of experienced scientists and fresh graduates where everyone contributes their ideas and talents towards a variety of diverse projects. We believe in a work environment that should be fun, safe, and productive with fully equipped, state-of-the art laboratories and flexible work hours. We are focused on attracting, retaining, developing, and advancing our people to their full potential by rewarding bold ways of thinking and integrating inclusive behaviors into every aspect of our work.

RESPONSIBILITIES:

The successful candidate will be part of a growing in vitro biology team developing biochemical assays for target-based screening and drug metabolism assays to support the drug discovery team. An extensive knowledge in assay development is required for this position. The main responsibilities are:

Develop assays and cutting-edge technologies for discovery against challenging targets;
Establish new biochemical assays using a variety of readouts and technologies;
Transfer assays to robotic systems when applicable and run screening assays;
Develop in vitro assays that includes recombinant proteins as well as whole cells or cell lysates
Design, plan, and execute experiments, either independently or in collaboration with your teammates;
Maintain excellent documentation and communicate clearly results to the team and client;
Solve problems at a high level;
Organize, support, and collaborate with other team members to meet project deliverables and timelines.

REQUIREMENTS:

MS/PhD in Biology/Biochemistry;
Experience in enzymatic activity assays;
Assay experience on different platforms including ELISA and spectrophotometry (absorbance, fluorescence, TRFRET) would be a strong asset;
Experience with automation and bioinformatics is an asset;
Ability to multitask, prioritize and function in a fast-paced, dynamic CRO environment;
Demonstrate experience in enzymology and/or cell biology and data analysis;
Excellent written, organizational and documentation skills;
Proactive with strong interpersonal skills; able to thrive in a team-based environment;
Ability to communicate progress effectively with colleagues and managers;
Impeccable attention to details;
Applicants must be eligible to work in Canada (Canadian citizen, permanent resident, or work permit).

COMPENSATION AND BENEFITS:

Salary:

Competitive and based on experience.

Additional pay:

Annual bonus incentive plan.

Advantages:

Full time permanent position;
Health and dental care insurance plan;
Short- and long-term disability insurance;
Life insurance;
RRSP employer’s matching program;
Casual dress code;
Flexible schedule;
On-site free parking;
Free lunch on Fridays;
Continuing education;
Career development.

Schedule:

Monday to Friday

Apply today to work with state-of-the-art research facility and become part of the NuChem Sciences Drug Discovery Team!

Français

ASSOCIÉ(E) DE RECHERCHE/ SCIENTIFIQUE, BIOLOGIE

NuChem Sciences, une entreprise de recherche contractuelle en synthèse organique et biologie, est en pleine expansion et recherche des candidats pour combler des postes d’Associés de recherche et Scientifiques en biologie. NuChem fournit une variété de services pour aider les industries biotechnologiques et pharmaceutiques à identifier et optimiser les candidats précliniques dans le domaine de la découverte de médicaments à petites molécules. Visitez www.nuchemsciences.com

Nous sommes une équipe dynamique composée de scientifiques expérimentés et de jeunes diplômés où chaque scientifique contribue activement par leurs idées et leurs talents à divers projets de découverte de médicament. Nous croyons à un environnement de travail agréable, sécuritaire et stimulant dans nos laboratoires à la fine pointe de la technologie. Nous nous efforçons d'attirer, de fidéliser, de développer et de faire progresser nos employés à leur plein potentiel en récompensant les façons de penser audacieuses et en intégrant des comportements inclusifs dans chaque aspect de notre travail.

RESPONSABILITÉS:

Le candidat retenu fera partie d’une équipe de biologie in vitro en pleine croissance qui développe des essais biochimiques pour le criblage basé pour des cibles à l’étude et des analyses de métabolisme des médicaments afin de soutenir l'équipe de découverte du médicament. Une connaissance approfondie du développement d'essais est requise pour ce poste. Les principales responsabilités sont : · Développer des essais et des technologies de pointe pour l’analyse de cibles comprenant un défi accru ;· Établir de nouveaux tests biologiques connus en utilisant une variété de technologies et de mode d’analyse;· Transférer les tests à un système robotique, le cas échéant et effectuer des analyses d’activité ;· Maintenir une excellente documentation et communiquer clairement les résultats à l’équipe et au client ;· Développer des tests in vitro qui incluent des protéines recombinantes ainsi que des cellules entières ou des lysats cellulaires. · Concevoir, planifier et exécuter des expériences, indépendamment ou en collaboration avec vos coéquipiers ;· Résoudre des problèmes de haut niveau· Organiser, soutenir et collaborer avec les autres membres de l’équipe pour respecter les livrables et les échéanciers du projet.

QUALIFICATIONS:

MS/PhD en biologie/Biochimie;
Expérience dans les tests d’activité enzymatique;
Expérience de différentes plateformes incluant ELISA et spectrophotométrie (absorbance, fluorescence, TRFRET) est un atout important;
Expérience avec l’automatisation et la bio-informatique est un atout ;
Capacité à effectuer plusieurs tâches, à prioriser et à fonctionner dans un environnement ORC dynamique ;
Expérience en enzymologie et/ou en biologie cellulaire et en analyse de données ;
Excellentes compétences rédactionnelles, organisationnelles et documentaire ;
Proactif avec de solides compétences interpersonnelles ;
Capacité à communiquer efficacement les progrès avec les collègues et les gestionnaires ;
Souci du détail impeccable ;
Les candidats doivent être admissibles à travailler au Canada (Citoyen canadien, résident permanent ou permis de travail).

*

RÉMUNÉRATION ET AVANTAGES SOCIAUX :

Salaire :

Compétitif et selon l'expérience.

Prime :

Plan de boni annuel.

Avantages :

Soins de santé et dentaire;
Assurance invalidité;
Assurance-vie;
REER avec contribution jumelée de l’employeur;
Code vestimentaire décontracté;
Horaire flexible;
Stationnement sur place gratuity;
Dîner gratuity les vendredis;
Formation continue;
Développement professionnel.

Horaire :

Lundi au vendredi

Postulez dès aujourd'hui pour travailler dans de nouveaux laboratoires de recherche et faites partie de l'équipe de découverte de médicaments NuChem Sciences!

Job Types: Full-time, Permanent

Schedule:

8 hour shift

Work remotely:

No","NuChem Sciences
5.0",Saint-Laurent
193,Data Scientist / Scientifique des données,"STATUT: Poste permanent à temps plein
BUREAU: Vieux-Montréal, QC
HORAIRE DE TRAVAIL: 35 heures semaine - horaire flexible et télétravail
RÉMUNÉRATION: Salaire compétitif dans l’industrie et excellents avantages sociaux

VEUILLEZ SVP ENVOYER VOTRE CV À CAROLE.VIGER@GROOMASSOCIES.COM

Nous vous remercions de l’intérêt que vous portez aux occasions d’emploi offertes par notre entreprise. Seuls les candidats sélectionnés seront contactés.

Pour plus d'informations sur nos services de recrutement, veuillez visiter notre site web www.groomassocies.com

Avec plus de 30 ans d’expérience, notre client est LA firme la plus précise au Canada.
Joindre l'entreprise, c’est intégrer une équipe de 600 personnes passionnées et investies dans leur travail. L'équipe forme la plus grande firme de sondages, de recherche marketing et analytique à propriété canadienne répartie dans 8 bureaux à travers le Canada et aux États-Unis.

Au-delà d’être la référence dans l’industrie et d’offrir des conseils stratégiques importants à leurs clients, notre client se distingue par leurs culture d’entreprise, leurs direction transparente, leurs dynamisme et leurs esprit porte ouverte. L'équipe est la base de leurs succès et comme on dit, qui se ressemble, s’assemble.

Votre rôle en tant que Data Scientist

Fournir des insights efficaces, pertinents et innovants aux clients grâce à la modélisation des données
Conseiller les clients internes & externes sur les données et modèles à utiliser pour répondre à leurs besoins d’affaires
Mettre à contribution vos compétences en exploitation et modélisation de données de masse (big data), i.e algorithmes de machine learning, analyses statistiques avancées,..
Partager vos connaissances et votre expertise auprès de vos collègues
Rejoindre l'équipe en tant que Data Scientist c’est avoir à cœur les valeurs de qualité, de service client, d’innovation, de collaboration et d’engagement. C’est être passionnée par les données, les différentes analyses statistiques et le storytelling. C’est vouloir partager ses connaissances, fournir des conseils et contribuer à la croissance de l’équipe. C’est surtout vous épanouir et évoluer dans un environnement stimulant et convivial.

Responsabilités

Exploitation (data mining) et modélisation des données diverses (données de sondage, CRM, données opérationnelles,…)
Exécuter des analyses statistiques avancées?: segmentation, maxdiff, analyses conjointes, analyses factorielles, TURF, etc. et appliquer les différentes techniques à l’industrie de la recherche marketing
Développer des modèles prédictifs, de classification, d’attribution marketing, …
Traiter des données structurées et non-structurées (médias sociaux, vidéos,..)
Proposer et élaborer des solutions en intelligence d’affaires efficaces et alignées sur les besoins des clients (internes & externes)
Développer des outils commercialisables tels que des simulateurs, des tableaux de bord et des modèles prédictifs
Conseiller les équipes de recherche sur les propositions de services, les produits livrables, les modèles et analyses potentielles à utiliser, les données à utiliser, l’interprétation des résultats, etc.
Exigences & Aptitudes

Diplôme d’études supérieures dans un domaine quantitatif tel qu’en sciences informatique, ingénierie, physique, statistiques, mathématiques appliquées ou l’équivalent
Solides connaissances des langages de programmation avec emphase sur le machine learning et les techniques d’analytique avancée ( R et Python)
Expérience pratique en SQL et codage de bases de données
Maîtrise du français et de l’anglais, essentiel
Au moins 2 ans d’expérience dans le domaine de l’intelligence d’affaires et de la modélisation des données
Connaissances des techniques statistiques et du data-mining
Expérience pratique avec des bases de données massives
Esprit de collaboration et capacité de communiquer efficacement des idées complexes aux clients ainsi qu’à ses collègues
Excellentes capacités en résolution de problème, habiletés en analyse de problème, en identification des causes et capacités de fournir des recommandations rapidement
Expérience en recherche marketing et en marketing
Grande rigueur, attention aux détails et précision dans le traitement des données
Travailler avec des échéanciers serrés et gestion de projets multiples
Toujours pas convaincu?
Notre client est plus qu’une firme qui se différencie par son intelligence marketing c’est aussi…


Travailler dans une ambiance amicale, respectueuse et plaisante… le bonheur au travail, une de leurs top priorités!
Des nouveaux projets à longueur d’année… impossible de trouver le temps long!
Créer des liens d’amitié serrés… à travers le Canada et les États-Unis!
Profiter de plein d’avantages… vous allez voir on s’occupe bien de vous!
Et plus encore… il faut bien vous garder des surprises!
Nous vous remercions de l’intérêt que vous portez aux occasions d’emploi offertes par notre entreprise. Seuls les candidats sélectionnés seront contactés.

Pour plus d'informations sur nos services de recrutement, veuillez visiter notre site web www.groomassocies.com","Groom & Associes
4.3",Montreal
194,Senior Data Scientist,"Who We Are
We care about the health, safety and wellness of the internet – you have the chance to make a real difference in the ability for the diversity of humanity to engage each other in a more compelling, supportive, and optimistic way. We’re looking for bold thinkers that look at the person to person interactions on the internet and know they have the empathy, insight and bias to action that will bring our vision of a better internet for the world to life.

Working with complex systems and deep-learning data architectures, you will have the ability to define and drive cutting edge features and products that amplify positive interactions, while interfacing with a diverse set of customers – and their end-users. Your work will celebrate what is good about the ease and ubiquity of internet socialization and community, while protecting participants in online communities from threats ranging from the relatively benign, to the most serious threats the internet exposes us to. And you’ll do it across 100 billions of interactions a month on many of the most famous communities on earth.

What We Are Looking For
Senior Data Scientists at Two Hat work cross functionally to develop creative solutions for customers using high-quality data sets through intrinsic curiosity, goal-oriented focus, and the ability to identify meaningful discoveries.

They supervise Interns, guide research activities, are key contributors to product development and product operations where machine learning is used to deliver amazing and beautiful products to our customers. They are responsible for collecting and analyzing the data used to train and test powerful machine learning models which scale to support over 100B human interactions every month. They also use that data to provide value to both customers and internal stakeholders.

As our Senior Data Scientist you:
Supervise and support our team of Research Interns.
Develop tools, algorithms, machine learning models and automated systems that help identify high risk user generated content on social networks.
Work closely with our Product and Engineering Team to turn models into products.
Perform data exploration, statistical analysis, and model the ways that social networks can use our tools.
Use insights to identify meaningful features and patterns.
Create prototypes and experiments to test the viability of insights and demonstrate results to the Product Team.
Partner with high profile clients to understand their data science needs
Present and visualize data to communicate findings to non-data science team members and Executive Team


Who You Are
You believe in our mission and are passionate about amplifying joy and removing negativity from online communities.

You have completed a PhD or Masters degree in computer science, statistics, or related field.

You have 5+ years of real world experience solving business problems with text, image or other media classification, using machine learning, data mining, and exploratory data analysis. Experience should include:
Working with related deep-learning technologies (Python, TensorFlow, PyTorch)
Working with cloud platforms (AWS/Sagemaker, Snowflake)
Experience with Tableau is an asset
Experience with Golang is an asset


The Details
Permanent position, 40 hours/week
Remote applicants are welcome


Two Hat welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.


Join us
We believe in an internet that is safe for everyone - it is a vision that this team stands behind and strives to create every day.

We believe that we are what we do. We are a growing startup with an evolving culture. Our teams are ambitious, focused on quality, innovative, and deeply conscientious people. Being part of this team means that you get to wake up everyday knowing that you are part of making the world a better, safer place for our children, families, and friends!

As an organization we are focused on delivering a beautiful, quality product to our customers; companies that trust us to keep their communities connected and safe.

Are you optimistic, focused, collaborative, ambitious, and service driven but worried you don't have it all? At Two Hat we know that not everyone gains experience following a traditional path. If you share our values and drive for growth, want to make a difference in the world, and meet most of the qualifications, we encourage you to apply.

Express your interest here and then follow us on Facebook, Twitter, and LinkedIn to learn more about how passionate we are about making the internet a better place.","Two Hat
4.4",Kelowna
195,Senior Clinical Data Manager,"Do you want to watch clinical development change, or do you want to be the one to shape it?

Because we’re hoping you’re here for the latter.

Who are we?

We Are PRA.

We are 20,000+ employees strong, operating in more than 90 countries. We are committed to saving lives and we are constantly striving to be the best at what we do. Our impact is real and we see it every single day. We help get life-saving drugs into the hands of those who need them most.


Clinical Data Manager

Summary:

The CDM will perform scientific (complex) clinical data review in close collaboration with the Study Responsible Physicians (SRP) and Study Responsible Scientists (SRS).


Responsibilities
Services rendered will adhere to applicable Johnson & Johnson SOPs, WIs, policies, local regulatory requirements, ICH-GCP, etc.
Provides scientific data review support for more than one low to moderate complexity trial or one high complexity trial.
The data management expert who, within the therapeutic area, is performing scientific (complex) clinical data review in close collaboration with the Study Responsible Physicians (SRP) and Study Responsible Scientists (SRS). Tapping into technical and clinical expertise, closely collaborating with the SRP, SRS, Data Management functions and the rest of the study team members when implementing the data management related activities for protocols, with focus on more complex indication and therapy related elements of the study. Reviews all necessary data flows, the Data Management Plans and performs continuous (complex) data review activities on the studies in the assigned program.
Involved in study related activities from the protocol design stage onwards, providing input into the study specific and/or indication specific data collection tools.
Reviews (complex) scientific study data, manages CDM and SRS/SRP related queries in eDC system and holds discussions with SRS/SRP. Involvement in other review activities (e.g., Coding, SAE reconciliation) is possible. Leads and/or attends meetings as appropriate.
Takes a leadership role with SRP/SRS and collaborates with the GDM to establish, align and confirm scientific clinical data review expectations for assigned trial(s).
With the trial customer, CRO and other functional partners in relation to CDM related activities:
Reviews content and integration requirements for eCRF and other data collection tools
Establishes conventions and quality expectations for clinical data.
Set timelines and follow‐up regularly to ensure delivery of all Clinical Data Managemen milestones
Creates the Integrated Review Plan ensuring appropriate quality, scientific content, organization, clarity, accuracy, format, and consistency. Reviews related clinical data management documents.
Ensures compliance with regulatory guidelines and documentation requirements.
Ensures real‐time inspection readiness of all assigned deliverables for the trial; participate in Regulatory Agency inspection and J&J internal audits as necessary.
Plans and tracks applicable CDM deliverables. Ensures CDM deliverables are on time.
Takes a leadership role in collaborating with the SRS/SRP to ensure that DM and Therapeutic Area trial needs and deliverables are met.
Identifies and communicates lessons learned, best practices and frequently asked questions at the trial level.
Identifies and participates in process, system, and tool improvement initiatives within clinical data management.
Acts as backup for GDM, as appropriate (for example, former GDMs for a short term).


Qualifications
BS/BA degree or higher preferably in Health Sciences, or BS/BA degree or higher with professional clinical experience/exposure.
Data Management experience preferably including clinical data review or significant experience with clinical data review. Knowledge in medical terminology would be preferable
Collaboration with Clinical teams.
Experience in clinical drug development within the pharmaceutical industry or related industry.
College graduate: Data management experience or clinical data review.

To qualify, applicants must be legally authorized to work in the United States, and should not require, now or in the future, sponsorship for employment visa status.
PRA is an EEO/AA employer and is committed to providing opportunities to minorities, women, veterans and individuals with disabilities.

Options
Apply for this job onlineApply
Share
Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.
Share on your newsfeed
Connect With Us!","PRA Health Sciences
4.0",Remote
196,"Data Scientist, R&D","Individually we are people, but together we are Aviva. Individually these are just words, but together they are our Values – Care, Commitment, Community, and Confidence.

This role will start off as work from home, gradually you will be required to work in the Toronto or Montreal office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of using data science and AI to drive impactful decisions. The insurance industry has entered a period of unprecedented change. The last few years has seen a huge increase in the number of connected consumer devices such as home assistants, smart home sensors and cars with self-driving technology. Aviva recognizes that data created by these devices allows new ways to understand clients deeply and offer them personalized digital services and experiences in real-time. This exciting role is at the heart of a high-performing Data Science team that is impacting all aspects of insurance, from distribution to underwriting and pricing to claims.

As a Data Scientist – R&D, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products. You will work collaboratively with stakeholders to formulate problems and conduct research to propose viable solutions. You will leverage new data sources and experiment with new approaches providing enhancements through iterations.

What you’ll do

Influence the R&D roadmap by identifying emerging business challenges and R&D initiatives that have a high potential for applicability.

Push the boundaries on new methods and ways of addressing fundamental challenges in the area of AI/ML within the context of Insurance industry

Assist in creating compelling prototypes by working closely with teams of actuaries, data scientists and engineers building end-to-end analytics solutions that drive impact.

Dive into huge, noisy, and complex real-world data to discover insights and new predictive models for various business challenges.

Leverage the state-of-the-art in the field, including sound publications in well-known journals and conferences, and stay ahead of the curve on the newest AI methods.

Fast prototyping, feasibility studies, specification and implementation of data product components.

What you'll bring

As a data-scientist, you will need the following skills and experience to succeed in the role:

University Degree in Computer Science, Math, Statistics, Physics, Actuarial Science or related field or equivalent. A Ph.D. degree is strongly preferred.

Extensive R&D experience in machine learning, statistics, and applying data science methods.

Proven research track record as scientific publication in well-known machine-learning journals and conferences will be considered an asset.

Advanced level understanding of machine learning fundamentals and model development principles.

Excellent presentation and communication skills, with a knack for articulating complex scientific and analytical concepts to people from various backgrounds.

3-5 years of programming experience preferably in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.

3-5 years of experience of building machine learning models for business applications.

2-3 years experience with ML/AI technologies, such as scikit-learn, Keras, TensorFlow, PyTorch.

Experience mining IoT sensor data will be considered an asset.

Experience with Big Data Technologies such as Spark, Databricks, Scala will be considered an asset.

What sets you apart

A growth mindset with versatile skills and able to work through problems from first-principles.

A portfolio of projects that demonstrate your ability to draw inferences from data.

Experience at all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment.

Experience working as part of an Agile Team.

The best problems in the industry are yet to be articulated. We need someone who is creative and self-motivated.

What you’ll get

Competitive rewards package including base compensation, eligibility for annual bonus, retirement savings, share plan, health benefits, personal wellness, and volunteer opportunities.

Exceptional Career Development opportunities.

We’ll support your professional development education.

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","Aviva
3.7",Markham
197,Data Scientist,"Emplacement Montréal Québec


De quoi s’agit-il? :


Il sera pratiquement impossible pour le cerveau humain de comprendre comment faire fonctionner et optimiser la prochaine génération de réseaux sans fil, c'est-à-dire le réseau 5G avec calcul en périphérie distribué, qui entraînera une transformation économique et sociale pour tous les aspects de la société. Les technologies d’apprentissage automatique (ML) et d’autres technologies d’intelligence artificielle (IA) seront essentielles si nous voulons saisir cette opportunité. Nous sommes en train de mettre en place un accélérateur d’intelligence artificielle mondial au Canada, aux États-Unis, en Suède et en Inde, regroupant 300 experts chargés d’accélérer l’exécution de notre stratégie.

Ericsson est maintenant à la recherche de scientifiques des données expérimentés pour élargir considérablement son équipe mondiale pour l’accélération de l’IA. Avez-vous une compréhension approfondie des technologies de ML et d’IA?


Dans ce rôle, vous aurez :

Besoin d’avoir de solides compétences en programmation et une bonne compréhension de la science des données et des outils d’apprentissage automatique. Vos connaissances et votre expérience des méthodologies de la science des données seront mises à profit pour résoudre des problèmes difficiles du monde réel au sein d'une équipe très dynamique et internationale. Vous travaillerez dans un environnement hautement collaboratif où vous communiquerez et planifierez les tâches et les idées. Vous travaillerez sur des initiatives à fort impact avec d'autres DS en intelligence artificielle afin de stimuler la croissance et la rentabilité économique d'Ericsson et de ses clients en développant les offres actuelles d'Ericsson. Vous contribuerez également à la création de nouvelles offres dans les domaines des réseaux 4G et 5G pilotés par l'intelligence artificielle, du nuage distribué, de l'IdO et d'autres activités émergentes.


Diriger l'analyse fonctionnelle et technique au sein des entreprises Ericsson et pour les clients stratégiques afin de comprendre les besoins et les opportunités des entreprises basées sur les systèmes d'information.
Permettre le développement rapide et itératif d'une solution minimale viable validée répondant à ces besoins. Cela implique de travailler avec des pétaoctets de réseaux 4G/5G, des données IoT et exogènes, et de proposer/sélectionner/tester des modèles prédictifs, des moteurs de recommandation, des systèmes de détection d'anomalies, des modèles statistiques, des systèmes d'apprentissage en profondeur, d'apprentissage par renforcement et autres systèmes d'apprentissage machine.
Mener des études et utiliser de manière créative des sources de données nouvelles et/ou existantes. Travailler avec les architectes de données pour exploiter les modèles de données existants et en créer de nouveaux selon les besoins.
Collaborer avec les équipes de développement de produits et les partenaires des entreprises Ericsson pour industrialiser les modèles et solutions d'apprentissage machine dans le cadre des offres Ericsson, notamment en fournissant le code source, les flux de travail et les documents.
Travailler avec les nouvelles technologies et les promouvoir au sein des communautés d'entrevue de motivation d'Ericsson.
Contribuer au renforcement des compétences en matière d'entrevues de motivation au sein des entreprises et des unités de service à la clientèle d'Ericsson.
Élaborer de nouveaux concepts, méthodologies et techniques, et appliquer ou développer les concepts, méthodologies et techniques existants pour les projets interfonctionnels.


Pour réussir, vous devez avoir :

Une maîtrise ou un doctorat en ingénierie électrique, en informatique, en intelligence artificielle, en apprentissage machine, en physique ou dans un domaine connexe
Expérience pratique : Plus de 2 ans d’expérience d'apprentissage automatique dans le domaine de la science des données.
Une expérience confirmée dans la rédaction de logiciels de production
Une grande expérience dans le développement de modèles et la gestion du cycle de vie dans un ou plusieurs secteurs d'activité/applications
De solides compétences en programmation dans divers langages (C++, Scala, Java, R) et une maîtrise de Python ou C++
Des compétences confirmées en apprentissage automatique, par exemple en analyse discriminante par régression linéaire/logistique, ensachage, forêt aléatoire, modèle bayésien, MVC, réseaux neuronaux, etc.
De solides compétences dans l'utilisation des cadres d'apprentissage automatique de pointe actuels tels que Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc.
La capacité confirmée à mettre en œuvre de nouveaux algorithmes et de nouvelles méthodologies issus d'initiatives et de documents de recherche de premier plan sur les logiciels libres et portant sur leurs fonctionnalités, leur évolutivité et leur viabilité globale d'industrialisation
Des connaissances en statistiques, telles que l'analyse descriptive et l'analyse supervisée et non supervisée


Vous pourriez également avoir :

Une certification IM de MOOC, un atout
Des applications et des connaissances spécialisées en télécommunications ou en IdO, un atout
La capacité à travailler de manière indépendante avec beaucoup d'énergie, d'enthousiasme et de persévérance
Une bonne aptitude à communiquer en anglais écrit et parlé
Une capacité à travailler dans un environnement de collaboration, notamment à travailler avec des unités commerciales complexes à parties prenantes multiples, des clients mondiaux, des partenaires technologiques et d'autres partenaires de l'écosystème dans une organisation matricielle mondiale multiculturelle, avec tact et persévérance


Qu’est-ce que vous y gagnez?

Chez Ericsson, notre culture repose sur plus d’un siècle de décisions courageuses. Chez nous, vous ne rêvez plus de l'avenir, vous le redéfinissez. Vous ne développerez pas pour le statu quo, mais vous construirez ce qui le remplace. Nous rejoindre est une façon de faire évoluer votre carrière dans la direction que vous souhaitez ; avec des centaines d'opportunités de carrière dans des lieux partout dans le monde, dans un endroit où la co-création et la collaboration sont ancrées dans les murs. Vous vous retrouverez dans un environnement de communication où l’empathie et l’humanité servent de pierres angulaires pour notre façon de travailler et où l’équilibre travail-vie personnelle est une priorité. Bienvenue dans une entreprise inclusive et mondiale où votre possibilité d’avoir un impact est infinie.


Que se passe-t-il une fois que vous avez présenté votre candidature?

Pour vous préparer aux prochaines étapes, veuillez consulter ici: https://www.ericsson.com/en/careers/job-opportunities/hiring-process


Location Montreal Quebec


Our Exciting Opportunity:

It will be practically impossible for human brains to understand how to run and optimize next generation of wireless networks, i.e., 5G network with distributed edge compute, that will drive economic and social transformation for all aspects of society. Machine Learning (ML) and other Artificial Intelligence (AI) technologies will be vital for us to handle this opportunity. We are setting up a Global AI Accelerator in Canada, the US, Sweden and India, with 300 experts, to fast-track our strategy execution.

Ericsson is now looking for Experienced Data Scientists to significantly expand its global team for AI acceleration. Do you have in depth understanding of ML and AI technologies?


In this role, you will:

Need to have strong programming skills and strong understanding of data science and Machine Learning tools. You will use your knowledge and/or experience in Data Science methodologies apply them to solve challenging real-world problems as part of a highly dynamic and global team. You will work in a highly collaborative environment where you communicate and plan tasks and ideas. You will be working on high impact initiatives with other DS in Machine Intelligence to drive growth and economic profitability for Ericsson and its customers by accelerating current Ericsson offerings. Your contribution will also help to create new offerings in the areas of MI driven 4G and 5G network, distributed cloud, IoT and other emerging businesses.


Conduct functional and technical analysis within Ericsson organization and strategic customers to understand MI-driven business needs and opportunities
Contribute to rapid and iterative development of validated minimum viable solution addressing these needs. This includes working with petabytes of 4G/5G-networks, IoT and exogenous data, and proposing/selecting/testing predictive models, recommendation engines, anomaly detection systems, statistical model, deep learning, reinforcement learning and other machine learning systems
Conduct studies and find creative usage of new and/or existing data sources. Work with Data Architects to leverage existing data models and build new ones, as needed.
Collaborate with product development teams and partners in Ericsson Businesses to industrialize machine learning models and solutions as part of Ericsson offerings including providing source code, workflows and documents
Work with new technologies and champion them in MI Communities within Ericsson.
Assist MI Competence build-up in Ericsson Businesses and Customer Serving Units
Help to develop new and apply/extend existing, concepts, methodologies, techniques for cross functional initiatives


To be successful; you have:

MS, or PhD in Electrical Engineer, Computer Science, Artificial Intelligence, Machine Learning, Physics, or related field
Applied experience: 2+ years of Machine Learning experience in data science.
Proven experience writing production-grade software
Extensive experience in model development and life-cycle-management in one or more industry/application domain
Strong Programming skills in various languages (C++, Scala, Java, R) with proficiency in Python and/or C++
Proven skills in Machine Learning, e.g., linear/logistics regression discriminant analysis, bagging, random forest, Bayesian model, SVM, neural networks, etc.
Strong skills in the use of current state of the art machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow and Spark, etc.
Demonstrated ability to implement new algorithms and methodologies from leading open source initiatives and research papers addressing their functionalities, scalability and overall industrialization viability
Strong knowledge in Statistics, e.g., descriptive analysis and supervised and unsupervised analysis


You may also have:

Certifying MI MOOCS, a plus
Applications/Domain-knowledge in Telecommunication and/or IoT, a plus.
Ability to work independently with high energy, enthusiasm and persistence
Good communication skills in written and spoken English
Ability to work in a collaborative environment, i.e., working with complex multiple stakeholder business units, global customers, technology and other ecosystem partners in a multi-culture, global matrix organization with sensitivity and persistence


What´s in it for you?

Here at Ericsson, our culture is built on over a century of courageous decisions. With us, you will no longer be dreaming of what the future holds – you will be redefining it. You won’t develop for the status quo but will build what replaces it. Joining us is a way to move your career in any direction you want; with hundreds of career opportunities in locations all over the world, in a place where co-creation and collaboration are embedded into the walls. You will find yourself in a speak-up environment where empathy and humanness serve as cornerstones for how we work, and where work-life balance is a priority. Welcome to an inclusive, global company where your opportunity to make an impact is endless.


DISCLAIMER: The above statements are intended to describe the general nature and level of work being performed by employees in this position. They are not an exhaustive list of all responsibilities, duties and skills required for this position, and may be required to perform additional job tasks required by the manager.

We provide equal employment opportunities without regard to race, color, gender, sexual orientation, transgender status, gender identity, gender expression, marital status, pregnancy, parental status, religion, political opinion, nationality, ethnic background, social origin, social status, indigenous status, disability, age, union membership or employee representation and any other characteristic protected by local law or Ericsson’s Code of Business Ethics.

If you need assistance or to request an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (877) 338-9966 for further assistance.


Primary country and city: Canada (CA) || || Saint-Laurent || [[mfield2]]

Req ID: 543303","Ericsson
4.1",Saint-Laurent
198,Senior Data Scientist,"Job Description


Our Precima team helps retailers turn shopper insights into strategic advantage. We leverage our deep expertise in data science and technology to mine shopper data, uncovering what drives consumer decision making. By using advanced modeling, artificial intelligence and cloud-based SaaS solutions, we are able to put these insights at the fingertips of our clients.

As a Data Scientist, you will be responsible for developing and analyzing results and presenting insights and recommendations to our clients using ML/Statistics methods. In this client facing role you will be responsible for generating and leveraging advanced analytics to deliver and build customer insights and customer-centric strategies for our clients. This role is an integral part of the Data Science solution team. You bring relevant retail or CPG industry experience and expert capabilities in developing and interpreting segmentation, optimization and statistical modeling for both marketing and merchandising.

What you'll do

Implement, score, and maintain advanced statistical and mathematical models and customer segmentations.
Produce accurate statistical analysis and ensure high quality of the data analysis produced
Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations based off customer-centric data
Take analytical objectives and define data requirements. Extract, clean, and transform customer and item-level data for purposes of analysis, modeling/segmentation and reporting
Hands-on data extraction and reporting off customer database

We're looking for people who have

Master’s Degree Math/Statistics, Computer Science, Economics, Industrial Engineering
Minimum of 2+ years of directly related work or intern experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives through a structured analysis - leading to insights and recommendations.
Highly proficient in SQL and Python
Experience in retail and/or CPG is strongly preferred.
Strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis
Ability to translate business objectives into analytical plan/framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams - and then to clients.
Ability to translate statistical and analytical results into clear written and verbal communication to internal/external stakeholders
Excellent ability to be part of multiple projects/initiatives of varying size and complexity, while simultaneously meeting and exceeding deadlines in a diverse environment
Strong team player and ability to work in a collaborative environment
Strong interpersonal skills including written and oral communication


Additional Information


Nielsen Precima is a wholly owned business unit of Nielsen. Nielsen invented the very concept of market share. Today, our data and insights continue to provide the essential foundation that make markets possible in the rapidly evolving world of commerce. Modern consumers have access to more choices via more channels than ever before. #LI-AK3

About NielsenIQ

NielsenIQ is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. We provide consumer packaged goods manufacturers/fast-moving consumer goods and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. Our approach marries proprietary NielsenIQ data with other data sources to help clients around the world understand what’s happening now, what’s happening next, and how to best act on this knowledge. We like to be in the middle of the action. That’s why you can find us at work in over 90 countries, covering more than 90% of the world’s population. For more information, visit www.niq.com.

NielsenIQ is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.",NielsenIQ,Midtown Toronto
199,Data Scientist (AI/ML),"Duration:6 Months (Strong possibility of extension or contract to hire)
Location:Can be Remote (Canada Only)


We are seeking a Data Scientist with AI, ML experience.

The Data Scientist will be responsible for partnering with key business stakeholders and leveraging client and industry data to develop predictive algorithms and models. The primary focus of the data scientist will be to identify trends in data to extract meaningful business insights and drive cross-functional business solutions via statistical data analysis, and advanced analytics techniques in Artificial Intelligence (AI) and Machine Learning (ML). The individual will also work closely with the product team and support the various stages of the analytics development lifecycle.

Roles and Responsibilities

Using complex analysis techniques to uncover hidden insights in complex, multi-variate data.
Turning questions that start with “why” into data-driven answers.
Using data and trends to drive sophisticated forecasting, modeling and contact strategies.
Prepare and present insights directly with key stakeholders.
Writing and Evaluating Machine Learning Algorithms.
Leverage strong communication skills and business acumen to work closely with cross-functional business owners to drive data and analytics technologies for business use.
Design, develop and implement predictive/analytical algorithms and statistical data modeling tools to derive insights for complex business operations and processes.
Be a subject matter expert in supervised and unsupervised ML algorithms and other applied AI techniques to derive meaningful and actionable insights from big data.
Implement scalable, efficient processes for large scale data analyses, model development and deployment.
Be responsible for effectively communicating insights, findings, test results, performance analysis to both functional teams, and the senior management along with recommendations for enhancements/improvements.
Continually drive to learn and master new technologies and techniques. Constantly upskill and remain fully updated with the evolving data and analytics community.

Qualification and Experience

Master’s degree in Computer Science, IT, or Math (or Undergraduate Degree in Computer Science, Math).
Have a good understanding of data analysis, advanced analytics with exposure to AI/ML and technologies.
Experience with machine learning/artificial intelligence, and numerical programming frameworks (e.g., TensorFlow, MATLAB).
5+ years of experience in data science, data mining, analysis, and visualization with the ability to identify and present actionable insights from data to address business problems.
Demonstrated experience in using statistical and data manipulation languages (e.g. Python, R, SQL).
Strong communication, presentation and documentation skills is also required.



We thank you for visiting the job page. Only candidates closely matching the requirement will be contacted for interview. Wishing you all the best in your job search.

Email your resume to info@oggninc.com",OGGN Inc.,Remote
200,Data Engineer/Scientist,"Data Engineer/ Scientist

nugget.ai is recruiting and screening candidates on behalf of our partner TEEMA. nugget.ai will be responsible for application and screening processes and if you’re selected, TEEMA will be responsible for the interview stages of the hiring process.

TEEMA’s client is looking for an experienced Data Engineer/Scientist who understands the data and aspires to learn and innovate. This role offers an opportunity to work with a twenty-person product development team, managing your own team and collaborating with them, organizing the data and create models and algorithms based on the data along with interactions with clients and providing solutions to product development teams.



Qualifications:

Master’s Degree on a relevant field
Hands-on experience as a Data Scientist on a production environment
Experience with Scala and Machine Learning
Good knowledge about Java, Python, R, JVM and Hadoop
Strong ability to communicate on both business and technical subjects
Authorized to work in Canada.

Core Competencies:

Action-Oriented - Maintains a sense of urgency to complete a task and seeks information rather than waiting for it.
Problem-Solving - Assesses situations quickly and provides effective and creative solutions for resolution.
Innovative - Contributes to the creation and promotion of an environment where creative thinking is embraced and encouraged.
Collaboration - Actively works with multiple individuals to complete a task or achieve a goal.
Data Gathering & Resource Planning - Ability to define problems, identify data sources, and develop a data collection plan.
Open-minded - Willing to consider new ideas and/or new tools.
Resilience/Resourceful - Possesses the capacity to recover quickly from difficulties.

The company is a 10-year old Vancouver based and for the foreseeable future, they are working 100% from home. You might need to visit the office a couple of days a week, so the candidate needs to reside in Vancouver.

If you're an exceptional Data Engineer/Scientist, please apply today!","nugget.ai
3.0",Vancouver
201,Data Scientist,"Stradigi AI est un fournisseur spécialisé dans les plateformes d'IA qui transforme la façon dont les personnes et les entreprises interagissent avec l'intelligence des données en vue de relever des défis, d'accélérer la prise de décision et de grandir avec l'IA dès aujourd'hui.

Joignez-vous à une entreprise d'IA avant-gardiste et innovante qui a à cœur votre contribution, votre point de vue et votre bien-être.

Stradigi AI est à la recherche d'un(e) Scientifique des données qui soutiendra nos équipes avant-vente et marketing avec des informations tirées de l'analyse des données de l'entreprise. Le candidat idéal doit avoir une solide expérience de l'utilisation d'une variété de méthodes d'exploration de données/d'analyse de données, de l'utilisation d'une variété d'outils de données, de la construction et de la mise en œuvre de modèles, de l'utilisation / de la création d'algorithmes et de la création/exécution de simulations. Ils doivent avoir une capacité avérée à générer des résultats commerciaux grâce à leurs connaissances basées sur les données. Ils doivent être à l'aise de travailler avec un large éventail de parties prenantes et d'équipes fonctionnelles. Le bon candidat aura la passion de découvrir des solutions cachées dans de grands ensembles de données et de travailler en collaboration pour améliorer les résultats commerciaux.

Faites partie d'une entreprise d'IA innovante et avant-gardiste qui valorise vraiment ce que vous faites, ce que vous pensez et ce que vous ressentez.

Ce que vous ferez

Participez et dirigez des ateliers pour clients dans le but de capturer les objectifs commerciaux et les traduire en exigences de données à des fins d'apprentissage automatique.
Travailler avec les autres contributeurs de l'organisation pour identifier les opportunités de tirer parti des données de l'entreprise pour développer des solutions commerciales.
Extraire et analyser les données des bases de données de l'entreprise pour optimiser et améliorer le développement de produits, les techniques de marketing et les stratégies commerciales.
Évaluer l'efficacité et l'exactitude des nouvelles sources de données et des techniques de collecte de données.
Développez des modèles de données et des algorithmes personnalisés à appliquer aux ensembles de données.
Utilisez la modélisation prédictive pour augmenter et optimiser l'expérience client, la génération de revenus, le ciblage publicitaire et d'autres résultats commerciaux.
Coordonner avec différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats.
Développer des processus et des outils pour surveiller et analyser les performances des modèles et l'exactitude des données.

Profil recherché

Expérience de l'utilisation de langages informatiques statistiques (R, Python, SQL, etc.) pour manipuler des données et tirer des informations à partir de grands ensembles de données.
Expérience de travail et de création d'architectures de données.
Une connaissance financière ou une expérience des marchés financiers est un atout certain.
Connaissance d'une variété de techniques d'apprentissage automatique (clustering, apprentissage par arbre de décision, réseaux de neurones artificiels, etc.) et de leurs avantages/inconvénients dans le monde réel.
Connaissance des techniques et concepts statistiques avancés (régression, propriétés des distributions, tests statistiques et bon usage, etc.) et expérience des applications.
Excellentes compétences en communication écrite et verbale pour la coordination entre les équipes.
Compétences solides en présentation pour les collaborations internes et les ateliers clients.
Une volonté d'apprendre et de maîtriser les nouvelles technologies et techniques.
Nous recherchons une personne avec 4 à 7 ans d'expérience dans la manipulation d'ensembles de données et la construction de modèles statistiques, titulaire d'une maîtrise ou d'un doctorat en statistiques, mathématiques, informatique ou dans un autre domaine quantitatif et familiarisée avec les logiciels/outils suivants:

Connaissance et expérience des techniques statistiques et d'exploration de données: GLM/Régression, Random Forest, Boosting, Arbres, text mining, analyse de réseaux sociaux, etc.
Expérience de l'interrogation de bases de données et de l'utilisation de langages informatiques statistiques: R, Python, SQL, etc.
Expérience de l'utilisation des services Web.
Expérience de la création et de l'utilisation d'algorithmes et de statistiques avancés d'apprentissage automatique: régression, simulation, analyse de scénario, modélisation, clustering, arbres de décision, réseaux de neurones, etc.
Expérience de l'analyse de données de fournisseurs tiers: Google Analytics, Facebook Insights, etc.
Expérience avec les données/outils informatiques distribués: Map/Reduce, Hadoop, Hive, Spark, MySQL, etc.
Expérience de visualisation/présentation de données pour les parties prenantes à l'aide de: Tableau, Periscope, Business Objects.

Pourquoi considérer Stradigi AI?

Nous offrons des salaires compétitifs, la possibilité de détenir des actions dans l'entreprise grâce à notre régime d'actionnariat des salariés, une contribution au REER allant jusqu'à 3 %, un programme de vacances généreux, des jours de congé payés durant le temps des Fêtes, une assurance pour les soins médicaux et les soins dentaires, des modalités de travail flexibles, et bien plus! Nous soutenons également un horaire de travail flexible qui permet de travailler autant à la maison qu'au bureau.",Stradigi AI (Française),Montreal
202,Senior Data Scientist,"The Modern Life and Learning Studio is looking for a strong Data Scientist to join our Data Science team to enable us to understand and drive data-informed, high impact business decisions across our organization.

In this role, you will be joining a team hungry to learn, leverage and value your expertise to grow the Data Science discipline into the rhythm of our BXT (Business, Experience, Technology) team structure. You will help shape and strengthen the business strategy for Microsoft Education and how technology can be used effectively in the classroom. You will have the opportunity to work closely with our product engineers, program managers, designers, and user researchers to help shape our business strategies for many of our products.

The successful candidate will have experience analyzing data from a wide range of datasets and across a breadth of technology platforms. They enjoy challenging projects, have strong analytical and presentation skills, technical aptitude and a collaborative work style. We are looking for people who see challenges as opportunities, people who can look at complex problems and are able to provide actionable insights and informed decisions.
Responsibilities
As a Data Scientist in the Modern Life and Learning Studio, you would be responsible for:
Influencing stakeholders to make product improvements that yield business value by effectively making compelling cases through storytelling, visualizations, and other influencing tools
Data preparation, statistics, and machine learning to investigate problems with the goal of supporting the questions required to support the greatest business needs.
Excellent creative thinking skills with emphasis on developing innovative solutions to solve complex problems that may not have one clear answer.
Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.
Use and promote data-exploration techniques to discover new or previously unasked questions.
Provide input to software engineering teams on new analytical capabilities needed.
Training and knowledge transfer to several Software Engineers and Project Managers across the team
Partner with Researchers to help product teams better understand their users.
Help designers explore and understand scenarios in the product to address the unmet needs of the users.
Qualifications
5+ years work experience as a Data Scientist
Experience with R or Python and SQL
Experience with one or more of the following technologies: C, C++, C#, Shell Scripting, Java, Scope, Hive, MapReduce, Scala, Spark, or Pig
Bachelor’s degree is required, with preference given to a Quantitative (Statistics, Data Mining, Machine Learning, Mathematics, Computer Science, or Data Science), or Applied Science (Biology, Physics, Chemistry, or Psychology) discipline.; MS, or Dedicated Data Science training preferred

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
203,"Data Scientist, Remote","Introduction

As a Data Scientist, you will be working closely with a fast-paced software engineering team consisting of open-minded and highly skilled individuals, that designs and continuously delivers a wide range of data analytics services for both clients and business partners.

Company

Infostrux is a Select Snowflake Services Partner building and operating reliable ‘as code’ data cloud solutions for business intelligence, data analytics, and data product use cases.

Position Overview

Interact with technical as well as purely business-oriented clients: analyze and document data science requirements, report progress and present results
Analyze data in any way needed, build statistical and machine learning models, help with AI projects
Work closely with data engineers on importing data from various data sources, data cleaning, integration, enhancement and validation
Suggest reusable patterns and process improvements to be implemented across the whole organization
Follow the trends and newest techniques and approaches in data science and bring them to practice where appropriate
Mentor other engineers

Qualifications

Passion for data
Excellent communication and technical writing skills
Experience with and deep understanding of different data science methodologies, approaches and processes
2+ years of hands-on data science experience
Hands-on experience with AWS, Azure and/or GCP
Subject matter expertise in various business domains
Desired
M.Sc or Ph.D. degree
Strong math/statistics or data mining/machine learning/AI background
SQL, NoSQL, Spark or similar technologies
Python, R, JavaScript, Kotlin or Java, Scala
Some software engineering experience",Infostrux Solutions,Quebec
204,"Data Scientist, Machine Learning Model Validation","TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us.

Department Overview

TD Model Validation (MV) group is responsible for the independent validation and approval of analytical models used for risk, pricing, hedging, insurance, marketing and capital evaluation for portfolio of financial products. This also includes validation of decision making models.

Job Description

The position reports to Senior Manager, Non-Retail Model Validation group within MV. Detailed accountabilities include:

Validate (review and provide effective challenge) Machine Learning models and AI applications.
Develop/implement Machine Learning model validation methodologies and standards. Ensure that the validation methodologies and standards are in line with industry best practice or address regulatory and audit requirements and/or findings in a timely manner.
Develop and apply a variety of statistical tests and modeling techniques to identify/recommend improvements to models and undertake related initiatives. Ensure extensive testing of model sensitivity that help assessing model behavior and risk.
Implement and evaluate external models used for benchmarking internal model performance. Participate in model selection and related due diligence activity.
Actively participate with business partners in internal data management to ensure data integrity and the completeness of data capture for model validation and development purpose.
Maintain full professional knowledge of techniques and developments in the field of Machine Learning and share knowledge with business partners and senior management.


The position involves working effectively with different internal partners such as TD Wealth, TD Insurance, ED&A, PBSA, Layer6 and etc.

Job Requirements

Strong quantitative skills with an advanced degree in one or more of the following areas: computer science, mathematics, physics, statistics, machine learning, economics, finance, engineering, and/or actuarial science.

Up to 3 years' experience of working in analytical environments.

Experience with and strong knowledge of Machine Learning theory and predictive algorithms: Bagging and Gradient Boosting methods, Neural Networks/Deep Learning, NLP, Generalized Additive Models, Graphical Models, Bayesian/probabilistic methods and etc.

Experience or knowledge of Machine Learning Model Interpretation/Explanation, as well as Bias/Fairness assessment, tools and algorithms.

Experience with Big Data analytics tools and environments, such as, Hadoop/Hive, Spark, and H2O.

Ability to research and implement Machine Learning algorithms from academic research papers is a plus.

Object Oriented programming skills.

Proficient in one or more programming languages such as Java, Scala, Python and/or R.

Knowledge of neural network tools such as Tensorflow/Keras, PyTorch and/or MXNet.

Excellent verbal and written communication skills (position requires writing reports).

Quick learner who constantly works on improving their skills and expertise.

Good time management and multitasking skills with minimal supervision.

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Job Family

Advanced Analytics & Modelling

Job Category - Primary

Enterprise Data & Analytics

Job Category(s)

Enterprise Data & Analytics

Hours

37.5

Business Line

Corporate

Time Type

Full Time

Employment Type

Regular

Country

Canada

**Province/State (Primary)

Quebec

City (Primary)

Montreal

Work Location

1350 Rene-Levesque Blvd Corporate, TD Centre - TD Tower - 66 Wellington Street West

ProvState 2

Ontario

City(s) 2

Toronto

Job Expires

13-Jul-2021","TD Bank
4.0",Montreal
205,"Data Scientist, R&D for Data Analytics Platform","Transforming the Future with the Convergence of Simulation and Data



Data Scientist, R&D for Data Analytics Platform:

Do you like a challenge, are you a complex thinker who likes to solve problems? If so, then you might be the new Altairian we are searching for. At Altair, your curiosity matters. We pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients' success, as well as our own.


Job Summary:

As a Data Scientist, you will be part of the Product team, working in an R&D capacity for development of features for the Altair’s Data Analytics Platform.


What You Will Do:

Researching industry best practices for features to be implemented in the Data Analytics platform, with a focus on Data Science features including Data Preparation, Machine Learning, AutoML and Explainable AI Features
Ensuring that new features fit within the architecture of the Data Analytics Platform
Developing Python or R prototypes of the above Data Science features
Working closely with multiple developer teams to productize the Python and R templates in the Data Analytics platform, ensuring incremental value delivered with each software version release



What You Will Need:

Basics:

Advanced Python, SQL and R (optional), including experience with data processing and ML pipelines
Excellent knowledge of the landscape of data analytics tools, including open source tools (e.g. Python sklearn/Pandas, Keras, Jupyter, R, Docker) as well as enterprise platforms.
Experience working with big data
2+ years experience building models that have achieved business value or reached production
Able to work in a fast-paced environment
Can collaborate with others and build relationships with multiple teams, including developers, designers, subject matter experts and stakeholders
Empathy to translate end-user needs into valuable features
Excellent communication skills – able to communicate complex technical features to non-technical teams and stakeholders. Not afraid to ask for help when needed



How You Will Be Successful:

Envision the Future
Communicate Honestly and Broadly
Seek Technology and Business “Firsts”
Embrace Diversity and Take Risks



What We Offer:

Competitive Salary
Comprehensive Benefit Package
Outstanding Work/Life Balance
Flex Time
Paid holidays
Paid time off for community services
Collaborative environment



Why Work with Us:

Altair is a global technology company that provides software and cloud solutions in the areas of product development, high-performance computing (HPC) and artificial intelligence (AI). Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.




Our vision is to transform customer decision making with data analytics, simulation, and high-performance computing and artificial intelligence (AI).




For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com .


Ready to go? #ONLYFORWARD


At our core we are explorers; adventurers; pioneers. We are the brains behind some of the world’s most revolutionary innovations and are not only comfortable in new and uncharted waters, we dive in headfirst. We are the original trailblazers that make the impossible possible; discovering new solutions to our customer’s toughest challenges.


Altair is an equal opportunity employer. Our backgrounds are diverse, and every member of our global team is critical to our success. Altair's history demonstrates a belief that empowering each individual authentic voice reinforces a culture that thrives because of the uniqueness among our team.","Altair Engineering
4.2",Midtown Toronto
206,Data Scientist - Financial Crimes,"Address:

100 King Street West

Job Family Group:

Data Analytics & Reporting

Applies knowledge of advanced analytic algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to deliver better predictions and/or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. Applies strong communication and story-telling skills to summarize statistical/algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business/groups. Drives innovation through the development of Data & AI products that can be leveraged across the organization and establishes best practices in in alignment with Data & AI governance frameworks of BMO.

Acts as a trusted advisor to assigned business/group.
Influences and negotiates to achieve business objectives.
Recommends and implements solutions based on analysis of issues and implications for the business.
Assists in the development of strategic plans.
Identifies emerging issues and trends to inform decision-making.
Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports data collection, integration, and retention requirements for data.
Develops experimental design approaches to validate findings or test hypotheses.
Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.
Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.
Applies innovative and best practices to advanced analytics services to ensure high quality standards.
Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.
Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.
Provides advice and guidance to assigned business/group on implementation of analytical solutions.
Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and/or decisions.
Works with various data owners to discover and select available data from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.
Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.
Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.
Performs experimental design approaches to validate finding or test hypotheses.
Uses the appropriate algorithms to discover patterns.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports development of tools and delivers training for data analytics and AI.
Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.
Leads/participates in the design, implementation and management of core business/group processes.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Provides specialized consulting, analytical and technical support.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently and regularly handles non-routine situations.
Broader work or accountabilities may be assigned as needed.

Qualifications:

Typically between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.
Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience
Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).
Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).
Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms.
Deep knowledge and technical proficiency gained through extensive education and business experience.
Verbal & written communication skills - In-depth.
Collaboration & team skills - In-depth.
Analytical and problem solving skills - In-depth.
Influence skills - In-depth.
Data driven decision making - In-depth.

We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

To find out more visit us at https://jobs.bmo.com/ca/en .

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.","BMO Financial Group
3.8",Midtown Toronto
207,Senior Data Scientist,"Nucleo Digital is searching for a Senior Data Scientist help us design and build a modern tech stack for our client. We are looking for individuals who are passionate about the latest technologies and can lead the design and development of nimble and scalable applications. A successful candidate will bring deep analytical ability, software engineering expertise, and the ability to deliver results within a fast-moving agile environment.

Requirements
The following is a general description of the qualities that will make sure you are successful in this role. To be successful in this role:
You need to be comfortable with one or more dynamic programming languages, preferably Java, C, R, Python.
Strong experience with SQL and NoSQL, particularly the platforms MongoDB, Elasticsearch, Postgres, MS SQL and DB2.
Proficiency in mainstream machine learning/deep learning frameworks: sklearn/tensorflow/keras/pytorch, etc.
Knowledge of classic and modern machine learning theories and algorithms especially using their output to create business enhancing knowledge graphs.
Experience in modular design for software development, such as creating and working with microservices
Experience with distributed systems such as Spark and Hadoop
You articulate complex technical issues in plain language and always endeavour to improve and expand how you communicate.
You thrive on rapid feedback and iterations to improve your practice. This team operates best with open collaborative communications channels.

What is the job?
Your role can be described as Prime of the Enterprise Data team. To achieve this, you will collaborate with multiple teams and business departments. Guide company projects to deliver and consume reliable, stable, and consistent dataset to the rest of the business. Lead the design, development, and delivery of our end to end data and advanced analytics (AI) strategy to power our business platforms. Day to day this role requires you to have significant skills and capabilities in delivering the following with speed, quality, and accuracy.
Design database structure/schema as well as ETL processes to integrate data sources across the organization.
Curate and prepare data from multiple sources and APIs in various forms for business consumption on regular basis.
Define data curation process automating the update and monitoring.
Build data solutions including search, machine learning models and knowledge graphs.
Participate in the building and maintenance of necessary microservices for the data solutions.
Coach and support Data team members as well as develop and manage relationships with data vendors and partners.
Define data objects suitable for our enterprise requirements.
Diligently document your work and actions so they are repeatable actions.
Propose technical design and lead the implementation of data solutions.
Analyze existing database designs for performance or feature enhancement.

What could your strong points be:
This role is an experienced one, with extensive experience in data wrangling, data science, and analysis. You are talented, measured by motivation, alignment of purpose, skills, depth of experience and learning agility. With this you bring to the team:

A sharpness, kindness, and open-mindedness that is fuelled by both excellence and impact.
A quick learning capability and are actively staying on top of the latest in the world of data science
Experience with the full data stack - data analysis, data engineering, data science, and data infrastructure.
Effective communication able to build credibility and trust with the business.
A hunger to make significant contribution to building and growing an impact-driven AI and technology business over a period of several years.
Benefits

What this full time position has to offer:
Competitive salary/rate commensurate with experience
Supportive, challenging, and collaborative work environment",Nucleo Digital,Midtown Toronto
208,"Data Scientist, Advertising Revenue Recommendations","Bachelor's Degree
3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
2 years working as a Data Scientist
Experience in as many of the following areas: causal inferencing, multi-variate testing & design, A/B testing & design, descriptive analytics, and regression analysis.
Good understanding of supervised and unsupervised learning models.
Amazon Advertising is one of Amazon's fastest growing and most profitable businesses. As a core product offering within our advertising portfolio, Sponsored Products (SP) helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through Amazon. The SP team's primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

To be successful with Amazon Advertising, customers need to receive high quality recommendations that inform them of the right opportunities that help grow, defend and drive their business. To generate these high quality recommendations, we must discover differentiated insights that allow advertisers to understand the performance of their business over time, and performance and growth against their peers. This requires us to create models that predict successful outcomes for customers, create workflows for implementation, and measure the downstream impact of our recommendations. Our science investment in this area helps advertising customers choose when to make changes to their advertising strategy, specifies the changes to make to drive their strategy, and predicts how their business will change as a result.

Job Responsibilities:

Contribute to customer-facing products; provide insights and metrics to track recommendation performance & downstream impact.
Solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ML models by tailoring to business needs, and collaborating with Scientists, Engineers, BIE's, and Product Managers.
Utilize code (Python, R, Scala, etc.) to analyze data and build statistical models to solve specific business problems.
Apply statistical or machine learning knowledge to specific business problems and data.
Build decision-making models and propose solution for the business problem you defined
Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers to produce the required data.
Deliver with independence on challenging large scale problems with ambiguity.
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytic capabilities, platforms, and pipelines.
Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.
Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Why you love this opportunity
Amazon is investing heavily in building a world-class advertising business. This team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth
You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven fundamentally from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video https://youtu.be/zD_6Lzw8raE


PhD in Statistics, Economics or related quantitative field.
Experience in measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, manipulating data & analyzing very large data sets, descriptive analytics, and regression analysis.
Excellent quantitative modeling, good knowledge of ML methods, statistical analysis, and problem-solving skills.
Experience processing, filtering, and presenting large quantities (millions to billions of rows) of data.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences.
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Experience in advertising is a plus.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/ontario","AMZN CAN Fulfillment Svcs, ULC
3.8",Toronto
209,"Data Scientist, Advertising Revenue Recommendations","Bachelor's Degree
3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
2 years working as a Data Scientist
Experience in as many of the following areas: causal inferencing, multi-variate testing & design, A/B testing & design, descriptive analytics, and regression analysis.
Good understanding of supervised and unsupervised learning models.
Amazon Advertising is one of Amazon's fastest growing and most profitable businesses. As a core product offering within our advertising portfolio, Sponsored Products (SP) helps merchants, retail vendors, and brand owners succeed via native advertising, which grows incremental sales of their products sold through Amazon. The SP team's primary goals are to help shoppers discover new products they love, be the most efficient way for advertisers to meet their business objectives, and build a sustainable business that continuously innovates on behalf of customers. Our products and solutions are strategically important to enable our Retail and Marketplace businesses to drive long-term growth. We deliver billions of ad impressions and millions of clicks and break fresh ground in product and technical innovations every day!

To be successful with Amazon Advertising, customers need to receive high quality recommendations that inform them of the right opportunities that help grow, defend and drive their business. To generate these high quality recommendations, we must discover differentiated insights that allow advertisers to understand the performance of their business over time, and performance and growth against their peers. This requires us to create models that predict successful outcomes for customers, create workflows for implementation, and measure the downstream impact of our recommendations. Our science investment in this area helps advertising customers choose when to make changes to their advertising strategy, specifies the changes to make to drive their strategy, and predicts how their business will change as a result.

Job Responsibilities:

Contribute to customer-facing products; provide insights and metrics to track recommendation performance & downstream impact.
Solve real world problems by analyzing large amounts of business data, diving deep to identify business insights and opportunities, designing simulations and experiments, developing statistical and ML models by tailoring to business needs, and collaborating with Scientists, Engineers, BIE's, and Product Managers.
Utilize code (Python, R, Scala, etc.) to analyze data and build statistical models to solve specific business problems.
Apply statistical or machine learning knowledge to specific business problems and data.
Build decision-making models and propose solution for the business problem you defined
Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies. In cases where questions cannot be answered with available data, work with engineers to produce the required data.
Deliver with independence on challenging large scale problems with ambiguity.
Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions or improving system performance.
Analyze historical data to identify trends and support decision making.
Improve upon existing methodologies by developing new data sources, testing model enhancements, and fine-tuning model parameters.
Provide requirements to develop analytic capabilities, platforms, and pipelines.
Formalize assumptions about how our systems are expected to work, create statistical definition of the outlier, and develop methods to systematically identify these outliers. Work out why such examples are outliers and define if any actions needed.
Given anecdotes about anomalies or generate automatic scripts to define anomalies, deep dive to explain why they happen, and identify fixes.
Conduct written and verbal presentation to share insights and recommendations to audiences of varying levels of technical sophistication.
Why you love this opportunity
Amazon is investing heavily in building a world-class advertising business. This team is responsible for defining and delivering a collection of advertising products that drive discovery and sales. Our solutions generate billions in revenue and drive long-term growth for Amazon’s Retail and Marketplace businesses. We deliver billions of ad impressions, millions of clicks daily, and break fresh ground to create world-class products. We are highly motivated, collaborative, and fun-loving team with an entrepreneurial spirit - with a broad mandate to experiment and innovate.

Impact and Career Growth
You will invent new experiences and influence customer-facing shopping experiences to help suppliers grow their retail business and the auction dynamics that leverage native advertising; this is your opportunity to work within the fastest-growing businesses across all of Amazon! Define a long-term science vision for our advertising business, driven fundamentally from our customers' needs, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus, and business understanding.

Team video https://youtu.be/zD_6Lzw8raE


PhD in Statistics, Economics or related quantitative field.
Experience in measurement problems, causal inferencing, multi-variate testing & design, A/B testing & design, manipulating data & analyzing very large data sets, descriptive analytics, and regression analysis.
Excellent quantitative modeling, good knowledge of ML methods, statistical analysis, and problem-solving skills.
Experience processing, filtering, and presenting large quantities (millions to billions of rows) of data.
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering, and business audiences.
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.
Experience in advertising is a plus.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/ontario","AMZN CAN Fulfillment Svcs, ULC
3.8",Toronto
210,Data Scientist - Financial Crimes,"Address:

100 King Street West

Job Family Group:

Data Analytics & Reporting

Applies knowledge of advanced analytic algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to deliver better predictions and/or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. Applies strong communication and story-telling skills to summarize statistical/algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business/groups. Drives innovation through the development of Data & AI products that can be leveraged across the organization and establishes best practices in in alignment with Data & AI governance frameworks of BMO.

Acts as a trusted advisor to assigned business/group.
Influences and negotiates to achieve business objectives.
Recommends and implements solutions based on analysis of issues and implications for the business.
Assists in the development of strategic plans.
Identifies emerging issues and trends to inform decision-making.
Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports data collection, integration, and retention requirements for data.
Develops experimental design approaches to validate findings or test hypotheses.
Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.
Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.
Applies innovative and best practices to advanced analytics services to ensure high quality standards.
Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.
Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.
Provides advice and guidance to assigned business/group on implementation of analytical solutions.
Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and/or decisions.
Works with various data owners to discover and select available data from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.
Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.
Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.
Performs experimental design approaches to validate finding or test hypotheses.
Uses the appropriate algorithms to discover patterns.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports development of tools and delivers training for data analytics and AI.
Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.
Leads/participates in the design, implementation and management of core business/group processes.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Provides specialized consulting, analytical and technical support.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently and regularly handles non-routine situations.
Broader work or accountabilities may be assigned as needed.

Qualifications:

Typically between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.
Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience
Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).
Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).
Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms.
Deep knowledge and technical proficiency gained through extensive education and business experience.
Verbal & written communication skills - In-depth.
Collaboration & team skills - In-depth.
Analytical and problem solving skills - In-depth.
Influence skills - In-depth.
Data driven decision making - In-depth.

We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

To find out more visit us at https://jobs.bmo.com/ca/en .

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.","BMO Financial Group
3.8",Midtown Toronto
211,"Data Scientist, Advanced Analytics, Global Risk Management - Toronto, ON","Requisition ID: 106515

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Data Scientist, Advanced Analytics will support business use-cases delivery, in an agile rapid lab environment, aimed at accelerating benefits for customers and the bank, leveraging enterprise-level data management tools and advanced analytics. She/he will work closely with peers across Global Risk teams, the business lines, IT&S and Digital Banking to expand the ‘Credit Science’ practice and drive the GRM Analytics COE interaction model. The candidate will identify and prioritize opportunities to deliver innovative retail credit solutions leveraging risk-reward predictions and strategy optimization frameworks.

Is this role right for you? In this role you, will:

Work in Agile Rapid Lab environment to deploy new credit solutions in 90-day increments
Support forward-thinking, high impact analytical use cases focused on supporting GRM Data, Analytics and Technology Strategy and deliver actionable insights to capitalize on business opportunities
Collaborate with GRM Analytics COE key stakeholders and partners to define machine learning and artificial intelligence best-practices for agile rapid labs
Support risk-reward predictions delivery, strategy optimizations and machine learning playbooks to drive innovative credit solutions within risk appetite thresholds
Build 1-2 analytical playbooks (i.e. Cashflow Insights, Pre-approved Credit, Credit Optimization, High Risk Account Management, Collections, Fraud, etc.) across global retail and business banking footprint to support growth or de-risking initiatives
Support Research & Development work focused on the effective application of design thinking and scalable advanced techniques to drive ideation and innovation in analytics, machine learning and artificial intelligence
Support a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team
Support GRM Analytics COE with thought leadership and R&D activities to influence GRM stakeholders on trends regarding practical applications of machine learning and artificial intelligence to banking
Understand how the Bank’s risk appetite and risk culture should be considered in decision making

Do you have the skills that will enable you to succeed in this role? - We'd love to work with you if you have:

Post graduate degree in relevant STEM discipline (Science, Technology, Engineering and Mathematics)
1~3 years working experience in Data Science/Machine learning/Modeling, financial industry or fintech preferred
Ability to ingest and work with large volumes of structured and unstructured non-traditional data
Working experience with big data tools such as SQL, Hive, Spark
Working experience with open-source programming languages such as Python, Pyspark, R, Scala
Working experience with ML/AI techniques for strategy design (supervised, unsupervised, NLP, decision tree, reinforcement learning, recommendation engines, APIs)
Knowledge of strategy optimization leveraging operations research principles would be an asset
Working experience with cloud computing platforms such as MS Azure and Google Cloud
Working experience with DevOps principles and/or software engineering best practices would be an asset
Working knowledge of visualization tools such as Tableau and Power BI would be an asset
Strong collaboration skills with ability to translate technical knowledge into business value
Effective communication skills with ability to prepare project documentation and presentations

What’s in it for you?

The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers.
A rewarding career path with diverse opportunities for professional development.
Internal development to support your growth and enhance your skills.
A competitive compensation and benefits package.
An organization committed to making a difference in our communities– for you and our customers.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown Toronto

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
212,"Data Scientist, Advanced Analytics, Global Risk Management - Toronto, ON","Requisition ID: 106515

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Data Scientist, Advanced Analytics will support business use-cases delivery, in an agile rapid lab environment, aimed at accelerating benefits for customers and the bank, leveraging enterprise-level data management tools and advanced analytics. She/he will work closely with peers across Global Risk teams, the business lines, IT&S and Digital Banking to expand the ‘Credit Science’ practice and drive the GRM Analytics COE interaction model. The candidate will identify and prioritize opportunities to deliver innovative retail credit solutions leveraging risk-reward predictions and strategy optimization frameworks.

Is this role right for you? In this role you, will:

Work in Agile Rapid Lab environment to deploy new credit solutions in 90-day increments
Support forward-thinking, high impact analytical use cases focused on supporting GRM Data, Analytics and Technology Strategy and deliver actionable insights to capitalize on business opportunities
Collaborate with GRM Analytics COE key stakeholders and partners to define machine learning and artificial intelligence best-practices for agile rapid labs
Support risk-reward predictions delivery, strategy optimizations and machine learning playbooks to drive innovative credit solutions within risk appetite thresholds
Build 1-2 analytical playbooks (i.e. Cashflow Insights, Pre-approved Credit, Credit Optimization, High Risk Account Management, Collections, Fraud, etc.) across global retail and business banking footprint to support growth or de-risking initiatives
Support Research & Development work focused on the effective application of design thinking and scalable advanced techniques to drive ideation and innovation in analytics, machine learning and artificial intelligence
Support a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team
Support GRM Analytics COE with thought leadership and R&D activities to influence GRM stakeholders on trends regarding practical applications of machine learning and artificial intelligence to banking
Understand how the Bank’s risk appetite and risk culture should be considered in decision making

Do you have the skills that will enable you to succeed in this role? - We'd love to work with you if you have:

Post graduate degree in relevant STEM discipline (Science, Technology, Engineering and Mathematics)
1~3 years working experience in Data Science/Machine learning/Modeling, financial industry or fintech preferred
Ability to ingest and work with large volumes of structured and unstructured non-traditional data
Working experience with big data tools such as SQL, Hive, Spark
Working experience with open-source programming languages such as Python, Pyspark, R, Scala
Working experience with ML/AI techniques for strategy design (supervised, unsupervised, NLP, decision tree, reinforcement learning, recommendation engines, APIs)
Knowledge of strategy optimization leveraging operations research principles would be an asset
Working experience with cloud computing platforms such as MS Azure and Google Cloud
Working experience with DevOps principles and/or software engineering best practices would be an asset
Working knowledge of visualization tools such as Tableau and Power BI would be an asset
Strong collaboration skills with ability to translate technical knowledge into business value
Effective communication skills with ability to prepare project documentation and presentations

What’s in it for you?

The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers.
A rewarding career path with diverse opportunities for professional development.
Internal development to support your growth and enhance your skills.
A competitive compensation and benefits package.
An organization committed to making a difference in our communities– for you and our customers.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown Toronto

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
213,Senior Data Scientist,"For over forty years, Vanguard has been on a mission – to change the way the world invests. From our outstanding ownership structure to our low cost options, we are committed to our belief that nothing should stand in the way of investors meeting their goals. Our Center for Analytics & Insights (CAI) is dedicated to removing obstacles to these investors by using advanced analytics to solve our most difficult problems.

Do you want to lead and execute investigate diagnostic, predictive, and prescriptive analytics to support data driven business decision-making? You will be responsible to build alternative model approaches to assess sophisticated model design and advance future capabilities. Mentors and develops junior data scientists and analysts.

In This Role You Will

Leads the execution of large scale, more complex analytics projects. Applies significant quality control and risk assessment of the model, methodologies, outputs, and processes for major data science projects.

Identifies and diagnoses data inconsistencies and errors, documents data assumptions, and forages to fill data gaps.

Engages with senior leadership to understand and probe business processes in order to develop hypotheses. Brings structure to requests and translates requirements into an analytic approach.

Guides test design, research design, and model validation. Provides statistical consultation services. Serves as the analytics authority on cross functional teams for large critical initiatives and supplies to the growth of the Vanguard analytic community.

Prepares and delivers insight presentations and action recommendations. Communicates sophisticated analytical findings and implications to business leaders.

Reimagine the investment experience

A World-class client experience is something that can only be defined by our clients. Leading the development and delivery of advanced, meaningful analytic products and services you will work to uncover difficulties and challenges a client may face and how they may differ across product lines. Using analytical approaches such as predictive and prescriptive modeling your goal will be to bring tangible and significant business impact on Vanguard’s businesses and clients to drive overall efficiency.

Qualifications of the position:

Minimum of eight years related work experience in analytical roles. Experience with data wrangling required - Programming skills to access, transform and prepare large scale data for statistical modeling. Experience utilizing statistical and machine learning methods required.

Undergraduate degree in Analytics, Applied Mathematics, Economics, Statistics or related analytical field of study or equivalent combination of training and experience. Graduate degree preferred.

An ideal candidate will have:

Graduate degree in a quantitative/analytical field such as Data Science, Machine Learning, Mathematics, Statistics, Economics, Computer Science, Engineering, Operations Research, Physics, or other meaningful scientific field; PhD preferred. Undergraduate degree in Analytics, Applied Mathematics, Economics, Statistics or related analytical field of study or equivalent combination of training and experience.

Deep understanding and experience building models using Deep Learning, Machine Learning and Optimization methods (for example – CNN, RNN, LSTM, Regression (GLMs), Tree based models, SVM, Random Forests, GBM, Time-series analysis, Linear/Non-Linear/Integer programming, etc.)

Demonstrated experience in using the above methods to solve complex business problems thereby generating insights and providing best-in-class data driven solutions for customers.

Proven experience in managing and leading large complex projects, including (but not limited to) formulating the business and analytical problem, extracting, cleansing, and manipulating large, and diverse data sets, building descriptive, predictive and prescriptive solutions and deploying these solutions in the cloud and/or on premise systems.

Proven experience in presenting analytical solutions, data relationships and results, and their business impacts to multiple business partners and, through outstanding data visualization and storytelling skills.

Strong proficiency in Python, R, Spark (Scala, PySpark).




About Vanguard

We are Vanguard. Together, we’re changing the way the world invests.

For us, investing doesn’t just end in value. It starts with values. Because when you invest with courage, when you invest with clarity, and when you invest with care, you can get so much more in return. We invest with purpose – and that’s how we’ve become a global market leader. Here, we grow by doing the right thing for the people we serve. And so can you.

We want to make success accessible to everyone. This is our opportunity. Let’s make it count.

Inclusion Statement

Vanguard’s continued commitment to diversity and inclusion is firmly rooted in our culture. Every decision we make to best serve our clients, crew (internally employees are referred to as crew), and communities is guided by one simple statement: “Do the right thing.”

We believe that a critical aspect of doing the right thing requires building diverse, inclusive, and highly effective teams of individuals who are as unique as the clients they serve. We empower our crew to contribute their distinct strengths to achieving Vanguard’s core purpose through our values.

When all crew members feel valued and included, our ability to collaborate and innovate is amplified, and we are united in delivering on Vanguard's core purpose.

Our core purpose: To take a stand for all investors, to treat them fairly, and to give them the best chance for investment success.","Vanguard
3.5",Midtown Toronto
214,Senior Professional Environmental Scientist (Geoscience) and Business Lead,"Senior Professional Environmental Scientist and Business Lead 
Duncan or Abbotsford, B.C.

Madrone Environmental Services Ltd. (Madrone) has immediate openings for a Senior Professional Environmental Scientist and Business Lead at our Duncan or Abbotsford offices. This is a full-time position with comprehensive benefits.

Madrone is a well-established environmental services company offering our employees a flexible work environment as well as exciting opportunities to advance within their professions. Our interdisciplinary team of professionals include: Biologists, Foresters, Geoscientists, Geomorphologists, Hydrologists, Agrologists and Archaeologists. Working together, we help our clients achieve best use of natural resources while meeting environmental protection goals. Wage will be commensurate with experience.

Opportunity:
As a Senior Professional Environmental Scientist with Madrone’s Geoscience practice, you will be the Geoscience Business Lead and senior team member focused on the successful initiation to completion of projects, whose practice experience, organizational skills and leadership will play a pivotal role in our current breadth of Geoscience practice. Your role will be to provide technical expertise with the delivery of current projects, develop new business, and provide senior technical support and mentorship to staff. You will work with a team of professionals on a variety of initiatives to advance the efficiency of operations while providing mentorship for junior professionals and achieving business development goals for the geoscience business group.

Requirements:

Master’s degree in geology, earth sciences, or engineering, or equivalent, preferred; 
Professional Geoscientist (P.Geo) or Professional Engineer (P.Eng/L.Eng) registration in good standing, or eligible for immediate registration in the Province of British Columbia; 
Minimum 15 years of consulting experience or equivalent, focused on geoscience related services including practice in land development, mining, forestry, and government; 
Ability to develop complex and long-duration projects through effective client, landowner and regulator liaisons, and to develop detailed scopes of work to facilitate client goals and regulatory requirements; 
Project and team management experience is required, including effective management of schedules and budgets; 
Direct Leadership experience  in guiding Intermediate and Junior geoscience staff on project deliverables, and ability to supportively collaborate with a diversity of QPs – both of which are borne by excellent interpersonal communication and writing ability; 
Previous relevant client management and business development experience is preferred; 
Recent field experience within Western Canada and with applicable legislative frameworks; 
Strong organizational, time management, problem-solving and analytical skills.

General duties include:

Adherence and promotion of all safety procedures; 
Data driven permitting and regulatory support services; 
Mentoring, developing and providing technical guidance to intermediate and junior staff; 
Develop and manage strong relationships with new and existing clients;
Ensuring appropriate Quality Management on all team’s projects;
Participating in multi-disciplinary project teams, guiding and coaching others;
Contributing to the overall strategic development of the Geoscience group, including growth, profitability and supporting the development of new processes, services, geographies and client sectors;
Project management duties include cost tracking, invoicing, and working with deliverable deadlines; 
Leading specific tasks and objectives related to supervision/advisement of external 3rd party contractors. 

Notice regarding Covid 19: All interviews will be conducted virtually to maintain the safety of the applicants and interviewers.

Please send a cover and résumé: attention to Michelle Lancaster, HR Manager. We thank all applicants, however, only those shortlisted will be contacted. Application deadline: June 28, 2021 but may be extended until filled.
Visit our website at www.madrone.ca

Please visit our website to view all current job postings

Job Types: Full-time, Permanent

Salary: $38.00-$51.00 per hour

Additional pay:

Overtime pay

Benefits:

Casual dress
Dental care
Employee assistance program
Extended health care
Flexible schedule
Life insurance
On-site parking
Paid time off
Vision care
Work from home

Schedule:

8 hour shift
Day shift
Monday to Friday
Overtime

Work remotely:

Temporarily due to COVID-19",Madrone Environmental Services Ltd,Abbotsford
215,Pricing Data Scientist,"With thousands of beautiful spaces built for travel and living, Sonder is transforming the future of hospitality. Each Sonder is purposefully selected, designed and maintained - customized to reflect the vibe of its neighborhood. Whether your stay is two days, two months or two years, in a studio or a six-bedroom, Sonder ensures a unique, yet consistent experience. And with 24/7 contactless service, professional cleanings that exceed CDC recommendations, and over 200 other quality standards, we're taking stay further for guests all around the world.

Sonder started in 2014, and now has thousands of spaces in cities across the globe.

AT SONDER YOU WILL:
Drive revenue growth by developing, deploying and testing optimal pricing algorithms and strategies across Sonder's portfolio of units
Solve fundamental pricing strategy problems such as

How do we develop a unique pricing strategy across our wide range of markets
How do we identify and price optimally across different customer segments
How do we optimally allocate inventory and build up bookings across channels (sales, group, wholesale and direct to consumer channels)
How do we price and allocate inventory across different lengths of stay to maximize calendar utilization and contribution margin
How do we test and measure the effectiveness of our pricing strategy

Define and implement a rigorous set of pricing metrics and experimentation methodologies
Partner with Engineering, Analytics and Pricing Ops team to implement and operationalize various pricing solutions
Partner with other functions such as Sales, Distribution and Markets to define revenue strategy, targets and pricing guardrails

WHAT WE LOOK FOR:
Bachelor Degree in Economics/Econometrics, Quantitative Finance, Computer Science, Math, Engineering, or related quantitative field.
Experience working with Product and Engineering teams at high growth companies to solve problems, identify trends and opportunities, productionize recommendations
Prior experience in pricing optimization in a related industry (hospitality, airlines, tickets) is a big bonus
3+ years experience in a Data Science role
3+ years of experience with SQL and Python
Great communication skills – being able to explain your work and the impact on the business to all types of business partners
High-energy self-starter with a passion for data, attention to detail, and a positive attitude

We also have great benefits to make your life easier so you can focus on what you're best at:

Competitive salary
Generous stock option plan
Medical, dental and vision insurance
Unlimited vacation
Annual free credits and discounts to stay in Sonders
A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status or other protected classes

Avec des milliers de beaux espaces construits pour le voyage et la vie, Sonder transforme l'avenir de l'hospitalité. Chaque Sonder est sélectionné, conçu et entretenu de manière ciblée, et personnalisé pour refléter l'ambiance de son quartier. Que votre séjour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, Sonder vous garantit une expérience unique, mais cohérente. Et grâce à un service sans contact 24 heures sur 24, 7 jours sur 7, à des nettoyages professionnels qui dépassent les recommandations de l'ASPC et à plus de 200 autres normes de qualité, nous allons encore plus loin pour nos clients du monde entier.

Sonder a débuté en 2014, et compte aujourd'hui des milliers de chambres dans des villes du monde entier.

Sonder a débuté il y a un peu plus de cinq ans et compte aujourd'hui des milliers de places dans des villes du monde entier. L'équipe de Pricing Data Science est particulièrement bien placée pour assurer le succès et la rentabilité de Sonder. L'équipe crée et met en œuvre des stratégies de tarification basées sur les données afin d'optimiser les revenus et est responsable du développement continu de nos modèles de prévision.

CHEZ SONDER, VOUS LE FEREZ :
Stimuler la croissance des revenus en développant, en déployant et en testant des algorithmes et des stratégies de tarification optimale dans l'ensemble du portefeuille d'unités de Sonder

Résoudre des problèmes fondamentaux de stratégie de tarification tels que

Comment élaborer une stratégie de prix unique sur notre large éventail de marchés
Comment identifier et fixer les prix de manière optimale dans les différents segments de clientèle
Comment répartir les stocks de manière optimale et constituer des réservations entre les différents canaux (ventes, groupes, vente en gros et canaux de vente directe aux consommateurs)
Comment fixer le prix et répartir les stocks sur différentes durées de séjour pour maximiser l'utilisation du calendrier et la marge de contribution
Comment tester et mesurer l'efficacité de notre stratégie de prix
Définir et mettre en œuvre un ensemble rigoureux de mesures de tarification et de méthodes d'expérimentation

Travailler en partenariat avec l'équipe des opérations d'ingénierie, d'analyse et de tarification pour mettre en œuvre et rendre opérationnelles diverses solutions de tarification

Établir des partenariats avec d'autres fonctions telles que les ventes, la distribution et les marchés pour définir la stratégie de revenus, les objectifs et les garde-fous en matière de prix

CE QUE NOUS RECHERCHONS :
Licence en économie/économétrie, finance quantitative, informatique, mathématiques, ingénierie ou domaine quantitatif connexe.

Expérience de travail avec des équipes de produits et d'ingénierie dans des entreprises à forte croissance pour résoudre des problèmes, identifier des tendances et des opportunités, produire des recommandations

Une expérience préalable dans l'optimisation des prix dans un secteur connexe (hôtellerie, compagnies aériennes, billets) est un atout important

3+ ans d'expérience dans un poste de Data Science

3+ ans d'expérience avec SQL et Python

Grande capacité de communication - être capable d'expliquer votre travail et l'impact sur l'entreprise à tous les types de partenaires commerciaux

Une personne énergique, passionnée par les données, attentive aux détails et ayant une attitude positive

Nous avons également de grands avantages à vous faciliter la vie pour que vous puissiez vous concentrer sur ce que vous faites le mieux :

Un salaire compétitif

Un plan d'options d'achat d'actions généreux

Assurance médicale, dentaire et visuelle

Vacances illimitées

Crédits annuels gratuits et réductions pour séjourner à Sonders

Une entreprise qui a une grande vision, un environnement de travail dynamique et une équipe de collègues intelligents, ambitieux et agréables à travailler !

Nous sommes un employeur souscrivant au principe de l'égalité des chances et valorisons la diversité au sein de notre entreprise. Nous ne faisons aucune discrimination fondée sur la race, la religion, la couleur, l'origine nationale, le sexe, l'orientation sexuelle, l'âge, l'état civil, le statut d'ancien combattant, le handicap ou d'autres catégories protégées","Sonder
3.2",Montreal
216,Data Scientist Engineer,"Data Scientist Engineer-2100905


You can be part of an inclusive team of diverse talent and character. In this diversity lies our greatest strength.
Description


At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation.




We provide a challenging and rewarding work environment with a strong emphasis on process safety, as well as the safety of our employees and the communities we operate in and are always working to form the best team—especially from within, through an emphasis on lifelong learning and development.




And we are constantly striving to become an even better place to work. BASF has been recognized as one of Canadas Best 100 Employers in 2019. Come join us on our journey to create solutions for a sustainable future!




Data Scientist Engineer (ID: 2100905)




Where the Chemistry Happens…

The Data Scientist will model complex business problems and provide insights through data analysis. In addition, the Data Scientist will be responsible for also evangelizing the capabilities of data science and basing decisions on data.

The Data Scientist will be expected to participate in a community-of-practice to maximize the effectiveness of the insights team, through knowledge sharing and thoughtful curation of algorithms and methods. To identify opportunities for data-driven insights, the Data Scientist, as an evangelist for marketing data science, will interact frequently with leaders and experts in various business organizations and become part of a global team. The Data Scientist will be responsible for coordinating and initiating their own activities as it relates to maximizing the value of insights delivered and derived from data.




Formula for Success: You Will…




Guiding business partners and non-experts in the selection of valuable and feasible cases to create insights with statistics and machine learning.



Data selection and engineering (at least for prototyping)



Model selection and optimization (statistical, machine learning) – programming primarily in Python



Model deployment in existing environments
Qualifications


Ingredients for Success: What We Look for in You…




Bachelor’s degree (Master preferred) in quantitative/computational science with a strong focus on marketing and statistics.



5+ years experience in using statistic/modeling tools in non-academic environment with a focus on business growth.



Certifications or publications relevant to data science, technical expertise, or marketing insights.



Demonstrated, hands-on experience with R, Python, or similar data science tools.



Significant experience with enterprise-wide data initiatives and working with complex data and system infrastructures.



Experience in change management, scoping, requirements and solutions execution.



Experience in defining metrics and scorecards to demonstrate benefits of a successful data governance program.



Experience in handling exceptions and communication and partnering with cross-functional teams.



Experience working in cloud-first environments, particularly Azure and AWS.



Exposure to and experience with visualization tools (e.g. Tableau, Power BI).



Knowledge of IT and business management Information systems from a data perspective.



Strong communication skills demonstrated through work and education experiences



Understanding and prior experience with the agriculture industry a heavy plus.



Create Your Own Chemistry: What We Offer You




Adding value to our customers begins with adding value to you. You@BASF is the suite of benefits, perks, programs and unique opportunities we offer to support you—the whole you—in all stages of your life and career. With you@BASF, you create your own chemistry.




The total rewards that you receive as a BASF employee go way beyond a paycheck. From competitive health and insurance plans, to robust retirement benefits that include company-matching contributions, to making sure you never stop learning, we believe investing in you is investing in our success. Working for a large, global organization, you’ll have a chance to grow professionally and personally, expand your network and build a rewarding and dynamic career.




BASF provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job



Primary Location: CA-ON-Mississauga
Function: ITSE - Information Technology & Services
Job Type: Standard
Shift: Day Job
Organization: GDA/BC-RBPS NA Canada Mexico MidWest-63009551","BASF
4.2",Mississauga
217,Data Scientist - Molecular & Cell Engineering,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21502

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated scientist with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our Molecular & Cell Engineering group. We focus on the discovery and development of therapeutic antibodies from natural immune repertoires, and believe that through teamwork, innovation, and mutual support, we can tackle the most challenging scientific problems.

The successful candidate will interact with a multidisciplinary and dynamic team in a fast-paced and focused environment. The candidate will be adept at multitasking, problem-solving and critical-thinking, and will demonstrate scientific rigour in their work.

How you might spend your days:

Using your understanding of molecular and cell biology to analyze and interpret large multifactorial data sets for the purpose of driving drug-discovery, especially with regard to high-throughput workflows and lead candidate selection
Facilitating effective communication between computational and experimental scientists, with an emphasis on bioinformatics and biology teams, in addition to other colleagues and partners
Organizing, supporting, and collaborating with team members to meet project deliverables and timelines
Building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high-throughput experiments (e.g. IC50 calculations, DNA sequence data, flow cytometry)
Leading initiatives to standardize data output and data analysis
Training, mentoring, and supervising members of a dynamic team

We'd love to hear from you if:

You thrive in a collaborative environment
You enjoy bringing out the best in your teammates
You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities
You take pride in being a self-motivated person, fast learner, team player, and creative problem solver
You are passionate about communicating complex data to interdisciplinary project teams

Required qualifications and experience:

PhD or MSc with work experience in a relevant field
Background in the life sciences; Molecular Biology, Cell Biology, Biochemistry, or Biophysics preferred
Proficiency in Python or R for analysis and data visualization
Demonstrated ability to create flexible data analysis pipelines intended for use by others
Experience working with and creating data architectures
Excellent skills in data visualization and presentation of key findings
Drive to learn and master new techniques
Excellent documentation and organizational skills
Impeccable attention to detail
Willingness to work flexible hours (occasional evenings and weekends)

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please submit your application through our website and refer to Job ID 21502 in your cover letter. Only applicants selected for an interview will be contacted.","AbCellera Biologics
4.8",Vancouver
218,Data Scientist - Molecular & Cell Engineering,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21502

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated scientist with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our Molecular & Cell Engineering group. We focus on the discovery and development of therapeutic antibodies from natural immune repertoires, and believe that through teamwork, innovation, and mutual support, we can tackle the most challenging scientific problems.

The successful candidate will interact with a multidisciplinary and dynamic team in a fast-paced and focused environment. The candidate will be adept at multitasking, problem-solving and critical-thinking, and will demonstrate scientific rigour in their work.

How you might spend your days:

Using your understanding of molecular and cell biology to analyze and interpret large multifactorial data sets for the purpose of driving drug-discovery, especially with regard to high-throughput workflows and lead candidate selection
Facilitating effective communication between computational and experimental scientists, with an emphasis on bioinformatics and biology teams, in addition to other colleagues and partners
Organizing, supporting, and collaborating with team members to meet project deliverables and timelines
Building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high-throughput experiments (e.g. IC50 calculations, DNA sequence data, flow cytometry)
Leading initiatives to standardize data output and data analysis
Training, mentoring, and supervising members of a dynamic team

We'd love to hear from you if:

You thrive in a collaborative environment
You enjoy bringing out the best in your teammates
You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities
You take pride in being a self-motivated person, fast learner, team player, and creative problem solver
You are passionate about communicating complex data to interdisciplinary project teams

Required qualifications and experience:

PhD or MSc with work experience in a relevant field
Background in the life sciences; Molecular Biology, Cell Biology, Biochemistry, or Biophysics preferred
Proficiency in Python or R for analysis and data visualization
Demonstrated ability to create flexible data analysis pipelines intended for use by others
Experience working with and creating data architectures
Excellent skills in data visualization and presentation of key findings
Drive to learn and master new techniques
Excellent documentation and organizational skills
Impeccable attention to detail
Willingness to work flexible hours (occasional evenings and weekends)

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please submit your application through our website and refer to Job ID 21502 in your cover letter. Only applicants selected for an interview will be contacted.","AbCellera Biologics
4.8",Vancouver
219,Data Scientist – Antibody Assessment,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21503

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated Data Scientist, with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our multidisciplinary team. Our ideal candidate is a highly motivated and self-directed scientist, a team-player who thrives in a fast-paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. This is an exciting opportunity to join one of Canada’s most innovative biotech companies and to contribute to our cutting-edge research, driving the discovery of novel monoclonal antibodies for therapeutic use.

How you might spend your days:

Using your understanding of bioinformatics and biochemistry to analyze and interpret large multifactorial data sets for the purpose of driving drug discovery, especially with regard to lead candidate selection and predictive analysis
Organizing, supporting, and collaborating with team members to meet project deliverables and timelines
Building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high-throughput analytical and biophysical experiments (e.g. SPR, mass spectrometry, HPLC, light scattering, etc)
Developing tools to collate, organize and process data inputs for our in-house data visualization platform, Celium.
Leading initiatives to standardize data output and data analysis for integration into laboratory information management systems (LIMS) or electronic notebook (ELN)
Collaborating with other data scientists on projects, finding solutions, and sharing code

We'd love to hear from you if:

You thrive in a collaborative environment and enjoy bringing out the best in your teammates
You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities
You take pride in being a self-motivated person, fast learner, team player, and creative problem solver
You are passionate about analysis of complex data and communication to interdisciplinary project teams

Required qualifications and experience:

A graduate degree (PhD or MSc) in Bioinformatics, Computational Biology, Immunology, Immunogenetics, or a related field
Experience in the Life Sciences; Biochemistry, Biophysics, Cell Biology, or Molecular Biology preferred
Proficiency in at least one common coding language: Python or R (Python preferred)
Demonstrated ability to create flexible, reproducible data analysis pipelines intended for use by others
Experience working with and creating databases, data provenance, or data architectures
Excellent skills in data visualization and presentation of key findings
Drive to learn and master new techniques
Excellent documentation and organizational skills, with impeccable attention to detail
A solid foundation in statistical analysis
An understanding of basic machine learning would be desired

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please submit your application through our website and refer to Job ID 21503 in your cover letter. Only applicants selected for an interview will be contacted.","AbCellera Biologics
4.8",Vancouver
220,Data Architect,"Job Description:
We’re a naan traditional company…

What is the recipe for a great career at FGF?

Working at FGF Brands, there is never a dull moment! As a successful company that is continually growing there is always challenging yet rewarding work to be a part of. We have an entrepreneurial mindset which encourages all our team members to use their own creativity and out of the box thinking to come up with solutions and new ideas.

Let’s be frank. FGF is not for everybody. Our culture is unique. We dive headfirst into the unknown. If you’re fun-loving, talented and fearless, we’re for you.

What FGF Offers:
Disruptive and a naan-traditional mindset
An inclusive and dynamic culture
Accelerated career progression
Commitment to learning and development
Opportunity to be impactful
Competitive compensation

Data Architect

FGF brands is seeking an experienced Data Architect who will be responsible for the design and support of our data infrastructure and ecosystem. The position will be part of the Business Insight and Analytics team. The ideal candidate will not only possess great communication skills but will also be very technical and hands-on. Additionally, the candidate requires deep IT Service Management knowledge, coupled with broad technical knowledge, and the ability to design solutions by mapping business problems, providing end-to-end solutions combining process with technology.

Demonstrated ability to engage in discussions related to availability, agility, business value, security management, disaster recovery, and the value of process in an enterprise environment is required.
The ideal candidate will be self-motivated, a results-driven technologist, who is passionate about building a highly scalable data infrastructure, keeping up with FGF brands rapid growth.

Key Responsibilities

Defines data governance and standards to deliver a cohesive information architecture for FGF brands.
Define system level architecture and conduct dimension modeling & data mart design.
Owns data solution design, methodology approach, and system architecture development.
Provide direction and insight on FGF data strategy, defining the target state architecture and roadmap.
Take active role in building, delivering and execution of target state architecture.
Actively work on migrating data from legacy systems to new solutions.
Design, document, construct and deploy database architectures and applications (e.g. large relational databases)
Integrate technical functionality (e.g. scalability, security, performance, data recovery, reliability, etc.)
Optimize and improve current database system performance by conducting tests, troubleshooting, and integrating new elements.
Break down complex projects and problems into actionable tasks that be delivered quickly and iteratively and provide value to the business stakeholders
Coordinate with Data sciences department to identify future needs and requirements, supporting all Translates user requirements and business use cases to conceptual, logical, and physical data models and workflow processes.
Translates a business glossary into logical and physical data models, and coach/ supports data modelers, solution developers and data scientists in their development/ testing/ implementation effort.
POC implementations and roadmap definition.
Work with a wide variety of data ranging between structured and un-structured datasets
Own the KPIs to measure the performance of the data ecosystem and provide visibility to senior leadership team
Provide operation support for Information System.
Be a data advocate throughout the company

Qualifications
5+ years of experience in Enterprise environment working in data architecture/data warehouse, big data design and development.
BS/BA or MS/MA in Computer Science/ Data Science or related filed, or equivalent work experience highly preferred.
Data Management Association International certification as “Certified Data Management Professional” (CDMP) highly desired.
Expert level of experience working with SQL server and relational databases and data modeling.
Strong programming skills and experience designing and building large-scale data systems.
SAP BW and SAP4Hana exposure and knowledge is highly desirable.
Working experience with cloud-based data warehouse technologies such as Microsoft Azure is highly desired.
Strong experience working in an Agile (SCRUM, XP etc.) development environment is highly desirable
Familiarity with data visualization tools (e.g. PowerBi, SAC)
Knowledge of data mining and segmentation techniques
Proven analytical skills
Problem-solving attitude
DevOps knowledge

FGF DNA:
We are foodies and our passion is baked in...
Customer and Product Centricity -You are always keeping our products front and center.
Flexibility, Agility, Adaptability- You embrace speed, change and uncertainty.
Teamwork and Collaboration -You are a relationship builder.
Passion for Excellence -You look for innovative solutions and challenges the status quo.
Drives Execution -You are a risk taker!

www.fgfbrands.com/careers

Follow us on LinkedIn Follow us on Glassdoor Follow us on Instagram

Disclaimer: The above describes the general responsibilities, required knowledge and skills. Please keep in mind that other duties may be added, or this description may be amended at any time.

GenHO
IND1","fgf brands
4.5",Midtown Toronto
221,Data Architect,"Job Description:
We’re a naan traditional company…

What is the recipe for a great career at FGF?

Working at FGF Brands, there is never a dull moment! As a successful company that is continually growing there is always challenging yet rewarding work to be a part of. We have an entrepreneurial mindset which encourages all our team members to use their own creativity and out of the box thinking to come up with solutions and new ideas.

Let’s be frank. FGF is not for everybody. Our culture is unique. We dive headfirst into the unknown. If you’re fun-loving, talented and fearless, we’re for you.

What FGF Offers:
Disruptive and a naan-traditional mindset
An inclusive and dynamic culture
Accelerated career progression
Commitment to learning and development
Opportunity to be impactful
Competitive compensation

Data Architect

FGF brands is seeking an experienced Data Architect who will be responsible for the design and support of our data infrastructure and ecosystem. The position will be part of the Business Insight and Analytics team. The ideal candidate will not only possess great communication skills but will also be very technical and hands-on. Additionally, the candidate requires deep IT Service Management knowledge, coupled with broad technical knowledge, and the ability to design solutions by mapping business problems, providing end-to-end solutions combining process with technology.

Demonstrated ability to engage in discussions related to availability, agility, business value, security management, disaster recovery, and the value of process in an enterprise environment is required.
The ideal candidate will be self-motivated, a results-driven technologist, who is passionate about building a highly scalable data infrastructure, keeping up with FGF brands rapid growth.

Key Responsibilities

Defines data governance and standards to deliver a cohesive information architecture for FGF brands.
Define system level architecture and conduct dimension modeling & data mart design.
Owns data solution design, methodology approach, and system architecture development.
Provide direction and insight on FGF data strategy, defining the target state architecture and roadmap.
Take active role in building, delivering and execution of target state architecture.
Actively work on migrating data from legacy systems to new solutions.
Design, document, construct and deploy database architectures and applications (e.g. large relational databases)
Integrate technical functionality (e.g. scalability, security, performance, data recovery, reliability, etc.)
Optimize and improve current database system performance by conducting tests, troubleshooting, and integrating new elements.
Break down complex projects and problems into actionable tasks that be delivered quickly and iteratively and provide value to the business stakeholders
Coordinate with Data sciences department to identify future needs and requirements, supporting all Translates user requirements and business use cases to conceptual, logical, and physical data models and workflow processes.
Translates a business glossary into logical and physical data models, and coach/ supports data modelers, solution developers and data scientists in their development/ testing/ implementation effort.
POC implementations and roadmap definition.
Work with a wide variety of data ranging between structured and un-structured datasets
Own the KPIs to measure the performance of the data ecosystem and provide visibility to senior leadership team
Provide operation support for Information System.
Be a data advocate throughout the company

Qualifications
5+ years of experience in Enterprise environment working in data architecture/data warehouse, big data design and development.
BS/BA or MS/MA in Computer Science/ Data Science or related filed, or equivalent work experience highly preferred.
Data Management Association International certification as “Certified Data Management Professional” (CDMP) highly desired.
Expert level of experience working with SQL server and relational databases and data modeling.
Strong programming skills and experience designing and building large-scale data systems.
SAP BW and SAP4Hana exposure and knowledge is highly desirable.
Working experience with cloud-based data warehouse technologies such as Microsoft Azure is highly desired.
Strong experience working in an Agile (SCRUM, XP etc.) development environment is highly desirable
Familiarity with data visualization tools (e.g. PowerBi, SAC)
Knowledge of data mining and segmentation techniques
Proven analytical skills
Problem-solving attitude
DevOps knowledge

FGF DNA:
We are foodies and our passion is baked in...
Customer and Product Centricity -You are always keeping our products front and center.
Flexibility, Agility, Adaptability- You embrace speed, change and uncertainty.
Teamwork and Collaboration -You are a relationship builder.
Passion for Excellence -You look for innovative solutions and challenges the status quo.
Drives Execution -You are a risk taker!

www.fgfbrands.com/careers

Follow us on LinkedIn Follow us on Glassdoor Follow us on Instagram

Disclaimer: The above describes the general responsibilities, required knowledge and skills. Please keep in mind that other duties may be added, or this description may be amended at any time.

GenHO
IND1","fgf brands
4.5",Midtown Toronto
222,Senior Data Scientist,"About Us:

Propel (formerly MoneyKey) is an innovative Fintech Company that provides services and unsecured financial products to consumers via a safe and secure online platform. Propel was founded in 2011 in Toronto to remove the complexity and bureaucracy that people often experience while trying to borrow money, and to provide an underserved population with unsecured credit in a respectful way and with extraordinary service. Our goal is to provide our customers with a simple and convenient process!

Our amazing team has experienced phenomenal growth and thrives on an entrepreneurial spirit, passion, and top-tier talent. We believe in innovation and in measuring success through results and growing within; talent and hard work never goes unnoticed, and we succeed together.

About You:

You are a talented professional looking for a career, not a job. Reporting to the Chief Risk Officer, you will collaborate with business lines and other stakeholders and identify opportunities to drive business value. As a Sr. Data Scientist you’ll be working to uncover fraud and manage risk

You picture yourself succeeding within a vibrant and entrepreneurial organization where your ideas will be heard, and where you will have an opportunity to showcase your talents and great skills. You are motivated by goals, a self-starter, and a hardworking individual who likes to wear multiple hats. We are seeking a proven, driven team player who is looking to join a fast-paced, high growth, energetic and forward-thinking team.

Responsibilities

· Ingest massive volumes of structured and unstructured format data, model, transform and store it in a variety of data stores.

· Leverage distributed and open-source computing tools (e.g. Python, Jupyter, PyML) for analysis, data mining and modeling.

· Collaborate with Data engineering and operational teams to deploy models and algorithms in production, across different channels and customer platforms.

· Create and apply model and algorithm testing strategies to measure conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes.

· Prepare detailed documentation to outline data sources, models and algorithms used and developed.

· Present results to business line stakeholders and help implement real data-driven changes.

· Design and Develop statistical models for usage in: Underwriting, Existing Customer Management, Marketing Campaigns, and Collection/Recovery.

· Assessing, cleaning, merging, and analyzing large datasets.

· Design and Develop business logic, pricing strategies, business forecasts, while optimizing profitability.

· Utilize advanced statistical software to develop linear/non-linear, parametric/non-parametric, and classical/machine learning based predictive modeling/data mining analytic methodologies to minimize credit/fraud losses, maximize response and approval rates, and/or profitability of products.

· Assist with the implementation of scorecards

· Writing of clear and detailed model documentation.

· Provide solutions and ideas to business partners to solve complex modeling and other analytic problems.

Requirements

· University degree in relevant STEM disciplines (Mathematics, Computer Sciences, Electrical/Computer/Software Engineering).

· Minimum M.S./M.A. in a highly quantitative field (Statistics, Economics, Mathematics, Computer Science or other quantitatively-oriented degree).

· Strong quantitative/statistical modeling capabilities, along with 2-3 years of experience in credit scoring and model development.

· 3-4+ years of experience within the consumer lending environment preferred.

· Production experience with experimental design, statistical analysis, machine learning and predictive modeling (e.g., cross-sell, upsell, attrition, acquisition and lookalike models).

· Programming skills in Java, R or Python.

· Experience with common machine Learning libraries in R, Python, Spark.

· Experience with UNIX tools and shell scripting.

· Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL).

We welcome and encourage applications from individuals from all groups, including aboriginal, women, visible minorities, and persons with disabilities, regardless of race, ethnicity, sexual orientation, creed, family status, national origin, age and gender.

We thank all applications for showing an interest in this position. Only those selected for an interview will be contacted. No agencies or phone calls.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Dental care
Life insurance
Paid time off
RRSP match

Schedule:

8 hour shift

Education:

Bachelor's Degree (required)

Experience:

consumer lending environment: 3 years (preferred)
quantitative/statistical modeling capabilities: 3 years (required)

Work remotely:

Temporarily due to COVID-19","Propel Holdings
3.1",Midtown Toronto
223,Data Engineer,"ABOUT US

CI Global Asset Management is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.


POSITION: Data Engineer
LOCATION: Toronto (M5J 0A3)
STATUS: Full-time


JOB OVERVIEW

We are currently seeking a Data Engineer to join our IT - Client Reporting & Data Management team. The successful candidate will be responsible for optimizing our enterprise data pipeline to support delivery of enriched data for BI and Advanced Analytics consumption for Portfolio Managers. The successful candidate will become an integral part of our team by applying their proven data engineering ability to define and drive fit for purpose data pipeline solutions.


WHAT YOU WILL DO

Design & build large-scale data pipelines and data infrastructure leveraging the wide range of data sources across the organization
Document & assist development teams with best practice, data delivery solutions using enterprise data ingestion, ETL and data management tools
Work closely with infrastructure teams to ensure an optimal data & advanced analytics platform, for current and future state
Clean, prepare and optimize datasets, ensuring lineage and quality controls are applied throughout the data integration cycle
Support Business Intelligence Analysts in modelling data for visualization and reporting
Stay current with advanced technologies, including AI/Machine learning, Data Management, and Cloud Data Storage techniques


WHAT YOU WILL BRING

Experience

3 years of proven experience as a Data Engineer in a Big Data environment
Experience with integrating structured and unstructured data across various platforms and sources
Hands on experience with the AWS suite of services supporting big data (S3, Redshift, Lambda, Athena, EMR, Glue, RDS and others)
Experience in the Financial Services specifically in Portfolio Management would be preferred
Experience in interacting with common Portfolio Management tools such as BARRA, Factset, Charles River and Bloomberg would be preferred
Experience with Master Data Management tools and processes would be an asset

Education/Training

Bachelor’s degree in Computer Science, Engineering or a related field

Knowledge, Skills, and Abilities

Proficient in Python, Java, SQL & related languages
Proficient in SQL database management systems
Knowledge of Talend ETL and related suite of tools an asset
Confident & versatile IT professional with the ability to communicate effectively across all levels of the Business and IT community


WORKING CONDITIONS:

Routine office environment


WHAT YOU CAN EXPECT FROM US

Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:

Recognition & Compensation
Training & Development
Health & Well-being
Communication & Feedback


If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.

Only qualified candidates selected for an interview will be contacted.

CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.


Posting Tags: IND#","CI Financial
3.4",Midtown Toronto
224,"Data Scientist, Fall 2021 Student Opportunities (8 Months Only)","What is the opportunity?
Who wouldn't want to be a part of a fantastic team of Data Scientists? At RBC, our Data Science teams offer the opportunity to leverage RBC’s data assets to develop innovative solutions in support of RBCs big data strategy. This position is an essential part to the bank as you develop next-generation applications to meet our customers’ needs. By joining the RBC team as a Data Scientist, you will have the opportunity to analyze, design and implement data solutions to assist all business customers.


Please only apply if you are available for 8 months.


What will you do?

Utilize the latest technologies available, designing and building data solutions to meet business needs
Be an active contributor to not only your individual team, but to the RBC development community
Constantly seek out better ways to do things, new tools, new technologies, new processes
Work on transformational projects delivering new value
Work as part of an agile team responsible for end-to-end delivery of business needs
Deploy production-scale solutions using the Hadoop Ecosystem, transforming statistical and machine learning models from single node architecture to parallel processing grid technology
Use business domain knowledge to independently lead the analytics process to identify valuable and innovative insights
Promote analytics across the enterprise to enable RBC to become a data-driven organization


What do you need to succeed?

Must-have:

Programming skills in one or more of the following languages: Python or R
Experience utilizing SQL scripts/querying
Proficient in building statistical and algorithmic models with complex and large datasets, including but not limited to: supervised statistical learning, clustering, natural language processing, recommendation systems, times-series analysis, experimental design (A/B testing), data visualization, deep learning
Ability to data extract, transform, and load processes with a variety of data types
Ability to perform complex data analysis on large volumes of data and present findings to stakeholders


Nice to have:

Experience with big data technologies, primarily in machine learning and statistics function
Exposure to Apache Spark, Hadoop and Public Cloud technologies, data serialization (JSON, Avro, Parquet, ORC)
Experience with big data processing tools like Spark and Hive, GitHub functionality and workflow experience/exposure
Experience with messaging (Kafka, Solace, RabbitMQ) & working on Agile projects


What’s in it for you?
We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients succeed. We care about each other, reaching our potential, making a difference to our communities and achieving success that is mutual. Visit people.rbc.com


Continued career advancement opportunities
Exposure to strong mentorship and leadership examples
A world-class training program in financial services
Opportunities to be a valuable member of a close-knit, collaborative team that encourages networking
A comprehensive Total Rewards Program including bonuses and flexible benefits
Competitive compensation


We encourage you to apply as soon as possible as we accept applications on a rolling basis, but please note that the formal application deadline is June 27, 2021. Should you be selected to progress, someone from our team will reach out directly to provide instructions on next steps. Otherwise, feel free to check for progress updates by logging in to your RBC profile. If the status has not changed, it denotes the fact that your application is still under review.

While there is no one date when our employees will return, we can confirm that the majority of Fall Work Integrated Learning | Co-op positions will start working remotely, however may transition to working at an RBC office as essential service restrictions are lifted.


TAD2021


Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Virtual
Address: Virtual
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: [[filter7]]
Career Level: Student Job
Application Deadline: 06/27/2021
Platform: Technology and Operations
Req ID: 375217
Ad Code(s):","RBC
4.1",Ontario
225,Major Projects Data Scientist,"Major Projects Data Scientist - ( 210000H9 )

Description

Your Opportunity

Stantec is seeking a Major Projects Data Scientist to join our Project Risk Review team. This position is based in Vancouver, BC, Canada.

Our Project Risk Review team manages Stantec’s corporate risk review practice, using data-driven insight to support Major Projects teams across all business lines through the pursuit and execution of Stantec’s largest and most complex engineering and architecture projects. This position reports directly to the CPO and offers exposure to the broader business with frequent interaction and mentorship from executive leadership throughout our global organization. This opportunity would appeal to individuals interested in gaining a unique professional development experience, applying advanced data science, visualization, and machine learning techniques on complex business and risk management problems. The ideal candidate would establish a one-of-a kind foundation and professional network to be at the forefront of business intelligence within the project management and engineering consulting industry.

Your Key Responsibilities

Develop and optimize machine learning and statistics models to support the Project Risk Review practice, liaising with Stantec’s executive leadership and project teams across all business lines and regions to review, issue go-conditions, track, and report on Major Projects worth over $15B in fees.
Lead the development of project and partner analytics, objective risk metrics, and machine learning tools to assess enterprise risk supporting executive leadership decision-making with data-driven insight.
Prepare and present quarterly risk management and major projects tracking reports identifying risk review trends and examining pursuit and project execution outcomes for executive leadership.
Lead the development and evolution of BI and collaboration tools supporting the Project Risk Review processes to drive efficiency, improve data management practices, and streamline workflows utilized company wide.
Create a single source of truth by consolidating our various data models and queries
Create and enforce software engineering best practices to analytics code through version control, testing, and continuous integration.
Support ad-hoc tasks and projects as required
Provide comprehensive analysis of current state of practice, identify best data sets, data science methodologies, algorithms, tools and infra needed to generate models to support the planned ML-based investments

Qualifications

Your Capabilities and Credentials:

A strong understanding of addressing business needs through the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques
You are a collaborative, creative, open-minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ML-driven models through an iterative approach
A strong track record of performing data analysis and machine learning model development using Python, R, and SQL
Excellent interpersonal and communication skills; ability to communicate complex results with confidence to technical and non-technical audiences and stakeholders (Stantec leadership and project personnel) daily.
Must have experience with Machine Learning (Supervised and Unsupervised), Classification, Clustering, Segmentation, Time Series Analysis, NLP, Demand Forecasting and Optimization
Must be an effective ‘team player’ who has a demonstrated ability to work intuitively with minimal supervision, and possess qualities of professionalism, assertiveness, maturity and judgement.
Excellent attention to detail, time management and organization skills with a proven commitment to follow-up and follow-through
Ability to multi-task, adapt and prioritize tasks to meet deadlines in a very dynamic environment; the role requires the ability to handle interruptions and balance numerous and shifting priorities, and assist with multiple projects simultaneously
Ability to apply detailed solutions to “big picture” thinking
Knowledge of Risk Management frameworks and risk management concepts within a business, consulting or construction environment would be an asset.
You are well versed in software and AI development lifecycles
Data visualization experience: PowerBI, R (ggplot, shiny)
Database experience: MS SQL, Oracle
Development experience: R, Python (familiar with packages such as numpy, pandas, tensorflow, pytorch, scikit-learn, matplotlib, etc. and equivalent packages in R)

Education and Experience

Completed, or in the process of completing, a Bachelor’s or Master’s Degree in a field such as Data Science, Computer Science, Mathematics, Engineering, or Statistics.
0-3 years of work experience
Knowledge of engineering and construction terms and contracting practices

[Working conditions, special requirements]

Typical office environment working with computers. Sedentary; no field work required. A combination of remote working and in-office collaboration anticipated.

Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best.

Primary Location : Canada-British Columbia-Vancouver

Job : IT Generalist

Organization : BC-1303 CPO-Canada

Employee Status : Regular

Job Level : Individual Contributor

Travel : No

Schedule : Full-time

Job Posting : Mar 8, 2021, 11:28:32 AM

Req ID: 210000H9

Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","Stantec
3.8",Vancouver
226,Major Projects Data Scientist,"Major Projects Data Scientist - ( 210000H9 )

Description

Your Opportunity

Stantec is seeking a Major Projects Data Scientist to join our Project Risk Review team. This position is based in Vancouver, BC, Canada.

Our Project Risk Review team manages Stantec’s corporate risk review practice, using data-driven insight to support Major Projects teams across all business lines through the pursuit and execution of Stantec’s largest and most complex engineering and architecture projects. This position reports directly to the CPO and offers exposure to the broader business with frequent interaction and mentorship from executive leadership throughout our global organization. This opportunity would appeal to individuals interested in gaining a unique professional development experience, applying advanced data science, visualization, and machine learning techniques on complex business and risk management problems. The ideal candidate would establish a one-of-a kind foundation and professional network to be at the forefront of business intelligence within the project management and engineering consulting industry.

Your Key Responsibilities

Develop and optimize machine learning and statistics models to support the Project Risk Review practice, liaising with Stantec’s executive leadership and project teams across all business lines and regions to review, issue go-conditions, track, and report on Major Projects worth over $15B in fees.
Lead the development of project and partner analytics, objective risk metrics, and machine learning tools to assess enterprise risk supporting executive leadership decision-making with data-driven insight.
Prepare and present quarterly risk management and major projects tracking reports identifying risk review trends and examining pursuit and project execution outcomes for executive leadership.
Lead the development and evolution of BI and collaboration tools supporting the Project Risk Review processes to drive efficiency, improve data management practices, and streamline workflows utilized company wide.
Create a single source of truth by consolidating our various data models and queries
Create and enforce software engineering best practices to analytics code through version control, testing, and continuous integration.
Support ad-hoc tasks and projects as required
Provide comprehensive analysis of current state of practice, identify best data sets, data science methodologies, algorithms, tools and infra needed to generate models to support the planned ML-based investments

Qualifications

Your Capabilities and Credentials:

A strong understanding of addressing business needs through the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques
You are a collaborative, creative, open-minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ML-driven models through an iterative approach
A strong track record of performing data analysis and machine learning model development using Python, R, and SQL
Excellent interpersonal and communication skills; ability to communicate complex results with confidence to technical and non-technical audiences and stakeholders (Stantec leadership and project personnel) daily.
Must have experience with Machine Learning (Supervised and Unsupervised), Classification, Clustering, Segmentation, Time Series Analysis, NLP, Demand Forecasting and Optimization
Must be an effective ‘team player’ who has a demonstrated ability to work intuitively with minimal supervision, and possess qualities of professionalism, assertiveness, maturity and judgement.
Excellent attention to detail, time management and organization skills with a proven commitment to follow-up and follow-through
Ability to multi-task, adapt and prioritize tasks to meet deadlines in a very dynamic environment; the role requires the ability to handle interruptions and balance numerous and shifting priorities, and assist with multiple projects simultaneously
Ability to apply detailed solutions to “big picture” thinking
Knowledge of Risk Management frameworks and risk management concepts within a business, consulting or construction environment would be an asset.
You are well versed in software and AI development lifecycles
Data visualization experience: PowerBI, R (ggplot, shiny)
Database experience: MS SQL, Oracle
Development experience: R, Python (familiar with packages such as numpy, pandas, tensorflow, pytorch, scikit-learn, matplotlib, etc. and equivalent packages in R)

Education and Experience

Completed, or in the process of completing, a Bachelor’s or Master’s Degree in a field such as Data Science, Computer Science, Mathematics, Engineering, or Statistics.
0-3 years of work experience
Knowledge of engineering and construction terms and contracting practices

[Working conditions, special requirements]

Typical office environment working with computers. Sedentary; no field work required. A combination of remote working and in-office collaboration anticipated.

Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best.

Primary Location : Canada-British Columbia-Vancouver

Job : IT Generalist

Organization : BC-1303 CPO-Canada

Employee Status : Regular

Job Level : Individual Contributor

Travel : No

Schedule : Full-time

Job Posting : Mar 8, 2021, 11:28:32 AM

Req ID: 210000H9

Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","Stantec
3.8",Vancouver
227,Senior Data Scientist,"We're transforming the grocery industry

Instacart is the North American leader in online grocery and one of the fastest-growing companies in e-commerce. Since 2012, we've been working towards creating a world where everyone has access to the food they love and more time to enjoy it together.

Groceries delivered to your door in as little as an hour. It seems simple, right? Well, it's more complex than that. From re-routing deliveries during snowstorms, to connecting customers with coupons and deals for their favorite brands, to updating over half a billion grocery data lines every night...our efforts bring Instacart closer to being the operating system for the grocery industry.

Solving these problems is what helps our customers get back time in their day, so they can do more of what they love.

Introducing Our Hybrid Working Model

As the future of work evolves, so do we. We have a hybrid model where our roles are open to in-office, flex, or remote work. Learn more about our flexible approach to where we work.

OVERVIEW

You will be joining a growing data science team and will tackle some of the most challenging and impactful problems that are transforming how people buy groceries every day. You will be embedded within our data-driven product team as a trusted partner in uncovering barriers in the product's usability and utilize these insights to inform product improvements that drive angle-changing growth. We're looking for a self-driven, strategic thinker who can hit the ground running to ultimately influence decision-making across the entire organization.

ABOUT THE JOB

Own analytical frameworks that guide the product roadmap

Design rigorous experiments and interpret results to draw detailed and actionable conclusions

Develop statistical models to extract trends, measure results, and predict future performance of our product

Build simulations to project impact of various product and policy interventions

Enable objective decision making across the company by democratizing data through dashboards and other analytical tools

Use expertise in causal inference, machine learning, complex systems modeling, behavioral decision theory etc. to shape the future of Instacart

Present findings in a compelling way to influence Instacart's leadership

ABOUT YOU

5+ years experience working in a quantitative role at a product company or a research organization

Ability to run rigorous experiments and come up with scientifically sound recommendations

Ability to write complex, efficient, and eloquent SQL queries to extract data

Ability to write efficient and eloquent code in Python or R

A desire to build and improve consumer software products

Ability to translate business needs into analytical frameworks

Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic environment, and a growth mindset needed to build a successful team and company

#LI-Remote","Instacart
3.7",Ontario
228,Data Scientist - 312112,"Data Scientist

On behalf of our client in the Banking Sector, PROCOM is looking for a Data Scientist.

Data Scientist – Job Description

The contractor is responsible for developing and implementing quantification methodologies for Business Banking credit risk parameters, which are key drivers to the risk rating system, internal processes and regulatory processes
Develop, implement and maintain risk quantification methodologies for non-retail credit risk parameters such as PD, LGD and UGD
Perform research and analysis of applicable methodologies; present and recommend appropriate alternatives; implement estimation methodologies
Benchmark internal estimates with external models and/or data sources; provide analysis and recommend actions as appropriate
Implement and maintain a rigorous framework of internal controls and comprehensive documentation for various applications and databases used in parameter estimation
Communicate results of analyses through documentation to internal/external audiences, and effectively manage the interface with relevant parties such as Validation, Audit, and Regulators
Keep abreast with advances in credit risk analytics developments, products, and applications by vendors, consultants, regulatory agencies and competitors. Recommend/develop enhancements appropriate for the Bank

Data Scientist – Mandatory Skills

Excellent computing development skills, particularly statistical and database modeling tools (i.e., SQL, Python, SAS, R, Access/VBA, etc.) well-developed ability to adapt to various programming languages and environments
1 year of hands-on experience in quantitative analysis and machine learning; exposure to quantitative analysis related to credit risk management and modeling is preferred
In-depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte-carlo simulation and bootstrapping techniques
Well-developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses
Ability to efficiently manage multiple priorities to ensure timely delivery
Attention to details, independence, and ability to effectively collaborate in teamwork
Flexibility and creativity in problem solving
A graduate degree (or equivalent) in Statistics, Computer Science or comparable quantitative discipline that includes rigorous exposure to statistical knowledge and techniques

Data Scientist – Nice to Have Skills

1+ years of experience in hands-on quantitative/statistical analysis, preferably related to the non-retail credit risk area in a major financial institution

Data Scientist - Assignment Start Date

ASAP – 12 months to start

Data Scientist - Assignment Location

Toronto, ON – Work Remotely","Procom
4.3",Midtown Toronto
229,"Senior Data Scientist, NLP Natural Language Processing","Introduction
As a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
IBM Watson Health is looking for talented individuals destined to usher in the next era of healthcare. We live in a moment of remarkable change and opportunity. The convergence of data and technology is transforming healthcare and life sciences organizations today. New opportunities are being created that never existed before to meet the demands of this transformation.

The Rapid Development team is a group of Scientists and Cognitive Software Developers within IBM Watson Health Imaging. In collaboration with cross-functional Watson Health teams, IBM Research and external partners, the team develops cognitive solutions that combine imaging and clinical data to enhance clinical decision making. The team is responsible for developing and validating robust and scalable cognitive services (text analytics and image analytics) and applications, including validation and evaluation of technologies being transferred from Research and other collaborators. The team follows Agile and DevOps methodologies to enable rapid iteration and responsiveness.

We are looking for self-motivated and driven candidates that are passionate about working on cutting edge technologies and that thrive in a highly collaborative environment.

Job Responsibilities
Design and development of robust algorithms and techniques using text analytics, Natural Language Processing (NLP) and machine learning
Rapid development and validation of cognitive solutions by using and/or enhancing existing methodologies, frameworks and architecture
Development of criteria for testing algorithm and system’s cognitive performance objectively from end-user and market perspective. Conduct performance evaluation and testing of algorithms and systems on test and real clinical data
Work with clinical collaboration and joint development partners to develop cognitive solutions
Support collection and annotation of data for algorithm development and evaluation
Integration of cognitive systems and components in Watson Health architecture, including Watson Health cloud
Planning, processing and performing all jobs in an efficient manner with minimum supervision
Conduct product development in compliance with Watson Health’s methodology, practices and Quality Management system.

Required Technical and Professional Expertise

3-5 years experience with solving real-world problems using Data Analytics, Natural Language Processing (NLP), and Machine Learning
Strong experience in Machine Learning, including deep learning and statistical models
Strong Programming skills (Java/J2EE, C++, Python) and experience with software systems architecture, web services, web applications, and current software development tools, technologies and frameworks
Strong publication record in peer-reviewed conferences and journals
Demonstrated communication and cross-functional collaboration skills;
Fluent in English, spoken and written

Preferred Technical and Professional Expertise

Strong knowledge of clinical information analytics domain, having applied NLP and machine learning techniques on unstructured data in EMRs
Interest or experience with healthcare information protocols and common interoperability standards, such as IHE, HL7, DICOM, XDS and IHE, and healthcare systems such as PACS, EMR, EHR, HIS and RIS;
PhD in Text Processing / NLP applied to medical reports

Must have the ability to work in Canada without sponsorship.
About Business UnitIBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementThis role will involve working with technology that is covered by Export Regulations sanctions. If you are a Foreign National from any of the following US sanctioned countries (Cuba, Iran, North Korea, and Syria) on a work permit, you are not eligible for employment in this position.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","IBM
3.9",Mississauga
230,Senior Data Scientist,"Miovision’s mission is to provide the foundation for tomorrow’s smart cities by transforming the way traffic networks are managed today. Backed by the world’s most advanced traffic AI, Miovision’s innovations in traffic signal planning and operations have made it possible for cities to improve the transportation experience for drivers, cyclists and pedestrians since 2005. With offices in Kitchener, Canada and Cologne, Germany, Miovision serves over 17,000 municipalities worldwide. For more information, visit www.miovision.com

Position Summary

Miovision is looking for a Senior Data Scientist who is passionate about using data to improve transportation networks all over the world. We have collected a variety of datasets from transportation networks globally, spanning multiple years. We are looking for a data scientist to “live in the data”; determining the right questions to ask of the data, and to communicate the resulting insights.

We want you to apply a variety of techniques, such as data analysis, statistical modelling and machine learning, to help our customers solve real-world traffic problems. You will collaborate with data scientists, software developers, traffic engineers and computer vision specialists to develop data-driven, customer-facing solutions for a web-based analytics platform.

Key Accountabilities

This role’s main responsibility is to generate and own insights from these data.

Other accountabilities are to:

Prepare, manipulate and analyze data from real-world intersections
Build and own customer-facing models around real-time, 24/7 traffic data
Identify new sources of traffic data to combine with existing data sets
Research and implement new tools and techniques to solve novel problems
Drive improvements to data quality and completeness across the company
Frequently communicate insights and analyses with relevant departments
Master Miovision’s data stores and determine best practices for analyzing them
Understanding of current data collection techniques and biases/gaps

Skills/Qualifications

5+ years experience with data analysis, statistical analysis, predictive modeling, machine learning, or deep learning
Proficiency in one or more data-related programming languages; Python and SQL are preferred
Experience with data visualization tools
Experience with developing, validating and deploying models deployed in a production environment is an asset
Propensity to dive into new datasets, identify patterns or issues, and drive insights
A desire to ask and answer questions using data
Eagerness to share new results across multiple disciplines

Perks and Benefits

Note: The majority of Miovision employees are continuing to work from home due to COVID-19 Public Health regulations. When it is safe to do so, we plan on a cautious reopening of our Canadian office but will continue to offer flexible onsite and remote work options. Our Benefits are designed to reflect this and include:

Comprehensive health benefits starting on day one
RRSP Matching Plan
Mio-Days: We extend all three-day weekends to four-days and provide a Holiday Shutdown in December
Virtual Healthcare Service providing employees and their families access to healthcare providers 24/7
Internet subsidy and a remote work allowance
Enhanced paternity and maternity leaves
Unlimited vacation policy
Virtual fitness classes

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Please indicate if you require accommodation on your application, and our team will work with you to meet your accessibility needs.

8qRZxAAvqv","Miovision
4.5",Remote
231,Senior Data Scientist / Scientifique des données senior,"The opportunity

Unity Monetization team builds advertising, in-game purchase promotion, and technologies used in hundreds of thousands of apps. Our Monetization platform processes TBs of data and delivers relevant content to hundreds of millions of users every day. Unity is investing heavily in deep learning.

In Montreal, we develop groundbreaking machine learning-centric products that provide millions of predictions each and every second to optimize the efficiency and profitability of user acquisition advertising campaigns.

We are looking now for a Senior Data Scientist to join our growing team! You will have a huge impact on scoping out, contributing, and delivering on new Monetization initiatives. Unity's vast game monetization ecosystem provides you unique chances to create real-world impact.

What you'll be doing

Improve and develop deep learning models to revolutionize user acquisition advertisement for mobile gaming

Drive Unity's user acquisition product in close collaboration with other data scientists, product managers, and engineers

Initiate and define new business opportunities and products based on data insights

Convey ideas, guide execution, and mentor junior team members

What we're looking for

Strong background in deep learning, from concepts to implementation

Production experience of machine learning systems at scale

Proven focus on delivering business value

Good coding skills and engineering practices, familiar with agile software process and data-driven development

Work with the tech stack of Python/BigQuery/Spark/TensorFlow/Kubeflow/Airflow

You might also have

Experience in mobile advertisement and gaming

Background in business analytics or software engineering

Experience in container technologies (Docker, Kubernetes)

Life at Unity

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com .

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

L'opportunité

L'équipe Monetization de Unity crée des publicités et des promotions pour les achats intégrés au jeu, ainsi que des technologies utilisées dans des centaines de milliers d'applications. Notre plateforme de monétisation traite au quotidien plusieurs téraoctets de données, pour fournir un contenu pertinent à des centaines de millions d'utilisateurs. Unity investit massivement dans l'apprentissage profond.

L'équipe de Montréal développe des produits révolutionnaires centrés sur l'apprentissage machine qui fournissent des millions de prévisions chaque seconde, afin d'optimiser l'efficacité et la rentabilité des campagnes publicitaires d'acquisition d'utilisateurs.

Nous sommes désormais à la recherche d'une ou d'un scientifique des données sénior qui rejoindra une équipe en pleine expansion! Vous contribuerez grandement à l'élaboration, à la mise en œuvre et à la réalisation de nouveaux projets de monétisation. L'écosystème de monétisation des jeux de Unity est immense et vous offre des possibilités uniques de produire un impact réel.

Ce que vous allez faire

Développer et améliorer des modèles d'apprentissage profond destinés à révolutionner la publicité liée à l'acquisition d'utilisateurs pour les jeux sur mobile

Diriger les projets d'acquisition d'utilisateurs de Unity en étroite collaboration avec les scientifiques des données, les chefs de produits et les développeurs issus d'autres équipes

Lancer et définir de nouvelles possibilités commerciales et de nouveaux produits sur la base des données recueillies

Communiquer les idées des uns et des autres, guider l'exécution des projets et encadrer les équipiers moins expérimentés

Ce que nous recherchons

Une expérience importante en matière d'apprentissage profond, depuis la conception jusqu'à la mise en œuvre

Expérience de la production de systèmes d'apprentissage machine à grande échelle

Priorité confirmée à la production de valeur commerciale

Bonnes compétences dans les domaines du codage et des meilleures pratiques d'ingénierie, connaissance des processus logiciels agiles et du développement piloté par les données

Travailler avec la pile technologique Python/BigQuery/Spark/TensorFlow/Kubeflow/Airflow

Vous avez peut-être également

Expérience dans la publicité et les jeux sur mobile

Expérience en matière d'analyse commerciale ou logicielle

Expérience en matière de technologies de conteneurs (Docker, Kubernetes)

La vie chez Unity

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com .

Unity est un employeur axé sur l'égalité qui s'engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d'emploi qui ne tiennent pas compte de l'âge, de l'ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l'identité sexuelle ou d'un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n'hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n'acceptons pas d'être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-DD1 #SEN","Unity Technologies
4.6",Montreal
232,Senior Data Scientist,"Status: Remote work from any Canadian location. Work location may be re-evaluated based on pandemic status. This is a temporary full-time role, covering a 14 to 16-month leave.

We're looking for a Senior Data Engineer to support Data Science initiatives for top tier eCommerce clients such as Costco, Sam's Club, Staples and FedEx.

As a senior member of the Data team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional, and the ideal candidate will work across disciplines. You are able to iterate quickly on all stages of data pipeline and you will develop large scale data pipelines and analytical solutions using Big Data (and streaming) technologies.

The successful candidate has strong communication and engineering skills. You will need to have a passion for quality and an ability to understand sophisticated systems.

Responsibilities:

Design, model and develop data sets to support reporting analytics and exploratory analysis.
Research and employ cutting edge techniques to build and design the data infrastructure for distributed processing, aggregation, and collection of streamed real-time data.
Architect and build data delivery solutions in a microservice environment.
Contribute to technical design and ongoing development of our custom ETL solutions and analytics platforms, and help improve of design and delivery standards.
Focus on automation and optimization for all areas of DW/ETL maintenance and deployment.
Work with big data developers to build scalable and supportable infrastructure.
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together.
Assess and recommend the implementation available and latest big data technologies.
Recommend ways to improve data reliability, efficiency and quality.
Responsible for developing the data architecture components that scales for the ever evolving data needs of the entire company.
Solve big data warehousing problems on a massive scale and apply cloud-based services to solve challenging problems around: big data processing, data warehouse design, and enabling self-service.
Collaborate effectively with other members of the team and broader services group, including but not limited to Product Team, Data Science Team, Development Teams and Release and Operations Teams

Requirements:

Min Bachelor of Computer Science ideally Masters in Data
7+ years of Data Engineering or similar experience.
Experience in high level programming languages such as Java, Scala, or Python.
Proficiency with databases and SQL is required.
Experience working with large data sets - both SQL and NoSQL databases (e.g. MySQL, PostgreSQL, DynamoDB, etc.).
Experience building ETLs and data pipelines using tools such as Apache Airflow and Spark.
Experience working with cloud technologies (Azure, AWS).
Demonstrated ETL/data programming skills (using scripts or products like Informatica, DataStage).
Experience with DevOps practices, CI/CD, managing production deployments, Git and GitHub.
Ability to communicate design, concepts and decisions both verbally and in writing.
Ability to mentor other data engineering talent in the team.
Experience with large scale data warehousing, mining or analytic systems.
Ability to work with analysts to gather requirements and translate them into data engineering tasks.
Awareness of security, performance, high-availability and fault-tolerance and best practices.
Aptitude to independently learn new technologies.

Nice to have skills:

Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Experience building real time data pipelines using Apache Kafka.
Experience with virtualization, containers, and orchestration (Docker, Kubernetes).
Knowledge of data visualization and reporting tools like Tableau.
Experience with AWS EMR, AWS DMS, Talend, Apache Airflow, Stitch.
Experience with Amazon Web Services - RDS, EC2, S3, Lambda, Amazon Redshift.

About PNI Media:
At PNI, we're fueled by fun times, great experiences, and passion for the work we do. Over 25 million consumers use our platform each day to create and order millions of products from leading brand companies, and we're committed to delivering customers a high-quality experience. We know that healthy, happy people create amazing things, so we deliver a top tier experience for our employees, too: creative perks and benefits; a dynamic work environment; and a culture that honours diversity, wellbeing, community interaction and employee development. We're proud of PNI's achievements, our people, and our place at the top of the market.

Contract length: 14 - 16 months

Job Types: Full-time, Temporary

Salary: $2.00-$4.00 per year

Benefits:

Casual dress
Company events
Work from home

Schedule:

8 hour shift
Monday to Friday

COVID-19 considerations:
Remote virtual interviews, and COVID-19 precautions in place for in-person interviews.

Education:

Bachelor's Degree (required)

Experience:

data engineering or similar: 7 years (required)

Work remotely:

Temporarily due to COVID-19","PNI Media
3.9",Vancouver
233,"Educator, Data Scientist","BrainStation is the global leader in digital skills training and development, offering a 12-week accredited Diploma program in Data Science. BrainStation is currently seeking a full-time Data Science professional (40 hours per week) to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities

Lead our 12-week Data Science Diploma program

Help build a world class technical team

Deliver lectures and mentor the next wave of Data Science talent

Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses

Actively work on writing and researching new content to teach the most up to date skills in data science to our students

Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students

Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material

Define the education experience of the future

Successful candidates will have

4+ years experience as a Data Scientist or Analytics professional and at least a Master's degree relevant to the subject matter

Experience building and leading teams

Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles

Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner

Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job

An empathetic, friendly, and approachable demeanor

A proven ability to work under pressure and meet deadlines

Ability to teach the entire program in English

Teaching experience in Canada preferred

While not required, a PhD would be preferred.

Perks and Benefits

Flexible Vacation Policy

Health & Wellness Programs

Culture of Learning & Development

New Shiny Device Upgrades

Compensation includes an annual salary commensurate with experience ($85K-110K) full health and medical benefits, and RRSP matching.

About BrainStation

BrainStation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, London, Toronto, and Vancouver. Founded in 2012, BrainStation has worked with over 400 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 100,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.


Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings .
NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.","BrainStation
3.7",Midtown Toronto
234,Lead Data Scientist,"While people dream of a better energy future, Peak Power is building it. Founded in 2015, Peak has developed a comprehensive software platform that alleviates strain on the electricity grid and drives value to owners of clean energy assets, buildings, and electric vehicles through electricity markets. Our Synergy software platform optimizes the operation of distributed energy resources by forecasting and predicting the behavior of electricity markets.

Reporting to the VP of Innovation, you will have the opportunity to work with a talented group of Data Scientists, Data Engineers, and business stakeholders in a fast-paced and exciting environment. As a Lead Data Scientist, you will guide a team on a mission to provide insights and predictions to our customers. Using large volumes of data from our production applications, you will use your people, process, and technology skills to solve fascinating problems.

This work matters. Even a small change to optimize power utilization can significantly impact our customers, our electrical grid, and our environment. We’re building something that will have a lasting, positive impact.


Our new Lead Data Scientist will:

Lead the development of machine learning models, such as energy demand prediction, to provide insights and automation for our customers and have a good understanding of the company’s business model/strategy
Lead analytics projects involving multiple analysts and business stakeholders to optimize the accuracy of predictions
Have a global vision of the whole projects as well as the company’s goal
Collaborate and lead the teams in feature extraction, data representation, and automatic data pipeline and collection design, as well as data quality assurance monitoring
Provide an expert opinion on data-related topics such as validation of assumptions, use of advanced statistical techniques and hypothesis testing, and product decisions related to data
Use data visualization tools to deliver insights to stakeholders to create new business opportunities.
Stay current with the latest cloud computing, machine learning, and data science technologies
Experiment with new models and techniques and be able to provide model improvement solution continuously

What you bring to Peak Power:

Master’s degree in data science, computer science, applied math, or a related technical field
5+ years of experience with applied data science, from requirement gathering to serving models, to solve business problems and create value for customers
Experience with SQL and NoSQL databases
Working with large data sets and familiar with big data platforms such as Hadoop, PySpark, and Kubernetes, etc.
Solid understanding of machine learning, deep knowledge of advanced statistical techniques and concepts, machine learning techniques, and expertise in their applications with advanced knowledge of languages/libraries such as pandas and Scikit-Learn;
Experience with computer vision and familiar with significant computer vision libraries such as TensorFlow/Keras, PyTorch, and OpenCV
Experience building machine learning pipelines, such as with Amazon SageMaker
Strong people, process, and technical leadership abilities
Excellent communication and collaborative problem-solving skills
Continuously learning new frameworks and technologies to generate innovative solutions


So why Peak Power?

We are focused on solving problems that impact energy markets both locally and around the world. We are a growth-stage clean technology company that has partnered with major names in real estate, electricity, and smart city spaces. To work with us is not only to work with an exciting company, but to also be on the cutting edge of the global transition to distributed, clean, and carbon-free energy.


Join us!

Peak Power is an equal opportunity employer. We welcome people of different backgrounds, experiences, abilities, and perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process.

CUtsWX48r1","Peak Power
5.0",Midtown Toronto
235,Senior Data Scientist,"Come to work for Realtor.com! A leader in online real estate and backed by industry experience and the News-Corp Brand, Realtor.com's vision is to be the leading destination to discover and create your perfect home, and today millions of unique users visit our company's website and mobile apps monthly. What you can do at Realtor.com has the potential to touch people in a real and meaningful way.

At realtor.com, we process terabytes of data everyday and transform that data into information that powers decisions for millions of home buyers, sellers, renters, dreamers, and real estate professionals. You'll engage with some of the best and the brightest co-workers and leaders, learn and contribute, and have a great time. If you enjoy working in a fast-paced, dynamic, cutting-edge work environment and desire to make a meaningful contribution to the business, then make the move!

We seek a highly seasoned ML practitioner to join our Data Science - Machine Learning team and help take it to the next level. We use advanced ML to build recommender systems and matching models, search relevance & ranking systems, user personalizations and consumer segmentation models. We also leverage the latest advancements in deep learning on images and NLP to build rich, next-gen experiences for our users. As a key member of the team, you will be responsible for the development and deployment of innovative concepts, research, predictive modeling, and machine learning algorithms. You will also serve as a mentor for the junior members on the team and provide guidance on their projects.

Responsibilities:
Research, build and deploy machine learning and deep learning algorithms.
Design and build solutions leveraging the wealth of consumer clickstream data, real estate property data, images and text data of realtor.com.
Create scalable machine learning models - classification & regression (GBMs, RF, LR, etc.), forecasting, clustering, neural networks (CNNs, LSTMs, Transformers, etc.) that integrate into batch, streaming and real-time systems.
Build end-points to serve ML models in production.
ML Ops (monitor inference performance, scalability, availability, etc).
Effectively partner with product and engineering teams to ideate and build new data-driven and machine learning based features for enriching the experience of home shoppers.
Drive A/B & multivariate tests and design of experiments to facilitate testing of new product and design features, with focus on improving engagement, retention, and conversion.
Help improve the scope of our data sets by identifying new data collection and procurement opportunities on an ongoing basis.
Generate descriptive visualizations and presentations to communicate insights and results.
Mentor the team on data exploration, machine learning, deep learning and developing data-oriented products.
Work with a sense of ownership and urgency, advocate for experimentation-based, agile culture.

Requirements:
MS/PhD in machine learning, computer science, applied mathematics or related fields.
5+ years of relevant work experience in the industry building and productionizing ML models.
Proficient in Python, Scikit-learn, XGBoost, PyTorch/TensorFlow, and other languages and frameworks appropriate for ML modeling and deployment.
Proficiency in Recommender Systems or Consumer Classification modeling is a plus!
Proficiency in Deep Learning (NLP and/or Computer Vision) is a plus!
Experience with relational databases (SQL) and large scale distributed systems.
Comfortable with experiment design and A/B and multivariate tests.
Exposure to Docker and Containerization.
Knowledgeable of core CS concepts such as: structured and unstructured data, data management and querying, common data structures and algorithms.
Strong creative thinking and problem solving skills.
Excellent oral and written communication and presentation skills.

About realtor.com

At realtor.com ®, we believe that everyone deserves a home of their own. We're a community of nearly 2,000 employees who work hard to ensure that from the moment someone starts dreaming about a new home, to the moment they walk in the door and beyond, we're there to lend a helping hand. Every month, over 85 million people trust us with their journey home by visiting our site and mobile apps, and we'd love to have you join our team to help.

We've got great offices in the U.S. and Canada with lots of sweet jobs to choose from, so we're hoping you'll join us on our journey to make buying, selling, renting, and living in homes easier and more rewarding for everyone.

Let's make a difference, together. For Real.","realtor.com
3.6",Vancouver
236,"Senior Data Scientist TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Architect and build AI and machine learning models
Provide expert input on architecture of Tonal's data collection, analytics, infrastructure, and learning systems
Identify innovative opportunities for data-driven features
Develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more.
Develop algorithm to recommended weights to users over time
Recommend workouts that users are likely to enjoy
Improve real-time rep and set detection from sensor data
Analyze user behavior and engagement to inform feature roadmap and marketing
Collaborate with ML, front-end, back-end, and firmware engineers to implement algorithms

Who You Are

Advanced degree in mathematical field or equivalent experience
5+ years data science experience
Knowledge of machine learning and signal processing algorithms
Knowledge of data filtering, and cleansing techniques
Strong knowledge of Python, SQL, and one of Java, C/C++, Kotlin, or Go
Team player with high integrity
Open to feedback and constantly striving to improve
High degree of self-awareness

Extra Credit

Experience with gyros and accelerometers, computer vision, or control theory
Experience as a software engineer

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
237,"Data Analyst, Customer Success","WHO WE ARE


We are Power Factors, developer of the world’s leading cloud platform for renewable energy companies. Our SaaS platform, Drive, is used to manage over 35 Gigawatts of renewable energy across the planet (enough to power approximately 1.5 million homes). We’re tackling one of the world’s most important challenges in making renewable energy the world’s leading source of power by driving down the cost to operate wind and solar power plants. Our company is going through accelerated growth fueled by the unprecedented transition to clean, renewable energy.


The Drive platform continues to extend throughout the renewable energy market. Our platform collects millions of IoT and other data points, cleanses the data, detects occurring issues, identifies leading indicators to predict future issues, and adds a full advanced analytic capability on top of this rich, high-value dataset. In addition to issue detection and analytics, Drive adds the toolsets needs to take analytic insights to action such as case management and work order management.


To our customers, we deliver excellent customer service and a high-value system of engagement that provides the results they are looking for: lower operations costs and higher output from their renewable energy power plants. We are an agile development company, big enough to make an impact, but small enough to move quickly to execute in a growing industry and take advantage of rapidly evolving technology. To our employees, we provide a culture that values respect, teamwork, transparency, and achievement.


THE ROLE


Power Factors is seeking a qualified candidate to join our Company in the role of Data Analyst, Customer Success. In this role, you will be responsible for the design, development, and implementation of tools that aims at automating tasks and optimize processes and increase efficiency. More precisely, you will write scripts and develop helper applications to automate repetitive tasks. You will work on identifying new process improvement opportunities, tracking the most important metrics to diagnose problems, develop and tool filter and categorize issues and prioritize cases . Ultimately, you will ensure the workflows, reports, and tools implemented are constantly improving the level of service of the Customer Success Department.




In this position, you will report to the Director, Technical Solutions and you will be working from home, in Canada.


IMPORTANT NOTE: Power Factors is applying COVID-19 preventive measures to safeguard the health and safety of our employees, customers, business partners, and communities where we have offices. Please note that the selected candidate will be working from home for the duration of said applicable measures.


RESPONSIBILITIES



Design, develop, and implement tools and applications for the Customer Success Helpdesk team to automate repetitive tasks;
Independently take a project from idea to functional application;
Work in partnership with Helpdesk teams to gather, process, and interpret Case information and workflows to formulate Business Impact Analysis;
Support with broader ticket analysis. report writing and presenting findings and propose workflow solutions; Translate business requirements into well-designed solution tools that best leverage our platform;
Interpreting data, analyzing results using statistical techniques;
Work with management to prioritize business and information needs.
Identify, propose, and actively participate in process improvement and other projects as required.


REQUIREMENTS



Bachelor’s in software engineering or college technical degree in a related field;
Minimum of 5 years of significant experience working as a Data Analyst / Data scientist / Business Data Analyst in a software company:
Strong knowledge of analytics tools and processes;
Strong understanding of reporting packages/spreadsheet tools (Microsoft Power BI), databases (querying and scripting in SQL. etc), programming (Python, PowerShell, JavaScript or related languages);
Good working knowledge with OSISoft’s PI system, SQL, Salesforce, and Microsoft Power BI is beneficial;
Familiar with cloud-based technologies Azure, AWS, & Rackspace;

ITIL / Lean-Six Sigma certification is considered an asset.


KEY COMPETENCIES



Accountability

Agility
Effective Communication
Critical Thinking
Problem Analysis
Process Development
Project Management
Decision Making/ Judgement


EQUAL OPPORTUNITY EMPLOYER


Power Factors is an Equal Opportunity Employer committed to engaging a diverse workforce and sustaining an inclusive culture. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.


IND123","Power Factors
4.5",Montreal
238,Senior Data Engineer,"Position Summary

The SmartThings Big Data team in Vancouver is looking for a Senior Data Engineer who is passionate on big data technology and delivering data solutions. The Senior Data Engineer will work closely with our business strategy, cloud engineering, client engineering, UX design, consumer insights and marketing teams to make decisions on how we should invest in specific data-driven features and products.

You are a team player and know how to work well with others. You have a strong analytical mind and you like to see the whole picture. You have passion for solving complex problems and have a high degree of aptitude when it comes to learning new technologies. You love data and numbers and understand how important your role is in helping with business decisions.

If you want to work for one of the most recognized brands in the world and one of the Top 100 Employers in Canada, then please keep reading!

What We Offer:

Competitive Salary
Employer Paid Health Coverage (from day one)
Employee Purchase Program – discounts!
Social and Wellness Events
Employee Referral Program –we want great talent like you!

Role and Responsibilities

Be responsible for data engineering activities including data ingestion, data modelling, data processing data governance
Analyze different data in the ecosystem and create meaningful topics analysis reports.
Work with team to improve the data pipeline to process large scale data efficiently
Be a data steward to educate and promote the data importance and data-driven culture.
Collaborate with other groups worldwide to assist in product design, business strategy and user experience research, etc.
Be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data

Skills and Qualifications

5+ years of experience in big data engineering
Have deep understanding on data engineering principles
Hands-on experience of large scale and high availability systems
Strong knowledge of SQL (MySQL, PostgreSQL) and preferably experience with NoSQL databases
Proficient in at least one programming language and scripting languages (bash, Python, etc.)
Experience with various AWS services (EC2, S3, AWS CLI, Lambda, Kinesis Firehose, Redshift etc.)
Hadoop ecosystem knowledge (Hadoop, Spark, Kafka, Hive, Pig, Sqoop, etc.)
BS or MS in Computer Science or equivalent experience

Bonus Skills

Experience with Ariflow, EKS, EMR, Redshift, OLAP
Experience with Git and CircleCI
DevOps skills: create build & install scripts, terraform, UNIX-based systems management, release management, production monitoring, etc.
Agile/Scrum software development methodologies

Please note that this position is a 12 month contract.



Samsung is an equal employment opportunity employer. We thank you for your interest in working for Samsung; only candidates selected for an interview will be contacted.
#indhigh
#LI-DJ1","Samsung Electronics
3.4",Vancouver
239,Senior Data Engineer,"Position Summary

The SmartThings Big Data team in Vancouver is looking for a Senior Data Engineer who is passionate on big data technology and delivering data solutions. The Senior Data Engineer will work closely with our business strategy, cloud engineering, client engineering, UX design, consumer insights and marketing teams to make decisions on how we should invest in specific data-driven features and products.

You are a team player and know how to work well with others. You have a strong analytical mind and you like to see the whole picture. You have passion for solving complex problems and have a high degree of aptitude when it comes to learning new technologies. You love data and numbers and understand how important your role is in helping with business decisions.

If you want to work for one of the most recognized brands in the world and one of the Top 100 Employers in Canada, then please keep reading!

What We Offer:

Competitive Salary
Employer Paid Health Coverage (from day one)
Employee Purchase Program – discounts!
Social and Wellness Events
Employee Referral Program –we want great talent like you!

Role and Responsibilities

Be responsible for data engineering activities including data ingestion, data modelling, data processing data governance
Analyze different data in the ecosystem and create meaningful topics analysis reports.
Work with team to improve the data pipeline to process large scale data efficiently
Be a data steward to educate and promote the data importance and data-driven culture.
Collaborate with other groups worldwide to assist in product design, business strategy and user experience research, etc.
Be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data

Skills and Qualifications

5+ years of experience in big data engineering
Have deep understanding on data engineering principles
Hands-on experience of large scale and high availability systems
Strong knowledge of SQL (MySQL, PostgreSQL) and preferably experience with NoSQL databases
Proficient in at least one programming language and scripting languages (bash, Python, etc.)
Experience with various AWS services (EC2, S3, AWS CLI, Lambda, Kinesis Firehose, Redshift etc.)
Hadoop ecosystem knowledge (Hadoop, Spark, Kafka, Hive, Pig, Sqoop, etc.)
BS or MS in Computer Science or equivalent experience

Bonus Skills

Experience with Ariflow, EKS, EMR, Redshift, OLAP
Experience with Git and CircleCI
DevOps skills: create build & install scripts, terraform, UNIX-based systems management, release management, production monitoring, etc.
Agile/Scrum software development methodologies

Please note that this position is a 12 month contract.



Samsung is an equal employment opportunity employer. We thank you for your interest in working for Samsung; only candidates selected for an interview will be contacted.
#indhigh
#LI-DJ1","Samsung Electronics
3.4",Vancouver
240,Data Engineer/ETL Developer,"Our Client is looking for a Data Engineer/ETL Developer to join their growing team of Data and BI experts. Our Client has embarked on a journey to build next generation data platform to support the growing need of data from business intelligence and analytics. The candidate will be responsible designing, developing and productionizing ETL jobs to ingest data into Data Lake, load data to data marts; and extract data to integrate with various business applications.

Roles and Responsibilities:

Design and Develop ETL Pipeline to ingest data into Hadoop from different data sources (Files, Mainframe, Relational Sources, NoSQL Etc.) using Informatica BDM
Parse unstructured data, semi structured data such as JSON, XML etc. using Informatica Data Processor.
Analyze the Informatica PowerCenter Jobs and redesign and develop them in BDM.
Design and develop efficient Mapping and workflows to load data to Data Marts.
Perform the GAP analysis between various legacy applications to migrate them to newer platforms/data marts.
Write efficient queries in Hive or Impala and PostgreSQL to extract data on Adhoc basis to do the data analysis.
Identify the performance bottlenecks in ETL Jobs and tune their performance by enhancing or redesigning them.
Work with Hadoop administrators, PostgreS DBAs to partition the hive tables, refresh metadata and various other activities, to enhance the performance of data loading and extraction.
Performance tuning of ETL mappings and queries.
Write simple or medium complex shell scripts to preprocess the files, schedule ETL jobs etc.
Identify various manual processes, queries etc. in the Data and BI areas, design and develop ETL Jobs to automate them.
Participate in daily scrums; work with vendor partners, QA team and business users in various stages of development cycle.


Skill Required:

7+ years of experience in designing and developing ETL Jobs (Informatica or any other ETL tool)
3+ years of experience working on Informatica BDM platform
Experience on various execution modes in BDM such Blaze, Spark, Hive, Native.
3+ years of experience working on Hadoop Platform, writing hive or impala queries.
5+ years of experience working on relational databases (Oracle, Teradata, PostgreSQL etc.) and writing SQL queries.
Should have deep knowledge on performance tuning of ETL Jobs, Hadoop Jobs, SQL’s, Partitioning, Indexing and various other techniques.
Experience in writing Shell scripts.
Experience in Spark Jobs (Python or Scala) is an asset.
1+ years of experience with working on AWS technologies for data pipelines, data warehouses
Minimum 5+ years of experience with building ETLs to load data warehouse, data marts
Awareness of Kimball and Inmon data warehouse methodologies
Nice to have knowledge on all the products of Informatica such as IDQ, MDM, IDD, BDM, Data Catalogue, PowerCenter etc.
Must have experience working in Agile SCRUM methodology, should have used Jira, Bit bucket, GIT, Jenkins to deploy the codes from one environment to other.
Experience working in diverse multicultural environment with different vendors, onsite/offshore vendor teams etc.
P&C Insurance industry knowledge will be an added asset
Certifications in Informatica product suite as a developer
Nice to have 2+ years of experience with AWS data stack (IAM, 33, Kinesis Stream, Kinesis firehose, Lambda, Athena, Glue, RedShift and EMR
Exposure to other cloud platforms such as Azure and GCP are acceptable as well",Demand For HR,Markham
241,Data Engineer/ETL Developer,"Our Client is looking for a Data Engineer/ETL Developer to join their growing team of Data and BI experts. Our Client has embarked on a journey to build next generation data platform to support the growing need of data from business intelligence and analytics. The candidate will be responsible designing, developing and productionizing ETL jobs to ingest data into Data Lake, load data to data marts; and extract data to integrate with various business applications.

Roles and Responsibilities:

Design and Develop ETL Pipeline to ingest data into Hadoop from different data sources (Files, Mainframe, Relational Sources, NoSQL Etc.) using Informatica BDM
Parse unstructured data, semi structured data such as JSON, XML etc. using Informatica Data Processor.
Analyze the Informatica PowerCenter Jobs and redesign and develop them in BDM.
Design and develop efficient Mapping and workflows to load data to Data Marts.
Perform the GAP analysis between various legacy applications to migrate them to newer platforms/data marts.
Write efficient queries in Hive or Impala and PostgreSQL to extract data on Adhoc basis to do the data analysis.
Identify the performance bottlenecks in ETL Jobs and tune their performance by enhancing or redesigning them.
Work with Hadoop administrators, PostgreS DBAs to partition the hive tables, refresh metadata and various other activities, to enhance the performance of data loading and extraction.
Performance tuning of ETL mappings and queries.
Write simple or medium complex shell scripts to preprocess the files, schedule ETL jobs etc.
Identify various manual processes, queries etc. in the Data and BI areas, design and develop ETL Jobs to automate them.
Participate in daily scrums; work with vendor partners, QA team and business users in various stages of development cycle.


Skill Required:

7+ years of experience in designing and developing ETL Jobs (Informatica or any other ETL tool)
3+ years of experience working on Informatica BDM platform
Experience on various execution modes in BDM such Blaze, Spark, Hive, Native.
3+ years of experience working on Hadoop Platform, writing hive or impala queries.
5+ years of experience working on relational databases (Oracle, Teradata, PostgreSQL etc.) and writing SQL queries.
Should have deep knowledge on performance tuning of ETL Jobs, Hadoop Jobs, SQL’s, Partitioning, Indexing and various other techniques.
Experience in writing Shell scripts.
Experience in Spark Jobs (Python or Scala) is an asset.
1+ years of experience with working on AWS technologies for data pipelines, data warehouses
Minimum 5+ years of experience with building ETLs to load data warehouse, data marts
Awareness of Kimball and Inmon data warehouse methodologies
Nice to have knowledge on all the products of Informatica such as IDQ, MDM, IDD, BDM, Data Catalogue, PowerCenter etc.
Must have experience working in Agile SCRUM methodology, should have used Jira, Bit bucket, GIT, Jenkins to deploy the codes from one environment to other.
Experience working in diverse multicultural environment with different vendors, onsite/offshore vendor teams etc.
P&C Insurance industry knowledge will be an added asset
Certifications in Informatica product suite as a developer
Nice to have 2+ years of experience with AWS data stack (IAM, 33, Kinesis Stream, Kinesis firehose, Lambda, Athena, Glue, RedShift and EMR
Exposure to other cloud platforms such as Azure and GCP are acceptable as well",Demand For HR,Markham
242,Data Scientist – Antibody Assessment,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21503

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated Data Scientist, with expertise in integrated analysis and mining of complex biological data from a multitude of sources to join our multidisciplinary team. Our ideal candidate is a highly motivated and self-directed scientist, a team-player who thrives in a fast-paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. This is an exciting opportunity to join one of Canada’s most innovative biotech companies and to contribute to our cutting-edge research, driving the discovery of novel monoclonal antibodies for therapeutic use.

How you might spend your days:

Using your understanding of bioinformatics and biochemistry to analyze and interpret large multifactorial data sets for the purpose of driving drug discovery, especially with regard to lead candidate selection and predictive analysis
Organizing, supporting, and collaborating with team members to meet project deliverables and timelines
Building automated analysis pipelines, including streamlining of data output and curation, for a variety of data types derived from high-throughput analytical and biophysical experiments (e.g. SPR, mass spectrometry, HPLC, light scattering, etc)
Developing tools to collate, organize and process data inputs for our in-house data visualization platform, Celium.
Leading initiatives to standardize data output and data analysis for integration into laboratory information management systems (LIMS) or electronic notebook (ELN)
Collaborating with other data scientists on projects, finding solutions, and sharing code

We'd love to hear from you if:

You thrive in a collaborative environment and enjoy bringing out the best in your teammates
You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities
You take pride in being a self-motivated person, fast learner, team player, and creative problem solver
You are passionate about analysis of complex data and communication to interdisciplinary project teams

Required qualifications and experience:

A graduate degree (PhD or MSc) in Bioinformatics, Computational Biology, Immunology, Immunogenetics, or a related field
Experience in the Life Sciences; Biochemistry, Biophysics, Cell Biology, or Molecular Biology preferred
Proficiency in at least one common coding language: Python or R (Python preferred)
Demonstrated ability to create flexible, reproducible data analysis pipelines intended for use by others
Experience working with and creating databases, data provenance, or data architectures
Excellent skills in data visualization and presentation of key findings
Drive to learn and master new techniques
Excellent documentation and organizational skills, with impeccable attention to detail
A solid foundation in statistical analysis
An understanding of basic machine learning would be desired

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please submit your application through our website and refer to Job ID 21503 in your cover letter. Only applicants selected for an interview will be contacted.","AbCellera Biologics
4.8",Vancouver
243,Data Scientist Engineer,"Data Scientist Engineer-2100905


You can be part of an inclusive team of diverse talent and character. In this diversity lies our greatest strength.
Description


At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation.




We provide a challenging and rewarding work environment with a strong emphasis on process safety, as well as the safety of our employees and the communities we operate in and are always working to form the best team—especially from within, through an emphasis on lifelong learning and development.




And we are constantly striving to become an even better place to work. BASF has been recognized as one of Canadas Best 100 Employers in 2019. Come join us on our journey to create solutions for a sustainable future!




Data Scientist Engineer (ID: 2100905)




Where the Chemistry Happens…

The Data Scientist will model complex business problems and provide insights through data analysis. In addition, the Data Scientist will be responsible for also evangelizing the capabilities of data science and basing decisions on data.

The Data Scientist will be expected to participate in a community-of-practice to maximize the effectiveness of the insights team, through knowledge sharing and thoughtful curation of algorithms and methods. To identify opportunities for data-driven insights, the Data Scientist, as an evangelist for marketing data science, will interact frequently with leaders and experts in various business organizations and become part of a global team. The Data Scientist will be responsible for coordinating and initiating their own activities as it relates to maximizing the value of insights delivered and derived from data.




Formula for Success: You Will…




Guiding business partners and non-experts in the selection of valuable and feasible cases to create insights with statistics and machine learning.



Data selection and engineering (at least for prototyping)



Model selection and optimization (statistical, machine learning) – programming primarily in Python



Model deployment in existing environments
Qualifications


Ingredients for Success: What We Look for in You…




Bachelor’s degree (Master preferred) in quantitative/computational science with a strong focus on marketing and statistics.



5+ years experience in using statistic/modeling tools in non-academic environment with a focus on business growth.



Certifications or publications relevant to data science, technical expertise, or marketing insights.



Demonstrated, hands-on experience with R, Python, or similar data science tools.



Significant experience with enterprise-wide data initiatives and working with complex data and system infrastructures.



Experience in change management, scoping, requirements and solutions execution.



Experience in defining metrics and scorecards to demonstrate benefits of a successful data governance program.



Experience in handling exceptions and communication and partnering with cross-functional teams.



Experience working in cloud-first environments, particularly Azure and AWS.



Exposure to and experience with visualization tools (e.g. Tableau, Power BI).



Knowledge of IT and business management Information systems from a data perspective.



Strong communication skills demonstrated through work and education experiences



Understanding and prior experience with the agriculture industry a heavy plus.



Create Your Own Chemistry: What We Offer You




Adding value to our customers begins with adding value to you. You@BASF is the suite of benefits, perks, programs and unique opportunities we offer to support you—the whole you—in all stages of your life and career. With you@BASF, you create your own chemistry.




The total rewards that you receive as a BASF employee go way beyond a paycheck. From competitive health and insurance plans, to robust retirement benefits that include company-matching contributions, to making sure you never stop learning, we believe investing in you is investing in our success. Working for a large, global organization, you’ll have a chance to grow professionally and personally, expand your network and build a rewarding and dynamic career.




BASF provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job



Primary Location: CA-ON-Mississauga
Function: ITSE - Information Technology & Services
Job Type: Standard
Shift: Day Job
Organization: GDA/BC-RBPS NA Canada Mexico MidWest-63009551","BASF
4.2",Mississauga
244,Data Scientist Engineer,"Data Scientist Engineer-2100905


You can be part of an inclusive team of diverse talent and character. In this diversity lies our greatest strength.
Description


At BASF, we create chemistry through the power of connected minds. By balancing economic success with environmental protection and social responsibility, we are building a more sustainable future through chemistry. As the world’s leading chemical company, we help our customers in nearly every industry meet the current and future needs of society through science and innovation.




We provide a challenging and rewarding work environment with a strong emphasis on process safety, as well as the safety of our employees and the communities we operate in and are always working to form the best team—especially from within, through an emphasis on lifelong learning and development.




And we are constantly striving to become an even better place to work. BASF has been recognized as one of Canadas Best 100 Employers in 2019. Come join us on our journey to create solutions for a sustainable future!




Data Scientist Engineer (ID: 2100905)




Where the Chemistry Happens…

The Data Scientist will model complex business problems and provide insights through data analysis. In addition, the Data Scientist will be responsible for also evangelizing the capabilities of data science and basing decisions on data.

The Data Scientist will be expected to participate in a community-of-practice to maximize the effectiveness of the insights team, through knowledge sharing and thoughtful curation of algorithms and methods. To identify opportunities for data-driven insights, the Data Scientist, as an evangelist for marketing data science, will interact frequently with leaders and experts in various business organizations and become part of a global team. The Data Scientist will be responsible for coordinating and initiating their own activities as it relates to maximizing the value of insights delivered and derived from data.




Formula for Success: You Will…




Guiding business partners and non-experts in the selection of valuable and feasible cases to create insights with statistics and machine learning.



Data selection and engineering (at least for prototyping)



Model selection and optimization (statistical, machine learning) – programming primarily in Python



Model deployment in existing environments
Qualifications


Ingredients for Success: What We Look for in You…




Bachelor’s degree (Master preferred) in quantitative/computational science with a strong focus on marketing and statistics.



5+ years experience in using statistic/modeling tools in non-academic environment with a focus on business growth.



Certifications or publications relevant to data science, technical expertise, or marketing insights.



Demonstrated, hands-on experience with R, Python, or similar data science tools.



Significant experience with enterprise-wide data initiatives and working with complex data and system infrastructures.



Experience in change management, scoping, requirements and solutions execution.



Experience in defining metrics and scorecards to demonstrate benefits of a successful data governance program.



Experience in handling exceptions and communication and partnering with cross-functional teams.



Experience working in cloud-first environments, particularly Azure and AWS.



Exposure to and experience with visualization tools (e.g. Tableau, Power BI).



Knowledge of IT and business management Information systems from a data perspective.



Strong communication skills demonstrated through work and education experiences



Understanding and prior experience with the agriculture industry a heavy plus.



Create Your Own Chemistry: What We Offer You




Adding value to our customers begins with adding value to you. You@BASF is the suite of benefits, perks, programs and unique opportunities we offer to support you—the whole you—in all stages of your life and career. With you@BASF, you create your own chemistry.




The total rewards that you receive as a BASF employee go way beyond a paycheck. From competitive health and insurance plans, to robust retirement benefits that include company-matching contributions, to making sure you never stop learning, we believe investing in you is investing in our success. Working for a large, global organization, you’ll have a chance to grow professionally and personally, expand your network and build a rewarding and dynamic career.




BASF provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job



Primary Location: CA-ON-Mississauga
Function: ITSE - Information Technology & Services
Job Type: Standard
Shift: Day Job
Organization: GDA/BC-RBPS NA Canada Mexico MidWest-63009551","BASF
4.2",Mississauga
245,Senior Data Scientist,"About Us:

Propel (formerly MoneyKey) is an innovative Fintech Company that provides services and unsecured financial products to consumers via a safe and secure online platform. Propel was founded in 2011 in Toronto to remove the complexity and bureaucracy that people often experience while trying to borrow money, and to provide an underserved population with unsecured credit in a respectful way and with extraordinary service. Our goal is to provide our customers with a simple and convenient process!

Our amazing team has experienced phenomenal growth and thrives on an entrepreneurial spirit, passion, and top-tier talent. We believe in innovation and in measuring success through results and growing within; talent and hard work never goes unnoticed, and we succeed together.

About You:

You are a talented professional looking for a career, not a job. Reporting to the Chief Risk Officer, you will collaborate with business lines and other stakeholders and identify opportunities to drive business value. As a Sr. Data Scientist you’ll be working to uncover fraud and manage risk

You picture yourself succeeding within a vibrant and entrepreneurial organization where your ideas will be heard, and where you will have an opportunity to showcase your talents and great skills. You are motivated by goals, a self-starter, and a hardworking individual who likes to wear multiple hats. We are seeking a proven, driven team player who is looking to join a fast-paced, high growth, energetic and forward-thinking team.

Responsibilities

· Ingest massive volumes of structured and unstructured format data, model, transform and store it in a variety of data stores.

· Leverage distributed and open-source computing tools (e.g. Python, Jupyter, PyML) for analysis, data mining and modeling.

· Collaborate with Data engineering and operational teams to deploy models and algorithms in production, across different channels and customer platforms.

· Create and apply model and algorithm testing strategies to measure conduct multi-variate testing and A/B testing to measure effectiveness of models and make ongoing changes.

· Prepare detailed documentation to outline data sources, models and algorithms used and developed.

· Present results to business line stakeholders and help implement real data-driven changes.

· Design and Develop statistical models for usage in: Underwriting, Existing Customer Management, Marketing Campaigns, and Collection/Recovery.

· Assessing, cleaning, merging, and analyzing large datasets.

· Design and Develop business logic, pricing strategies, business forecasts, while optimizing profitability.

· Utilize advanced statistical software to develop linear/non-linear, parametric/non-parametric, and classical/machine learning based predictive modeling/data mining analytic methodologies to minimize credit/fraud losses, maximize response and approval rates, and/or profitability of products.

· Assist with the implementation of scorecards

· Writing of clear and detailed model documentation.

· Provide solutions and ideas to business partners to solve complex modeling and other analytic problems.

Requirements

· University degree in relevant STEM disciplines (Mathematics, Computer Sciences, Electrical/Computer/Software Engineering).

· Minimum M.S./M.A. in a highly quantitative field (Statistics, Economics, Mathematics, Computer Science or other quantitatively-oriented degree).

· Strong quantitative/statistical modeling capabilities, along with 2-3 years of experience in credit scoring and model development.

· 3-4+ years of experience within the consumer lending environment preferred.

· Production experience with experimental design, statistical analysis, machine learning and predictive modeling (e.g., cross-sell, upsell, attrition, acquisition and lookalike models).

· Programming skills in Java, R or Python.

· Experience with common machine Learning libraries in R, Python, Spark.

· Experience with UNIX tools and shell scripting.

· Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL).

We welcome and encourage applications from individuals from all groups, including aboriginal, women, visible minorities, and persons with disabilities, regardless of race, ethnicity, sexual orientation, creed, family status, national origin, age and gender.

We thank all applications for showing an interest in this position. Only those selected for an interview will be contacted. No agencies or phone calls.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Dental care
Life insurance
Paid time off
RRSP match

Schedule:

8 hour shift

Education:

Bachelor's Degree (required)

Experience:

consumer lending environment: 3 years (preferred)
quantitative/statistical modeling capabilities: 3 years (required)

Work remotely:

Temporarily due to COVID-19","Propel Holdings
3.1",Midtown Toronto
246,Data Engineer,"What You'll Do:

As a data engineer, you will provide input into architectural design decision, develop code to meet business needs and ensure the applications built are meeting high standards of quality and support-ability. This position will be part of the data science team and will require high collaboration within and across the different Unioncrate teams.

Primary Responsibilities:

Collaborate with the different teams to normalize client data to Unioncrate standards
Write Python code to improve and optimize complex ETL process for batch data processing from a variety of SQL and non-SQL data sources
Take loosely-defined business questions and translate them into clearly-defined technical/data specifications for implementation
Ensure that data pipelines are scalable, repeatable and secure
Add to our portfolio of client libraries that interface with 3rd party API’s
Assist the Data Science team in optimizing newly developed algorithms
Work with the Cloud Engineering team to improve our current deployment process
Ensure all deliverables and processes are of high-quality throughout the project by adhering to best practices
Mentor less experienced members of the team

Qualifications / Requirements:

2-3 years of hands-on experience designing and implementing large-scale, complex ETL applications using industry-leading products/platforms
4-5 years of experience using SQL to perform complex data manipulation
1+ year experience with Python
Ability to deal with ambiguity and work with rapidly-changing business data
Team player, great communicator, collaborative and optimistic by nature
Comfortable working in a startup environment with remote colleagues across the globe
Familiarity with common programming tools and best practices such as unit testing, Git, and Jira

Nice To Have:

Exposure to time series data / signal processing
Experience writing client API libraries
Experience working with Docker containers
Experience working with functional programming paradigms
Experience in any of the more popular Clouds (Azure, AWS or GCP)

Application deadline: 2021-06-22

Job Type: Permanent

Pay: $90,000.00-$120,000.00 per year

Benefits:

Dental care
Paid time off
Stock options
Vision care
Work from home

Schedule:

Monday to Friday

Education:

Bachelor's Degree (required)

Experience:

ETL: 2 years (preferred)
Python: 4 years (preferred)

Work remotely:

Yes",AI Demand Prediction Startup,Midtown Toronto
247,Senior Data Scientist,"We're transforming the grocery industry

Instacart is the North American leader in online grocery and one of the fastest-growing companies in e-commerce. Since 2012, we've been working towards creating a world where everyone has access to the food they love and more time to enjoy it together.

Groceries delivered to your door in as little as an hour. It seems simple, right? Well, it's more complex than that. From re-routing deliveries during snowstorms, to connecting customers with coupons and deals for their favorite brands, to updating over half a billion grocery data lines every night...our efforts bring Instacart closer to being the operating system for the grocery industry.

Solving these problems is what helps our customers get back time in their day, so they can do more of what they love.

Introducing Our Hybrid Working Model

As the future of work evolves, so do we. We have a hybrid model where our roles are open to in-office, flex, or remote work. Learn more about our flexible approach to where we work.

OVERVIEW

You will be joining a growing data science team and will tackle some of the most challenging and impactful problems that are transforming how people buy groceries every day. You will be embedded within our data-driven product team as a trusted partner in uncovering barriers in the product's usability and utilize these insights to inform product improvements that drive angle-changing growth. We're looking for a self-driven, strategic thinker who can hit the ground running to ultimately influence decision-making across the entire organization.

ABOUT THE JOB

Own analytical frameworks that guide the product roadmap

Design rigorous experiments and interpret results to draw detailed and actionable conclusions

Develop statistical models to extract trends, measure results, and predict future performance of our product

Build simulations to project impact of various product and policy interventions

Enable objective decision making across the company by democratizing data through dashboards and other analytical tools

Use expertise in causal inference, machine learning, complex systems modeling, behavioral decision theory etc. to shape the future of Instacart

Present findings in a compelling way to influence Instacart's leadership

ABOUT YOU

5+ years experience working in a quantitative role at a product company or a research organization

Ability to run rigorous experiments and come up with scientifically sound recommendations

Ability to write complex, efficient, and eloquent SQL queries to extract data

Ability to write efficient and eloquent code in Python or R

A desire to build and improve consumer software products

Ability to translate business needs into analytical frameworks

Eagerness to learn, flexibility to pivot when needed, savviness to navigate and thrive in a dynamic environment, and a growth mindset needed to build a successful team and company

#LI-Remote","Instacart
3.7",Ontario
248,Data Engineer,"Company Description
As one of the largest professional services firms in Atlantic Canada, Mariner has a team of 200+ management and technology consultants working with our public and private sector clients throughout Atlantic Canada and beyond.Our team delivers specific strengths in the areas of digital transformation, digital health, organizational change management, and in key technical areas including cybersecurity, IT infrastructure, BI & Analytics.
Job Description
Mariner's Data Engineers work with extended team ofdata architects, software architects, business owners, and other specialists to implement, build, and operate datarelated solutions for Mariner's clients in public sector, utilities, telecommunications, and other industrial sectors.
The successful candidates will be well versed in all phases of the consulting cycle from pre-sales through the design and delivery. He/she will be comfortable presenting complex technical concepts at an appropriate level for a wide range of audiences (technical, management, and executive).
Qualifications
Our Data Engineering consultants requires extensive technical skills across most of all of the following:

Database architecture and data warehousing.
Data modeling and mining.
Statistical modeling and regression analysis.
Data Lakes design, implementation, and maintenance
Azure based data technologies (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse)
Databricks
Snowflake
ETL tools and techniques
DevOps process & pipeline
Data architecture experience in on-premises, cloud, andhybrid environments.

Other basic qualifications include:

Bachelor or Masters degree in Computer Science, Computer Engineering or related field.
5+ years professional experience in a large enterprise (mandatory) or professional services (preferred) environment.
Exceptional oral, written, and listening communication skills.
Specific experience working with Public Service, Utility, and Telecommunication organizations of all sizes (strongly preferred).

Additional Information
Why Mariner Partners?
We believe in making a positive impact in the communities where we live and work - our team is located in major cities all across Canada, throughout the US and internationally. We are proud to be headquartered here, and are passionate about growing a strong technology sector here in Atlantic Canada and beyond. We offer competitive compensation; benefits packages and training and development.
We recognize that empowered employees are more innovative, more efficient, deliver better customer service and can flat out-perform conventional organizations. Our people have built products for national deployments at the world's largest TV and Internet companies and leading real estate, financial and government organizations.
We are looking for passionate IT professionals who are curious about data, who love solving problems for customers and who want to grow their careers.
Join our growing team!
I'm interested","Mariner Partners
3.7",Halifax
249,Senior Data & Applied Scientist,"Are you interested in building personalized recommendation for billions of users, especially in finance domains?
Finance Recommendation team in Content Service organization is building personalized recommendation in finance domains in various product, including MSN and Edge default home page, etc. Our team focus on whole recommendation stack building, especially the modeling parts in different recommendation layers, including document understanding, segment recall, user profile modeling, personalized ranking, diversity optimization, etc.

If you’re looking for one team to utilize your ML skills to optimize user engagement of real product, grow your ML skills by iterating against users’ feedbacks and resolving real product challenges, then this is the team for you!

Responsibilities
As one applied scientist in the team, your major responsibilities including:
Thinking through the product scenarios and goals, identify key challenges and design experimental process for iteration and optimization.
Offline model training and optimizing, collaborating with platform team on online serving and perf optimization for shipping.
Keeping on track of research trends in the fields of personalized recommendation, deep learning and AI.
Work independently and collaboratively with other research teams and product teams.
Qualifications
Required:
Master / PhD in computer science or related fields focus on machine learning and AI.
3+ years’ experiences in areas of machine learning, natural language processing or large-scale data mining.
Solid coding skill and good experience on deep learning framework like PyTorch, TensorFlow, CNTK, etc.
Preferred:
Working / research experiences on recommendation areas is good plus.
Good communication skills and self-motivated.
Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

#ContentServices# #webXT#","Microsoft
4.4",Vancouver
250,Major Projects Data Scientist,"Major Projects Data Scientist - ( 210000H9 )

Description

Your Opportunity

Stantec is seeking a Major Projects Data Scientist to join our Project Risk Review team. This position is based in Vancouver, BC, Canada.

Our Project Risk Review team manages Stantec’s corporate risk review practice, using data-driven insight to support Major Projects teams across all business lines through the pursuit and execution of Stantec’s largest and most complex engineering and architecture projects. This position reports directly to the CPO and offers exposure to the broader business with frequent interaction and mentorship from executive leadership throughout our global organization. This opportunity would appeal to individuals interested in gaining a unique professional development experience, applying advanced data science, visualization, and machine learning techniques on complex business and risk management problems. The ideal candidate would establish a one-of-a kind foundation and professional network to be at the forefront of business intelligence within the project management and engineering consulting industry.

Your Key Responsibilities

Develop and optimize machine learning and statistics models to support the Project Risk Review practice, liaising with Stantec’s executive leadership and project teams across all business lines and regions to review, issue go-conditions, track, and report on Major Projects worth over $15B in fees.
Lead the development of project and partner analytics, objective risk metrics, and machine learning tools to assess enterprise risk supporting executive leadership decision-making with data-driven insight.
Prepare and present quarterly risk management and major projects tracking reports identifying risk review trends and examining pursuit and project execution outcomes for executive leadership.
Lead the development and evolution of BI and collaboration tools supporting the Project Risk Review processes to drive efficiency, improve data management practices, and streamline workflows utilized company wide.
Create a single source of truth by consolidating our various data models and queries
Create and enforce software engineering best practices to analytics code through version control, testing, and continuous integration.
Support ad-hoc tasks and projects as required
Provide comprehensive analysis of current state of practice, identify best data sets, data science methodologies, algorithms, tools and infra needed to generate models to support the planned ML-based investments

Qualifications

Your Capabilities and Credentials:

A strong understanding of addressing business needs through the application of data mining and analysis, predictive modeling, statistics, and other advanced analytical techniques
You are a collaborative, creative, open-minded individual who possesses a natural curiosity and desire to experiment with novel algorithms and technologies to perform hypothesis testing and validation, and develop ML-driven models through an iterative approach
A strong track record of performing data analysis and machine learning model development using Python, R, and SQL
Excellent interpersonal and communication skills; ability to communicate complex results with confidence to technical and non-technical audiences and stakeholders (Stantec leadership and project personnel) daily.
Must have experience with Machine Learning (Supervised and Unsupervised), Classification, Clustering, Segmentation, Time Series Analysis, NLP, Demand Forecasting and Optimization
Must be an effective ‘team player’ who has a demonstrated ability to work intuitively with minimal supervision, and possess qualities of professionalism, assertiveness, maturity and judgement.
Excellent attention to detail, time management and organization skills with a proven commitment to follow-up and follow-through
Ability to multi-task, adapt and prioritize tasks to meet deadlines in a very dynamic environment; the role requires the ability to handle interruptions and balance numerous and shifting priorities, and assist with multiple projects simultaneously
Ability to apply detailed solutions to “big picture” thinking
Knowledge of Risk Management frameworks and risk management concepts within a business, consulting or construction environment would be an asset.
You are well versed in software and AI development lifecycles
Data visualization experience: PowerBI, R (ggplot, shiny)
Database experience: MS SQL, Oracle
Development experience: R, Python (familiar with packages such as numpy, pandas, tensorflow, pytorch, scikit-learn, matplotlib, etc. and equivalent packages in R)

Education and Experience

Completed, or in the process of completing, a Bachelor’s or Master’s Degree in a field such as Data Science, Computer Science, Mathematics, Engineering, or Statistics.
0-3 years of work experience
Knowledge of engineering and construction terms and contracting practices

[Working conditions, special requirements]

Typical office environment working with computers. Sedentary; no field work required. A combination of remote working and in-office collaboration anticipated.

Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best.

Primary Location : Canada-British Columbia-Vancouver

Job : IT Generalist

Organization : BC-1303 CPO-Canada

Employee Status : Regular

Job Level : Individual Contributor

Travel : No

Schedule : Full-time

Job Posting : Mar 8, 2021, 11:28:32 AM

Req ID: 210000H9

Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","Stantec
3.8",Vancouver
251,Senior Data Scientist,"Qui sommes-nous :
BusPatrouille est une entreprise spécialisée dans la technologie de sécurité. À titre de principal fournisseur international de dispositifs visant à faire respecter le bras d'arrêt des autobus scolaires, notre mission principale est d'améliorer la vie des élèves où qu'ils se trouvent.

La technologie de BusPatrouille a été déployée sur un plus grand nombre d'autobus et a été utilisée pour délivrer un plus grand nombre de constats d'infraction relatifs au bras d'arrêt des autobus scolaires que toute autre technologie des autres entreprises existantes à l'échelle mondiale. Notre technologie exclusive transforme les autobus scolaires en autobus intelligents équipés de caméras vidéo, de GPS, de télémétrie, de traitement de données et d'archivage. De cette manière, nous permettons aux comtés et aux districts scolaires d'améliorer la sécurité des enfant

BusPatrouille est en pleine croissance. Nous sommes donc à la recherche d'un.e scientifique de données principal.e pour intégrer notre service de veille stratégique (BI). Si vous aimez travailler dans un environnement dynamique avec des collègues talentueux, ce poste est pour vous.

Responsabilités :
Le poste de scientifique de données principal.e a une grande influence et nécessite de travailler en étroite collaboration avec les clients ainsi qu'avec les équipes des ventes et de l'exploitation afin d'aider à prendre des décisions fondées sur les données de manière à stimuler une croissance efficace de BusPatrouille. Si vous aimez la communication narrative et le fait d'influencer les décisions opérationnelles au moyen des chiffres, nous voulons faire votre connaissance!

Il s'agit d'un poste de premier plan qui vous permettra d'interagir régulièrement avec les chefs d'entreprise, de définir la feuille de route de l'équipe et de recenser les besoins pour fournir des solutions innovantes. La personne idéale est autonome, très analytique, curieuse et a de la facilité à plonger dans de grands ensembles de données afin d'en tirer des enseignements. Notre environnement évolue rapidement et requiert une personne enthousiaste, flexible, soucieuse du détail, analytique et à l'aise pour travailler avec plusieurs équipes et des priorités concurrentes.

Mettre en pratique d'excellentes compétences en matière d'analyse et de résolution de problèmes pour prendre des décisions d'affaires dans un environnement dynamique afin de fournir des avantages aux clients et des analyses de performance.

Travailler de manière indépendante et en collaboration avec d'autres scientifiques, des ingénieurs, des concepteurs, des développeurs en veille stratégique (BI) et des gestionnaires de produits sur des projets complexes qui génèrent de la valeur pour BusPatrouille.

Posséder d'excellentes aptitudes à la communication et être capable de structurer un scénario convaincant pour présenter une narration à l'aide de données exploitables.

Être capable de conceptualiser des problématiques ou des occasions d'affaires, de formuler des hypothèses et des objectifs, de définir des indicateurs clés de performance et de faire des recommandations adéquates.

Construire des modèles prescriptifs et prédictifs de calibre international pour résoudre des problèmes commerciaux dans un environnement qui évolue rapidement.

Tirer parti des données internes et externes pour synthétiser des idées intéressantes qui expliquent les tendances sous-jacentes de l'écosystème de l'application automatisée des lois.

Repérer les possibilités d'automatisation pour favoriser l'évolutivité et améliorer tant l'efficacité que la productivité de l'équipe élargie.

Posséder de solides compétences en communication écrite et verbale, avec la capacité de synthétiser efficacement des idées (notamment la théorie des modèles, les compromis de sélection et les limites) pour les présenter à la haute direction ou à des clients.

En temps voulu, embaucher, former, encadrer et diriger une solide équipe d'analyse de données pour BusPatrouille

Exigences :
Un diplôme d'études supérieures (de préférence un doctorat) en économie, en finance, en statistique ou dans un autre domaine quantitatif.

Plus de huit ans d'expérience pertinente.

Une expérience avérée de la manipulation d'un large éventail de sources et de systèmes de données pour fournir des analyses et des visualisations qui ont des répercussions sur l'activité.

Une solide compréhension théorique et une expertise concrète des bases de données, des structures de données, des mégadonnées, de l'apprentissage automatique et des méthodes (le partitionnement en k-moyennes [K-Means], la forêt d'arbres décisionnels, les algorithmes d'amplification de gradient [Gradient Boosting], etc.).

Une expertise dans les approches analytiques de pointe (par exemple, l'analyse des bases de données, l'analyse numérique, la visualisation des données) et les plateformes (par exemple, Redshift, MySQL, PostgreSQL, Amazon, Tableau).

Une grande maîtrise de SQL, R ou Python.

Des compétences analytiques exceptionnelles et un sens aigu des affaires.

D'excellentes compétences en communication, avec la capacité d'influencer les décideurs et d'obtenir un consensus au sein des équipes.

Une curiosité intellectuelle, une grande autonomie et un esprit d'équipe.

Rémunération et avantages :
Un salaire concurrentiel.

Des avantages sociaux complets, notamment une assurance soins médicaux, soins dentaires et soins de la vue.

Un poste de direction au sein d'une entreprise qui se développe rapidement et qui est investie d'une mission.

L'occasion de travailler avec une équipe très performante

L'occasion de contribuer à la création d'une entreprise vouée à la sécurité des enfants.

Nous sommes à la recherche de membres essentiels de l'équipe de BusPatrouille qui nous aideront dans notre quête pour accroître la sécurité des enfants. Ce poste joue un rôle important dans notre entreprise et constitue une formidable opportunité pour les personnes qui seront retenues. Nous offrons un milieu de travail inclusif, diversifié, enthousiaste, intègre et profondément engagé. Venez nous aider à assurer la sécurité des enfants.

Who We Are:
BusPatrol is a Safety Technology company. Our core mission is to improve the lives of students everywhere as the leading international provider for school bus stop arm enforcement

BusPatrol's technology has been deployed onto more buses and has been used to issue more school bus stop arm citations than any other company in the world. Our proprietary technology turns school buses into Smart Buses equipped with video, GPS, telemetry, data processing, and archiving. In this way, we enable counties and school districts to enhance the safety of children in their communities.

BusPatrol is undergoing rapid expansion. We are looking for a Senior Data Analyst to join our Business Intelligence. If you thrive working in a fast-paced environment with talented peers, this position is for you.

Responsibilities:
The Senior Data Scientist is a high-impact role that will work closely with our Customer, Sales, and Operations teams to help drive data-driven decisions that accelerate BusPatrol's efficient growth. If storytelling and impacting operational decisions through numbers is exciting to you, we want to hear from you!

This is a high visibility role that will be interfacing with business leaders on a regular basis, defining team roadmap and gathering requirements to deliver innovative solutions. The ideal candidate is a self-starter, highly analytical, curious, and comfortable diving deep into large data sets to unearth insights. Our environment is fast-paced, and requires someone who is enthusiastic, flexible, detail-oriented, analytical, and comfortable working with multiple teams and competing priorities.

Apply excellent analytical and problem-solving skills to drive business decisions in a dynamic environment to deliver customer benefit and performance analytics

Work both independently and collaboratively with other scientists, engineers, designers, BI developers, and product managers on complex projects that deliver value to BusPatrol

Excellent communication skills and ability to structure a compelling storyline to present a narrative using actionable data-driven insights

Ability to conceptualize business issues or opportunities, formulate hypotheses and goals, define KPIs and make appropriate recommendations

Build world class prescriptive and predictive models to solve business problems in a fast-moving environment

Leverage internal and external data to synthesize nuggets of insights that explain underlying trends in the automated enforcement ecosystem

Identify opportunities for automation to drive scalability, improve efficiency and productivity of the broader team

Strong written and verbal communication skills with ability to effectively synthesize insights (including model theory, selection tradeoffs, and limitations) to executives and/or customers

In time, hire, train, mentor and lead a robust data analytics team for BusPatrol

Requirements:
An advanced degree (PhD preferred) in economics, finance, statistics, or other quantitative subject area

8+ years relevant experience

Proven track record navigating across a wide range of data sources and systems to deliver analytics and visualization that deliver business impact

Strong theoretical understanding and applied expertise with databases, data structures, big data, machine learning, and methods (K-Means, Random Forest, Gradient Boosting, etc.)

Expertise with industry-leading analytics approaches (e.g., database analytics, digital analytics, data visualization) and platforms (e.g., Redshift, MySQL, PostgreSQL, Amazon, Tableau)

Expert proficiency in SQL, R, and/or Python

Exceptional analytical skills and strong business acumen

Outstanding communication skills with the ability to influence decision makers and build consensus with teams

Intellectually curious, self-starter, team player

Compensation and benefits:
Competitive salary

Comprehensive benefits including medical, dental and vision insurance

Leadership role in a rapidly scaling, mission-driven organization

An opportunity to work with a high performing team

An opportunity to help build a company dedicated to children's safety

We're looking for critical members of the BusPatrol team to assist us in our quest to improve children's safety. This is an important role for us and a great opportunity for the right candidates. Our environment is inclusive, diverse, ignited, built on integrity and deeply committed. Come and help us keep our children safe.","BusPatrol
3.8",Montreal
252,Data Scientist / Senior Data Scientist - North American Integrated Analytics,"Data Scientist / Senior Data Scientist - North American Integrated Analytics

In keeping with our global position as an industry leader and innovator, Munich Re is driving transformative change in the life insurance industry through data science. The North American Integrated Analytics team in Toronto is looking for a Data Scientist / Senior Data Scientist.




Location
Toronto , Canada


As a Data Scientist you will apply statistical techniques and machine learning to build solutions to core challenges in the life insurance industry. You will be immersed in real-time business problems while engaged in a collaborative approach to delivering world-class, innovative solutions for our North American operations and clients. We see the use of data as instrumental in making it easier for people to buy life insurance and to expand the number of people insured.

Your job

Apply advanced statistical and machine learning techniques to build models for underwriting, experience studies, assumption development, pricing, and claims management;
Help us to drive innovation, enabling new underwriting paradigms, distribution models, and data management;
Build and implement solutions that enable operational units to improve quality and speed of core processes in order to generate incremental revenue or reduce expense;
Proactively research new ways of modeling data to unlock actionable insights or improve processes;
Collaborate across Munich Re functions and with clients to use analytics to influence business decisions;
Work with existing data science groups at Munich Re and collaborate with internal partners to leverage capabilities in big data technology.

Your profile

First and foremost, the successful candidate will demonstrate a natural desire to provide exceptional client service through his/her energy, enthusiasm and initiative.

In addition, we are looking for the following qualifications:

Undergraduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 3 years’ experience OR Graduate Degree in Computer Science, Engineering, Statistics, or Applied Mathematics, plus 1 years’ experience;
Insurance or financial services background is preferred but not required;
Actuarial examinations or designation is an asset but not required;
Expertise in advanced predictive analytic techniques;
Strong experience working with Python, or R; working knowledge of SQL (familiarity with multiple languages considered an asset);
Experience working with analytics through the modeling lifecycle including gathering data, design, recommendations, testing, implementation, communication, and retraining;
Familiarity with cloud computing platforms (ex. AWS, Microsoft Azure)
Familiarity with big data technologies (ex. Apache Spark, Hadoop, etc), natural language processing and deep learning frameworks (ex. Tensorflow, Pytorch) is an asset but not required;
Excellent communication skills, effectively interpreting modeling results, distilling actionable insights and presenting them to partners;
The ability to learn quickly;
A drive to make a difference;
Thrive in a dynamic environment and successfully deliver on multiple assignments under deadlines.

About us

Munich Re is one of the world’s leading reinsurance companies with approximately 45,000 employees in over 50 locations around the globe. As an industry leader, we provide a unique opportunity to be part of a global success story. We offer our employees a diverse and challenging work environment which champions high performance, professional development, innovation and passion; and rewards top performers with a highly competitive total rewards package.




Apply now! Apply for this Job!

Munich Re Canada is committed to providing a work environment that is inclusive and free of employment barriers and discrimination. Accommodations will be made for qualified applicants with a disability throughout the recruitment process. If you receive a request for an interview and you have a disability which will require an accommodation to support your participation, please consult with Human Resources or contact AODARequestHR@munichre.ca as soon as practical so that suitable accommodations can be arranged.","Munich RE
4.1",Midtown Toronto
253,"Data Scientist, Fall 2021 Student Opportunities (8 Months Only)","What is the opportunity?
Who wouldn't want to be a part of a fantastic team of Data Scientists? At RBC, our Data Science teams offer the opportunity to leverage RBC’s data assets to develop innovative solutions in support of RBCs big data strategy. This position is an essential part to the bank as you develop next-generation applications to meet our customers’ needs. By joining the RBC team as a Data Scientist, you will have the opportunity to analyze, design and implement data solutions to assist all business customers.


Please only apply if you are available for 8 months.


What will you do?

Utilize the latest technologies available, designing and building data solutions to meet business needs
Be an active contributor to not only your individual team, but to the RBC development community
Constantly seek out better ways to do things, new tools, new technologies, new processes
Work on transformational projects delivering new value
Work as part of an agile team responsible for end-to-end delivery of business needs
Deploy production-scale solutions using the Hadoop Ecosystem, transforming statistical and machine learning models from single node architecture to parallel processing grid technology
Use business domain knowledge to independently lead the analytics process to identify valuable and innovative insights
Promote analytics across the enterprise to enable RBC to become a data-driven organization


What do you need to succeed?

Must-have:

Programming skills in one or more of the following languages: Python or R
Experience utilizing SQL scripts/querying
Proficient in building statistical and algorithmic models with complex and large datasets, including but not limited to: supervised statistical learning, clustering, natural language processing, recommendation systems, times-series analysis, experimental design (A/B testing), data visualization, deep learning
Ability to data extract, transform, and load processes with a variety of data types
Ability to perform complex data analysis on large volumes of data and present findings to stakeholders


Nice to have:

Experience with big data technologies, primarily in machine learning and statistics function
Exposure to Apache Spark, Hadoop and Public Cloud technologies, data serialization (JSON, Avro, Parquet, ORC)
Experience with big data processing tools like Spark and Hive, GitHub functionality and workflow experience/exposure
Experience with messaging (Kafka, Solace, RabbitMQ) & working on Agile projects


What’s in it for you?
We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients succeed. We care about each other, reaching our potential, making a difference to our communities and achieving success that is mutual. Visit people.rbc.com


Continued career advancement opportunities
Exposure to strong mentorship and leadership examples
A world-class training program in financial services
Opportunities to be a valuable member of a close-knit, collaborative team that encourages networking
A comprehensive Total Rewards Program including bonuses and flexible benefits
Competitive compensation


We encourage you to apply as soon as possible as we accept applications on a rolling basis, but please note that the formal application deadline is June 27, 2021. Should you be selected to progress, someone from our team will reach out directly to provide instructions on next steps. Otherwise, feel free to check for progress updates by logging in to your RBC profile. If the status has not changed, it denotes the fact that your application is still under review.

While there is no one date when our employees will return, we can confirm that the majority of Fall Work Integrated Learning | Co-op positions will start working remotely, however may transition to working at an RBC office as essential service restrictions are lifted.


TAD2021


Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Virtual
Address: Virtual
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: [[filter7]]
Career Level: Student Job
Application Deadline: 06/27/2021
Platform: Technology and Operations
Req ID: 375217
Ad Code(s):","RBC
4.1",Ontario
254,Senior Data Scientist,"Senior Data Scientist
London, ON, Canada Req #19

Thursday, September 17, 2020

ABOUT THIS POSITION


Digital Extremes is currently seeking a Senior Data Scientist to join our team. You will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. As a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action. As an ideal candidate, you will also have experience with free to play games.


RESPONSIBILITIES
Collaborate closely with the Data team improving internal processes.
Help marketing and development teams to identify trends and opportunities.
Develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences.
Architect, implement, deploy, and maintain data science intensive applications.
Synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies.
Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team.
Follow up with additional analysis once initiatives have begun to determine success or need for continued improvements.
Assist in designing and building business intelligence tools for data mining and reporting.
Suggest improvements in tools and techniques to help scale the team.
Conduct ad hoc data analysis based on current team needs and management priorities.
Mentor other Data scientists with the team.
REQUIREMENTS
Excellent organizational, communication and interpersonal skills
Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other)
Minimum 3 years of tried and true statistical analysis and data mining experience
A passion for video games and understanding of gaming culture
Experience in the gaming industry, specifically Free to Play gaming is a plus
In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks
Experience in defining/designing/building/managing a data warehouse is a plus
Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling
Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action
Excellent organizational, communication and interpersonal skills
Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas
ABOUT DIGITAL EXTREMES


Founded in 1993 by James Schmalz, Digital Extremes ranks as one of the world’s top independent video game development studios. Originating with the co-creation of Epic Games’ multi-million unit selling Unreal® franchise including Unreal and Unreal Tournament, Digital Extremes went on to develop Dark Sector®, BioShock® for the PlayStation®3, the BioShock 2 multiplayer campaign, and The Darkness® II. The studio has reached its greatest critical and commercial success with the free-to-play action game, Warframe®, boasting a global community of 50 million registered players on PC, PS4™, Xbox One and Nintendo Switch™. For more information about Digital Extremes, visit www.digitalextremes.com. To sign up for Warframe, visit www.warframe.com.


WHY WORK AT DIGITAL EXTREMES


Our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. Developing new and existing talent is our long-term focus. We are honored that our work environment has been consistently recognized as one of “Canada’s Top 100 Employers”. We summon you to join our elite team!


The rewards of a career with Digital Extremes include:
Competitive salary with bonus opportunities
Excellent benefits and paid time off
Matching RRSP plan
Employee Assistance Program (EAP)
Professional development and career support
Fitness and parking/transit subsidies
Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff
All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more
JOIN US


Digital Extremes is an equal opportunity employer committed to diversity and inclusion. We welcome and encourage applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the recruitment process. We thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted.

Other details

Pay Type

Salary","Digital Extremes
3.5",London
255,Senior Data Scientist,"Senior Data Scientist
London, ON, Canada Req #19

Thursday, September 17, 2020

ABOUT THIS POSITION


Digital Extremes is currently seeking a Senior Data Scientist to join our team. You will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. As a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action. As an ideal candidate, you will also have experience with free to play games.


RESPONSIBILITIES
Collaborate closely with the Data team improving internal processes.
Help marketing and development teams to identify trends and opportunities.
Develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences.
Architect, implement, deploy, and maintain data science intensive applications.
Synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies.
Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team.
Follow up with additional analysis once initiatives have begun to determine success or need for continued improvements.
Assist in designing and building business intelligence tools for data mining and reporting.
Suggest improvements in tools and techniques to help scale the team.
Conduct ad hoc data analysis based on current team needs and management priorities.
Mentor other Data scientists with the team.
REQUIREMENTS
Excellent organizational, communication and interpersonal skills
Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other)
Minimum 3 years of tried and true statistical analysis and data mining experience
A passion for video games and understanding of gaming culture
Experience in the gaming industry, specifically Free to Play gaming is a plus
In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks
Experience in defining/designing/building/managing a data warehouse is a plus
Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling
Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action
Excellent organizational, communication and interpersonal skills
Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas
ABOUT DIGITAL EXTREMES


Founded in 1993 by James Schmalz, Digital Extremes ranks as one of the world’s top independent video game development studios. Originating with the co-creation of Epic Games’ multi-million unit selling Unreal® franchise including Unreal and Unreal Tournament, Digital Extremes went on to develop Dark Sector®, BioShock® for the PlayStation®3, the BioShock 2 multiplayer campaign, and The Darkness® II. The studio has reached its greatest critical and commercial success with the free-to-play action game, Warframe®, boasting a global community of 50 million registered players on PC, PS4™, Xbox One and Nintendo Switch™. For more information about Digital Extremes, visit www.digitalextremes.com. To sign up for Warframe, visit www.warframe.com.


WHY WORK AT DIGITAL EXTREMES


Our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. Developing new and existing talent is our long-term focus. We are honored that our work environment has been consistently recognized as one of “Canada’s Top 100 Employers”. We summon you to join our elite team!


The rewards of a career with Digital Extremes include:
Competitive salary with bonus opportunities
Excellent benefits and paid time off
Matching RRSP plan
Employee Assistance Program (EAP)
Professional development and career support
Fitness and parking/transit subsidies
Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff
All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more
JOIN US


Digital Extremes is an equal opportunity employer committed to diversity and inclusion. We welcome and encourage applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the recruitment process. We thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted.

Other details

Pay Type

Salary","Digital Extremes
3.5",London
256,Aerodynamicist/Data Scientist,"Company Overview

GiBLI Tech has developed a patent pending, cutting edge aerodynamic sensor for cycling and triathlon applications. As part of the growing GiBLI team in Halifax Nova Scotia, you will be a key player in advancing this technology for a global market.




Responsibilities

As the Aerodynamicist/Data Scientist your primary role will be to improve existing algorithms, lead experimental design setup for R&D, and data processing.

Develop experiments derived from fundamental aerodynamics principles
Lead wind tunnel testing
Algorithm improvements using test results and data processing techniques
Statistical analysis of sensor data



What we want
Strong understanding of aerodynamics and engineering fundamentals
Experimental background
Strong mathematics background (statistics and numerical methods)
Experience in signal processing
Familiarity with SQL and or time series data
Matlab programming skills
Python programming skills
Strong problem-solving skills and attention to detail
Self-motivated and can work independently
Positive attitude with strong communication skills



Nice to have
Experience in version control workflow (e.g. Bitbucket, GitHub, Gitlab)
Experienced in CFD
Has worked with embedded systems
Interest in cycling



Requirements
Graduate or Undergraduate degree in Engineering or related field with focus on aerodynamics



How to apply

Please send a cover letter and resume to careers@giblitech.com",GiBLI Tech,Halifax
257,Lead Data Scientist - Core Local Business (Remote),"At Yelp, it’s our mission to connect people with great local businesses. Yelp’s unique dataset contains billions of interactions between users and businesses around the globe, from a review of a coffee shop to requesting a repair quote with a photo of a leaky faucet. Data Scientists at Yelp work to make sense of these interactions to deliver impactful analyses and products to our users, business partners and the general public.



The Data Science & Analytics team performs analyses, builds models, and designs experiments that directly impact Yelp’s products and users. Our teams sit in Yelp’s central product management organization and work directly with cross-functional leaders to understand quantitatively how our products are performing and where the largest opportunities are. We are adept at tasks like modeling user preferences, inference from user and marketplace experiments, and generating insights about the health of local economies. With diverse backgrounds and expertise, we strive for learning and growth in a collaborative environment.

We are looking for a Lead Data Scientist to join the Core Local Business team. The team is centrally located within our product organization, and focused on analytics, research, and inference support for product and engineering stakeholders. The Core Local Business team partners with product and engineering teams building the Yelp for Business Owners user experience, from claiming a free business listing, to paid product acquisition, and long-term engagement and retention. Lead Data Scientists at Yelp are technical and cultural leaders within their teams, and collectively influence the development of shared tools, infrastructure, and processes across the organization.
Where You Come In
Join a team of Data Scientists and Data Science Analysts that develop analytical frameworks and reliable measurement strategies for Yelp products.
Design, execute, and analyze complex business and user experiments.
Partner with other senior Data Scientists and Data Engineers to set the vision for and develop our experimentation platform.
Devise and evaluate models for diverse business needs, such as identifying growth opportunities, estimating the impact of new features on our platforms, and personalizing the user experience.
Proactively research and build ETL pipelines for product and marketplace metrics.
Communicate key insights from analyses, experiments and data products to stakeholders.

What It Takes to Be Successful
MS/PhD in quantitative field and 3+ years of industry experience in a senior quantitative role.
Ability to apply statistical, analytical and technical expertise to product and business problems.
Prior experience structuring and leading impactful data science projects independently.
Oral and written communication skills to mentor colleagues, and work effectively with partners on engineering, product and business teams.
Expertise in SQL, and R or Python for data analysis and platform development.
Enthusiasm for building a culture of learning and development.

Nice to Have
Product analytics experience with small businesses.
Prior industry experience building online experimentation and machine learning platforms.

Local businesses are turning to Yelp because we’re uniquely positioned to help them reach their customers during these challenging times. Our Engineering & Product teams have responded by quickly identifying their needs and building innovative products and features to support them. Our commitment to connecting people with great local businesses has never been stronger.



#LI-Remote

At Yelp, we believe that diversity is an expression of all the unique characteristics that make us human: race, age, sexual orientation, gender identity, religion, disability, and education — and those are just a few. We recognize that diverse backgrounds and perspectives strengthen our teams and our product. The foundation of our diversity efforts are closely tied to our core values, which include “Playing Well With Others” and “Authenticity.”

We’re proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition or disability.

We are committed to providing reasonable accommodations for individuals with disabilities in our job application process. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-recruiting@yelp.com or 415-969-8488.

Note: Yelp does not accept agency resumes. Please do not forward resumes to any recruiting alias or employee. Yelp is not responsible for any fees related to unsolicited resumes.","Yelp
3.4",Midtown Toronto
258,Data Engineer,"About Pinterest:

Millions of people across the world come to Pinterest to find new ideas every day. It's where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you'll be challenged to take on work that upholds this mission and pushes Pinterest forward. You'll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.

The mission of the Business Intelligence team is to empower high-impact decisions at Pinterest by engineering data driven solutions. We are looking for a Software Engineer who will design, build and maintain the most critical data sets and visualizations for our company. Aligned to one of our verticals like Ads, Shopping, Infrastructure, Sales and Finance - you’ll be working directly with the Analysts, Data Scientists and Business Leaders in that area to ensure they have the data they need.

What you’ll do:

Understand the business drivers and analytical use-cases and translate these to data products
Explore new technologies and learn new techniques to solve business problems creatively
Think big and drive the strategy for better data quality within Pinterest
Design, implement and maintain pipelines that produce business critical data reliably and efficiently using cloud technology
Become the voice of business within engineering, and of engineering within business
Create data visualizations that allow easy consumption of the data learnings and insights
Collaborate with many teams from Product, Engineering and Business to produce relevant data solutions that can be used across multiple use cases

What we’re looking for:

4+ years of experience with big data (Hadoop, Hive, Presto, Spark), scripting language (Python) and data visualization (Tableau) technologies
Hands-on experience in principled data warehouse design, data visualization and data pipeline design and development
Prior experience working with business stakeholders in the technology space is a plus
Great communication skills. You should be able to directly communicate with senior business leaders, embed yourself with business teams, and present solutions to business stakeholders
Experience in working independently and driving projects end to end
Strong analytical skills

#LI-MJ1

Not Specified
0","Pinterest
4.2",Midtown Toronto
259,Data Analyst - Data Science,"Job Title: Data Analyst

Location: Remote(Anywhere in Canada)

Reports to : Senior Director, Data Science

The Role:
As an Analyst in Data Science, you will analyze and interpret the results of survey research studies that measure customer satisfaction, and provide technical programming expertise working with Python, R, SAS, Excel, and other automation tools. Your job is to work closely with other researchers and scientists in the execution of programs to run advanced statistical modeling, data mining and analysis on survey and non-survey data.

The Impact:
You will support syndicated studies that address industry-level consumer needs and serve as customer satisfaction benchmarks in a variety of industries such as Automotive, Financial Services, Insurance, Energy, and Telecom. The outcome of your work will be used by clients to help them understand what is important to consumers, how their brand performs relative to their competition, what their brand needs to do to improve and the financial benefit of making these improvements.

Responsibilities:
Organized, detail oriented, and analytical thinker with experience in data modeling/mining, analysis, and reporting.

Able to leverage broad scope of knowledge including business rules and methodologies when performing basic and advanced analyses on datasets

Creates and maintains scripts/codes to clean and manipulate data, develop models, accurately calibrate model parameters, validate model performance, and create analytical outputs

Applies basic quantitative analytical skills for specific projects/studies

Able to take ownership of projects and work with other individuals and teams to ensure project accuracy and timeliness of information to clients

Qualifications:
Python (required), R, SAS, SPSS

Bachelors or Masters in Data Science, Statistics, Math, Computer Science, Engineering, Economics or related fields

2+ years of an advanced understanding of statistics and/or machine learning methods

Must be able to work effectively and collaboratively in a team oriented, global, and multi-cultural environment.

Fluent in English (read, write and speak)

The Career Opportunity:
You will have the opportunity to work with industry experts to learn how different industries are structured and how they leverage consumer information to guide product development and service improvement efforts. You will also have the opportunity to strengthen your research design and statistical skills by daily exposure to senior research staff at JD Power.

The Team / The Business:
Data Science has global responsibility for the research design, analyses planning and execution of all advanced analytics at JD Power. Additionally, the team is responsible for establishing and monitoring the adherence of research best practices that serve as the basis for the quality of all research products at JD Power. Our role is critical to the success of not only individual studies, but to the strength and credibility of the JD Power brand. You will report directly to the Data Science Sr. Director and join a team of highly educated and enthusiastic researchers and data scientists that collaborate regularly with each other and with other teams across the firm.

Our Hiring Manager says:
I'm looking for someone who can work as part of a broader engagement team and can use our data to help companies understand what drives customer satisfaction for their industry. This individual also has to work independently to analyze data using analytic packages (Python, SAS, SPSS). If you're right for this role, you are a self-starter who is able to develop creative solutions to problems, not be afraid to ask questions as you learn our company's culture and do it all with enthusiasm.

J.D. Power is a global leader in consumer insights, data, analytics, and advisory services that helps clients drive growth and profitability. The company's industry benchmarks and reputation for independence and integrity have established it as one of the world's most well-known and trusted brands.

Truth that Transforms: At J.D. Power, we amplify the voice of the consumer, and help brands improve the value of their products and services. Our capabilities empower everyone in the global commerce ecosystem, enabling better purchase decisions – and better business results. We understand that the customer experience is vital and that simply measuring it is not enough. Our analysts focus on driving results that improve customer loyalty and advocacy. Our success is driven by how much we help companies improve the customer experience. But data is only as powerful as the analysis and insights tied to it—and we put that power in the hands of our clients through our interactive reporting platforms. The data, analytics, insights, best practices, and action plans clients need are available whenever and wherever they need them, to help them make data-driven decisions that will improve their customer experience and drive positive financial results.

J.D. Power's recruitment efforts are aligned with the company's commitment to provide opportunities rooted in diversity, inclusion, and equality.

Our Vision: To be the leader in providing advanced data solutions that empower industry transformation.

Our Mission: We unite industry leading data and insights with world-class technology to solve our clients' toughest challenges.

Our Values: We are Truth Finders, Change Makers and Team Driven.

We are dedicated to leverage comprehensive and equitable practices which contribute to the overall success of the company and its employees. We invite you to learn more about our DE&I efforts.

To all recruitment agencies: J.D. Power does not accept unsolicited agency resumes and we are not responsible for any fees related to unsolicited resumes.

#LV-SV1","J.D. Power
3.0",Ontario
260,"Senior Data Scientist, NLP Natural Language Processing","Introduction
As a Data Scientist at IBM, you will help transform our clients’ data into tangible business value by analyzing information, communicating outcomes and collaborating on product development. Work with Best in Class open source and visual tools, along with the most flexible and scalable deployment options. Whether it’s investigating patient trends or weather patterns, you will work to solve real world problems for the industries transforming how we live.

Your Role and Responsibilities
IBM Watson Health is looking for talented individuals destined to usher in the next era of healthcare. We live in a moment of remarkable change and opportunity. The convergence of data and technology is transforming healthcare and life sciences organizations today. New opportunities are being created that never existed before to meet the demands of this transformation.

The Rapid Development team is a group of Scientists and Cognitive Software Developers within IBM Watson Health Imaging. In collaboration with cross-functional Watson Health teams, IBM Research and external partners, the team develops cognitive solutions that combine imaging and clinical data to enhance clinical decision making. The team is responsible for developing and validating robust and scalable cognitive services (text analytics and image analytics) and applications, including validation and evaluation of technologies being transferred from Research and other collaborators. The team follows Agile and DevOps methodologies to enable rapid iteration and responsiveness.

We are looking for self-motivated and driven candidates that are passionate about working on cutting edge technologies and that thrive in a highly collaborative environment.

Job Responsibilities
Design and development of robust algorithms and techniques using text analytics, Natural Language Processing (NLP) and machine learning
Rapid development and validation of cognitive solutions by using and/or enhancing existing methodologies, frameworks and architecture
Development of criteria for testing algorithm and system’s cognitive performance objectively from end-user and market perspective. Conduct performance evaluation and testing of algorithms and systems on test and real clinical data
Work with clinical collaboration and joint development partners to develop cognitive solutions
Support collection and annotation of data for algorithm development and evaluation
Integration of cognitive systems and components in Watson Health architecture, including Watson Health cloud
Planning, processing and performing all jobs in an efficient manner with minimum supervision
Conduct product development in compliance with Watson Health’s methodology, practices and Quality Management system.

Required Technical and Professional Expertise

3-5 years experience with solving real-world problems using Data Analytics, Natural Language Processing (NLP), and Machine Learning
Strong experience in Machine Learning, including deep learning and statistical models
Strong Programming skills (Java/J2EE, C++, Python) and experience with software systems architecture, web services, web applications, and current software development tools, technologies and frameworks
Strong publication record in peer-reviewed conferences and journals
Demonstrated communication and cross-functional collaboration skills;
Fluent in English, spoken and written

Preferred Technical and Professional Expertise

Strong knowledge of clinical information analytics domain, having applied NLP and machine learning techniques on unstructured data in EMRs
Interest or experience with healthcare information protocols and common interoperability standards, such as IHE, HL7, DICOM, XDS and IHE, and healthcare systems such as PACS, EMR, EHR, HIS and RIS;
PhD in Text Processing / NLP applied to medical reports

Must have the ability to work in Canada without sponsorship.
About Business UnitIBM’s Cloud and Cognitive software business is committed to bringing the power of IBM’s Cloud and Watson/AI technologies to life for our clients and ecosystem partners around the world. IBM provides you with the most comprehensive and consistent approach to development, security and operations across hybrid environments—with complete software solutions for business and IT operations, development, data science, security, and management. Our experts and software capabilities help organizations develop applications once and deploy them anywhere, integrate security across the breadth of their IT estate, and automate operations with management visibility. With IBM, you also have access to new skills and methods, governance and management approaches, and a deep ecosystem of industry experts and partners.

Your Life @ IBMWhat matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBMIBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location StatementThis role will involve working with technology that is covered by Export Regulations sanctions. If you are a Foreign National from any of the following US sanctioned countries (Cuba, Iran, North Korea, and Syria) on a work permit, you are not eligible for employment in this position.

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.","IBM
3.9",Mississauga
261,Data Engineer,"What is the opportunity?

The DNA (Data & Analytics) group is responsible for enabling RBC to become a data-driven organization. As part of this mission, DNA works with various lines of business (Personal & Commercial Banking, Wealth Management, Insurance, Capital Markets, etc…) to create and build data-driven solutions to serve our clients better.


The DNA Data Services team will build data-driven products and services/API’s, tackle challenging and interesting data-related problems using RBC's massive internal datasets (client relationships, user behavior across channels, transactions, etc….) and strategically partner with the business to enable client interactions to be informed by Artificial Intelligence (AI).


What will you do?

Take full ownership of work outcomes including design and implementation of API/microservices and backend components of our domain driven Machine Learning and AI services
Apply design thinking and an agile mindset in working with other engineers, data scientists and business stakeholders to continuously experiment, iterate and deliver on new initiatives.
Leverage best practices in continuous integration and delivery, with a strong commitment to leading with quality
Explore new capabilities and technologies to drive innovation.
Participate in code reviews for the engineers on your team, ensuring our delivery of clean, well-tested, and performant software


What do you need to succeed?

Must-have

Bachelor’s degree in computer science, software engineering, or equivalent
Experience in developing scalable, configurable applications using Python/Java/Scala and application frameworks (e.g. Spring, Spring Boot, etc)
Experience with streaming or messaging technologies (Kafka, etc…)
Experience leveraging big data technologies (Hadoop, Spark, and related technologies) to build data products and services
Strong foundational knowledge of relational databases (MySQL, SQL Server, etc…) and NoSQL stores (Elasticsearch, Redis, MongoDB, etc…)
Experience in building scalable, high-available and performant microservices
A passion for simplifying and automating work, making things better, continuous learning, solving open-ended problems, improving efficiency and helping others
Strong communication skills with ability to work cross-functionally to articulate, measure and solve issues


Nice-to-have

Knowledge of public cloud environments (Azure & AWS)
Experience deploying to and running applications on Kubernetes/Openshift
Experience building or executing Machine Learning pipelines
Experience building operational REST APIs
Knowledge of vulnerability mitigation, identity management, public and private cloud security risks, and security best practices


What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.

A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Work in a dynamic, collaborative, progressive, and high-performing team
Flexible work/life balance options
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with business partners


Learn more about RBC Tech Jobs","IBM
3.9",Midtown Toronto
262,Fraud Data Analyst,"Mistplay is the first Loyalty Program for mobile gamers. Players use our platform to play games, connect with friends, and earn awesome rewards; such as Amazon gift cards and prepaid Visas.

We leverage a wealth of in-game data and Machine Learning to recommend the best games to our users and coach developers of all sizes to help them build games. We use our marketing expertise and platforms to make sure our studio partners' games reach millions of players around the world.

With a growth of over 10 million users in under 3 years, Mistplay is one of the fastest-growing companies in North America. Join us as we continue to level up!



As a fast-growing tech start-up, you can jump right into the action and deep dive directly into the open AI challenges we are facing. Join our skilled team of Data Scientists, Engineers and Analysts to help us improve our AI-products with a real-time impact on our business. Each day will bring new challenges and opportunities to work on different components of our platform.

We are looking for people that are passionate about AI and our product. Technical ability is important, but so is being able to add to our culture. A can-do attitude and growth mindset will take you a long way with Mistplay!
What You'll Be Doing:
Work on a daily basis with our Fraud team of Data Analysts, Data Scientists and Operation Manager to track and identify fraudulent users
Work with a rich database that will push your creativity into engineering novel features that will have direct impact on the company
Help us keep track of our current models in production by building dashboards
Assist in investigation of suspicious users that exhibit bot-behaviour qualities
Collaborate with our Content team to review monthly fraud reports coming from our clients
What We're Looking For:
A Bachelors degree in Science, Computer Science, Statistics, Economics, Business Analytics or any quantitative related field is required
Ability to explore our rich database, continuously uncover new channels of fraud and propose newly engineered features to boost the performance of our models
Strong analytical and statistical analysis skills in order to extract insights and recommendations
Strong knowledge of SQL for analytics, data mining and data manipulation. Python/R is a solid bonus
Data visualizations such as Tableau is a solid bonus
What We Offer:
Generous stock option package
We match 20% of your contribution to your retirement plan
Monthly public transportation stipend
Annual gym membership
Dialogue membership - unlimited free video calls and texts with nurses and doctors anytime - they’ll even help you book IRL appointments
Weekly happy hour
Frequent team outings and off-sites
Private healthcare - includes massages
We work hard to make our work atmosphere as inviting and fun as possible! Working at Mistplay is coupled with a whole array of perks that we've adopted virtually and in-person: Team Lunches, game nights, company-wide events, and so much more.



Our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. We utilize data to constantly learn, improve, and adapt. We foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life.



Think you have what it takes? We'd love to meet you!","Mistplay
4.7",Montreal
263,Data Engineer,"Uberflip is a marketing technology company with 140+ employees founded in Toronto, Canada in 2012. Our content experience platform empowers marketing and sales to create engaging, relevant content destinations quickly for every campaign, audience, and stage of the customer journey. Marketing teams use our platform to scale how they incorporate content into every touchpoint and remove friction from the customer journey by surfacing the right content at the right time.
We're on the search for a Data Engineer! Reporting into our BI Manager, you will be working with the team to support our leaders in making more strategic decisions for our business.
What you will be doing:
Work in a collaborative manner and Interact with other engineering team members, Solution Architects, Project Managers, and Business Analysts.
You'll play a key role in our B.I. and Product Analytics roadmap by implementing and maintaining data flows to transfer and transform data from/to multiple cloud-based sources and destinations.
You will be maintaining and creating new business model mappings for our internal/external users using our B.I. platform.
You will be relying on advanced SQL skills to accurately handle reporting requirements.
You will be involved in supporting many aspects of our databases solution ecosystem.
We want to talk to you if you have experience with:
3+ years of software development experience with an emphasis in Database Development
Solid SQL skills to support our reporting needs using SQL and occasionally Python.
Knowledge in extracting data from various flat files, RDBMS, and third-party API’s.
Familiar with AWS environment (ie. S3, EC2, etc)
Front-end experience working with BI platforms (Microstrategy, OBIE, Looker, Tableau, PowerBI etc) to create logical layers.
Data Warehouse / BI Platforms: Snowflake/Looker
Third Party Software: Salesforce, Catalyst, Pendo, ZenDesk
Usage of code collaboration tools: Jira, Confluence, Git, and Github
What you will love about us:
Great Company Culture
Inclusive and Collaborative work environment
Competitive Health Benefits for you and your family starting day one
Wellness Programs including company paid counselling
Flexible Working Hours OR Remote work flexibility
Employee Stock Option Program
Additional Paid L.U.V and Wellness Days
Parental Leave Top Up Program
Learning Credits to put towards your professional development
(Virtual) Regular Standups, Demos, and Socials to keep us aligned and connected
And so much more!
Uberflip is committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work will be. If you're smart and good at what you do, come as you are!","Uberflip
4.3",Midtown Toronto
264,Data Engineer,"Uberflip is a marketing technology company with 140+ employees founded in Toronto, Canada in 2012. Our content experience platform empowers marketing and sales to create engaging, relevant content destinations quickly for every campaign, audience, and stage of the customer journey. Marketing teams use our platform to scale how they incorporate content into every touchpoint and remove friction from the customer journey by surfacing the right content at the right time.
We're on the search for a Data Engineer! Reporting into our BI Manager, you will be working with the team to support our leaders in making more strategic decisions for our business.
What you will be doing:
Work in a collaborative manner and Interact with other engineering team members, Solution Architects, Project Managers, and Business Analysts.
You'll play a key role in our B.I. and Product Analytics roadmap by implementing and maintaining data flows to transfer and transform data from/to multiple cloud-based sources and destinations.
You will be maintaining and creating new business model mappings for our internal/external users using our B.I. platform.
You will be relying on advanced SQL skills to accurately handle reporting requirements.
You will be involved in supporting many aspects of our databases solution ecosystem.
We want to talk to you if you have experience with:
3+ years of software development experience with an emphasis in Database Development
Solid SQL skills to support our reporting needs using SQL and occasionally Python.
Knowledge in extracting data from various flat files, RDBMS, and third-party API’s.
Familiar with AWS environment (ie. S3, EC2, etc)
Front-end experience working with BI platforms (Microstrategy, OBIE, Looker, Tableau, PowerBI etc) to create logical layers.
Data Warehouse / BI Platforms: Snowflake/Looker
Third Party Software: Salesforce, Catalyst, Pendo, ZenDesk
Usage of code collaboration tools: Jira, Confluence, Git, and Github
What you will love about us:
Great Company Culture
Inclusive and Collaborative work environment
Competitive Health Benefits for you and your family starting day one
Wellness Programs including company paid counselling
Flexible Working Hours OR Remote work flexibility
Employee Stock Option Program
Additional Paid L.U.V and Wellness Days
Parental Leave Top Up Program
Learning Credits to put towards your professional development
(Virtual) Regular Standups, Demos, and Socials to keep us aligned and connected
And so much more!
Uberflip is committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe that the more inclusive we are, the better our work will be. If you're smart and good at what you do, come as you are!","Uberflip
4.3",Midtown Toronto
265,Data Scientist - 312112,"Data Scientist

On behalf of our client in the Banking Sector, PROCOM is looking for a Data Scientist.

Data Scientist – Job Description

The contractor is responsible for developing and implementing quantification methodologies for Business Banking credit risk parameters, which are key drivers to the risk rating system, internal processes and regulatory processes
Develop, implement and maintain risk quantification methodologies for non-retail credit risk parameters such as PD, LGD and UGD
Perform research and analysis of applicable methodologies; present and recommend appropriate alternatives; implement estimation methodologies
Benchmark internal estimates with external models and/or data sources; provide analysis and recommend actions as appropriate
Implement and maintain a rigorous framework of internal controls and comprehensive documentation for various applications and databases used in parameter estimation
Communicate results of analyses through documentation to internal/external audiences, and effectively manage the interface with relevant parties such as Validation, Audit, and Regulators
Keep abreast with advances in credit risk analytics developments, products, and applications by vendors, consultants, regulatory agencies and competitors. Recommend/develop enhancements appropriate for the Bank

Data Scientist – Mandatory Skills

Excellent computing development skills, particularly statistical and database modeling tools (i.e., SQL, Python, SAS, R, Access/VBA, etc.) well-developed ability to adapt to various programming languages and environments
1 year of hands-on experience in quantitative analysis and machine learning; exposure to quantitative analysis related to credit risk management and modeling is preferred
In-depth understanding of statistical techniques and procedures related to analysis of various distributions, regression modeling, monte-carlo simulation and bootstrapping techniques
Well-developed writing and presentation skills, including competence in comprehensively and concisely reporting and presenting the results of complex analyses
Ability to efficiently manage multiple priorities to ensure timely delivery
Attention to details, independence, and ability to effectively collaborate in teamwork
Flexibility and creativity in problem solving
A graduate degree (or equivalent) in Statistics, Computer Science or comparable quantitative discipline that includes rigorous exposure to statistical knowledge and techniques

Data Scientist – Nice to Have Skills

1+ years of experience in hands-on quantitative/statistical analysis, preferably related to the non-retail credit risk area in a major financial institution

Data Scientist - Assignment Start Date

ASAP – 12 months to start

Data Scientist - Assignment Location

Toronto, ON – Work Remotely","Procom
4.3",Midtown Toronto
266,Senior Data Scientist,"Clearco is a company built by founders for founders, and we're laser-focused on our mission to help entrepreneurs succeed. The Senior Data Scientist will have the opportunity to create models, build advanced analytics, and leverage machine learning to help Clearco's founders improve their understanding of their data and grow their businesses.

Application Deadline: June 22, 2021

Please be advised someone from the recruitment team will be in touch shortly after the application deadline.

What your day-to-day will look like:
You will collaborate and influence senior leadership to ensure Data Science directly impacts strategy
As your first task, you will leverage NLP techniques for web scraping to build a custom email automation platform that maximizes incoming company sales leads!
You will draw connections about a domain's change in Facebook followers and it's likelihood to take a capital infusion and so much more
You will analyze and build models on data, but will have the autonomy to collect their own data via purchase, web scraping (highly encouraged), and manual collection (via outsourced contractors)
You will conduct original analyses to advise and influence product, engineering, and operations efforts

You will thrive if you have:
Exceptional time-management and organization skills – you can manage project ambiguity, complexity, and interdependencies
Excellent interpersonal skills - you are able work with and influence a diverse group of stakeholders
A self-starter mindset – you enjoy discussing a problem and after the discussion is over, you can't wait to get started on the execution of a project!
The ability to think outside the box and understand the bigger picture – you are an innovative thinker
Demonstrated the ability to thrive in a fast-paced environment, while collaborating with and influencing business partners to achieve strategic goals

Technical Requirements:
4+ years of experience in a Statistician, Researcher, Machine Learning Engineer, Data Engineer, or Data Analyst role
A Bachelor's Master's, and/or PhD in Statistics, Machine Learning, Mathematics, Computer Science, Economics or any other related quantitative field
Experience with Python, Kubernetes/Docker, Version Control/Git, Snowflake/SQL, Analytics, and Statistics
Experience with spaCy, word embedding, web scraping for data collection

Clearco is an equal opportunity employer. We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. At Clearco, we're committed to developing and upholding an inclusive, transparent, and comfortable environment for all. We create a space where every voice, perspective, and idea is heard and acknowledged. We embrace differences, and know that our diverse team is our strength and what drives our innovation.

Clearco is committed to developing a barrier-free recruitment process and work environment. If you require any accommodation, please email us at accommodations@clear.co and we'll work with you to meet your accessibility needs.","Clearco
3.9",Ontario
267,Data Visualization Analyst,"About Us

Our Information Technology department is seeking a highly motivated and career minded individual to join our team as a Data Visualization Analyst - Roadside.

The focus of this position is to work closely with Business Systems Analysts and Data Scientists to gain in-depth understanding of business strategy, processes, services, roadmap and the context in which the business operates to create meaningful reports and dashboards based on various large sets of information. This role will be key to combining data from multiple sources to create meaningful actionable reports for business use.

Who we are

As Canada's largest automobile association, we are passionate about keeping our Members safe- whether they are on the road, at home, or travelling abroad. Meeting the diverse needs of our two-million Members requires high performing, forward thinking, and innovative people who work collaboratively to keep propelling our business forward. Life at CAA Club Group is fast paced, performance-driven and rewarding. We value our Associates' career growth and ongoing professional development- and we regularly recognize their achievements and outstanding results. CAA Club Group (CCG) is known for providing stellar emergency roadside assistance to our motoring Members and non-Members. We work hard and play hard. We're about doing what's right and feeling good about it.

Position Details

What You Will Do

Design, develop and test dynamic and informative data visualizations through actionable reports and dashboards
Combine large datasets from multiple sources to deliver
Transform data for visualizations which are easy to interpret, and can be used to identify trends and correlations
Collaborate with stakeholders to document business requirements to generate functional requirements for data visualizations
Research to identify relevant data to support various projects
Participate in roadmap development sessions for future visualization products and dashboards
Participate in machine-learning modeling projects by compiling data visualization requirements and creating relevant visualizations
Diligently support and lead where needed, various activities between the teams to ensure the business and technical requirements and objectives are met.
Participate and contribute to the overall system(s) design.

Who You Are

Strong attention to detail
Proficient in querying Oracle and SQL databases
1-2+ years experience with data visualization libraries, frameworks and tools (Python, Java, JavaScript)
Ability to establish and apply data visualization best practices and graphical design principles
Possesses excellent oral and written communication skills
Team player with strong interpersonal skills and ability to take a leadership role when necessary
Problem solving and analytical skills
Comfortable with handling large datasets
Experience with batch scripting and Linux commands are an asset
Our Commitment

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). CAA CCG will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require an accommodation, please notify us and we will work with you to meet your needs.","CAA Club Group
3.8",Thornhill
268,HEAD OF ANALYTICS & INSIGHTS/DATA SCIENTIST,"For over 25 years we’ve been helping our community with essential oil blends that actually work. These essential oil blends treat stress, pain, gut, balance, and support in relaxation prior to sleep, and for symptoms of coughs and colds. We know that a life committed to wellness is greater than one focused on illness, and believe that reaching for natural can enhance your long-term health and wellness, every day.

We have been ranked by Canadian Business and PROFIT as one of Canada’s fastest growing companies. To support us on our journey, we are seeking diverse, purpose-lead people to join our team.

Get ready to celebrate global wellness with us.

DESCRIPTION

The role of the Head of Analytics & Insights/Data Scientist, will be to help us unlock the key insights that will drive our business decisions - not only through analysis coming from the team, but also through the enablement of the right data and clear insights for leaders across the marketing and commercial organizations.

RESPONSIBILITIES

Analytics & Insights

Lead cross-functional projects using advanced data modeling and analysis techniques to discover insights that will guide strategic decisions and uncover future growth opportunities and business strategies.
Manage the process to uncover insights in business operations seeking to increase insight clarity, as well as efficiency in the process of data management
Lead our community member analytics supporting the definition of KPIs and targets, and using audience and segmentation strategies to increase our acquisition effectiveness (highest LTV) and foster brand-loyalty
In Partnership with the Head of Growth, direct the performance marketing analytics strategy - developing targets and uncovering key insights, and determining business and data requirements for omni-infrastructure
Lead the reporting and analysis of eCommerce performance metrics and support the Head of eCommerce in strategic planning and setting targets, measurement of new features, business performance insights, and leadership for testing, consumer connects, and A/B tests
Partner with marketing and channel leads to measure reach effectiveness through the funnel - from brand awareness, impressions, followers, channel traffic, and support clear identification of return on investment
Analyze market trends, research, and opportunities; monitor competitor marketing outcomes
Identify key external trends and performance indicators (e.g., SEO, research) to support the strategic direction for marketing and wider leadership including brand and product
Support the development of performance models for new business development, collaborations, and channel expansions
Integrate qualitative feedback into analysis in partnership with VOC, UX, Stores, Surveys and more

Data & Reporting

Partner with IT to represent the business in the development of key performance marketing and customer data and reporting infrastructure to develop a 360 view of our consumer
Build, develop and maintain data models, reporting systems, data automation systems, dashboards and performance metrics support that support key business decisions
Partner with cross-functional leadership (marketing-led) to identify key data challenges and determine technical and process solutions
Ensure accuracy and accessibility of data, with clear data-definitions for cross-functional leaders

Process & Team Management

Develop a team of data analysts that help inform the future business strategies.
Build on key reporting frameworks, cadences and process for weekly, monthly and quarterly business reviews
Identify key tools, platforms and training required to ensure that marketing and commercial leaders can uncover key insights for their business and manage their performance
Develop data visualization tools for teams to support presentation of insights, and support the preparation of communication on business results and strategic direction for executive and management teams.
Ensure accuracy of data and on-time delivery of deliverables
Support teams with management of data intake process, and clear prioritization framework
Develop and implement quality controls and departmental standards to ensure quality standards, organizational expectations, and regulatory requirements
Anticipate future demands of initiatives related to people, technology, budget and business within the organization to support an insights-driven approach
APPLICANT REQUIREMENTS
Bachelor's degree in business, consumer behavior, market research or quantitative discipline
15+ years of experience in marketing, market research, and customer strategy
Experience in utilizing new digital techniques and methodologies to understand changing consumers including social listening, digital testing, building a customer panel
Experience includes complex, strategic research projects and using innovative methodologies
Experience with multivariate statistics, predictive modeling, regression models
Experience in media measurement and creative testing
Experience with managing and executing within the perimeters of a budget
Skilled at influencing, generating consensus and negotiating at the executive level
Strong leadership and team building skills.
Excellent verbal and written communication and presentation skills
Excellent organizational and prioritization skills
Excellent problem-solving skills
Strong collaborator, with a track record of building cross-functional relationships and alignment to strategic creative approach","Saje Natural Wellness
3.6",Vancouver
269,Senior Data Scientist,"Status: Remote work from any Canadian location. Work location may be re-evaluated based on pandemic status. This is a temporary full-time role, covering a 14 to 16-month leave.

We're looking for a Senior Data Engineer to support Data Science initiatives for top tier eCommerce clients such as Costco, Sam's Club, Staples and FedEx.

As a senior member of the Data team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional, and the ideal candidate will work across disciplines. You are able to iterate quickly on all stages of data pipeline and you will develop large scale data pipelines and analytical solutions using Big Data (and streaming) technologies.

The successful candidate has strong communication and engineering skills. You will need to have a passion for quality and an ability to understand sophisticated systems.

Responsibilities:

Design, model and develop data sets to support reporting analytics and exploratory analysis.
Research and employ cutting edge techniques to build and design the data infrastructure for distributed processing, aggregation, and collection of streamed real-time data.
Architect and build data delivery solutions in a microservice environment.
Contribute to technical design and ongoing development of our custom ETL solutions and analytics platforms, and help improve of design and delivery standards.
Focus on automation and optimization for all areas of DW/ETL maintenance and deployment.
Work with big data developers to build scalable and supportable infrastructure.
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together.
Assess and recommend the implementation available and latest big data technologies.
Recommend ways to improve data reliability, efficiency and quality.
Responsible for developing the data architecture components that scales for the ever evolving data needs of the entire company.
Solve big data warehousing problems on a massive scale and apply cloud-based services to solve challenging problems around: big data processing, data warehouse design, and enabling self-service.
Collaborate effectively with other members of the team and broader services group, including but not limited to Product Team, Data Science Team, Development Teams and Release and Operations Teams

Requirements:

Min Bachelor of Computer Science ideally Masters in Data
7+ years of Data Engineering or similar experience.
Experience in high level programming languages such as Java, Scala, or Python.
Proficiency with databases and SQL is required.
Experience working with large data sets - both SQL and NoSQL databases (e.g. MySQL, PostgreSQL, DynamoDB, etc.).
Experience building ETLs and data pipelines using tools such as Apache Airflow and Spark.
Experience working with cloud technologies (Azure, AWS).
Demonstrated ETL/data programming skills (using scripts or products like Informatica, DataStage).
Experience with DevOps practices, CI/CD, managing production deployments, Git and GitHub.
Ability to communicate design, concepts and decisions both verbally and in writing.
Ability to mentor other data engineering talent in the team.
Experience with large scale data warehousing, mining or analytic systems.
Ability to work with analysts to gather requirements and translate them into data engineering tasks.
Awareness of security, performance, high-availability and fault-tolerance and best practices.
Aptitude to independently learn new technologies.

Nice to have skills:

Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Experience building real time data pipelines using Apache Kafka.
Experience with virtualization, containers, and orchestration (Docker, Kubernetes).
Knowledge of data visualization and reporting tools like Tableau.
Experience with AWS EMR, AWS DMS, Talend, Apache Airflow, Stitch.
Experience with Amazon Web Services - RDS, EC2, S3, Lambda, Amazon Redshift.

About PNI Media:
At PNI, we're fueled by fun times, great experiences, and passion for the work we do. Over 25 million consumers use our platform each day to create and order millions of products from leading brand companies, and we're committed to delivering customers a high-quality experience. We know that healthy, happy people create amazing things, so we deliver a top tier experience for our employees, too: creative perks and benefits; a dynamic work environment; and a culture that honours diversity, wellbeing, community interaction and employee development. We're proud of PNI's achievements, our people, and our place at the top of the market.

Contract length: 14 - 16 months

Job Types: Full-time, Temporary

Salary: $2.00-$4.00 per year

Benefits:

Casual dress
Company events
Work from home

Schedule:

8 hour shift
Monday to Friday

COVID-19 considerations:
Remote virtual interviews, and COVID-19 precautions in place for in-person interviews.

Education:

Bachelor's Degree (required)

Experience:

data engineering or similar: 7 years (required)

Work remotely:

Temporarily due to COVID-19","PNI Media
3.9",Vancouver
270,Data Scientist Lead,"Avenue Code is the leading software consultancy focused on delivering end-to-end development solutions for digital transformation across every vertical. We’re privately held, profitable, and have been on a solid growth trajectory since day one. We care deeply about our clients, our partners, and our people. We prefer the word ‘partner’ over ‘vendor’, and our investment in professional relationships is a reflection of that philosophy. We pride ourselves on our technical acumen, our collaborative problem-solving ability, and the warm professionalism of our teams.



About the opportunity:

We’re looking for a passionate, talented, and innovative Data Scientist with a strong machine learning background to help build industry-leading AI/ML enabled applications for retail/commerce platforms. As a Data Scientist you will be working with big data (text, images, audio & other) to solve real-world problems for customers & partners, will design and run experiments, research new AI/ML algorithms & techniques, and find new ways of optimizing risk, opportunities,profitability, and customer experience.




Required Qualifications:

Hands on experience in leveraging data science (including ML) and analytics to solve business problems (preferably ecommerce);
Industry experience in Machine Learning or related fields;
Extensive experience in Python and SQL;
Programming experience in Spark framework and PySpark;
Hands-on experience with Scikit-learn, Pandas, and at least one of the deep learning frameworks: PyTorch, Keras, or TensorFlow;
Experience with different recommender systems (Sequential recommenders, Content recommenders, RL recommenders, etc.) and frameworks (Ex:PredictionIO);
Experience with building systems from scratch, putting them into production, and performing A|B testing;
Experience with Machine Learning orchestration frameworks (Kubeflow, Airflow, MLflow).




Nice to Have:

Knowledge of Scala;
Familiarity with modern approaches to computer vision problems (RESNet, transfer learning, Inception, etc.);
Knowledge of Google Cloud Platform (Big Query, Big Table, Pub/Sub, DataFlow, DataProc);
Familiarity with Agile




Does this sound like you? Apply now to become an Avenue Coder! #LI-Remote","Avenue Code
4.2",Canada
271,Clinical Scientist / Scientifique clinique,"The Clinical Scientist is responsible for medical writing activities at Innovaderm. The individual will author or contribute to development of clinical and regulatory documents (synopsis, study protocols, statistical analysis plans, clinical study reports), as well as scientific publications.


This role will be perfect for you if:

You are a strong medical writer with demonstrated ability to produce high-quality scientific documents to support clinical research.
You enjoy learning continuously and keeping yourself informed.
Having an impact within a growing company with momentum motivates you.


RESPONSIBILITIES

Is accountable for own medical writing deliverables, including quality, stakeholder communication, resolution of project issues, and timeline management;
Collaborates to clinical development of Phase 1/First-in-Man studies, Proof of Concept (POC) trials, Phase 2b – 3 studies, and Phase 4/registry trials.
Contributes to study design and writes/reviews clinical study protocols/amendments;
Reviews informed consent/assent forms, study reference manuals, statistical analysis plans, and mock shells of statistical tables/figures/listings;
Reviews, analyzes, and interprets study data based upon scientific expertise and industry standard practices;
Writes/reviews narratives and clinical study reports;
Prepares scientific abstracts, posters, and manuscripts;
Performs on-line literature searches;
Provides documents with high quality in terms of scientific content, organization, clarity, accuracy, format and consistency;
May perform quality control review of documents prepared by other team members;
Participates in process improvement efforts of the department.

Requirements:



IDEAL PROFILE


Education

MSc in life sciences; PhD is an asset;


Experience

Experience in writing clinical / regulatory documents such as study protocols and clinical study reports;
Experience analyzing and reporting on study data


Knowledge and skills

Good knowledge of good clinical practices, and applicable Health Canada and Food and Drug Administration (FDA) regulations/guidelines.
Good knowledge of drug development process;
Advanced English writing skills; strong English communication skills; French is an asset;
Strong proficiency of Word;
Ability to handle varied and multiple tasks, organize own work, and prioritize workload;
Has excellent attention to detail;
Client-focused attitude;
Quick learner, good adaptability, and versatile.

Our company:



The work environment


At Innovaderm, you will work with brilliant and driven colleagues. Our values are collaboration, innovation, reliability and responsiveness. We offer a stimulating work environment and attractive advancement opportunities.


As a Clinical Scientist, you will be eligible for the following perks:

Flexible work schedule
Permanent full-time position
Complete benefits (medical, dental, vision, RRSP, vacation, personal days, virtual medical clinic, public transportation rebates, social activities)
Offices near public transportation (Sherbrooke metro station or Saint-Laurent metro station)
Possibility of working from home or our office in Montreal in accordance with company policies and public health directives
Ongoing learning and development


About Innovaderm

Innovaderm is a contract research organization (CRO) specialized in dermatology. Since its beginnings in 2000, our organization has benefited from a solid reputation for the quality of its research and services exceeding the expectations of its clients. Based in Montreal, Innovaderm continues to grow and expand in North America and Europe.


Innovaderm is committed to providing equitable treatment and equal opportunity to all individuals. As such, Innovaderm will provide accommodations throughout the recruitment and selection process to applicants with disabilities, upon request.

Innovaderm only accepts applicants who can legally work in Canada.


Description FR:



Le Scientifique clinique est responsable des activités de rédaction médicale chez Innovaderm. Cette personne rédigera ou contribuera à l'élaboration de documents cliniques et réglementaires (synopsis, protocoles d'études, plans d'analyses statistiques, rapports d'études cliniques), ainsi que de publications scientifiques.


Ce poste sera parfait pour vous si :

Vous êtes un rédacteur médical expérimenté avec une habileté démontrée à produire des documents scientifiques de haute qualité pour supporter la recherche clinique.
Vous aimez apprendre continuellement et vous garder informé sur les nouveautés dans le domaine.
Avoir un impact au sein d’une compagnie en pleine croissance et en pleine lancée vous motive.


RESPONSABILITÉS

Est responsable de ses propres livrables de rédaction médicale, y compris la qualité, la communication avec les parties prenantes, la résolution des problèmes du projet et la gestion du calendrier;
Collabore au développement clinique des études de phase 1/essais de première administration (FIM), des essais de preuve de concept (POC), des études de phase 2b - 3 et des essais de phase 4.
Contribue à la conception de l'étude et rédige et examine les protocoles et amendements des études cliniques;
Révise les formulaires de consentement éclairé et d'assentiment, les manuels de référence des études, les plans d'analyse statistique et les coquilles simulées des tableaux/figures/listes statistiques;
Révise, analyse et interprète les données d'étude en fonction de l'expertise scientifique et des pratiques standard de l'industrie;
Rédige et révise les rapports d'études cliniques;
Prépare des résumés, posters et manuscrits scientifiques;
Effectue des recherches de littérature en ligne;
Fournit des documents de haute qualité en termes de contenu scientifique, d'organisation, de clarté, d'exactitude, de format et de cohérence;
Peut effectuer un examen de contrôle de la qualité des documents préparés par d'autres membres de l'équipe;
Participe aux efforts d'amélioration des processus du département;

Requirements FR:



PROFIL RECHERCHÉ


Éducation

Maîtrise en sciences de la vie; un doctorat représente un atout.


Expérience

Expérience en rédaction de documents cliniques et réglementaires tels que les protocoles d'étude et les rapports d'études cliniques;
Expérience en en analyse et communication des données d'étude;


Aptitudes et connaissances

Bonne connaissance des bonnes pratiques cliniques et des règlements/lignes directrices applicables de Santé Canada et de la Food and Drug Administration (FDA).
Bonne connaissance du processus de développement des médicaments;
Excellentes compétences en rédaction anglaise; solides compétences en communication anglaise; le français est un atout;
Excellente maîtrise de Word;
Capacité à gérer des tâches variées et multiples, à organiser son propre travail et à prioriser la charge de travail;
Excellente attention aux détails;
Attitude axée sur le client;
Capacité à apprendre rapidement, bonne adaptabilité et polyvalent.

Our company FR:



NOTRE ENTREPRISE


L’environnement de travail

Chez Innovaderm, vous travaillerez avec des collaborateurs compétents et dynamiques. Nos valeurs sont la collaboration, l’innovation, la fiabilité et la réactivité. Nous offrons un environnement de travail stimulant et des possibilités d’avancement intéressantes.


Dans le poste de Scientifique clinique, vous bénéficierez des conditions suivantes :

Flexibilité sur l’horaire
Poste permanent à temps plein
Gamme d’avantages sociaux (assurances médicales, dentaire, vision, régime de retraite, vacances, journées personnelles, clinique médicale virtuelle, rabais sur le transport en commun, activités sociales)
Bureau à proximité du transport en commun (métro Saint-Laurent ou métro Sherbrooke)
Possibilité de travail au bureau à Montréal, ou à la maison en fonction des politiques de l’entreprise et des directives de la santé publique
Formation et développement continu


À propos d’Innovaderm

Innovaderm est une entreprise de recherche clinique contractuelle (CRO) spécialisée en dermatologie. Depuis ses débuts en 2000, notre entreprise à taille humaine bénéficie d’une solide réputation autant pour la qualité de la recherche effectuée que pour la qualité des soins offerts, dépassant les attentes de ses clients. Basé à Montréal, Innovaderm continue aujourd’hui sa croissance en Amérique du Nord et en Europe.


Innovaderm s’engage à assurer une approche équitable ainsi que des opportunités équivalentes pour tous les candidats. À ce titre, Innovaderm fournira sur demande des accommodations aux candidats ayant un handicap, et ce, à travers toutes les étapes du processus de recrutement, si demandé.

Innovaderm accepte uniquement les candidats pouvant légalement travailler au Canada.

Le genre masculin est utilisé sans discrimination et dans le seul but d'alléger le texte.","Innovaderm Research
4.5",Remote
272,Clinical Scientist / Scientifique clinique,"The Clinical Scientist is responsible for medical writing activities at Innovaderm. The individual will author or contribute to development of clinical and regulatory documents (synopsis, study protocols, statistical analysis plans, clinical study reports), as well as scientific publications.


This role will be perfect for you if:

You are a strong medical writer with demonstrated ability to produce high-quality scientific documents to support clinical research.
You enjoy learning continuously and keeping yourself informed.
Having an impact within a growing company with momentum motivates you.


RESPONSIBILITIES

Is accountable for own medical writing deliverables, including quality, stakeholder communication, resolution of project issues, and timeline management;
Collaborates to clinical development of Phase 1/First-in-Man studies, Proof of Concept (POC) trials, Phase 2b – 3 studies, and Phase 4/registry trials.
Contributes to study design and writes/reviews clinical study protocols/amendments;
Reviews informed consent/assent forms, study reference manuals, statistical analysis plans, and mock shells of statistical tables/figures/listings;
Reviews, analyzes, and interprets study data based upon scientific expertise and industry standard practices;
Writes/reviews narratives and clinical study reports;
Prepares scientific abstracts, posters, and manuscripts;
Performs on-line literature searches;
Provides documents with high quality in terms of scientific content, organization, clarity, accuracy, format and consistency;
May perform quality control review of documents prepared by other team members;
Participates in process improvement efforts of the department.

Requirements:



IDEAL PROFILE


Education

MSc in life sciences; PhD is an asset;


Experience

Experience in writing clinical / regulatory documents such as study protocols and clinical study reports;
Experience analyzing and reporting on study data


Knowledge and skills

Good knowledge of good clinical practices, and applicable Health Canada and Food and Drug Administration (FDA) regulations/guidelines.
Good knowledge of drug development process;
Advanced English writing skills; strong English communication skills; French is an asset;
Strong proficiency of Word;
Ability to handle varied and multiple tasks, organize own work, and prioritize workload;
Has excellent attention to detail;
Client-focused attitude;
Quick learner, good adaptability, and versatile.

Our company:



The work environment


At Innovaderm, you will work with brilliant and driven colleagues. Our values are collaboration, innovation, reliability and responsiveness. We offer a stimulating work environment and attractive advancement opportunities.


As a Clinical Scientist, you will be eligible for the following perks:

Flexible work schedule
Permanent full-time position
Complete benefits (medical, dental, vision, RRSP, vacation, personal days, virtual medical clinic, public transportation rebates, social activities)
Offices near public transportation (Sherbrooke metro station or Saint-Laurent metro station)
Possibility of working from home or our office in Montreal in accordance with company policies and public health directives
Ongoing learning and development


About Innovaderm

Innovaderm is a contract research organization (CRO) specialized in dermatology. Since its beginnings in 2000, our organization has benefited from a solid reputation for the quality of its research and services exceeding the expectations of its clients. Based in Montreal, Innovaderm continues to grow and expand in North America and Europe.


Innovaderm is committed to providing equitable treatment and equal opportunity to all individuals. As such, Innovaderm will provide accommodations throughout the recruitment and selection process to applicants with disabilities, upon request.

Innovaderm only accepts applicants who can legally work in Canada.


Description FR:



Le Scientifique clinique est responsable des activités de rédaction médicale chez Innovaderm. Cette personne rédigera ou contribuera à l'élaboration de documents cliniques et réglementaires (synopsis, protocoles d'études, plans d'analyses statistiques, rapports d'études cliniques), ainsi que de publications scientifiques.


Ce poste sera parfait pour vous si :

Vous êtes un rédacteur médical expérimenté avec une habileté démontrée à produire des documents scientifiques de haute qualité pour supporter la recherche clinique.
Vous aimez apprendre continuellement et vous garder informé sur les nouveautés dans le domaine.
Avoir un impact au sein d’une compagnie en pleine croissance et en pleine lancée vous motive.


RESPONSABILITÉS

Est responsable de ses propres livrables de rédaction médicale, y compris la qualité, la communication avec les parties prenantes, la résolution des problèmes du projet et la gestion du calendrier;
Collabore au développement clinique des études de phase 1/essais de première administration (FIM), des essais de preuve de concept (POC), des études de phase 2b - 3 et des essais de phase 4.
Contribue à la conception de l'étude et rédige et examine les protocoles et amendements des études cliniques;
Révise les formulaires de consentement éclairé et d'assentiment, les manuels de référence des études, les plans d'analyse statistique et les coquilles simulées des tableaux/figures/listes statistiques;
Révise, analyse et interprète les données d'étude en fonction de l'expertise scientifique et des pratiques standard de l'industrie;
Rédige et révise les rapports d'études cliniques;
Prépare des résumés, posters et manuscrits scientifiques;
Effectue des recherches de littérature en ligne;
Fournit des documents de haute qualité en termes de contenu scientifique, d'organisation, de clarté, d'exactitude, de format et de cohérence;
Peut effectuer un examen de contrôle de la qualité des documents préparés par d'autres membres de l'équipe;
Participe aux efforts d'amélioration des processus du département;

Requirements FR:



PROFIL RECHERCHÉ


Éducation

Maîtrise en sciences de la vie; un doctorat représente un atout.


Expérience

Expérience en rédaction de documents cliniques et réglementaires tels que les protocoles d'étude et les rapports d'études cliniques;
Expérience en en analyse et communication des données d'étude;


Aptitudes et connaissances

Bonne connaissance des bonnes pratiques cliniques et des règlements/lignes directrices applicables de Santé Canada et de la Food and Drug Administration (FDA).
Bonne connaissance du processus de développement des médicaments;
Excellentes compétences en rédaction anglaise; solides compétences en communication anglaise; le français est un atout;
Excellente maîtrise de Word;
Capacité à gérer des tâches variées et multiples, à organiser son propre travail et à prioriser la charge de travail;
Excellente attention aux détails;
Attitude axée sur le client;
Capacité à apprendre rapidement, bonne adaptabilité et polyvalent.

Our company FR:



NOTRE ENTREPRISE


L’environnement de travail

Chez Innovaderm, vous travaillerez avec des collaborateurs compétents et dynamiques. Nos valeurs sont la collaboration, l’innovation, la fiabilité et la réactivité. Nous offrons un environnement de travail stimulant et des possibilités d’avancement intéressantes.


Dans le poste de Scientifique clinique, vous bénéficierez des conditions suivantes :

Flexibilité sur l’horaire
Poste permanent à temps plein
Gamme d’avantages sociaux (assurances médicales, dentaire, vision, régime de retraite, vacances, journées personnelles, clinique médicale virtuelle, rabais sur le transport en commun, activités sociales)
Bureau à proximité du transport en commun (métro Saint-Laurent ou métro Sherbrooke)
Possibilité de travail au bureau à Montréal, ou à la maison en fonction des politiques de l’entreprise et des directives de la santé publique
Formation et développement continu


À propos d’Innovaderm

Innovaderm est une entreprise de recherche clinique contractuelle (CRO) spécialisée en dermatologie. Depuis ses débuts en 2000, notre entreprise à taille humaine bénéficie d’une solide réputation autant pour la qualité de la recherche effectuée que pour la qualité des soins offerts, dépassant les attentes de ses clients. Basé à Montréal, Innovaderm continue aujourd’hui sa croissance en Amérique du Nord et en Europe.


Innovaderm s’engage à assurer une approche équitable ainsi que des opportunités équivalentes pour tous les candidats. À ce titre, Innovaderm fournira sur demande des accommodations aux candidats ayant un handicap, et ce, à travers toutes les étapes du processus de recrutement, si demandé.

Innovaderm accepte uniquement les candidats pouvant légalement travailler au Canada.

Le genre masculin est utilisé sans discrimination et dans le seul but d'alléger le texte.","Innovaderm Research
4.5",Remote
273,Applied Scientist,"1+ years of hand-on modeling experience in the area of predictive modeling, NLP, personalization, recommendation system
Deep understanding of statistical modeling and deep learning techniques.
Strong problem solving ability
Strong written and verbal communication skills and data presentation skills.
1 year experience in Python and SQL
About Us

Inclusive Team Culture
Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-live balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.

Amazon Science gives you insight into the company’s approach to customer focused scientific innovation. Amazon fundamentally believes that scientific innovation is essential to being the most customer-centric company in the world. It’s the company’s ability to have an impact at scale that allows us to attract some of the brightest minds in artificial intelligence and related fields. Our scientists continue to publish, teach, and engage with the academic community, in addition to utilizing our working backwards method to enrich the way we live and work.

Please visit https://www.amazon.science for more information.

Are you interested in helping Amazon ensure that customers make great purchase decisions and that the world's most recognized Brands using Amazon are successful listing and selling their products? The Brand Protection team designs and builds high performance software systems using machine learning that identify and prevent abuse on behalf of brand owners worldwide.

We are looking for a highly talented scientist to help build of our vision for Brand Protection. As a applied scientist on the team, you will interface directly with Product and Engineer to build hands of the wheel solutions to determine how Selling Partners (e.g. Third Party Sellers and Retail Vendors) list on our catalog. You will work backwards from data insights and customer feedback to build the right machine learning solutions, and resourceful in finding innovative solutions to unsolved problems.

This is a global role that will include interaction with Brands, Sellers and internal teams in countries outside of the United States, requiring a strong ability to communicate effectively and understand the different needs of global customers. You should have extensive experience leading multiple Machine Learning initiatives, from conception to launch in a rapidly evolving environment. Amazon’s growth requires leaders who move fast, have an entrepreneurial spirit to create new solutions, have an unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems.

Major responsibilities:

Understand business challenges by analyzing data and customer feedback
Collaborate with tech and product teams on model building strategies and model experiment, implementation and continuous improvement
Analyze and extract relevant information from large amounts of both structured and unstructured data to design strategies to solve business problems.
Use CV, NLP and state-of-the-art machine learning techniques to create scalable solutions for business problems
Create business and analytics reports and present to the senior management teams
Research and implement novel machine learning and statistical approaches
3 years of hand-on modeling experience in the area of Deep Learning, NLP or Computer Vision
Understanding of Software Development Life Cycle (SDLC) and project planning/execution skills including estimating and scheduling.
Ability and willingness to multi-task and learn new technologies quickly.
Familiar with AWS machine learning technologies such as SageMaker.
Strong program skills in C/C++, Java, and/or matlab
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contacted for an employment opportunity, advise Human Resources if you require accommodation, including in order to apply for a position.","Amazon.com.ca, Inc.
3.8",Vancouver
274,Principal Clinical Data Scientist Lead,"Do you want to watch clinical development change, or do you want to be the one to shape it?

Because we’re hoping you’re here for the latter.

Who are we?

We Are PRA.

We are 20,000+ employees strong, operating in more than 90 countries. We are committed to saving lives and we are constantly striving to be the best at what we do. Our impact is real and we see it every single day. We help get life-saving drugs into the hands of those who need them most.


Principal Clinical Data Scientist Lead

Overview:

Leads end-to-end data review activities performed on a clinical trial. Accountable for achieving clinical data management deliverables
on-time, with high quality and to agreed financial metrics. Responsible for applying advanced analytics to centrally aggregate and
analyze data from disparate sources to identify risks and issues impacting data integrity, patient safety and/or regulatory compliance.
Triages and assigns data review findings to the appropriate project team role for follow-up and resolution. Communicates trending
analyses and a summary of findings to internal and external stakeholders to support the on-time delivery of data fit for analysis.

Responsibilities:
Serves as the primary contact for internal and external team members regarding clinical data management data review activities
and leads these review activities to ensure the delivery of data fit for analysis.
Provides input into clinical system development activities, to ensure systems support the data review needs of the study, focusing
on critical data and processes, and identified risks.
Ensures clinical data management review requirements are put into production per the study’s protocol risk evaluation and
integrated data review plan (IDRP), and that ongoing data review activities are compliant with study plan requirements.
Contributes to the development and maintenance of study plans documents specifying data review strategy and applicable
procedures on assigned protocols/projects, including but not limited to data management plan.
Develops and oversees timeliness of clinical data management activities during the life cycle of studies as it relates to data review
and data delivery milestones.
Centrally reviews clinical data at aggregate level, using analytic reporting tool(s) to support the identification of risks and data
patterns/trends. Mitigates risks by using signal detection and quality indicators.
Communicates and triages issues to appropriate roles for follow-up and action to address root cause.
Proactively identifies out-of-scope clinical data management activities to the study project managers to be implemented in required
change orders.
Leads and hosts the data monitoring meetings, communicating issues to the internal and external stakeholders in a meaningful
way such as summarizing the data and representing the information visually.
Leads clinical data management activities on more complex projects with diverse scope.
Accountable for creating and maintaining clinical data management timelines, to oversee and achieve high quality interim and final contractual
deliverables for more advanced projects.
Using detailed knowledge of the protocol, identifies critical data and processes from protocol review, and supports protocol risk evaluation process.
Works with assigned project teams to communicate, address and resolve complex datarelated questions and recommends potential solutions; escalates issues which potentially impact patient safety or study analysis.
Trains and mentors new and less experienced team members.
Participates in sponsor and/or third party audits.
Develops tools/analytics used to monitor compliance and identify trends.
Actively seeks new business opportunities with assigned clients and collaborates with internal colleagues for new business initiatives.
Develops and maintains data review study documentation as appropriate to facilitate data validation and analytics.
Performs complex analytic reviews as defined in the scope of work and functional plan, focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretations of the final analysis. Identifies root cause to systematically resolve complex data issues.
Sets expectations and ensures consistency in data review approach and compliance and identifying trends.
May help to write articles for industry publications and give presentations at industry conferences.
Qualifications:

Bachelor’s degree in quantitative, scientific or health related field required.
8 years of relevant experience required.
Knowledge and/or understanding of analytic open source and/or enterprise level ETL and Analytic tools and practices
Sound knowledge of analytic modeling methods such as regression, classification and clustering
Strong programming skills in applicable systems, e.g., R, SQL, Python, SAS
Skill to efficiently navigate through large volumes of complex data, to interpret complex data problems, and to apply technical solutions.
Ability to analyze a complex data issue and design paths to effective potential solutions, understanding the impact of suggested solutions and
to help the project team make better decisions.
In-depth knowledge of the drug development process including risk-based monitoring principles, clinical and biometrics procedures, workflows, and software systems.
Expertise in interpreting protocols and identifying risks and appropriate mitigation strategies for clinical studies
Excellent skill in aggregate data review and interpretation using visualization/ analysis software, e.g., JReview,Tableau, SAS
Exellent project management and leadership skills
Excellent written and verbal communication and presentation skills
Ability to work collaboratively and effectively in a crossfunctional and culturally diverse team
Advanced ability to proactively represent data management internally and externally for all study related items and find pragmatic solutions in
compliance with regulatory requirements and policies.
To qualify for a position located in the United States, U.S. applicants must be legally authorized to work in the United States, and should not require, now o
Options
Apply for this job onlineApply
Share
Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.
Share on your newsfeed
Connect With Us!","PRA Health Sciences
4.0",Remote
275,Applied Scientist 1,"In the Bing image search team, we use machine learning, deep learning and NLP to model user queries and return the content that best satisfies their intents.

It’s more than just finding a web page that matches a query – it’s about training sophisticated machine learnt models to drive ranking and triggering, using sentence embeddings and deep learning to understand the quality of matches, online learning to react quickly to change, natural language processing to understand queries. We take advantage of big data and signals from millions of people across the web, pulling together and combining information from multiple sources to provide the user with results that best match their intent. Machine learning, deep learning, natural language processing, computer vision, big data mining and information retrieval - it’s all part of the job.

This is a fun and fast paced environment, where developers are empowered to collaborate and innovate. This is a great opportunity to work on something highly strategic to Microsoft, and an opportunity to directly impact millions of users in an exciting area.

As a team dedicated to building and promoting a diverse and inclusive team and environment, we look forward to receiving applications from qualified individuals of all backgrounds!
Responsibilities
Build multi-lingual text embeddings, machine learning and deep learning models from big data, to solve multimedia related classification and ranking problems, including query classification and intent prediction.
Build text classification models leveraged by multiple teams throughout Microsoft.
ML fundamentals: Data mining, wrangling, processing, visualization, model training, analysis.
Contribute ideas and techniques to shape decisions and improve search quality metrics.
Participate in design, implementation and execution with a team of engineers, applied scientists and product managers.
Qualifications
Required Qualifications:
BS or higher degree in Computer Science, Statistics or Applied Mathematics, Data Science, Machine Learning or similar technical field or equivalent practical experience
1+ years of experience with general purpose programming language (C#/C++/Java/Python etc.)
1+ years of experience in the areas of machine learning, deep learning, information retrieval, natural language processing or data mining
Good communication skills and ability to work in a collaborative environment

Preferred Qualifications:

Knowledge of Information Retrieval, Natural Language Processing techniques and semantic embeddings
Experience with semi-supervised learning, active learning, outlier detection
Clearly demonstrated record of accomplishment in delivering results.
Passion, creative problem-solving skills, and ability to ramp up in new areas.
Scientific publications and experience of peer-review for journals / conferences

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
276,Data Engineer,"WHO IS RATEHUB.CA?

We’re a company on a mission. Every single team member, from product & engineering, to sales & marketing, finance, operations and everything in between is obsessed with one thing; helping Canadian’s make better financial choices. And we’re pretty great at it, too. Via our digital application technology and our award winning in-house brokerages, we help over 1m Canadian’s per month make a positive impact on their finances. 365 days a year we deliver our users the best online mortgage experience, personalized credit card options, and cheaper auto & home insurance policies than they typically get from their existing financial adviser.

Changing how people make financial choices isn’t easy, though. We know that achieving our mission is full of challenges; challenges that can be complex and often unexpected, but that are always interesting, rewarding and fun to solve as a team. This is where you come in. We are on the hunt for the right kind of people to join us and help lead us forward to continued growth.

We’re looking for a Data Engineer to join our growing team, in downtown Toronto (temporarily remote due to COVID). Reporting to the Director of Analytics, the Data Engineer is an integral member of Ratehub’s Analytics team. This role will be responsible for building automations for unstructured manual processes in the different functions such as finance, marketing and sales to increase efficiency of the overall business. In addition, the role is also responsible for working with business stakeholders to enable data self service and support them with adhoc analytics where needed. This is an exciting opportunity to join a high-performing team, directly impacting the business as well as the design and evolution of the organization’s internal processes and infrastructure.

YOUR RESPONSIBILITIES

Partner with internal stakeholders to determine requirements, anticipate future needs, and identify areas of opportunity to drive efficiency and scalability
Develop data pipelines from various internal and external sources and build robust and scalable automations for manual processes
Develop a good understanding of how data will flow and be stored through the organization across multiple applications such as CRM, Broker & Sales tools, Finance / Accounting tools, Backend etc
Build new ETL scripts to integrate additional data sources as needed by the business
Setup, maintain and roll out data self service for our business stakeholders
Support the business with adhoc analytical requests as required

YOUR QUALIFICATIONS

Post-secondary degree: We value intelligence over relevance, but a Bachelors in Computer Science would be looked upon favorably
3+ years’ of similar work experience
Advanced SQL knowledge
Experience in building and maintaining ETL pipelines (using Python) and managing them through distributed job schedulers (Apache Airflow)
Experience in working with AWS infrastructure (EC2, S3, Redshift etc)
Familiarity with Data visualization tools like Tableau, Power BI, Looker (we use Looker so extra points for that)
Familiarity with Excel and/or Google Sheets (including macros & google scripts)

BEYOND THE TECHNICAL YOU ARE:

Detail oriented: High standard of data quality and integrity
Resourceful: You don’t have all the answers, but you know how to get them
Strong problem-solving skills and critical thinking abilities
Adaptable to a fast paced environment and able to pivot quickly to align with changing priorities


CULTURE FIT

Fun: You bring your whole self to work and make an effort to contribute to our workplace culture in a positive way
Do the right thing: You are able to assess both customer and company needs to make good business choices
Growth mindset: You love to learn and try new things
Willing to Help: You care about your team members and are willing to help out outside your realm of expertise.
Impact orientated: You are motivated by results and track to completion

JOB PERKS

Competitive salary: We know it’s expensive to live/work in Toronto
Flexible hours: Enjoy a couple more hours of sleep in the morning, if you want
Benefits: Health is wealth! A benefits package with no employee contribution required
Perks: RRSP matching program, individual training allowance, access to financial literacy training and resources
Casual dress code: If it’s good enough for you, it’s good enough for us
Fun team socials

Ratehub welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.

P0wA2CwVEX","Ratehub
4.7",Midtown Toronto
277,Data Engineer,"WHO IS RATEHUB.CA?

We’re a company on a mission. Every single team member, from product & engineering, to sales & marketing, finance, operations and everything in between is obsessed with one thing; helping Canadian’s make better financial choices. And we’re pretty great at it, too. Via our digital application technology and our award winning in-house brokerages, we help over 1m Canadian’s per month make a positive impact on their finances. 365 days a year we deliver our users the best online mortgage experience, personalized credit card options, and cheaper auto & home insurance policies than they typically get from their existing financial adviser.

Changing how people make financial choices isn’t easy, though. We know that achieving our mission is full of challenges; challenges that can be complex and often unexpected, but that are always interesting, rewarding and fun to solve as a team. This is where you come in. We are on the hunt for the right kind of people to join us and help lead us forward to continued growth.

We’re looking for a Data Engineer to join our growing team, in downtown Toronto (temporarily remote due to COVID). Reporting to the Director of Analytics, the Data Engineer is an integral member of Ratehub’s Analytics team. This role will be responsible for building automations for unstructured manual processes in the different functions such as finance, marketing and sales to increase efficiency of the overall business. In addition, the role is also responsible for working with business stakeholders to enable data self service and support them with adhoc analytics where needed. This is an exciting opportunity to join a high-performing team, directly impacting the business as well as the design and evolution of the organization’s internal processes and infrastructure.

YOUR RESPONSIBILITIES

Partner with internal stakeholders to determine requirements, anticipate future needs, and identify areas of opportunity to drive efficiency and scalability
Develop data pipelines from various internal and external sources and build robust and scalable automations for manual processes
Develop a good understanding of how data will flow and be stored through the organization across multiple applications such as CRM, Broker & Sales tools, Finance / Accounting tools, Backend etc
Build new ETL scripts to integrate additional data sources as needed by the business
Setup, maintain and roll out data self service for our business stakeholders
Support the business with adhoc analytical requests as required

YOUR QUALIFICATIONS

Post-secondary degree: We value intelligence over relevance, but a Bachelors in Computer Science would be looked upon favorably
3+ years’ of similar work experience
Advanced SQL knowledge
Experience in building and maintaining ETL pipelines (using Python) and managing them through distributed job schedulers (Apache Airflow)
Experience in working with AWS infrastructure (EC2, S3, Redshift etc)
Familiarity with Data visualization tools like Tableau, Power BI, Looker (we use Looker so extra points for that)
Familiarity with Excel and/or Google Sheets (including macros & google scripts)

BEYOND THE TECHNICAL YOU ARE:

Detail oriented: High standard of data quality and integrity
Resourceful: You don’t have all the answers, but you know how to get them
Strong problem-solving skills and critical thinking abilities
Adaptable to a fast paced environment and able to pivot quickly to align with changing priorities


CULTURE FIT

Fun: You bring your whole self to work and make an effort to contribute to our workplace culture in a positive way
Do the right thing: You are able to assess both customer and company needs to make good business choices
Growth mindset: You love to learn and try new things
Willing to Help: You care about your team members and are willing to help out outside your realm of expertise.
Impact orientated: You are motivated by results and track to completion

JOB PERKS

Competitive salary: We know it’s expensive to live/work in Toronto
Flexible hours: Enjoy a couple more hours of sleep in the morning, if you want
Benefits: Health is wealth! A benefits package with no employee contribution required
Perks: RRSP matching program, individual training allowance, access to financial literacy training and resources
Casual dress code: If it’s good enough for you, it’s good enough for us
Fun team socials

Ratehub welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.

P0wA2CwVEX","Ratehub
4.7",Midtown Toronto
278,Data Engineer,"WHO IS RATEHUB.CA?

We’re a company on a mission. Every single team member, from product & engineering, to sales & marketing, finance, operations and everything in between is obsessed with one thing; helping Canadian’s make better financial choices. And we’re pretty great at it, too. Via our digital application technology and our award winning in-house brokerages, we help over 1m Canadian’s per month make a positive impact on their finances. 365 days a year we deliver our users the best online mortgage experience, personalized credit card options, and cheaper auto & home insurance policies than they typically get from their existing financial adviser.

Changing how people make financial choices isn’t easy, though. We know that achieving our mission is full of challenges; challenges that can be complex and often unexpected, but that are always interesting, rewarding and fun to solve as a team. This is where you come in. We are on the hunt for the right kind of people to join us and help lead us forward to continued growth.

We’re looking for a Data Engineer to join our growing team, in downtown Toronto (temporarily remote due to COVID). Reporting to the Director of Analytics, the Data Engineer is an integral member of Ratehub’s Analytics team. This role will be responsible for building automations for unstructured manual processes in the different functions such as finance, marketing and sales to increase efficiency of the overall business. In addition, the role is also responsible for working with business stakeholders to enable data self service and support them with adhoc analytics where needed. This is an exciting opportunity to join a high-performing team, directly impacting the business as well as the design and evolution of the organization’s internal processes and infrastructure.

YOUR RESPONSIBILITIES

Partner with internal stakeholders to determine requirements, anticipate future needs, and identify areas of opportunity to drive efficiency and scalability
Develop data pipelines from various internal and external sources and build robust and scalable automations for manual processes
Develop a good understanding of how data will flow and be stored through the organization across multiple applications such as CRM, Broker & Sales tools, Finance / Accounting tools, Backend etc
Build new ETL scripts to integrate additional data sources as needed by the business
Setup, maintain and roll out data self service for our business stakeholders
Support the business with adhoc analytical requests as required

YOUR QUALIFICATIONS

Post-secondary degree: We value intelligence over relevance, but a Bachelors in Computer Science would be looked upon favorably
3+ years’ of similar work experience
Advanced SQL knowledge
Experience in building and maintaining ETL pipelines (using Python) and managing them through distributed job schedulers (Apache Airflow)
Experience in working with AWS infrastructure (EC2, S3, Redshift etc)
Familiarity with Data visualization tools like Tableau, Power BI, Looker (we use Looker so extra points for that)
Familiarity with Excel and/or Google Sheets (including macros & google scripts)

BEYOND THE TECHNICAL YOU ARE:

Detail oriented: High standard of data quality and integrity
Resourceful: You don’t have all the answers, but you know how to get them
Strong problem-solving skills and critical thinking abilities
Adaptable to a fast paced environment and able to pivot quickly to align with changing priorities


CULTURE FIT

Fun: You bring your whole self to work and make an effort to contribute to our workplace culture in a positive way
Do the right thing: You are able to assess both customer and company needs to make good business choices
Growth mindset: You love to learn and try new things
Willing to Help: You care about your team members and are willing to help out outside your realm of expertise.
Impact orientated: You are motivated by results and track to completion

JOB PERKS

Competitive salary: We know it’s expensive to live/work in Toronto
Flexible hours: Enjoy a couple more hours of sleep in the morning, if you want
Benefits: Health is wealth! A benefits package with no employee contribution required
Perks: RRSP matching program, individual training allowance, access to financial literacy training and resources
Casual dress code: If it’s good enough for you, it’s good enough for us
Fun team socials

Ratehub welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.

P0wA2CwVEX","Ratehub
4.7",Midtown Toronto
279,Senior Data Scientist / Scientifique des données senior,"The opportunity

Unity Monetization team builds advertising, in-game purchase promotion, and technologies used in hundreds of thousands of apps. Our Monetization platform processes TBs of data and delivers relevant content to hundreds of millions of users every day. Unity is investing heavily in deep learning.

In Montreal, we develop groundbreaking machine learning-centric products that provide millions of predictions each and every second to optimize the efficiency and profitability of user acquisition advertising campaigns.

We are looking now for a Senior Data Scientist to join our growing team! You will have a huge impact on scoping out, contributing, and delivering on new Monetization initiatives. Unity's vast game monetization ecosystem provides you unique chances to create real-world impact.

What you'll be doing

Improve and develop deep learning models to revolutionize user acquisition advertisement for mobile gaming

Drive Unity's user acquisition product in close collaboration with other data scientists, product managers, and engineers

Initiate and define new business opportunities and products based on data insights

Convey ideas, guide execution, and mentor junior team members

What we're looking for

Strong background in deep learning, from concepts to implementation

Production experience of machine learning systems at scale

Proven focus on delivering business value

Good coding skills and engineering practices, familiar with agile software process and data-driven development

Work with the tech stack of Python/BigQuery/Spark/TensorFlow/Kubeflow/Airflow

You might also have

Experience in mobile advertisement and gaming

Background in business analytics or software engineering

Experience in container technologies (Docker, Kubernetes)

Life at Unity

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com .

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

L'opportunité

L'équipe Monetization de Unity crée des publicités et des promotions pour les achats intégrés au jeu, ainsi que des technologies utilisées dans des centaines de milliers d'applications. Notre plateforme de monétisation traite au quotidien plusieurs téraoctets de données, pour fournir un contenu pertinent à des centaines de millions d'utilisateurs. Unity investit massivement dans l'apprentissage profond.

L'équipe de Montréal développe des produits révolutionnaires centrés sur l'apprentissage machine qui fournissent des millions de prévisions chaque seconde, afin d'optimiser l'efficacité et la rentabilité des campagnes publicitaires d'acquisition d'utilisateurs.

Nous sommes désormais à la recherche d'une ou d'un scientifique des données sénior qui rejoindra une équipe en pleine expansion! Vous contribuerez grandement à l'élaboration, à la mise en œuvre et à la réalisation de nouveaux projets de monétisation. L'écosystème de monétisation des jeux de Unity est immense et vous offre des possibilités uniques de produire un impact réel.

Ce que vous allez faire

Développer et améliorer des modèles d'apprentissage profond destinés à révolutionner la publicité liée à l'acquisition d'utilisateurs pour les jeux sur mobile

Diriger les projets d'acquisition d'utilisateurs de Unity en étroite collaboration avec les scientifiques des données, les chefs de produits et les développeurs issus d'autres équipes

Lancer et définir de nouvelles possibilités commerciales et de nouveaux produits sur la base des données recueillies

Communiquer les idées des uns et des autres, guider l'exécution des projets et encadrer les équipiers moins expérimentés

Ce que nous recherchons

Une expérience importante en matière d'apprentissage profond, depuis la conception jusqu'à la mise en œuvre

Expérience de la production de systèmes d'apprentissage machine à grande échelle

Priorité confirmée à la production de valeur commerciale

Bonnes compétences dans les domaines du codage et des meilleures pratiques d'ingénierie, connaissance des processus logiciels agiles et du développement piloté par les données

Travailler avec la pile technologique Python/BigQuery/Spark/TensorFlow/Kubeflow/Airflow

Vous avez peut-être également

Expérience dans la publicité et les jeux sur mobile

Expérience en matière d'analyse commerciale ou logicielle

Expérience en matière de technologies de conteneurs (Docker, Kubernetes)

La vie chez Unity

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com .

Unity est un employeur axé sur l'égalité qui s'engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d'emploi qui ne tiennent pas compte de l'âge, de l'ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l'identité sexuelle ou d'un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n'hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n'acceptons pas d'être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-DD1 #SEN","Unity Technologies
4.6",Montreal
280,Senior Data Scientist/Manager,"About Cerebri AI
Cerebri AI CVX platform uses the best Artificial Intelligence ( AI ), Operation Research ( OR ), and software to provide what is required in our digital age: value a customer's commitment to a brand and related products. It then uses these insights to then drive the selling of products and services. We use AI to answer the fundamental questions of the digital age: Who talks to the customer? Who understands the customer? How do we do this at scale when we have millions of customers?
Cerebri AI CVX platform includes a streaming capable AI software pipeline that processes data intake thru to producing insights and actions & presenting them via our APIs, in our customers' systems, or our UX. One customer journey ( CJ ) per customer means all models targeting CX and revenue KPIs and related next best offers ( NBOs ) use the same journeys.
We work with companies selling to over 200 million consumers and have 26 patents filed ( 8 granted ) on the Cerebri CVX platform. We now have 35 employees in three offices in Austin, Toronto, and Washington DC ( well around three offices ). Over 80% of the staff are in technical roles in data science and software engineering.
How do we do this? We hire the best data scientists, mathematicians, and software developers and work as a cross-disciplinary team/gang/clan. We work hard, laugh hard, and impress our peers and clients. Because we can. And because we want to. To learn more, visit cerebriai.com. In the meantime, if you think you have what it takes, give us a spin and upload resume.
""Cerebri AI was recognized as 2019 Cool Vendor for Customer Journey Analytics by Gartner.""
The ideal candidate
The ideal candidate is adept at leveraging large data sets to find patterns and using modelling techniques to test the effectiveness of different actions. S/he must have strong experience using various data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms, creating/running simulations, and testing its real-time implication. S/he must be comfortable working with a wide range of stakeholders and functional teams, trading off design to help others.
Responsibilities for Senior/Principal Data Scientist
Design, develop, test, advocate, evangelize and build data-driven modeling approaches
Assess the effectiveness and performance of modeling and data enhancement techniques
Perform feature analysis
Develop ontology for key market segments
Develop outcome/event taxonomy for key business models
Coordinate with different functional teams to implement data engineering, models and monitor outcomes
Build utility code and handle miscellaneous support tasks
Documenting projects and maintaining project documentation
Qualifications
Strong problem-solving skills with an emphasis on product development
6+ year experience working with and creating data architectures
Experience with artificial intelligence, natural language processing, machine learning
Excellent understanding of machine learning techniques: Supervised/Unsupervised/semi-supervised Learning, SVM, Tree-based Methods, Neural Networks, Naive Bayes, k-NN, ensemble methods, CNN, RNN, NLP, Feature Engineering, hyperparameters optimization, data visualization
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, 0-hypothesis, Regularization)
Experience using statistical computer languages (Python, SQL, etc.) and conventional data science toolkits, such as PANDAS, Weka, NumPy, MATLAB
Experience with NoSQL databases
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
Excellent written and verbal communication skills
Project management
A drive to learn and master new technologies and techniques
Tools we use
Confluence
JIRA
Spark
Azure, AWS, Kubernetes
Python, Scala
Keras, Scikit-learn, PANDAS, Numpy
Bit bucket, GitHub
Jupyter Notebook
Postgress, Parquet, mySQL
JavaScript, airflow, Pulsar
Nice to haves
Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline
Experience in operations research, applied statistics, algorithmic complexity, RDS
Experience with time Series, econometrics
Experience with streaming systems
Experience with Object-oriented modeling/MVC design patterns


How do we do this? We hire the best data scientists, mathematicians, and software developers and work as a cross-disciplinary team/gang/clan. We work hard, laugh hard, and impress our peers and clients. Because we can. And because we want to. To learn more, visit cerebriai.com. In the meantime, if you think you have what it takes, give us a spin and upload resume.

Specify your location preference","Cerebri AI
3.9",Midtown Toronto
281,Senior Data Scientist/Manager,"About Cerebri AI
Cerebri AI CVX platform uses the best Artificial Intelligence ( AI ), Operation Research ( OR ), and software to provide what is required in our digital age: value a customer's commitment to a brand and related products. It then uses these insights to then drive the selling of products and services. We use AI to answer the fundamental questions of the digital age: Who talks to the customer? Who understands the customer? How do we do this at scale when we have millions of customers?
Cerebri AI CVX platform includes a streaming capable AI software pipeline that processes data intake thru to producing insights and actions & presenting them via our APIs, in our customers' systems, or our UX. One customer journey ( CJ ) per customer means all models targeting CX and revenue KPIs and related next best offers ( NBOs ) use the same journeys.
We work with companies selling to over 200 million consumers and have 26 patents filed ( 8 granted ) on the Cerebri CVX platform. We now have 35 employees in three offices in Austin, Toronto, and Washington DC ( well around three offices ). Over 80% of the staff are in technical roles in data science and software engineering.
How do we do this? We hire the best data scientists, mathematicians, and software developers and work as a cross-disciplinary team/gang/clan. We work hard, laugh hard, and impress our peers and clients. Because we can. And because we want to. To learn more, visit cerebriai.com. In the meantime, if you think you have what it takes, give us a spin and upload resume.
""Cerebri AI was recognized as 2019 Cool Vendor for Customer Journey Analytics by Gartner.""
The ideal candidate
The ideal candidate is adept at leveraging large data sets to find patterns and using modelling techniques to test the effectiveness of different actions. S/he must have strong experience using various data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms, creating/running simulations, and testing its real-time implication. S/he must be comfortable working with a wide range of stakeholders and functional teams, trading off design to help others.
Responsibilities for Senior/Principal Data Scientist
Design, develop, test, advocate, evangelize and build data-driven modeling approaches
Assess the effectiveness and performance of modeling and data enhancement techniques
Perform feature analysis
Develop ontology for key market segments
Develop outcome/event taxonomy for key business models
Coordinate with different functional teams to implement data engineering, models and monitor outcomes
Build utility code and handle miscellaneous support tasks
Documenting projects and maintaining project documentation
Qualifications
Strong problem-solving skills with an emphasis on product development
6+ year experience working with and creating data architectures
Experience with artificial intelligence, natural language processing, machine learning
Excellent understanding of machine learning techniques: Supervised/Unsupervised/semi-supervised Learning, SVM, Tree-based Methods, Neural Networks, Naive Bayes, k-NN, ensemble methods, CNN, RNN, NLP, Feature Engineering, hyperparameters optimization, data visualization
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests, 0-hypothesis, Regularization)
Experience using statistical computer languages (Python, SQL, etc.) and conventional data science toolkits, such as PANDAS, Weka, NumPy, MATLAB
Experience with NoSQL databases
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations
Excellent written and verbal communication skills
Project management
A drive to learn and master new technologies and techniques
Tools we use
Confluence
JIRA
Spark
Azure, AWS, Kubernetes
Python, Scala
Keras, Scikit-learn, PANDAS, Numpy
Bit bucket, GitHub
Jupyter Notebook
Postgress, Parquet, mySQL
JavaScript, airflow, Pulsar
Nice to haves
Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline
Experience in operations research, applied statistics, algorithmic complexity, RDS
Experience with time Series, econometrics
Experience with streaming systems
Experience with Object-oriented modeling/MVC design patterns


How do we do this? We hire the best data scientists, mathematicians, and software developers and work as a cross-disciplinary team/gang/clan. We work hard, laugh hard, and impress our peers and clients. Because we can. And because we want to. To learn more, visit cerebriai.com. In the meantime, if you think you have what it takes, give us a spin and upload resume.

Specify your location preference","Cerebri AI
3.9",Midtown Toronto
282,Data Analyst,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it’s up to you.

The Role

Veeva is looking for an all-star Data Analyst to grow a global data platform for Customer Relationship Management and other applications. We’re looking for a high-energy, passionate individual with experience working with and mining data to discover trends and derive business important insights.
In this role, you will be responsible for creating standard reports as well as custom analysis, as required, based on changing business conditions within a therapeutic area or country. You will need a good understanding of the Life Sciences industry on how field sales, medical, and marketing work. You will help create and work with benchmarks to make the industry promotional and scientific exchange efforts more productive, which will impact patient treatment and outcomes. You need to be able to think Big Data with a global data set, but also Small Data and be good with details as trending can be very localized.
What You'll Do
Collaborate closely with Product Management, Data Scientists, and Data Engineers to build the data platform
Create standard reports and run reports for various stakeholders
Investigate data and propose a business rationale for behavior based on an understanding of the Life Sciences industry
Build and maintain reference data groupings such as Therapeutic Areas, indications, etc.
Derive meaningful and impactful insights from the data, and communicate possibilities unearthed through data.
Have a good intuition on when data cannot be taken at face value, and build context and meaning around metrics.
Proactively suggest new ideas and ways of operating
Educate others and be a champion of how to use this data set
Requirements
Excellent communication skills; written, verbal and formal presentation
BA/BS degree in Computer Science, Engineering, Math, or related technical field
2+ years of hands-on data analysis experience
3 years or more of experience with enterprise software
Energized by working through complex problems and love working with data
Experience with commercial aspects of the Life Sciences industry
Nice to Have
Experience with Veeva CRM
Worked on global life science programmes
Perks & Benefits
Conveniently located in downtown Toronto
Snacks, beverages, and weekly lunches from local restaurants
Team events and rec league sports teams
Allocations for continuous learning & development
Health & wellness programs
Weekly yoga classes
Ping pong and other games
Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.



Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
283,Senior Data Scientist,"Miovision’s mission is to provide the foundation for tomorrow’s smart cities by transforming the way traffic networks are managed today. Backed by the world’s most advanced traffic AI, Miovision’s innovations in traffic signal planning and operations have made it possible for cities to improve the transportation experience for drivers, cyclists and pedestrians since 2005. With offices in Kitchener, Canada and Cologne, Germany, Miovision serves over 17,000 municipalities worldwide. For more information, visit www.miovision.com

Position Summary

Miovision is looking for a Senior Data Scientist who is passionate about using data to improve transportation networks all over the world. We have collected a variety of datasets from transportation networks globally, spanning multiple years. We are looking for a data scientist to “live in the data”; determining the right questions to ask of the data, and to communicate the resulting insights.

We want you to apply a variety of techniques, such as data analysis, statistical modelling and machine learning, to help our customers solve real-world traffic problems. You will collaborate with data scientists, software developers, traffic engineers and computer vision specialists to develop data-driven, customer-facing solutions for a web-based analytics platform.

Key Accountabilities

This role’s main responsibility is to generate and own insights from these data.

Other accountabilities are to:

Prepare, manipulate and analyze data from real-world intersections
Build and own customer-facing models around real-time, 24/7 traffic data
Identify new sources of traffic data to combine with existing data sets
Research and implement new tools and techniques to solve novel problems
Drive improvements to data quality and completeness across the company
Frequently communicate insights and analyses with relevant departments
Master Miovision’s data stores and determine best practices for analyzing them
Understanding of current data collection techniques and biases/gaps

Skills/Qualifications

5+ years experience with data analysis, statistical analysis, predictive modeling, machine learning, or deep learning
Proficiency in one or more data-related programming languages; Python and SQL are preferred
Experience with data visualization tools
Experience with developing, validating and deploying models deployed in a production environment is an asset
Propensity to dive into new datasets, identify patterns or issues, and drive insights
A desire to ask and answer questions using data
Eagerness to share new results across multiple disciplines

Perks and Benefits

Note: The majority of Miovision employees are continuing to work from home due to COVID-19 Public Health regulations. When it is safe to do so, we plan on a cautious reopening of our Canadian office but will continue to offer flexible onsite and remote work options. Our Benefits are designed to reflect this and include:

Comprehensive health benefits starting on day one
RRSP Matching Plan
Mio-Days: We extend all three-day weekends to four-days and provide a Holiday Shutdown in December
Virtual Healthcare Service providing employees and their families access to healthcare providers 24/7
Internet subsidy and a remote work allowance
Enhanced paternity and maternity leaves
Unlimited vacation policy
Virtual fitness classes

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Please indicate if you require accommodation on your application, and our team will work with you to meet your accessibility needs.

8qRZxAAvqv","Miovision
4.5",Remote
284,Senior Clinical Data Scientist Lead,"Do you want to watch clinical development change, or do you want to be the one to shape it?

Because we’re hoping you’re here for the latter.

Who are we?

We Are PRA.

We are 20,000+ employees strong, operating in more than 90 countries. We are committed to saving lives and we are constantly striving to be the best at what we do. Our impact is real and we see it every single day. We help get life-saving drugs into the hands of those who need them most.


Principal Clinical Data Scientist Lead

Overview:

Leads end-to-end data review activities performed on a clinical trial. Accountable for achieving clinical data management deliverables
on-time, with high quality and to agreed financial metrics. Responsible for applying advanced analytics to centrally aggregate and
analyze data from disparate sources to identify risks and issues impacting data integrity, patient safety and/or regulatory compliance.
Triages and assigns data review findings to the appropriate project team role for follow-up and resolution. Communicates trending
analyses and a summary of findings to internal and external stakeholders to support the on-time delivery of data fit for analysis.

Responsibilities:
Serves as the primary contact for internal and external team members regarding clinical data management data review activities
and leads these review activities to ensure the delivery of data fit for analysis.
Provides input into clinical system development activities, to ensure systems support the data review needs of the study, focusing
on critical data and processes, and identified risks.
Ensures clinical data management review requirements are put into production per the study’s protocol risk evaluation and
integrated data review plan (IDRP), and that ongoing data review activities are compliant with study plan requirements.
Contributes to the development and maintenance of study plans documents specifying data review strategy and applicable
procedures on assigned protocols/projects, including but not limited to data management plan.
Develops and oversees timeliness of clinical data management activities during the life cycle of studies as it relates to data review
and data delivery milestones.
Centrally reviews clinical data at aggregate level, using analytic reporting tool(s) to support the identification of risks and data
patterns/trends. Mitigates risks by using signal detection and quality indicators.
Communicates and triages issues to appropriate roles for follow-up and action to address root cause.
Proactively identifies out-of-scope clinical data management activities to the study project managers to be implemented in required
change orders.
Leads and hosts the data monitoring meetings, communicating issues to the internal and external stakeholders in a meaningful
way such as summarizing the data and representing the information visually.
Leads clinical data management activities on more complex projects with diverse scope.
Accountable for creating and maintaining clinical data management timelines, to oversee and achieve high quality interim and final contractual
deliverables for more advanced projects.
Using detailed knowledge of the protocol, identifies critical data and processes from protocol review, and supports protocol risk evaluation process.
Works with assigned project teams to communicate, address and resolve complex datarelated questions and recommends potential solutions; escalates issues which potentially impact patient safety or study analysis.
Trains and mentors new and less experienced team members.
Participates in sponsor and/or third party audits.
Develops tools/analytics used to monitor compliance and identify trends.
Actively seeks new business opportunities with assigned clients and collaborates with internal colleagues for new business initiatives.
Develops and maintains data review study documentation as appropriate to facilitate data validation and analytics.
Performs complex analytic reviews as defined in the scope of work and functional plan, focusing on errors that matter or have a meaningful impact on the safety of the subject or interpretations of the final analysis. Identifies root cause to systematically resolve complex data issues.
Sets expectations and ensures consistency in data review approach and compliance and identifying trends.
May help to write articles for industry publications and give presentations at industry conferences.
Qualifications:

Bachelor’s degree in quantitative, scientific or health related field required.
8 years of relevant experience required.
Knowledge and/or understanding of analytic open source and/or enterprise level ETL and Analytic tools and practices
Sound knowledge of analytic modeling methods such as regression, classification and clustering
Strong programming skills in applicable systems, e.g., R, SQL, Python, SAS
Skill to efficiently navigate through large volumes of complex data, to interpret complex data problems, and to apply technical solutions.
Ability to analyze a complex data issue and design paths to effective potential solutions, understanding the impact of suggested solutions and
to help the project team make better decisions.
In-depth knowledge of the drug development process including risk-based monitoring principles, clinical and biometrics procedures, workflows, and software systems.
Expertise in interpreting protocols and identifying risks and appropriate mitigation strategies for clinical studies
Excellent skill in aggregate data review and interpretation using visualization/ analysis software, e.g., JReview,Tableau, SAS
Exellent project management and leadership skills
Excellent written and verbal communication and presentation skills
Ability to work collaboratively and effectively in a crossfunctional and culturally diverse team
Advanced ability to proactively represent data management internally and externally for all study related items and find pragmatic solutions in
compliance with regulatory requirements and policies.
To qualify for a position located in the United States, U.S. applicants must be legally authorized to work in the United States, and should not require, now or in the future, sponsorship for employment visa status.
PRA is an EEO/AA employer and is committed to providing opportunities to minorities, women, veterans, and individuals with disabilities.
Options
Apply for this job onlineApply
Share
Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.
Share on your newsfeed
Connect With Us!","PRA Health Sciences
4.0",Remote
285,Senior Data Engineer,"Position Summary

The SmartThings Big Data team in Vancouver is looking for a Senior Data Engineer who is passionate on big data technology and delivering data solutions. The Senior Data Engineer will work closely with our business strategy, cloud engineering, client engineering, UX design, consumer insights and marketing teams to make decisions on how we should invest in specific data-driven features and products.

You are a team player and know how to work well with others. You have a strong analytical mind and you like to see the whole picture. You have passion for solving complex problems and have a high degree of aptitude when it comes to learning new technologies. You love data and numbers and understand how important your role is in helping with business decisions.

If you want to work for one of the most recognized brands in the world and one of the Top 100 Employers in Canada, then please keep reading!

What We Offer:

Competitive Salary
Employer Paid Health Coverage (from day one)
Employee Purchase Program – discounts!
Social and Wellness Events
Employee Referral Program –we want great talent like you!

Role and Responsibilities

Be responsible for data engineering activities including data ingestion, data modelling, data processing data governance
Analyze different data in the ecosystem and create meaningful topics analysis reports.
Work with team to improve the data pipeline to process large scale data efficiently
Be a data steward to educate and promote the data importance and data-driven culture.
Collaborate with other groups worldwide to assist in product design, business strategy and user experience research, etc.
Be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data

Skills and Qualifications

5+ years of experience in big data engineering
Have deep understanding on data engineering principles
Hands-on experience of large scale and high availability systems
Strong knowledge of SQL (MySQL, PostgreSQL) and preferably experience with NoSQL databases
Proficient in at least one programming language and scripting languages (bash, Python, etc.)
Experience with various AWS services (EC2, S3, AWS CLI, Lambda, Kinesis Firehose, Redshift etc.)
Hadoop ecosystem knowledge (Hadoop, Spark, Kafka, Hive, Pig, Sqoop, etc.)
BS or MS in Computer Science or equivalent experience

Bonus Skills

Experience with Ariflow, EKS, EMR, Redshift, OLAP
Experience with Git and CircleCI
DevOps skills: create build & install scripts, terraform, UNIX-based systems management, release management, production monitoring, etc.
Agile/Scrum software development methodologies

Please note that this position is a 12 month contract.



Samsung is an equal employment opportunity employer. We thank you for your interest in working for Samsung; only candidates selected for an interview will be contacted.
#indhigh
#LI-DJ1","Samsung Electronics
3.4",Vancouver
286,Senior Data Engineer,"Position Summary

The SmartThings Big Data team in Vancouver is looking for a Senior Data Engineer who is passionate on big data technology and delivering data solutions. The Senior Data Engineer will work closely with our business strategy, cloud engineering, client engineering, UX design, consumer insights and marketing teams to make decisions on how we should invest in specific data-driven features and products.

You are a team player and know how to work well with others. You have a strong analytical mind and you like to see the whole picture. You have passion for solving complex problems and have a high degree of aptitude when it comes to learning new technologies. You love data and numbers and understand how important your role is in helping with business decisions.

If you want to work for one of the most recognized brands in the world and one of the Top 100 Employers in Canada, then please keep reading!

What We Offer:

Competitive Salary
Employer Paid Health Coverage (from day one)
Employee Purchase Program – discounts!
Social and Wellness Events
Employee Referral Program –we want great talent like you!

Role and Responsibilities

Be responsible for data engineering activities including data ingestion, data modelling, data processing data governance
Analyze different data in the ecosystem and create meaningful topics analysis reports.
Work with team to improve the data pipeline to process large scale data efficiently
Be a data steward to educate and promote the data importance and data-driven culture.
Collaborate with other groups worldwide to assist in product design, business strategy and user experience research, etc.
Be constantly challenged to learn and grow with new technologies, identify and solve complex problems via data

Skills and Qualifications

5+ years of experience in big data engineering
Have deep understanding on data engineering principles
Hands-on experience of large scale and high availability systems
Strong knowledge of SQL (MySQL, PostgreSQL) and preferably experience with NoSQL databases
Proficient in at least one programming language and scripting languages (bash, Python, etc.)
Experience with various AWS services (EC2, S3, AWS CLI, Lambda, Kinesis Firehose, Redshift etc.)
Hadoop ecosystem knowledge (Hadoop, Spark, Kafka, Hive, Pig, Sqoop, etc.)
BS or MS in Computer Science or equivalent experience

Bonus Skills

Experience with Ariflow, EKS, EMR, Redshift, OLAP
Experience with Git and CircleCI
DevOps skills: create build & install scripts, terraform, UNIX-based systems management, release management, production monitoring, etc.
Agile/Scrum software development methodologies

Please note that this position is a 12 month contract.



Samsung is an equal employment opportunity employer. We thank you for your interest in working for Samsung; only candidates selected for an interview will be contacted.
#indhigh
#LI-DJ1","Samsung Electronics
3.4",Vancouver
287,Data Engineer,"About MakerSights

MakerSights ( www.makersights.com ) is a SaaS/Mobile product intelligence platform that is transforming the retail product development process by combining digital engagement and predictive analytics. MakerSights enables brands to make better, data-driven decisions throughout the entire product development lifecycle. Types of insights and decisions MakerSights enables include quantifying consumer sentiment on product designs, optimization of the product portfolio, product demand estimation, pricing strategies and go-to-market decisions (matching products to specific regions and sales channels). Our customers include some of the largest retail brands such as, Levi's, allbirds, Shinola, and many more.
What you'll do

Literally craft the foundation of our (eventually big) data environment
Take our data pipeline to the next level.

Build quality data transformations in Python for our SQL data warehouse.
Improve the quality and reliability of existing pipelines.
Own the evolution of the data architecture.

Build custom data integrations with (enterprise) retail brands
Discover novel data sets and data sources. Make new data sets available for modeling.
Build an environment for data scientists to train, evaluate and deploy machine learning models to enable quicker experimentation.
Solve computationally intensive simulation challenges

Experiences which confidently represent you:
You have extensive software engineering experience with python, including testing and architecting software systems.
You have experience designing and querying SQL schemas.
You've built, deployed and run ETL/data pipelines with python / pandas, ideally with Airflow on AWS.
You have worked on projects that require attention to detail and are comfortable shipping production-ready code every week.
You've built data integrations that pull in and harmonize external data sources with the internal data architecture.
You have worked productively in unstructured (startup) environments.","MakerSights
4.7",Vancouver
288,Data Scientist Technical Lead (Toronto),"How do you imagine life at an insurance company - its people, its culture, its offices? We bet that if you join Intact, you will be in for quite a surprise!

With offices in downtown Toronto, Montreal and Quebec city, the Intact Lab is an innovation hub bringing together data scientists, machine learning experts, AI developers, software engineers, actuaries and a meteorologist who work together to propose and implement innovative solutions to the complex issues facing us.

Merging the speed and culture of a start-up with the resources and means of a large enterprise, the Intact Lab is a dynamic team offering exciting challenges, inspiring colleagues and great career opportunities (at one of Canada’s Top 100 Employers!)






About the role






Are you a machine learning expert who believes we are only in the infancy of artificial intelligence? Are you passionate about advanced analytics and Big Data? Do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools? We have the perfect opportunity for you!

Hiring Manager: Amine Mahmoudi

Workplace: Toronto (700, University Ave)

Your contribution:

Be the technical leader that help defining data science problems and developing innovative solutions using machine learning and advanced statistics
Help achieve long-term business goals by identifying and implementing solutions to subtle or ambiguous problems with the highest scientific rigour
Influence the lab technical direction by making actionable recommendations based on scientific and business findings to management
Coaching and mentoring of senior data scientists on technical matters and act as a technical reference for management
Review machine learning solutions and identify their corresponding scientific debt, and ultimately assess readiness for production deployment
Help the teams maintain a high scientific level by monitoring the application of data science standards of practice and participate in their evolution
Keep pace with new approaches and trends and use them in your own solutions
Work with other departments to promote the adoption of analytical principles within the organization





Qualifications






Your assets:

Your Master’s or PhD’s degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field)
Your 8 years of experience in the field of advanced statistics, data mining and text mining
Strong communication, time management, great teamworking and organization skills
Expert-level understanding of the underlying theory of machine learning
Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence
A multi-platform production experience with commercial and open-source data mining frameworks like Python, R, GitHub, etc.
Your ability to focus on vaguely defined issues requiring the application of a creative approach

Here are a few reasons why others have joined our team:

An award-winning, inspiring workplace that supports its people and recognizes great work
Stimulating, challenging projects and development opportunities to help you grow your skills and career
Flexibility in how and where you work
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A casual ‘dress for your day’ culture that encourages you to be yourself
A $350 annual wellness account that promotes an active lifestyle





Closing Statement






We are an Equal Opportunity Employer

At Intact, our value of Respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. We value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard.

If we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the Talent Acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs.

Background Checks

As an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. We want Intact to be a great place to work! This means that internal and external candidates will be asked to consent to background checks so we can learn more about you. Please note that for positions with access to financial data or funds, your credit must be in good standing.

Internal Candidates

For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility to Work in Canada

It’s important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.






Referral Bonus






This role is eligible for employee referral bonus. #myReferrals3000






LinkedIn Sponsored






#LI-QuebecIT","Intact
4.4",Midtown Toronto
289,Senior Data Scientist,"SOTI is committed to providing its employees with endless possibilities; learning new things, working with the latest technologies and making a difference in the world.

Job Title:

Senior Data Scientist

Location:

Mississauga

Who We Are

Over the last 20 years, we have been a global leader in enterprise mobility technology, with over 1000 talented employees in 25 countries and 10 offices around the world. SOTI’s two decades of success has built strong partnerships with leading mobile platform providers and device manufacturers. These relationships give us unparalleled insight into new technology and industry trends before they happen. The SOTI ONE Platform software helps businesses remove functional silos, eliminate downtime, build apps faster, manage all mobile and IoT devices in one place and deliver actionable insights. When everything is connected, the SOTI ONE Platform makes mobile and IoT business operations simpler, smarter and more reliable at the same time, enables companies to securely manage any device or endpoint with any form-factor and any operating system throughout their entire lifecycle from deployment to retirement. We are looking for an experienced Data Scientist to join our data analytics team to work on Machine Learning and AI projects using the vast wealth of data that we collect today.

What’s in it for you?

The People - From our humble origins in our founder’s basement, to our industry leading position today, SOTI has worked hard to foster a company culture that we can all believe in. A culture that emphasizes personal growth, continuous innovation and fun.

The Growth - Our environment fosters new ideas, fresh perspectives, and the ability to take them over the goal line. SOTI is a fast-paced environment with a global reach that encourages you to make your mark and be part of something big!

The Technology - You’ll get the chance to work with leading edge technologies and take on complex and interesting projects, as part of highly collaborative and agile teams. You will work alongside SOTI’s partners which include leading tech giants that will keep you on the cusp of emerging technologies.

What You’ll Do

Collaborate with various business units and other stakeholders to identify opportunities to drive business value by leveraging business intelligence, data visualization and machine learning best-practices
Develop innovative and effective approaches and apply statistical and predictive modelling techniques to solve analytics problems and communicate results and methodologies to business clients and senior members of the analytics team
Stay current with trends in the data science space; translate those trends into actionable strategic and tactical objectives for the company
Lead end-to-end design and implementation of machine learning and data analytics solutions
Own and deliver projects of diverse scope. Oversee the work several junior data scientists
Research, define, and develop data science capabilities into product experience; partner effectively with software engineers, designers, and product managers to deliver those capabilities

Experience You’ll Bring:

Expert in Python programming to write production-ready code
Strong data profiling, cleaning, mining, and technical documentation skills
5 + years of experience in building machine learning models
3+ years of experience with NLP, classification, and predictive modeling in production environments
2+ years of experience with time-series analysis, forecasting, and anomaly detection
A deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems
Strong knowledge and experience of different deep neural networks architectures (RNN, CNN, GAN, seq2seq/Transformers)
Experience with ML\AI solutions developed on large cloud computing infrastructure providers such as Azure and AWS
Graduate degree in computer science, software engineering, data science, statistics, or equivalent industry experience.

About SOTI

SOTI is the world's most trusted provider of mobile and IoT management solutions, with more than 17,000 enterprise customers and millions of devices managed worldwide. SOTI's innovative portfolio of solutions and services provide the tools organizations need to truly mobilize their operations and optimize their mobility investments. SOTI extends secure mobility management to provide a total, flexible solution for comprehensive management and security of all mobile devices and connected peripherals deployed in an organization.

At SOTI, we celebrate the uniqueness of our global teams and are proud to be an equal opportunity workplace. We are curious problem solvers who are committed to bringing the best mobile and IoT management solutions to market. We offer careers with #EndlessPossibilities.

What are you waiting for? Apply today: https://www.soti.net/careers

If you want to bring your ideas to life, apply at SOTI today.

We are committed to providing accessible employment practices that are in compliance with the requirements under the Human Rights Code and the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation during any stage of the recruitment process, please notify People & Culture at careers@soti.net .

Please note that SOTI does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Services Agreement with agency/recruiter, SOTI will not consider or agree to payment of any referral compensation or recruiter fee.","SOTI Inc.
3.4",Mississauga
290,Senior Data Scientist,"Clearco is a company built by founders for founders, and we're laser-focused on our mission to help entrepreneurs succeed. The Senior Data Scientist will have the opportunity to create models, build advanced analytics, and leverage machine learning to help Clearco's founders improve their understanding of their data and grow their businesses.

Application Deadline: June 22, 2021

Please be advised someone from the recruitment team will be in touch shortly after the application deadline.

What your day-to-day will look like:
You will collaborate and influence senior leadership to ensure Data Science directly impacts strategy
As your first task, you will leverage NLP techniques for web scraping to build a custom email automation platform that maximizes incoming company sales leads!
You will draw connections about a domain's change in Facebook followers and it's likelihood to take a capital infusion and so much more
You will analyze and build models on data, but will have the autonomy to collect their own data via purchase, web scraping (highly encouraged), and manual collection (via outsourced contractors)
You will conduct original analyses to advise and influence product, engineering, and operations efforts

You will thrive if you have:
Exceptional time-management and organization skills – you can manage project ambiguity, complexity, and interdependencies
Excellent interpersonal skills - you are able work with and influence a diverse group of stakeholders
A self-starter mindset – you enjoy discussing a problem and after the discussion is over, you can't wait to get started on the execution of a project!
The ability to think outside the box and understand the bigger picture – you are an innovative thinker
Demonstrated the ability to thrive in a fast-paced environment, while collaborating with and influencing business partners to achieve strategic goals

Technical Requirements:
4+ years of experience in a Statistician, Researcher, Machine Learning Engineer, Data Engineer, or Data Analyst role
A Bachelor's Master's, and/or PhD in Statistics, Machine Learning, Mathematics, Computer Science, Economics or any other related quantitative field
Experience with Python, Kubernetes/Docker, Version Control/Git, Snowflake/SQL, Analytics, and Statistics
Experience with spaCy, word embedding, web scraping for data collection

Clearco is an equal opportunity employer. We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. At Clearco, we're committed to developing and upholding an inclusive, transparent, and comfortable environment for all. We create a space where every voice, perspective, and idea is heard and acknowledged. We embrace differences, and know that our diverse team is our strength and what drives our innovation.

Clearco is committed to developing a barrier-free recruitment process and work environment. If you require any accommodation, please email us at accommodations@clear.co and we'll work with you to meet your accessibility needs.","Clearco
3.9",Ontario
291,Senior Data Scientist,"Bachelor's Degree
5+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
4+ years working as a Data Scientist
Experience processing, filtering, and presenting large quantities (100K to Millions of rows) of data
Experience with statistical analysis, data modeling, machine learning, optimizations, regression modeling and forecasting, time series analysis, data mining, and demand modeling
Experience applying various machine learning techniques, and understanding the key parameters that affect their performance
Excellent written and verbal communication skills. Strong ability to interact, communicate, present, and influence within multiple levels of the organization.
Experience with Predictive analytics (e.g., forecasting, time-series, neural networks) and Prescriptive analytics (e.g., stochastic optimization, bandits, reinforcement learning)
Amazon's Sponsored Products advertising business is one of the fastest growing areas in the company. Have you ever wondered what happens behind that “Sponsored” label you see in search results on Amazon? Hint: it involves a lot of interesting tech delivered by a great team.

The Sponsored Products Marketplace team optimizes the systems and ad placements to match demand with supply using a combination of data-driven product innovation, machine learning, big data analytics, and low latency/high-volume engineering. By the time organic search results are ready, we've processed all of the potential ads and determined which ones are going to be shown. We do that billions of times per day, resulting in millions of engagements with products that might otherwise not have been seen by shoppers.

The business and technical challenges are significant. Fortunately, we have a broad mandate to experiment and innovate, and a seemingly endless range of new opportunities to build a big, sustainable business that helps Amazon continuously innovate on behalf of all customers.
We're looking for customer-obsessed, innovative, professional data scientist who can help us take our products to the next level of functionality, quality and performance. We embrace leaders with a startup mentality — those who seek a disruptive yet clear mission and purpose, have an unambiguous owner's mindset, and are relentlessly obsessed with delivering amazing products. As a Sr. Data Scientist on our team, you will be responsible for building and managing modeling projects, identifying data requirements, and delivering methodology and tools that are statistically grounded around our advertiser facing products such as new targeting controls, ad sourcing techniques, automated optimization strategies, and advertiser-facing recommendations. You should have superb analytical, technical, business and communication skills to be able to work with business and technology leaders to define and prioritize key business questions, build data acquisition processes, data sets, statistical models and analyses that answer those questions. If this sounds like your sort of challenge, read on.

Characteristics indicative of success in this role:
·

Highly analytical: You solve problems in ways that can be backed up with verifiable data. You focus on driving processes, tools, and statistical methods which support rational decision-making.
·

Technically fearless: You aren't satisfied by performing 'as expected' and push the limits past conventional boundaries. Your dial goes to '11'.
·

Engaged by ambiguity: You're able to explore new problem spaces with unique constraints and non-obvious solutions.
·

Team obsessed individual contributor: You help grow your team members to achieve outstanding results. You've learned that big plans generally involve collaboration and great communications.
·

Quality obsessed: You recognize that professional engineers ship complete, tested software to avoid getting trapped in a sea of technical debt. You balance speed with quality.
·

Humbitious: You’re ambitious, yet humble. You recognize that there’s always opportunity for improvement. You use introspection and feedback from teammates and peers to raise the bar.
Master's degree in Operations Research Engineering, Statistics or related field
10+ years professional experience in large-scale data science or advanced analytics
Experience with AWS and data-oriented tools such as Redshift, Spark, EMR
Experience in online advertising domain (particularly, ad targeting and serving)
Experience as team leader
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.","AMZN CAN Fulfillment Svcs, ULC
3.8",Midtown Toronto
292,Junior GCP Data Engineer - Mississauga,"One of our Retail clients is looking for a Junior Data Engineer with experience in the Google Cloud platform.

Some of the main responsibilities include-

Design and build an ecosystem of modern data technologies on-premise and on GCP cloud; Develop high-performance data processing pipelines; create and maintain quality code, provide support during testing cycles and post-production deployment; motivation to address and resolve highly complex and multifaceted development-related issues, often independently.




Advantages
Large Retail client - working on the Google Cloud Platform along with Technical Product Managers, Data Scientists, and Data Engineers

Responsibilities

Design and build an ecosystem of modern data technologies on-premise and on GCP cloud; Develop high-performance data processing pipelines; create and maintain quality code, provide support during testing cycles and post-production deployment; motivation to address and resolve highly complex and multifaceted development-related issues, often independently.

Qualifications
A Computer Science degree or diploma or any other technical or Business degree is preferred.

Summary
The client is looking for a Data Engineer with experience in GCP. DE will be designing, building and operationalizing large-scale enterprise data solutions and applications using one or more of GCP data and analytics services; designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Spark, Python, Scala etc.","Randstad
4.2",Mississauga
293,"Data Scientist Technical Lead (Montreal), Intact Lab","Who needs insurance? Everybody. That keeps us busy. Very busy.

At the Intact Lab, we use machine learning, data science, software engineering, AI, agility, UX and design thinking to transform the customer experience for millions of Canadians.

Simplifying insurance takes creativity, empathy and hard work. We explore, take risks, make mistakes, and learn all day, every day.

Here, innovation is everyone's job. Ready to make your mark?






About the role






Are you a machine learning expert who believes we are only in the infancy of artificial intelligence? Are you passionate about advanced analytics and Big Data? Do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools? We have the perfect opportunity for you!

Hiring Manager: Amine Mahmoudi

Workplace: Montreal (2020, Blvd. Robert-Bourassa)

Your contribution:

Be the technical leader that help defining data science problems and developing innovative solutions using machine learning and advanced statistics
Help achieve long-term business goals by identifying and implementing solutions to subtle or ambiguous problems with the highest scientific rigour
Influence the lab technical direction by making actionable recommendations based on scientific and business findings to management
Coaching and mentoring of senior data scientists on technical matters and act as a technical reference for management
Review machine learning solutions and identify their corresponding scientific debt, and ultimately assess readiness for production deployment
Help the teams maintain a high scientific level by monitoring the application of data science standards of practice and participate in their evolution
Keep pace with new approaches and trends and use them in your own solutions
Work with other departments to promote the adoption of analytical principles within the organization





Qualifications






Your assets:

Your Master’s or PhD’s degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field)
Your 8 years of experience in the field of advanced statistics, data mining and text mining
Strong communication, time management, great teamworking and organization skills
Expert-level understanding of the underlying theory of machine learning
Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence
A multi-platform production experience with commercial and open-source data mining frameworks like Python, R, GitHub, etc.
Your ability to focus on vaguely defined issues requiring the application of a creative approach

Here are a few reasons why others have joined our team:

An award-winning, inspiring workplace that supports its people and recognizes great work
Stimulating, challenging projects and development opportunities to help you grow your skills and career
Flexibility in how and where you work
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A casual ‘dress for your day’ culture that encourages you to be yourself
A $350 annual wellness account that promotes an active lifestyle





Closing Statement






We are an Equal Opportunity Employer

At Intact, our value of Respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. We value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard.

If we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the Talent Acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs.

Background Checks

As an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. We want Intact to be a great place to work! This means that internal and external candidates will be asked to consent to background checks so we can learn more about you. Please note that for positions with access to financial data or funds, your credit must be in good standing.

Internal Candidates

For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility to Work in Canada

It’s important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.






Referral Bonus






This role is eligible for employee referral bonus. #myReferrals3000






LinkedIn Sponsored






#LI-QuebecIT","Intact
4.4",Montreal
294,"Data Scientist Technical Lead (Montreal), Intact Lab","Who needs insurance? Everybody. That keeps us busy. Very busy.

At the Intact Lab, we use machine learning, data science, software engineering, AI, agility, UX and design thinking to transform the customer experience for millions of Canadians.

Simplifying insurance takes creativity, empathy and hard work. We explore, take risks, make mistakes, and learn all day, every day.

Here, innovation is everyone's job. Ready to make your mark?






About the role






Are you a machine learning expert who believes we are only in the infancy of artificial intelligence? Are you passionate about advanced analytics and Big Data? Do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools? We have the perfect opportunity for you!

Hiring Manager: Amine Mahmoudi

Workplace: Montreal (2020, Blvd. Robert-Bourassa)

Your contribution:

Be the technical leader that help defining data science problems and developing innovative solutions using machine learning and advanced statistics
Help achieve long-term business goals by identifying and implementing solutions to subtle or ambiguous problems with the highest scientific rigour
Influence the lab technical direction by making actionable recommendations based on scientific and business findings to management
Coaching and mentoring of senior data scientists on technical matters and act as a technical reference for management
Review machine learning solutions and identify their corresponding scientific debt, and ultimately assess readiness for production deployment
Help the teams maintain a high scientific level by monitoring the application of data science standards of practice and participate in their evolution
Keep pace with new approaches and trends and use them in your own solutions
Work with other departments to promote the adoption of analytical principles within the organization





Qualifications






Your assets:

Your Master’s or PhD’s degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field)
Your 8 years of experience in the field of advanced statistics, data mining and text mining
Strong communication, time management, great teamworking and organization skills
Expert-level understanding of the underlying theory of machine learning
Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence
A multi-platform production experience with commercial and open-source data mining frameworks like Python, R, GitHub, etc.
Your ability to focus on vaguely defined issues requiring the application of a creative approach

Here are a few reasons why others have joined our team:

An award-winning, inspiring workplace that supports its people and recognizes great work
Stimulating, challenging projects and development opportunities to help you grow your skills and career
Flexibility in how and where you work
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A casual ‘dress for your day’ culture that encourages you to be yourself
A $350 annual wellness account that promotes an active lifestyle





Closing Statement






We are an Equal Opportunity Employer

At Intact, our value of Respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. We value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard.

If we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the Talent Acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs.

Background Checks

As an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. We want Intact to be a great place to work! This means that internal and external candidates will be asked to consent to background checks so we can learn more about you. Please note that for positions with access to financial data or funds, your credit must be in good standing.

Internal Candidates

For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility to Work in Canada

It’s important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.






Referral Bonus






This role is eligible for employee referral bonus. #myReferrals3000






LinkedIn Sponsored






#LI-QuebecIT","Intact
4.4",Montreal
295,Data Engineer,"Company:
Finning International Inc.

Number of Openings:
1

Worker Type:
Permanent

Position Overview:
Data is deeply embedded in the product and engineering culture at Finning, to maximize productivity and safety of Finning engineers and our customers. The Data Engineer will be focused on building a state-of-the-art data foundation to solve real world business challenges and optimizing Finning processes across a wide range of areas including supply chain, marketing, pricing, and sales. As part of the Finning Global Digital Services team, you will be working closely with cross-functional teams using agile methodologies and tools, building reliable and scalable data-driven solutions for optimizing maintenance, inventory, fuel, scheduling, and other services for Finning customers. This position will require a background and love for data modeling, building batch processes, and working with data architects and infrastructure team to build end-to-end data processing pipelines.

The Data Engineer will work under the mentorship of Senior Data Engineers and other leaders on the team and work in collaboration with other members on the Finning Digital teams, including Project Managers, Product Managers, Visual Analysts, and Architects, Software Engineers and more as we continue to explore new areas inside and outside of business, on our digital journey.

Job Description:
Extract, transform and load data from internal and external systems to Azure services using a combination of Azure Data Factory, Azure Data Lake, Azure SQL, Azure Data Warehouse, Azure Databricks, T-SQL, and Spark SQL.
Work with the business and non-technical stakeholders to discover and document technical requirements and to understand the core problem
Monitors, troubleshooting and resolving of issues with our hybrid (on premise and cloud) data platform
Drive the continually improvement of ongoing reporting and analysis processes, automating and/or simplifying support.
Stay abreast of innovations in Cloud infrastructure, Business Intelligence, Analytics and Data Warehouse tools and technologies
Design, develop, and maintain data pipelines
Create automated metrics using complex distributed databases and sources

Education & Experience

Bachelor’s or Master’s degree in Computer Science or equivalent experience
5+ years of software development experience
3+ years of experience in Azure, AWS, or GCP
3+ years of experience in developing data injection, consumption, ETL, and data sanitization processes
Practical experience with Azure Data Lake, Azure Synapse Analytics, Azure SQL and SQL data warehouse, and Azure Databricks services.

W e are committed to diversity at Finning, to building and sustaining a diverse and inclusive workforce and as an equal opportunity employer we encourage applications from all qualified individuals. Finning does not discriminate against applicants based on genders, races, national and ethnic origins, religions, ages, sexual orientation, marital and family status, and/or mental or physical disabilities.","Finning International Inc.
3.5",Vancouver
296,Lead Data Scientist,"Our people love the exciting and meaningful work they do, the cutting-edge resources and technology they have access to, the benefits we offer and the great community we’ve built. Want to join them?

Consultant Data Scientist – The Job

As a Consultant Data Scientist in Kainos, you’ll be responsible for leading teams and developing high quality solutions that use AI and ML technologies to delight our customers and impact the lives of users worldwide. It’s a fast-paced environment so it is important for you to make sound, reasoned decisions. You’ll do this whilst learning about new technologies and approaches, with talented colleagues that will help you to learn, develop and grow. As the technical leader in the team, you will also interact with customers, share knowledge and mentor those around you.

Essential Experience:

A minimum of a 2.1 degree in Computer Science, Machine Learning, Data Science, Statistics or in a similar highly quantitative field.
A proven ability to solve complex problems with demonstrable ability to learn new business concepts and domains quickly.
Expertise in developing models in languages including Python/R
Expertise using machine learning libraries (e.g. scikit-learn, caret, mlr, mllib)
Significant experience in cleansing, filtering and re-factoring complex data from different sources (including non-traditional data sources).
Expertise of working with Relational databases, NoSQL and various visualisation techniques.
Experience in delivering AI/ML projects to production through leadership and mentoring of junior team members
Strong interpersonal skills with the ability to lead client projects and establish requirements in non-technical language.

Desirable Experience:

An advanced degree in Computer Science, Machine Learning, Operational Research, Statistics or in a similar highly quantitative field.
Multiple examples of delivering data science projects and predictive solutions to live in an industry production environment.
Experience of containerisation and cloud deployment.
Experience of Deep Learning Architectures (e.g. MLP, RNN, CNN)


Who you are

Determined – you’re flexible and overcome obstacles to get the job done to achieve personal and team goals.
Creative – you actively look for better ways to do things using the latest AI technologies to find fresh solutions to complex problems
Honest – always constructive when giving or receiving feedback, being transparent and truthful when dealing with others
Respectful – you treat others as you would like to be treated being encouraging, accepting and supportive to everyone you deal with
Cooperative – you share information, knowledge and experience, understanding the mutual benefits of team working

WHO YOU ARE:
Our vision is to enable outstanding people to create digital solutions that have a positive impact on people’s lives. Our values aren't abstract; they are the behaviours we expect from each other every day and underpin everything that we do. We expect everyone to display our values by being determined in how obstacles are overcome; honest when dealing with others; respectful of how you treat others; creative to find solutions to complex problems and cooperative by sharing information, knowledge and experience. These values, applied collectively, help to produce an outstanding Kainos person, team and culture.","Kainos
4.3",Midtown Toronto
297,Lead Data Scientist,"While people dream of a better energy future, Peak Power is building it. Founded in 2015, Peak has developed a comprehensive software platform that alleviates strain on the electricity grid and drives value to owners of clean energy assets, buildings, and electric vehicles through electricity markets. Our Synergy software platform optimizes the operation of distributed energy resources by forecasting and predicting the behavior of electricity markets.

Reporting to the VP of Innovation, you will have the opportunity to work with a talented group of Data Scientists, Data Engineers, and business stakeholders in a fast-paced and exciting environment. As a Lead Data Scientist, you will guide a team on a mission to provide insights and predictions to our customers. Using large volumes of data from our production applications, you will use your people, process, and technology skills to solve fascinating problems.

This work matters. Even a small change to optimize power utilization can significantly impact our customers, our electrical grid, and our environment. We’re building something that will have a lasting, positive impact.


Our new Lead Data Scientist will:

Lead the development of machine learning models, such as energy demand prediction, to provide insights and automation for our customers and have a good understanding of the company’s business model/strategy
Lead analytics projects involving multiple analysts and business stakeholders to optimize the accuracy of predictions
Have a global vision of the whole projects as well as the company’s goal
Collaborate and lead the teams in feature extraction, data representation, and automatic data pipeline and collection design, as well as data quality assurance monitoring
Provide an expert opinion on data-related topics such as validation of assumptions, use of advanced statistical techniques and hypothesis testing, and product decisions related to data
Use data visualization tools to deliver insights to stakeholders to create new business opportunities.
Stay current with the latest cloud computing, machine learning, and data science technologies
Experiment with new models and techniques and be able to provide model improvement solution continuously

What you bring to Peak Power:

Master’s degree in data science, computer science, applied math, or a related technical field
5+ years of experience with applied data science, from requirement gathering to serving models, to solve business problems and create value for customers
Experience with SQL and NoSQL databases
Working with large data sets and familiar with big data platforms such as Hadoop, PySpark, and Kubernetes, etc.
Solid understanding of machine learning, deep knowledge of advanced statistical techniques and concepts, machine learning techniques, and expertise in their applications with advanced knowledge of languages/libraries such as pandas and Scikit-Learn;
Experience with computer vision and familiar with significant computer vision libraries such as TensorFlow/Keras, PyTorch, and OpenCV
Experience building machine learning pipelines, such as with Amazon SageMaker
Strong people, process, and technical leadership abilities
Excellent communication and collaborative problem-solving skills
Continuously learning new frameworks and technologies to generate innovative solutions


So why Peak Power?

We are focused on solving problems that impact energy markets both locally and around the world. We are a growth-stage clean technology company that has partnered with major names in real estate, electricity, and smart city spaces. To work with us is not only to work with an exciting company, but to also be on the cutting edge of the global transition to distributed, clean, and carbon-free energy.


Join us!

Peak Power is an equal opportunity employer. We welcome people of different backgrounds, experiences, abilities, and perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process.

CUtsWX48r1","Peak Power
5.0",Midtown Toronto
298,Machine Learning Scientist,"Bachelor’s degree in Computer Science, Statistics, Data Science, or any other quantitative field.
2+ years of non-internship professional experience with machine learning, statistical modeling, data mining, and/or analytics techniques.
2+ years of experience with Python, R, or other scripting languages.
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management.
Are you interested to disrupt and redefine the way customers buy Beauty products online? Are you interested in using the latest advances in machine learning, computer vision, and augmented reality to build online customer experiences for Beauty products that can equal or even surpass an in-store experience?

We are looking for talented and innovation-driven scientists who are passionate about building improved customer experiences by leveraging data-science and machine-learning technologies. You will have an opportunity to revolutionize the customer shopping experience across the world's most extensive catalog of beauty products. You will be directly responsible for leveraging machine-learning/computer-vision algorithms and data-science techniques to drive innovation. You will collaborate with product managers, software engineers, UX designers, scientists, and the broader Amazon tech community to build solutions that enhance the beauty shopping experience across all surfaces, including desktop, mobile devices, and other Amazon devices.

About the team

The Amazon Beauty Tech is a brand-new team that is rapidly expanding. We are a small group of engineers, scientists, product managers, and designers who drive technological innovation to improve customer experience. We have a startup-like work culture where innovation is encouraged; we are never afraid to propose grand ideas for fear of failing!

We build:

Computer vision and augmented reality (AR) experiences: We bring exciting experiences directly to the customer's mobile phone using their cameras and combinations of facial recognition and AR.
Personalization using machine learning: We will be working with machine learning (ML) technologies such as data classification and reinforced learning models to provide better-personalized shopping experiences.
Elevated customer experiences: We will create beautiful and dynamic customer experiences that require deep knowledge of relevant UI technologies and user-centric design patterns.
Amazon scale systems: All our technology needs to work at Amazon scale, serving millions of customers with millisecond-level latency.
Data pipeline and analytics tools: Amazon is data-driven, and a robust data backbone is necessary for our systems. We build on robust and scalable data pipelines and tools using core AWS services.
Master’s degree or PhD in a highly quantitative field (Machine Learning, Statistics, Data Science, Math, etc.).
Experience applying various machine learning techniques, and understanding the key parameters that affect their performance.
Familiarity with deep learning algorithms and/or computer vision.
Familiarity with at least 1-2 popular AI/ML frameworks and tools - TensorFlow, PyTorch, MXNet, scikit-learn, OpenCV, ARCore, and ARKit.
Expertise in estimation, experimental design, hypothesis, and A/B testing.
Experience partnering with engineering teams to build and test production systems.
Familiarity with AWS services such as EC2, DynamoDB, RDS, AWS Lambda, and Amazon SageMaker.
Ability to achieve stretch goals in a highly innovative and startup-like environment.","Amazon Dev Centre Canada ULC
3.8",Vancouver
299,Senior Data Scientist,"Come to work for Realtor.com! A leader in online real estate and backed by industry experience and the News-Corp Brand, Realtor.com's vision is to be the leading destination to discover and create your perfect home, and today millions of unique users visit our company's website and mobile apps monthly. What you can do at Realtor.com has the potential to touch people in a real and meaningful way.

At realtor.com, we process terabytes of data everyday and transform that data into information that powers decisions for millions of home buyers, sellers, renters, dreamers, and real estate professionals. You'll engage with some of the best and the brightest co-workers and leaders, learn and contribute, and have a great time. If you enjoy working in a fast-paced, dynamic, cutting-edge work environment and desire to make a meaningful contribution to the business, then make the move!

We seek a highly seasoned ML practitioner to join our Data Science - Machine Learning team and help take it to the next level. We use advanced ML to build recommender systems and matching models, search relevance & ranking systems, user personalizations and consumer segmentation models. We also leverage the latest advancements in deep learning on images and NLP to build rich, next-gen experiences for our users. As a key member of the team, you will be responsible for the development and deployment of innovative concepts, research, predictive modeling, and machine learning algorithms. You will also serve as a mentor for the junior members on the team and provide guidance on their projects.

Responsibilities:
Research, build and deploy machine learning and deep learning algorithms.
Design and build solutions leveraging the wealth of consumer clickstream data, real estate property data, images and text data of realtor.com.
Create scalable machine learning models - classification & regression (GBMs, RF, LR, etc.), forecasting, clustering, neural networks (CNNs, LSTMs, Transformers, etc.) that integrate into batch, streaming and real-time systems.
Build end-points to serve ML models in production.
ML Ops (monitor inference performance, scalability, availability, etc).
Effectively partner with product and engineering teams to ideate and build new data-driven and machine learning based features for enriching the experience of home shoppers.
Drive A/B & multivariate tests and design of experiments to facilitate testing of new product and design features, with focus on improving engagement, retention, and conversion.
Help improve the scope of our data sets by identifying new data collection and procurement opportunities on an ongoing basis.
Generate descriptive visualizations and presentations to communicate insights and results.
Mentor the team on data exploration, machine learning, deep learning and developing data-oriented products.
Work with a sense of ownership and urgency, advocate for experimentation-based, agile culture.

Requirements:
MS/PhD in machine learning, computer science, applied mathematics or related fields.
5+ years of relevant work experience in the industry building and productionizing ML models.
Proficient in Python, Scikit-learn, XGBoost, PyTorch/TensorFlow, and other languages and frameworks appropriate for ML modeling and deployment.
Proficiency in Recommender Systems or Consumer Classification modeling is a plus!
Proficiency in Deep Learning (NLP and/or Computer Vision) is a plus!
Experience with relational databases (SQL) and large scale distributed systems.
Comfortable with experiment design and A/B and multivariate tests.
Exposure to Docker and Containerization.
Knowledgeable of core CS concepts such as: structured and unstructured data, data management and querying, common data structures and algorithms.
Strong creative thinking and problem solving skills.
Excellent oral and written communication and presentation skills.

About realtor.com

At realtor.com ®, we believe that everyone deserves a home of their own. We're a community of nearly 2,000 employees who work hard to ensure that from the moment someone starts dreaming about a new home, to the moment they walk in the door and beyond, we're there to lend a helping hand. Every month, over 85 million people trust us with their journey home by visiting our site and mobile apps, and we'd love to have you join our team to help.

We've got great offices in the U.S. and Canada with lots of sweet jobs to choose from, so we're hoping you'll join us on our journey to make buying, selling, renting, and living in homes easier and more rewarding for everyone.

Let's make a difference, together. For Real.","realtor.com
3.6",Vancouver
300,"Data Scientist, Liquidity and Funding Management","Address:

100 King Street West

Job Family Group:

Data Analytics & Reporting

Applies knowledge of advanced analytic algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to deliver better predictions and/or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. Applies strong communication and story-telling skills to summarize statistical/algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business/groups. Drives innovation through the development of Data & AI products that can be leveraged across the organization and establishes best practices in in alignment with Data & AI governance frameworks of BMO.

Qualifications:

Acts as a trusted advisor to assigned business/group.
Influences and negotiates to achieve business objectives.
Recommends and implements solutions based on analysis of issues and implications for the business.
Assists in the development of strategic plans.
Identifies emerging issues and trends to inform decision-making.
Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports data collection, integration, and retention requirements for data.
Develops experimental design approaches to validate findings or test hypotheses.
Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.
Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.
Applies innovative and best practices to advanced analytics services to ensure high quality standards.
Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.
Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.
Provides advice and guidance to assigned business/group on implementation of analytical solutions.
Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and/or decisions.
Works with various data owners to discover and select available data from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.
Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.
Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.
Performs experimental design approaches to validate finding or test hypotheses.
Uses the appropriate algorithms to discover patterns.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports development of tools and delivers training for data analytics and AI.
Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.
Leads/participates in the design, implementation and management of core business/group processes.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Provides specialized consulting, analytical and technical support.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently and regularly handles non-routine situations.
Broader work or accountabilities may be assigned as needed.
Typically between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.
Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience
Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).
Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).
Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms.
Deep knowledge and technical proficiency gained through extensive education and business experience.
Verbal & written communication skills - In-depth.
Collaboration & team skills - In-depth.
Analytical and problem solving skills - In-depth.
Influence skills - In-depth.
Data driven decision making - In-depth.

We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

To find out more visit us at https://jobs.bmo.com/ca/en .

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.","BMO Financial Group
3.8",Midtown Toronto
301,Data Intern (Scientist/Analyst/Engineer/DevOps),"During the Internship at ProCogia, the intern will get involved in a wide variety of data related projects. ProCogia are proud partners of RStudio PBC, Amazon APN and Snowflake. Through these partnerships the intern will gain exposure to a wide spectrum of activities. Activities can vary from Data Analytics, Science, Engineering and DevOps types of activities depending on the intern and the available projects.


Primary Accountabilities/Responsibilities


The intern is to deliver outcomes that can be used directly by the business for its own needs or for demonstrative purposes to potential and existing customers.



Develop applications, dashboards, reports and other materials for demonstrative purposes.
Assis the Product Development Team (KORUS) in developing novel data based software microservices. See appsedia.com for one such example.
Build impactful presentations to illustrate our deliverables at customer sites.
Develop in-house analytical solutions such as but not limited to:



o develop machine learning models for business operations,
o develop analytics dashboard for the financial forecasting,
o deploy a Data Warehouse for the company’s business systems,
o develop cloud automation scripts to deploy analytic environments.


The intern may also assist on some customer facing projects to gain real world experience. These activities could be wide ranging depending on the intern and the active projects. Examples could be such as below, but not limited to this:



Assist consultants in the data cleansing, preparation, analytics and ML phases,
Assist in writing efficient ETL scripts for engineering applications,
Develop customer facing dashboards and reports,
Assist in the install, configuration and management of cloud hosted data services.


The ultimate goal of the internship program is to ready individuals for life as an FTE at ProCogia. The right Intern will demonstrate during their time at ProCogia their embodiment of our values:


Growth Mindset -We are constantly learning and improving. There is no failure, just an opportunity to learn and grow.
Leadership - We take initiative, assume ownership and drive our customers forward.
Stewardship - We are diligent and resourceful. We show integrity and courage through our actions.
Customer First - We strive to earn and keep our customer’s trust by doing what’s right and delivering the best results.
Excellence - We go above and beyond in everything we do and deliver outstanding solutions.
Unified - We support, respect and trust each other. We are stronger together. When one of us wins, we all win.
Innovation - We take a proactive approach to embrace innovation, willingly take risks and adapt to changes.


Key Skills/Experience Required:


Candidate would ideally have or be in the process of finalizing a MSc or PhD in Mathematics, Statistics, Computer Science or other relevant technical area.
Candidates should be proficient in the following:


o R or Python
o Command Line Scripting
o PowerBI or other GUI based Dashboarding software.


Data Engineering or Data DevOps interns should have some experience with:


o AWS or SnowFlake.
o Ansible or other automation tools.
o Python, Scala or similar language.
o Terraform or other cloud infrastructure tool.


All candidates should have excellent written and verbal communication skills.","ProCogia
4.7",Vancouver
302,"Senior Data Scientist TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Architect and build AI and machine learning models
Provide expert input on architecture of Tonal's data collection, analytics, infrastructure, and learning systems
Identify innovative opportunities for data-driven features
Develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more.
Develop algorithm to recommended weights to users over time
Recommend workouts that users are likely to enjoy
Improve real-time rep and set detection from sensor data
Analyze user behavior and engagement to inform feature roadmap and marketing
Collaborate with ML, front-end, back-end, and firmware engineers to implement algorithms

Who You Are

Advanced degree in mathematical field or equivalent experience
5+ years data science experience
Knowledge of machine learning and signal processing algorithms
Knowledge of data filtering, and cleansing techniques
Strong knowledge of Python, SQL, and one of Java, C/C++, Kotlin, or Go
Team player with high integrity
Open to feedback and constantly striving to improve
High degree of self-awareness

Extra Credit

Experience with gyros and accelerometers, computer vision, or control theory
Experience as a software engineer

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
303,Applied Scientist,"1+ years of hand-on modeling experience in the area of predictive modeling, NLP, personalization, recommendation system
Deep understanding of statistical modeling and deep learning techniques.
Strong problem solving ability
Strong written and verbal communication skills and data presentation skills.
1 year experience in Python and SQL
About Us

Inclusive Team Culture
Here at Amazon, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-live balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.

Amazon Science gives you insight into the company’s approach to customer focused scientific innovation. Amazon fundamentally believes that scientific innovation is essential to being the most customer-centric company in the world. It’s the company’s ability to have an impact at scale that allows us to attract some of the brightest minds in artificial intelligence and related fields. Our scientists continue to publish, teach, and engage with the academic community, in addition to utilizing our working backwards method to enrich the way we live and work.

Please visit https://www.amazon.science for more information.

Are you interested in helping Amazon ensure that customers make great purchase decisions and that the world's most recognized Brands using Amazon are successful listing and selling their products? The Brand Protection team designs and builds high performance software systems using machine learning that identify and prevent abuse on behalf of brand owners worldwide.

We are looking for a highly talented scientist to help build of our vision for Brand Protection. As a applied scientist on the team, you will interface directly with Product and Engineer to build hands of the wheel solutions to determine how Selling Partners (e.g. Third Party Sellers and Retail Vendors) list on our catalog. You will work backwards from data insights and customer feedback to build the right machine learning solutions, and resourceful in finding innovative solutions to unsolved problems.

This is a global role that will include interaction with Brands, Sellers and internal teams in countries outside of the United States, requiring a strong ability to communicate effectively and understand the different needs of global customers. You should have extensive experience leading multiple Machine Learning initiatives, from conception to launch in a rapidly evolving environment. Amazon’s growth requires leaders who move fast, have an entrepreneurial spirit to create new solutions, have an unrelenting tenacity to get things done, and are capable of breaking down and solving complex problems.

Major responsibilities:

Understand business challenges by analyzing data and customer feedback
Collaborate with tech and product teams on model building strategies and model experiment, implementation and continuous improvement
Analyze and extract relevant information from large amounts of both structured and unstructured data to design strategies to solve business problems.
Use CV, NLP and state-of-the-art machine learning techniques to create scalable solutions for business problems
Create business and analytics reports and present to the senior management teams
Research and implement novel machine learning and statistical approaches
3 years of hand-on modeling experience in the area of Deep Learning, NLP or Computer Vision
Understanding of Software Development Life Cycle (SDLC) and project planning/execution skills including estimating and scheduling.
Ability and willingness to multi-task and learn new technologies quickly.
Familiar with AWS machine learning technologies such as SageMaker.
Strong program skills in C/C++, Java, and/or matlab
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contacted for an employment opportunity, advise Human Resources if you require accommodation, including in order to apply for a position.","Amazon.com.ca, Inc.
3.8",Vancouver
304,Data Scientist - Performance Engineering - Toronto Hub,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or in our Toronto office - it’s up to you.

Managing the performance needs of Veeva Vault, a complex and industry-standard SaaS system supporting Life Sciences requires analyzing data from our performance testing and production systems. It requires a careful analysis of test results and production metrics. The sheer amount of data generated in production and testing makes manual analysis a considerable challenge and error-prone. You will be helping to automatically detect performance degradations and correlate them to causes and find areas for improvement.

As a Data Scientist for the Veeva Vault Performance Engineering team, you focus on designing and building automated analysis tools to improve overall operational excellence and derive valuable and actionable information from data.
You are excited about statistics and applied data science on large datasets, exploratory data analysis, projection methodologies, anomaly detection, and more. You design and build computationally efficient and practical statistical algorithms while keeping the business problems we are solving in mind. While ML is an integral part of your toolkit, it's not your only skill. The ability to dissect the situation and to select from a variety of techniques is vital.
This position is an excellent opportunity for someone excited about using their statistics and data science expertise to design and build algorithms and models. Collaborate closely with Engineering to create a highly performant product and see the impact of your work on the Life Sciences industry.
What You'll Do
Use exploratory data analysis and visualization techniques to simplify analyzing large-scale performance data and extract actionable insights.
Collaborate closely with the team of Performance Engineers, developers to innovate, discover and deliver novel solutions for operational excellence.
Rapidly build prototype product solutions, communicate findings, iterate & enhance.
Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems, prioritize and solve
Work with product and engineering teams to implement performance improvements.
Apply machine learning, data mining, and statistical analysis techniques where appropriate
Requirements
5+ years of hands-on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects
B.S, M.S. or Ph.D. in Applied Statistics, Mathematics, Computer Science, Machine Learning or other quantitative disciplines
Highly proficient in Python (packages: pandas, scikit-learn, statsmodels) and SQL; experience working with AWS preferred
Experience working with large quantities of data to develop models that work in a stable, production approach with live data
Advanced knowledge of statistical analysis and data mining techniques (regression, multilevel regression, poststratification, semi-supervised learning, forecasting, decision trees, clustering, A/B testing, etc.)
Experience working with engineering to roll out software to production including monitoring, and documentation
Comfortable (and excited!) about ambiguity and breaking goals down into tangible and actionable work plans
Strong communication skills and ability to work across internal teams
Perks & Benefits
Flexible PTO
Allocations for continuous learning & development
Health & wellness programs
#LI-Remote

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
305,Data Engineer,"Coursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 82 million registered learners as of March 31, 2021. Coursera partners with over 200 leading university and industry partners to offer a broad catalog of content and credentials, including Guided Projects, courses, Specializations, certificates, and bachelor’s and master’s degrees. More than 6,000 institutions have used Coursera to upskill and reskill their employees, citizens, and students, including in high-demand fields such as data science, technology, and business. Coursera became a B Corp in February 2021.

Data Engineering is unique at Coursera. Our team doesn’t simply build reports on demand. Rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.

We’re looking for a talented and driven senior data engineer with a keen eye for data and business to help us build and scale our platform. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and software engineering skills, who shares our passion for education. In this role, you’ll directly work with cross-functional teams(product, engineering, services) to design, develop, and deploy data solutions for our enterprise learners and admins.
Responsibilities:
Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake
Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights
Build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data
Partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently
Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches
Basic Qualification:
1+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science
Preferred Qualifications:
Strong software engineering skills and at least one scripting language (e.g., Python)
Proficient with relational databases and SQL
Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred
Ability to communicate technical concepts clearly and concisely
Independence and passion for innovation and learning new technologies

If this opportunity interest you, you might like these courses on Coursera -
Big Data Specialization
Big Data Essentials - HDFS, MapReduce and Spark
Data Warehousing for Business Intelligence
Coursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.



Please review our CCPA Applicant Notice here.","Coursera
3.9",Midtown Toronto
306,Senior Data & Applied Scientist - Content Recommendation,"The Microsoft News & Feeds team is looking for self-motivated and experienced data & applied scientists for the content recommendation team - a team that has the potential to define the future of content services for Microsoft. We connect 500M+ users with the content they care about, not only to help them to stay informed and entertained but also empower them to start conversations with their friends, family, and colleagues. We bring together premium publishers and the best of the web into a personalized, intelligent feed that never stops. We are available globally and across the Microsoft ecosystem, in Windows, in Edge browser, on MSN.com, or on your phone. Whether its news, sports, shopping, videos, finance, weather or eSports, we have something for everyone.

At our core is our large-scale personalized recommendation system, large scale distribution platform[JW1] , data intelligence, and immersive experiences. We are a passionate, user-focused R&D team with world-class engineers, scientists, and product managers.

In this role, you will build a large-scale personalized recommendation system scaling globally to 1B+ users. You will work on problems such as recommendation, user modeling, ranking, content diversity, natural language processing, data mining and platforms, and topic modeling. You will provide thought leadership to scientists, and engineers to deliver highly quality personalized recommendations that will engage and delight our users. You will work with teams of talented scientists, and help recruit the best scientists in machine learning, e.g. personalized recommendation, NLP, data science.

As a senior member of the team, you are expected to be able to bring structure to ambiguous business problems and use science, logic, and practical experience to decompose them into straightforward, scalable solutions. You will set the standard for scientific excellence and make decisions that affect the way we build and integrate algorithms. Your solutions are exemplary in terms of algorithm design, clarity, model structure, efficiency, and extensibility. You tackle intrinsically hard problems; you're interested in learning; and you acquire skills and expertise as needed.

If you are seeking an iterative, fast-paced environment where you can drive innovation, apply state-of-the-art technologies to solve extreme-scale real world delivery challenges, and have business impact on global scale, this is your opportunity.

Responsibilities
You will be building state-of-the-art personalized recommendation systems. You will leverage state-of-the-art approaches across recommendation, NLP, data science. You will train models, run experiments, build data pipelines, and define measurements and metrics all in the pursuit of delighting 1B+ users through recommendation.
Set strategic direction and plan of execution based on insights gained through data analysis and customer feedback to drive meaningful business results.
You will mentor with potential to tech-lead teams of Data and Applied Scientists and Software Engineers to successfully execute on our roadmap and achieve your strategic objectives.
Drive collaboration and partnership with other R&D teams in Microsoft to deliver an outstanding product.
Qualifications
Required Qualifications:
6+ years of industry experience in a Data Scientist, Applied Scientist or related role.
6+ years of hands-on experience in one or more of the following areas: recommendation, deep learning, machine learning, text analysis, information retrieval, NLP, computer vision with a strong understanding of both practical and theoretical aspects.
3+ years of experience with large scale data processing infrastructure such as Spark, Hadoop, or similar.

Preferred Qualifications:
Advanced degree in CS/CE/EE/Data Science or related areas
Experience developing in Python/R/C++/C#
Ability to own Machine Learning systems end-to-end - from data pipelines and training to real-time prediction engines.
Ability to independently drive cross team collaborations and ship production features in a fast-paced startup environment.
Excellent communication and presentation skills, both verbal and written.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.

#Recommendation# #MachineLearning# #Personalization# #NLP# #WebXT# #BigData# #ContentServices#","Microsoft
4.4",Vancouver
307,Data Scientist - AML - 312972,"Business Analyst

On behalf of our client in the Banking Sector, PROCOM is looking for a Business Analyst.

Business Analyst – Job Description

Reporting to the Advanced Analytics Manager, the Data Scientist I will be conducting all analytical activities related to AML transaction monitoring systems
Provide maintenance of transaction monitoring scenarios, and analytical queries in support of the bank's strategic efforts to mitigate money laundering and terrorist financing risk
Conduct activities related to AML/ATF scenario performance review and tuning
Help maintain a structured documentation process to demonstrate an effective scenario review program to satisfy audit, compliance, and regulatory requirements
With assistance from management, assist with scenario related issues/questions from Global AML members, audit, and other partners
Provide solutions where there is a need for advanced quantitative, statistical, and analytical skills
Undertake ad hoc data mining research projects to find hidden patterns and potential anomalies within data
Partner with GAML teams to implement changes to existing solutions and/or the implementation of alternative solutions
Use statistical and data mining techniques to build and maintain effective and efficient transaction monitoring, customer behavior, and risk scoring machine-learning models
Communicate results to various stakeholders and ensure they fully understand implications of relevant measures

Business Analyst – Mandatory Skills

Masters’ degree or higher in Statistics, Computer Science/Software Engineering
Expert knowledge of SAS, SQL, R & Python are essential
Ability to apply statistical techniques and data mining tools to solve business problem
3+ years of experience in data modeling/machine learning
Experience in query optimization, debugging and automation
Strong knowledge of Microsoft Office suite, including Excel and PowerPoint
Excellent written and oral communication, analytical and interpersonal skills, including ability to communicate with individuals from various backgrounds
Excellent multi-tasking skills, ability to adapt to and manage changing priorities

Business Analyst – Nice to Have Skills

AML knowledge is an asset

Business Analyst - Assignment Start Date

ASAP – 20 months to start

Business Analyst - Assignment Location

Toronto, ON – Work Remotely","Procom
4.3",Midtown Toronto
308,"Senior Data Scientist, KPMG Lighthouse","Overview:
You’ve got big plans. We have opportunities to match, and we’re committed to empowering you to become a better you, no matter what you do.

When you join KPMG you’ll be one of over 219,000 professionals providing audit, tax, advisory and business enablement services across 147 countries.

With the support to do things differently, grow personally and professionally and bring your whole self to work, there’s no limit to the impact you can make. Let’s do this.

The opportunity:


Innovate. Collaborate. Shine. Lighthouse — KPMG Canada’s Center of Excellence for Data Valorization, Advanced Analytics— applies data science to solve real-word business problems, operationalize AI and optimize emerging technologies for its mission. Join a diverse team which is always curious and learning, thinking independently, working collaboratively, has a passion to solve difficult problems, and has fun doing it.


KPMG Lighthouse Québec has an exciting opportunity for a Senior Data Scientist to join our team! This role will be a rewarding experience for you if you:

Thrive on challenges and work best in a fast-paced environment where each day is different
Work well in a project team environment and have strong collaboration and interpersonal skills
Have a permanent “figure it out” mindset
What you will do:
Work closely with clients in understanding key business issues.
Gather and analyze requirements to develop impactful recommendations and solutions.
Utilize advanced analytical technics to solve challenging business problems. Leverage a diverse set of technologies and tools to deliver insights.
Solve problems through the application and the development of suitable statistical models, machine learning, deep learning, reinforcement learning algorithms & techniques such as clustering, neural networks, causal inference, probabilistic models, natural language processing (NLP), computer vision, time series algorithms, etc.
Work with large volumes of data (structured and unstructured).
Investigate and perform deeper analysis to produce impactful algorithms to achieve targeted outcomes.
Perform quantitative analysis of data issues.
Effectively communicate orally and in writing with peers within Lighthouse, KPMG and the client.
What you bring to this role:
University Degree in mathematics, statistics, machine learning, computer science, operations research, engineering or econometrics, other quantitative disciplines and/or equivalent combination of education in related disciplines.
5 years of professional experience in a related field.
Expert knowledge in advance modeling techniques and mathematical models, algorithm use and optimization, and data science technologies.
Understanding of the full spectrum of data feature retrieval, selection, and engineering; model technique selection and integration; interpretation of outputs, and development of recommendations.
Capability of identifying commonalities across seemingly disparate analytics use cases, in order to identify unique ways of approaching modeling.
Strong experience in data mining, mathematics, statistics, machine learning (deep learning and reinforcement learning an asset).
Strong communication in English and French and interpersonal skills.
Keys to your success:

Understanding the top issues faced by clients related to data and analytics through discussions with peers, clients, etc., and by following business media, industry issues reports, etc.
Ability to understand engagement objectives including:
Understanding the client's business problem.
How the engagement helps address the client's business problem.
Explain the business value of addressing the business problem.
Learn more about where a career at KPMG can take you.
Our Values, The KPMG Way:
Integrity, we do what is right | Excellence, we never stop learning and improving | Courage, we think and act boldly | Together, we respect each other and draw strength from our differences | For Better, we do what matters

KPMG in Canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier-free workplace that allows all of our people to reach their full potential. A diverse workforce is key to our success and we believe in bringing your whole self to work. We welcome all qualified candidates to apply and hope you will choose KPMG in Canada as your employer of choice.

If you have a question about accessible employment at KPMG, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact KPMG’s Employee Relations Service team for support at email: cdnersteam@kpmg.ca or phone: 416-777-8002 or toll free 1-888-466-4778 Option 3.

For general recruitment-related inquiries, please contact the HR Delivery Centre at cafmcdnhrsthotline@kpmg.ca.","KPMG
3.9",Montreal
309,Machine Learning Scientist,"Bachelor’s degree in Computer Science, Statistics, Data Science, or any other quantitative field.
2+ years of non-internship professional experience with machine learning, statistical modeling, data mining, and/or analytics techniques.
2+ years of experience with Python, R, or other scripting languages.
Advanced ability to draw insights from data and clearly communicate them (verbal/written) to the stakeholders and senior management.
Are you interested to disrupt and redefine the way customers buy Beauty products online? Are you interested in using the latest advances in machine learning, computer vision, and augmented reality to build online customer experiences for Beauty products that can equal or even surpass an in-store experience?

We are looking for talented and innovation-driven scientists who are passionate about building improved customer experiences by leveraging data-science and machine-learning technologies. You will have an opportunity to revolutionize the customer shopping experience across the world's most extensive catalog of beauty products. You will be directly responsible for leveraging machine-learning/computer-vision algorithms and data-science techniques to drive innovation. You will collaborate with product managers, software engineers, UX designers, scientists, and the broader Amazon tech community to build solutions that enhance the beauty shopping experience across all surfaces, including desktop, mobile devices, and other Amazon devices.

About the team

The Amazon Beauty Tech is a brand-new team that is rapidly expanding. We are a small group of engineers, scientists, product managers, and designers who drive technological innovation to improve customer experience. We have a startup-like work culture where innovation is encouraged; we are never afraid to propose grand ideas for fear of failing!

We build:

Computer vision and augmented reality (AR) experiences: We bring exciting experiences directly to the customer's mobile phone using their cameras and combinations of facial recognition and AR.
Personalization using machine learning: We will be working with machine learning (ML) technologies such as data classification and reinforced learning models to provide better-personalized shopping experiences.
Elevated customer experiences: We will create beautiful and dynamic customer experiences that require deep knowledge of relevant UI technologies and user-centric design patterns.
Amazon scale systems: All our technology needs to work at Amazon scale, serving millions of customers with millisecond-level latency.
Data pipeline and analytics tools: Amazon is data-driven, and a robust data backbone is necessary for our systems. We build on robust and scalable data pipelines and tools using core AWS services.
Master’s degree or PhD in a highly quantitative field (Machine Learning, Statistics, Data Science, Math, etc.).
Experience applying various machine learning techniques, and understanding the key parameters that affect their performance.
Familiarity with deep learning algorithms and/or computer vision.
Familiarity with at least 1-2 popular AI/ML frameworks and tools - TensorFlow, PyTorch, MXNet, scikit-learn, OpenCV, ARCore, and ARKit.
Expertise in estimation, experimental design, hypothesis, and A/B testing.
Experience partnering with engineering teams to build and test production systems.
Familiarity with AWS services such as EC2, DynamoDB, RDS, AWS Lambda, and Amazon SageMaker.
Ability to achieve stretch goals in a highly innovative and startup-like environment.","Amazon Dev Centre Canada ULC
3.8",Vancouver
310,Data Science Instructor,"About the Position

Exciting things are happening at Juno College! We’re in the midst of building out our Data Science Career Pathway and are seeking a __full-time Instructor to join our Data Science team in May.

We’re looking for someone who is collaborative, empathetic, and passionate about teaching, with a strong background in Data Science. This is a flexible role that’ll allow you to inspire and lead others, mould new pedagogies, research and test innovative ways of delivering content, and support the growth of our Data Science program offerings, while also still having the chance to practice your craft by taking on data science projects for Juno, exploring our various data sets, and delivering insights that can change the trajectory of our business.

We are currently offering all of our courses Live Online, and will only move back to in person learning when it's safe to do so. We anticipate having most, if not all, courses Live Online for all of 2021 and so this role is remote-friendly.

About Us

Founded in 2012, Juno College of Technology (formerly HackerYou College of Technology) is a well-loved provider of hands-on, project-based training for people who want to launch new careers in tech! From our 12,000 square foot office in downtown Toronto (pre- and post-COVID-19) to our Live Online classrooms, we run Bootcamps and continuing education courses year-round. With thousands of alumni and 1,000+ students a year, there’s a large community of people ready to welcome you to Juno!

Responsibilities
Work with a team of instructors and mentors to lead Data Analytics and Data Science courses, helping students learn through lessons, code-alongs and interactive exercises
Work directly with our students in the classroom and give project support
Help resolve issues, and coach through debugging and technical problem-solving
Provide a thoughtful, stimulating, and positive classroom experience
Participate in supporting student events
Create, update and refine curriculum using student feedback and new developments in the Data Science field according to our Curriculum Roadmap
Collaborate with the team to create and review program improvements and innovations
Contribute expertise to in-house data science projects using Juno’s data sets
Other tasks as required
About You

As a private career college, all of our instructors are required to have at least 2 years of practical, real-world experience as Data Analysts, Data Scientists or similar. Candidates who do not have the required experience will not be considered for this position. It would be great if you also have any experience as a teacher, instructor, or mentor, in any discipline.

Your Qualifications
Hold a degree, diploma, or certification from an Ontario college, university, private career college, or equivalent, and
Have 24 months occupational Data Science experience

Or

Have 36 months of teaching Data Science experience, and
Have 24 months occupational Data Science experience

Or

Have 48 months of occupational Data Science experience

You could be a great fit if you:

are an excellent public speaker and written communicator
are passionate about teaching data science and data fluency skills
have demonstrable hands-on industry experience in data science
are collaborative, energetic, and empathetic, and a great technical problem solver
have expertise in using Python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization
have practical knowledge of working with big data, performing customer segmentation, and using cloud services
are comfortable using Git, GitHub, Google Docs, Sheets, and Drive
have a positive attitude and a desire to help others.
Salary, Perks, and Benefits
Position type: Full-Time, Permanent
Starting salary: $70,000 - $85,000
Clear growth paths
Three weeks paid vacation plus extra time off in December
Seven paid personal days each year
Health spending account refreshed annually
& more

Visit our Careers page here for a full list of perks & benefits.","Juno College of Technology
3.8",Midtown Toronto
311,Data Engineer,"About Us

The Kraft Heinz Company is one of the largest food and beverage companies in the world, with eight $1 billion+ brands and global sales of approximately $25 billion. We’re a globally trusted producer of high-quality, great-tasting, and nutritious foods for over 150 years. Our brands are truly global, with products produced and marketed in over 40 countries. These beloved products include condiments and sauces, cheese and dairy, meals, meats, refreshment beverages, coffee, infant and nutrition products, and numerous other grocery products in a portfolio of more than 200 legacy and emerging brands.

We spark joy around mealtime with our iconic brands, including Heinz, Kraft, Bull's-Eye, HP, Lea and Perrins, Quero, ABC, Master, Banquete, Plasmon, Orlando, Benedicta, Honig, Pudliszki, Wattie’s among others.

No matter the brand, we’re united under one vision: To sustainably grow by delighting more consumers globally . Bringing this vision to life is our team of 39,000+ food lovers, creative thinkers, and high performers worldwide. Together, we help provide meals to those in need through our global partnership with Rise Against Hunger. We also stand committed to responsible, sustainable practices that extend to every facet of our business, our consumers, and our communities. Every day, we’re transforming the food industry with bold thinking and unprecedented results. If you share our passion – and are ready to create the future, build a legacy, and lead as a global citizen – there’s only one thing to do: join our table and let’s make life delicious!

Our Culture of Ownership, Meritocracy & Collaboration

We're not afraid to think differently. Embrace new ideas. Dream big. We empower our people at every level – from entry-level intern to senior leader – to own their work. We share a responsibility to think like Owners – to be mindful of the collective and sustained success of Kraft Heinz – which we apply to every situation, every day. As part of Kraft Heinz, you're supported to grow and achieve. You’re expected to bring your authentic self to work every day, to lead with humility, and drive outstanding performance at every level – and you’ll be rewarded. You’re given opportunities to leave a mark and build a legacy. But you won’t do it alone. You’re supported by passionate teammates along the way, and our collective, collaborative spirit fuels our incredible progress.

Job Description

As a Data Engineer, you will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from our connected data, enabling Kraft Heinz to advance data-driven decision-making capabilities across the enterprise. You will have a deep understanding of data architecture, data engineering, data analysis, and reporting - and a basic understanding of data science techniques and workflows, as well as the business processes supported by the data pipeline. Examples of problems you will tackle include helping R&D determine the next generation of household products, revolutionizing consumer engagement with personally relevant content, and reinventing our supply chain to eliminate food waste.

Responsibilities:

Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
Solve complex data problems to deliver insights that helps our business to achieve their goals
Create data products for Business Intelligence Engineers, Business Analyst and data scientist team members to improve their productivity
Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions
Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team
Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes
Partner with machine learning engineers, business intelligence engineers and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics.

Qualifications:

Bachelor’s degree required; Computer Science, MIS, or Engineering preferred
Expertise in ETL and data analysis and experience with SQL and at least one programming language (Python/R preferred)
Experience developing and maintaining data warehouses in big data solutions e.g. Snowflake
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)
Database development experience using Hadoop, SPARK or BigQuery and experience with a variety of relational, NoSQL, and cloud database technologies
Worked with BI tools such as Alteryx, Tableau, Power BI, Looker
Conceptual knowledge of data and analytics, such as dimensional modeling, ELT, reporting tools, data governance, data warehousing, structured and unstructured data.
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (preferred)
Familiarity with the Linux operating system
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
An agile learner who brings strong problem-solving skills, and enjoys working as part of a technical, cross functional team to solve complex data problems
A hard worker and consensus gainer who brings a strong numbers sense; you are intellectually curious and willing to adjust your position based on additional information

Kraft Heinz is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified candidates will be considered for our opportunities- regardless of race- religion- faith- creed- age- ethnicity- marital status- gender identity- sexual orientation- or disability. Job seekers with disabilities who require accommodation during the recruitment process or would like more details about accessibility should contact: accessibility@kraftheinzcompany.com .

IND123*

#LI-Location

Toronto- ON

Location(s)
Don Mills","Kraft Heinz Company
3.8",Don Mills
312,"Applied Scientist, Machine Learning","Your Role
We are seeking an Applied Scientist who will join our machine learning team in the Quantum Simulation Division. In this role, you will be developing and deploying state-of-the-art machine learning algorithms to improve the performance of electronic structure calculations. You will collaborate with the members of our R&D and software teams to deliver end-to-end machine learning solutions on the cloud. This is a unique opportunity to be part of an ambitious and growing team that aims at accelerating applications in advanced material science and life science.

This is a permanent, full-time role.

What You'll Do

Participate in the design for various stages of the machine learning lifecycle.
Implement and develop end-to-end machine learning pipelines on the cloud, including: data management, training, tuning, and debugging machine learning models as well as interpreting model results.
Use your experience with different machine learning frameworks and MLOps solutions to identify suitable tools for integration into our platform.
Use and encourage best coding practices within the machine learning team.
Stay up to date with recent advancements in the field of deep learning and MLOps
Collaborate with colleagues from science, engineering, and business backgrounds.

What You'll Bring
Members of our team bring a confluence of personality, skills, and goals that contribute to their individual development and our collective growth as an organization. The following criteria outline the complementary knowledge and mindset you’ll bring to our team:

A master's or doctorate degree in computer science, engineering, mathematics, or statistics, or equivalent work experience.
2+ years of professional experience building and deploying machine learning solutions, (industry experience is preferred).
Proficiency in Python and supporting numeric libraries.
Experience writing unit and integration tests for your code.
Experience with ML frameworks (such as TensorFlow, Theano, Keras, PyTorch) and MLOps solutions (MLFlow, Metaflow, etc).
Familiarity with a broad set of ML approaches and techniques including deep learning and transfer learning. Active learning and message passing neural networks is a plus.
Experience training and containerizing ML models on the cloud.
Experience with big data processing and database management.
Being comfortable providing feedback to team members, soliciting and acting on feedback to improve your performance.
Proactiveness in seeking out opportunities to help move projects forward and contribute to their improvement.
An eagerness to learn about new trends, tools, and technologies, and to continually consider how these will influence our projects in terms of opportunities and challenges.
Excellent verbal/written communication skills, including an ability to effectively collaborate with research and technical teams.

Who We Are
As part of the Quantum Simulation division, you will work in a dynamic environment where you will be challenged to solve scientific problems. Being in the field of bringing novel solutions to complex industry problems, you will constantly be challenged to both use your existing knowledge as well as learn new methods to solve problems. We also value open discussion of ideas with the firm belief that together we will get to the destination faster.

About 1QBit
1QBit is a global leader in advanced computing, with three innovation hubs located in Vancouver, Waterloo, and Sherbrooke. Along with its partners, 1QBit takes on computationally intensive problems across a variety of fields, including advanced materials, life sciences, energy, and finance. Trusted by Fortune 500 companies and top research institutions, 1QBit develops novel solutions by building on its broad expertise in hardware innovation, quantum computing, AI, and commercial application development. 1QBit offers unique deep-tech career opportunities through advanced internships, full-time positions, and a steadfast investment in our team’s expertise. Working at 1QBit means applying your thinking and skills to tackle exciting and relevant challenges.

Why work at 1QBit? You will have a chance to be part of a diverse and collaborative team and enjoy perks including: eligibility to take part in our Options Plan, full health and wellness benefits, extra long-long weekends, plenty of social events, and flexible work from home options.","1QBit
4.3",Vancouver
313,"Data Engineer, Omnia AI (CDC)","Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Learn from deep subject matter experts through mentoring and on the job coaching.
Be encouraged to deepen your technical skills…whatever those may be.
Partner with clients to solve their most complex problems




You have a passion for analytics and advanced Data Management? You want to build solutions that will allow customers to go further with the best of the existing Data solutions (AI/ML/ETL/Data lakes…)? You are ready to uncover the possibilities of AI in your career and set the foundation for success tomorrow? Then we have an opportunity waiting for you!

What will your typical day look like?

As a Data Engineer within our Omnia AI Canadian Delivery Center (CDC), you will be a team player to a portfolio of Deloitte’s Omnia AI engagements (projects). You will have the opportunity to be involved in the full life-cycle over AI projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. You will be able to work on the largest and most advanced Analytics projects on the market : 2019, 2020, 2021 Gartner Data & Analytics Service Provider leader.


Specifically, you will:

Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer
Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed)

About the team


Deloitte Omnia AI, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.


Our Omnia Canadian Delivery Center (CDC) team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. We work closely with the Omnia AI Strategy, Data Modernization Analytics, AI Insights and AI Factory (custom developed AI assets) teams to drive successful business outcomes. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. To support our continued growth, we are looking to add many team players with hands-on work experience ideally in the data, analytics and/or AI domains.


Enough about us, let’s talk about you

You are someone with:

Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications
2+ years of experience in Data related projects like Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes.
An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms.
Team player attitude
Intellectual curiosity, and strong analytical skills;
College/CEGEP or undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous

Differentiators but not required:

Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects
Bilingual (English / French)
Able to obtain Government of Canada security clearance

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.
The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?


Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Montreal
314,Data Engineer,"Job Title- Data Engineer
Location- Downtown, Toronto
Type - Full Time Permanent
Salary - Negotiable + Benefits



Focus on data architecture, best practices, reliability, security, and compliance
Improve and extend ETL, data processing, and analytics processes
Facility with PowerBI, including creating dashboards and data sources
Developing high complexity, fast performing SELECT queries.
Developing T-SQL procedures, functions, triggers, jobs, scripts, etc.
Development of Advanced T-SQL such as temporal tables, PIVOTs, recursive table expressions and more.
Modeling and implementing Data Mart solution for Power BI analytics
Managing indexes, statistics, query plans alerts, database activity, and overall performance activity.
In-depth experience working with relational databases, such as Microsoft SQL Server or PostgreSQL
Enthusiasm for applying good data design, testing, documentation, and support practices
Experience building and optimizing data pipelines, architectures, and data sets
Knowledge of message queueing, stream processing, and data stores/warehouses
Working knowledge of AWS products related to data engineering
Bachelor's degree in Computer Science, Software Engineering or an equivalent

Excellent communication skills - both written and verbal; ability to speak in Spanish is a bonus

To apply please send an email to sheetalk@tes.net","TES - The Employment Solution
3.5",Midtown Toronto
315,Data Engineer,"Here at Rakuten Kobo Inc. we offer a casual working start-up environment and a group of friendly and talented individuals. Our employees rank us highly in terms of commitment to work/life balance. We realize that for our people to be innovative, creative and passionate they need to have healthy minds and bodies. We believe in rewarding all our employees with competitive salaries, performance based annual bonuses, stock options and training opportunities.

If you’re looking for a company that inspires passion, personal, and professional growth – join Kobo and come help us make reading lives better.

The Role:
Rakuten Kobo Inc. is looking for a Data Engineer to join a new Data Operations team we are building that will help transform and govern our data. You will rewrite the process to ensure we use the data in the most flexible, effective manner possible to help the business achieve its goals. Not only will you build out the tools, you will be designing, implementing, and maintaining different data architectures. The role also includes managing the flow of data from methods of input and its life cycle.

Responsibilities:
Create & document efficient data pipelines (ETL/ELT)
Write and optimize complex queries on large data sets
Transform data and map them to more valuable and understandable sets for consumption
Create tooling to help with day to day tasks
Troubleshoot issues related to data accuracy and create the source of truth
Help remove the friction from other members of the organization and allow them to focus on their primary objective
Introduce new technologies to the environment through research and POCs
Reduce toil by automation

The Skillset:
A generalist who can jump on any problem where no level of work is beneath them.
A Problem solver
Believer of automation, Reducer of toil
One who loves to apply all their learnings to advance themselves, the team and ultimately the company
One who enjoys sharing knowledge & mentoring other team members
Highly adaptive to changes, fun and supportive
Motivated, creative, organized with attention to detail

Must Haves:
Advanced experience ( ~2 yr ) with Python, SQL, including, Spark, and Hive
Experience working with REST APIs and Python data analysis tools such as Pandas/Numpy.
Experience building ETL and big data pipelines with workflow management tools Airflow or Luigi
Experience with stream-processing systems: Storm, Flume, RabbitMQ, Kafka, etc.
Ability to prioritize competing requests and multiple tasks in a fast-paced, deadline driven environment
Experience managing a project backlog and working cross-functionally with multiple stakeholders
Ability to work effectively on a self-organizing team with minimal supervision
Initiative in communicating with co-workers, asking questions and learning
Excellent oral and written communication skills
Proactive and creative problem solver with the ability to multitask and manage tight deadlines

Nice to Haves:
Experience with continuous integration/deployment tools (Jenkins).
Experience with schema design and dimensional data modeling.
Exposure to containerized applications (Docker Kubernetes).

The Perks:
Flexible hours and unlimited work from home
Full benefits starting from your first day
Paid Volunteer days, unlimited sick days, and 3% RRSP matching
Monthly commuting allowance & internet allowance
Flexible health spending account
Talent and development training budget
Free Kobo device + free weekly e-book or audiobook
Weekly Kobo Tech University sessions
Weekly virtual happy hours (Thirsty Thursdays, as we like to call it)
Maternity/paternity leave top up

About Rakuten Kobo Inc.
Owned by Tokyo-based Rakuten and headquartered in Toronto, Rakuten Kobo Inc. is one of the most advanced global ecommerce companies, with the world’s most innovative eReading services offering more than 6 million eBooks and audiobooks to 30 million + customers in 190 countries. Kobo delivers the best digital reading experience through creative innovation, award-winning eReaders, and top-ranking mobile apps. Kobo is a part of the Rakuten group of companies.

Rakuten Kobo Inc. is an equal opportunity employer. Accessibility accommodations for candidates with disabilities participating in the selection process are available on request. Any information received related to accommodation needs of applicants will be addressed confidentially.

Rakuten Kobo would like to thank all applicants for their interest in this role however only qualified candidates will be shortlisted",Rakuten Kobo Inc.,Midtown Toronto
316,Data Engineer - Python Developer,"Join Unbounce and help the world experience better marketing. We’re a people first, customer obsessed company focused on helping employees do their best work. Our landing page and conversion platform empowers digital marketing teams and agencies to launch campaigns, increase conversions and get significantly better ROI on their marketing spend in a way that nobody else does today.

The Data Engineering team enables other teams by creating the ecosystem upon which data processing is built. We believe in working the DevOps way - from owning the infrastructure to writing tooling and building pipelines. We believe in fostering an environment that promotes growth, engagement, team ownership, responsibility, initiative and empowerment.

Note on remote: Due to Covid we are currently all working remotely (going into the office is available to those that need it). While Unbounce has shifted to be remote-first, we hope to work together in the same dog-friendly space again for that irreplaceable personal touch.


What You'll be Doing:

Work closely with the rest of the team to build high quality, complex systems.
Contribute to our Analyst and Data Science enablement ecosystems by building tooling and pioneering best practices.
Develop ETL pipelines and supporting infrastructure for data-driven insights.
Contribute to team ownership of our infrastructure upon which we run all our work.
Grow technical skills within and outside the team through code reviews, pairings, demos etc.
Set and maintain standards around data governance, code quality and efficient communication; and to evangelize best practices within the team and company.


A Little Bit About You:

Experience writing production-level Python and SQL
Proficiency in database management, data warehouse design and distributed systems
Experience in building production-level infrastructure for data processing to run on
You understand data governance - you have built systems that provide available, correct and secure data


Additional skills - These are skills that will help you hit the ground running, but if you don’t have them, you will have the opportunity to learn!

AWS tools (IAM, EC2, S3, CloudFormation, Route53, CloudWatch, RDS, EKS, lambda, Kinesis, Glue, Athena)
MySQL, Postgres, Dynamodb
Python API development
(Py)spark
Kubernetes
Airflow
Infrastructure as code
CI/CD
Kafka


What’s in it for You:

4 weeks vacation plus Christmas Holiday Closure - you're entitled to the week of Christmas off with pay through to and including Jan 1st
12 Personal Wellness Days (This includes: Sick days, moving days, personal days, etc)
Vacation bonus - $1,000.00
Health and Wellness budget - $500.00
Networking budget - $500.00
A paid day off for your birthday
One paid Volunteer day per year
One day every 2 weeks of dedicated professional development time


Unbounce Welcomes Everyone to Apply

At Unbounce we celebrate everyone and their multiple intersecting identities. We believe a panorama of experience allows us to make better decisions together and inspires innovation so that we can better serve our customers and community. Our goal is for every Unbouncer to feel deeply connected to their team through mutual value, respect, and understanding.


Please let us know if you require any accommodations or support during the recruitment process




q411aSVCjd","Unbounce
3.8",Vancouver
317,Actuarial Data Engineer,"About Swiss Re Corporate Solutions


Swiss Re is one of the world’s leading providers of reinsurance, insurance and other forms of insurance-based risk transfer. We anticipate and manage risks, from natural catastrophes and climate change to cybercrime.

Swiss Re Corporate Solutions is the commercial insurance arm of the Swiss Re Group. We offer innovative insurance solutions to large and midsized multinational corporations from our approximately 50 locations worldwide. We help clients mitigate their risk exposure, whilst our industry-leading claims service provides them with additional peace of mind.

Swiss Re Corporate Solutions offers a flexible working environment where curious and adaptable people thrive. Are you interested in joining us?




About the Role

To lead / assist in the creation and management of data pipelines to enable Actuarial Services / Data Science in the development of visualizations and advanced analysis that support business operations and decision-making processes.




Responsibilities will include:




Gain trust and working relationship with business stakeholders and internal partners
Conduct interviews with the Swiss Re Accident & Health clients to assess pain points, define visions of future products, and implement solutions that deliver value across people, process, data, and technology
Review and analyze business workflows and user data needs
Design and implement business performance dashboards
Write customized queries/programs to generate automatic periodical reports highlighting all the Key Performance Indicators (KPIs)
Visualize the correct metrics in the dashboard and use appropriate data forecasting models in order to aid the teams to make better business decisions and control risk more efficiently
Analytics Engineering in close collaboration with Data Engineers, Data Scientists, Business Users and Technical experts to provide high quality deliverables and timely submissions
Improve systems by evaluating current practices and designing modifications.
Support the modernization of the existing tools by replacing and rebuilding systems and overall move towards more predictive analytics
Utilize knowledge of database management system software, object oriented programming development, system architecture and components and various programming languages
Build applications using SQL and/or Python scripts to manipulate data, monitor and help to improve data quality
Design, build and maintain end-to-end data solutions supporting our processes with the right data architecture
Handle data pipelines while testing for data curation, parsing, cleaning, transformation and enrichment of data
Development and support of data pipelines.
Have working knowledge of Apache Spark, big data processing and building products on distributed cluster-computing framework
Work with fundamentals of data processing, data pipeline, data lineage and ETL (Extract-Transform-Load) methodologies
Implement the project according to the Software Development Life Cycle (SDLC) and programming by using fast paced agile methodology, involving task completion, user stories
Ensure compliance with internal group controls and guidelines
Shape and contribute to appropriate data governance along the whole data lifecycle
Construct workflow charts and diagrams and writing specifications
Documentation of end-to-end data pipeline process
Documentation of data assets for information management purposes
Develop cost estimate models to support ROI metrics
Ad hoc team / business support as needed
Exploration and evaluation of new technologies and platforms.



About You

Bachelors or equivalent degree Computer Science, Data Science, Statistics or another relevant quantitative field
5+ years of insurance industry experience
SQL Stack – SQL Server Management Studio (SSMS), SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS)
Microsoft MSBI Stack – Power Query, PowerPivot, PowerBI
Microsoft Access
Familiarity with relational database concepts
Detail-oriented, analytical and inquisitive
Highly organized with strong time-management skills
Ability to work independently and collaborate well with others
Ability to affect smooth organizational transformations.



Other Details

Position Type: Permanent; Full-time36.5 hours per week

Rate of Pay: 113,500.00 to $120,000 CAD per year

Benefits: Group insurance benefits, defined contribution retirement plan, employee savings plan, global share (stock) plan, paid time off

Location: Westport Insurance Corporation, 150 King Street West, Suite 1000, Toronto, Ontario, Canada M5H 1J9. Teleworking (remote work) is allowed during the pandemic.




Swiss Re is an equal opportunity employer. It is our practice to recruit, hire and promote without regard to race, religion, color, national origin, sex, disability, age, pregnancy, sexual orientations, marital status, military status, or any other characteristic protected by law. Decisions on employment are solely based on an individual's qualifications for the position being filled.

During the recruitment process, reasonable accommodations for disabilities are available upon request. If contacted for an interview, please inform the Recruiter/HR Professional of the accommodation needed.","Swiss Re
4.0",Midtown Toronto
318,Analytical Development Associate Scientist,"Title: Associate Scientist Analytical Development

The analytical development associate scientist supports the development of new pharmaceutical dosage forms in addition to improving existing products and procedures. These activities will be achieved by using knowledge and innovation of science, technology and chemistry to investigate the properties, components and abilities of chemicals and processes in the development of efficient manufacturing procedures and the development of appropriate analytical methodologies to create prototype formulations and clinical supplies.

This position performs activities assigned by the manager/upper management to meet the company's goals within the specified timelines. This position also requires documenting, reviewing, analysing and interpreting data, and interpreting scientific problems in support of HC, FDA, EMEA and ANVISA submissions in a timely manner while complying with departmental SOP's and guidelines set out by the regulatory agencies and ICH (International Conference on Harmonisation). This will be achieved by working very closely with the analytical development and R&D QA teams.

Key job responsibilities and duties:

Responsible and accountable for designing, planning and executing all aspects of assigned projects through scientific rationale using Quality by Design principles to develop new products per departmental SOP’s and ICH guidelines. This should be done in consultation with senior peers: Development Scientists, Manager or upper management.
Applies analytical/problem solving skills and utilizes available resources to identify process and/or formulation deficiencies and propose solutions to be implemented. In addition to working with more experienced colleagues to troubleshoot and resolve challenges during the development of analytical methodologies.
Supports writing the summary of pharmaceutical development reports including analytical method development, method validation, related substances identification, force degradation studies, stability reports and all other information required in the CMC sections of CTAs, NDS and S/NDS, in a timely fashion. Furthermore, provides the required information to support FDA, EMEA and ANVISA submissions.
Supports internal projects and external Contract Manufacturing Organization projects in alignment with Biolab’s objectives and initiatives. Communicates/interacts as indicated by management with QC/Contract Laboratory during transfer of analytical methodologies from R&D in a timely fashion.
Collaborates with regulatory documents, and team efforts to define formulation, manufacturing process and drug product specifications.
Ensures all analytical activities meet good laboratory practices and company’s policies.
Ensures the availability of chemicals, reagents, apparatus, HPLC columns, solvents, etc. needed to carry out all task in the analytical development area.
Performs data collection and analysis, discuss conclusions regarding progress of work, and effectively communicates information to peers and management in the form of presentations and reports.

Education and experience requirements:

Canadian equivalent to Master of Science, PhD or Bachelor of Science degree, preferably in Pharmacy, Chemistry or Pharmaceutical Chemistry.
More than three years of relevant hands on pharmaceutical experience in product development. Demonstrates knowledge and experience of analytical chemistry by developing analytical methods such as assay, dissolution and related substances. Understanding of DOE, risk based assessment tools, quality by design, method validation, equipment troubleshooting and technical transfer. Experience with Chromeleon software is preferred.
Demonstrated ability to work independently or as a part of a team, and to coach less experienced colleagues.
Highly motivated and have the skills to handle multiple projects and prioritize the work.
Excellent communication skills (oral and written) and interpersonal skills are required

Application deadline: 2021-06-30

Expected start date: 2021-07-19

Job Types: Full-time, Permanent

Salary: $54,000.00-$66,000.00 per year

Benefits:

Casual dress
Dental care
Disability insurance
Employee assistance program
Extended health care
Flexible schedule
Life insurance
On-site parking
Vision care

Schedule:

8 hour shift
Day shift
Monday to Friday
No weekends

COVID-19 considerations:
We are following all COVID19 guidelines from Peel Public Health

Education:

Bachelor's Degree (preferred)

Experience:

Canadian Pharmaceutical Industry: 5 years (preferred)

Language:

English (preferred)

Work remotely:

No",Biolab Pharma Ltd.,Mississauga
319,Senior Data Scientist,"Bachelor's Degree
5+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
4+ years working as a Data Scientist
Experience processing, filtering, and presenting large quantities (100K to Millions of rows) of data
Experience with statistical analysis, data modeling, machine learning, optimizations, regression modeling and forecasting, time series analysis, data mining, and demand modeling
Experience applying various machine learning techniques, and understanding the key parameters that affect their performance
Excellent written and verbal communication skills. Strong ability to interact, communicate, present, and influence within multiple levels of the organization.
Experience with Predictive analytics (e.g., forecasting, time-series, neural networks) and Prescriptive analytics (e.g., stochastic optimization, bandits, reinforcement learning)
Amazon's Sponsored Products advertising business is one of the fastest growing areas in the company. Have you ever wondered what happens behind that “Sponsored” label you see in search results on Amazon? Hint: it involves a lot of interesting tech delivered by a great team.

The Sponsored Products Marketplace team optimizes the systems and ad placements to match demand with supply using a combination of data-driven product innovation, machine learning, big data analytics, and low latency/high-volume engineering. By the time organic search results are ready, we've processed all of the potential ads and determined which ones are going to be shown. We do that billions of times per day, resulting in millions of engagements with products that might otherwise not have been seen by shoppers.

The business and technical challenges are significant. Fortunately, we have a broad mandate to experiment and innovate, and a seemingly endless range of new opportunities to build a big, sustainable business that helps Amazon continuously innovate on behalf of all customers.
We're looking for customer-obsessed, innovative, professional data scientist who can help us take our products to the next level of functionality, quality and performance. We embrace leaders with a startup mentality — those who seek a disruptive yet clear mission and purpose, have an unambiguous owner's mindset, and are relentlessly obsessed with delivering amazing products. As a Sr. Data Scientist on our team, you will be responsible for building and managing modeling projects, identifying data requirements, and delivering methodology and tools that are statistically grounded around our advertiser facing products such as new targeting controls, ad sourcing techniques, automated optimization strategies, and advertiser-facing recommendations. You should have superb analytical, technical, business and communication skills to be able to work with business and technology leaders to define and prioritize key business questions, build data acquisition processes, data sets, statistical models and analyses that answer those questions. If this sounds like your sort of challenge, read on.

Characteristics indicative of success in this role:
·

Highly analytical: You solve problems in ways that can be backed up with verifiable data. You focus on driving processes, tools, and statistical methods which support rational decision-making.
·

Technically fearless: You aren't satisfied by performing 'as expected' and push the limits past conventional boundaries. Your dial goes to '11'.
·

Engaged by ambiguity: You're able to explore new problem spaces with unique constraints and non-obvious solutions.
·

Team obsessed individual contributor: You help grow your team members to achieve outstanding results. You've learned that big plans generally involve collaboration and great communications.
·

Quality obsessed: You recognize that professional engineers ship complete, tested software to avoid getting trapped in a sea of technical debt. You balance speed with quality.
·

Humbitious: You’re ambitious, yet humble. You recognize that there’s always opportunity for improvement. You use introspection and feedback from teammates and peers to raise the bar.
Master's degree in Operations Research Engineering, Statistics or related field
10+ years professional experience in large-scale data science or advanced analytics
Experience with AWS and data-oriented tools such as Redshift, Spark, EMR
Experience in online advertising domain (particularly, ad targeting and serving)
Experience as team leader
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.","AMZN CAN Fulfillment Svcs, ULC
3.8",Midtown Toronto
320,Data Engineer,"Requisition ID: 105205

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

The Team

The Risk Technology group plays a critical role in enabling Global Enterprise Technology to deliver against its mission to bring innovation and value to the Bank with confidence and reliability, by acting as a key player in Regulatory Risk Management across the division.

The Role

As a Data Analyst, Risk Technology, you will play an active role in regulatory risk projects by collaboratively assessing, analyzing and implementing large scale data applications. You will leverage and gain a thorough understanding of Enterprise Data Platforms housing credit and insurance portfolios, contribute to design controls, data mappings and assisting in their implementation. Part of a strategic and comprehensive Risk Technology function, you will ensure control implementation in accordance with regulatory expectations, risk appetite, organizational risk practices and evolving business practices.

Some of the Key Accountabilities include:

Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Conducting data discovery, data requirements and gap analysis. Capturing and documenting of source to target mapping in support of procurement and development efforts.
Participate in the solution, design, plan, coordination and management of various data asset initiatives with varying scope and complexity.
Provide support to development and operations team to resolve production issues; perform assessment, root cause analysis, and formulating proposed solutions/remediation strategies.
Performs quality assurance activities to ensure handling, storage, and collection of data complies with Bank Policy and regulatory requirements.
Lead and take ownership on multiple simultaneous data integration projects. Managing relationships with upstream and downstream data / technology partners.
Assessing various dataflow architecture and developing strategies to optimize data availability, quality and performance.
Work with upstream source providers and downstream consumers for change request and release management.
Be curious, constantly learning about new trends in IT enterprise technologies especially in the area of CI/CD and DevOps and share the knowledge with end users and team members.
Work effectively in a remote team environment maintaining:
Collaboration with other team members, internal customers and other Scotiabank teams
Acquiring knowledge from peers and continuous self-learning.
Coaching other team/department members on the areas of expertise
Actively participate in team's huddles

What You Will Bring to Succeed

BSA and Data Analysis. 5+ years of experience
Experience with SQL Server, Hive/Hadoop, DB2, and Complex SQL queries. 5+ years of hands on experience
Experience with ETL tools such as SSIS, Python, Informatica, SAS and Datastage with ability to understand, investigate and reverse engineer code.
Experience with documenting data mappings from source to target. 3+ years of hands on experience
Data analytics and visualisation (PowerBI/Excel)
Excellent communication and presentation skills written & verbal (will be working closely with Business & Developers)
SDLC, change management, CI/CD, DevOps and Agile Project methodology. (5+ years)

Assets to have:

Experience with cloud environments; Azure.
Experience with Coding (Java, shell scripting, python, HQL/SQL) and data formats (XML, JSON, CSV, HDFS, etc.)
Logical and Physical Data Modelling
Experience with Credit Risk and Insurance Data.

The Workplace

We are technology partners who help the business transform how our employees around the world work
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world
We foster an environment of innovation and continuous learning
We care about our people, allowing them to design how they work to deliver amazing results
We offer a competitive total rewards package, including a performance bonus, company matching programs (on pension & profit sharing), and generous vacation

Scotiabank

As Canada's International Bank, we are a diverse and global team. We speak more than 100 languages with backgrounds from more than 120 countries. We value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.

Is this Role not the Exact fit?

Sign up to stay in touch; we’ll let you know when we have new positions on the team.

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
321,Python/Django Data Portal Developer,"Position Title: Python/Django Data Portal Developer

Classification: Casual Six-month Contract, with opportunities for extension

Division: Temerty Faculty of Medicine

Department: Temerty Centre for AI Research and Education in Medicine

About Us

T-CAIREM at the University of Toronto is an interdepartmental Centre that serves a s a focal point for collaboration between computer scientists, healthcare providers, trainees, medical basic science researchers and industry to advance health through machine learning. The mission of the Centre is to advance research, education, knowledge dissemination and digital infrastructure in the field of AI in medicine.

Your Opportunity

Python Data Portal Developer will support the development of a Django-based data sharing platform to support clinical research. Platform features that will need development include interfacing with cloud computing services, managing encryption keys to securely store data objects, authentication with external identity providers, and designing models for user workflows.

Essential Qualifications

Education & Certification: Bachelor’s Degree in science or engineering.

Experience:

· Extensive experience in development using the Python web framework Django.

· Experience in programming and systems development and design.

· Experience trouble shooting and resolving technical issues.

· Strong proficiency in Python/SQL.

· Comfort in collaborative development using source code control (git).

· Experience with Amazon AWS preferred.
Responsibilities & Duties
· Supporting the planning and development of the data sharing platform.

· Programming new and existing data systems.

· Trouble shooting and testing highly complex systems.

· Developing unit tests.

· Collaborating within a small team.

· Writing complex code.

Expected start date: 2021-07-05

Job Types: Full-time, Casual

Salary: $70,914.00-$133,027.00 per year

Schedule:

8 hour shift

Work remotely:

Yes","University of Toronto
4.3",Midtown Toronto
322,Data Engineer,"Company:
Finning International Inc.

Number of Openings:
1

Worker Type:
Permanent

Position Overview:
Data is deeply embedded in the product and engineering culture at Finning, to maximize productivity and safety of Finning engineers and our customers. The Data Engineer will be focused on building a state-of-the-art data foundation to solve real world business challenges and optimizing Finning processes across a wide range of areas including supply chain, marketing, pricing, and sales. As part of the Finning Global Digital Services team, you will be working closely with cross-functional teams using agile methodologies and tools, building reliable and scalable data-driven solutions for optimizing maintenance, inventory, fuel, scheduling, and other services for Finning customers. This position will require a background and love for data modeling, building batch processes, and working with data architects and infrastructure team to build end-to-end data processing pipelines.

The Data Engineer will work under the mentorship of Senior Data Engineers and other leaders on the team and work in collaboration with other members on the Finning Digital teams, including Project Managers, Product Managers, Visual Analysts, and Architects, Software Engineers and more as we continue to explore new areas inside and outside of business, on our digital journey.

Job Description:
Extract, transform and load data from internal and external systems to Azure services using a combination of Azure Data Factory, Azure Data Lake, Azure SQL, Azure Data Warehouse, Azure Databricks, T-SQL, and Spark SQL.
Work with the business and non-technical stakeholders to discover and document technical requirements and to understand the core problem
Monitors, troubleshooting and resolving of issues with our hybrid (on premise and cloud) data platform
Drive the continually improvement of ongoing reporting and analysis processes, automating and/or simplifying support.
Stay abreast of innovations in Cloud infrastructure, Business Intelligence, Analytics and Data Warehouse tools and technologies
Design, develop, and maintain data pipelines
Create automated metrics using complex distributed databases and sources

Education & Experience

Bachelor’s or Master’s degree in Computer Science or equivalent experience
5+ years of software development experience
3+ years of experience in Azure, AWS, or GCP
3+ years of experience in developing data injection, consumption, ETL, and data sanitization processes
Practical experience with Azure Data Lake, Azure Synapse Analytics, Azure SQL and SQL data warehouse, and Azure Databricks services.

W e are committed to diversity at Finning, to building and sustaining a diverse and inclusive workforce and as an equal opportunity employer we encourage applications from all qualified individuals. Finning does not discriminate against applicants based on genders, races, national and ethnic origins, religions, ages, sexual orientation, marital and family status, and/or mental or physical disabilities.","Finning International Inc.
3.5",Vancouver
323,Applied Scientist - Machine Learning,"Applied Scientist - Machine Learning

The Intelligent Conversation and Communications Cloud AI group applies machine learning to problems in advanced teleconferencing scenarios that are used by hundreds of millions of customers worldwide (via Teams, Skype and Skype for Business). We develop technologies and do applied research and development that enables state of the art customer experiences for real-time collaboration. We are seeking a highly capable Applied Scientist / Engineer who is passionate about data, machine learning applications and driven to make an impact for millions of customers.

#IC3
#M365Core
Responsibilities
Develop and deploy machine learning solutions that improve Skype/Teams real-time collaboration quality and reliability
Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration.
Understand and leverage core concepts of video/audio processing and real time communication
Drive independent investigations resulting in shipping product code, patents, and publications.
Qualifications
Required qualifications:
Minimum of 2 years of experience developing and shipping machine learnt software solutions.
Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience.

Preferred Qualifications
Deep knowledge of machine learning principals to solve complex problems.
Strong system software development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems

Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to, the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
324,Applied Scientist - Machine Learning,"Applied Scientist - Machine Learning

The Intelligent Conversation and Communications Cloud AI group applies machine learning to problems in advanced teleconferencing scenarios that are used by hundreds of millions of customers worldwide (via Teams, Skype and Skype for Business). We develop technologies and do applied research and development that enables state of the art customer experiences for real-time collaboration. We are seeking a highly capable Applied Scientist / Engineer who is passionate about data, machine learning applications and driven to make an impact for millions of customers.

#IC3
#M365Core
Responsibilities
Develop and deploy machine learning solutions that improve Skype/Teams real-time collaboration quality and reliability
Design, develop, and own components, tools, platforms, and systems for real-time media communication and collaboration.
Understand and leverage core concepts of video/audio processing and real time communication
Drive independent investigations resulting in shipping product code, patents, and publications.
Qualifications
Required qualifications:
Minimum of 2 years of experience developing and shipping machine learnt software solutions.
Ph.D. in Computer Science, Mathematics, Physics, Electrical Engineering, or Masters plus equivalent work experience.

Preferred Qualifications
Deep knowledge of machine learning principals to solve complex problems.
Strong system software development skills, with a long-range system view that leverages development ranging from rapid research prototypes to carefully architected complex systems

Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to, the following specialized security screenings:
Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
325,Senior Applied Data Scientist,"What is Yammer?
Microsoft Yammer is the industry-defining social network for the enterprise. Millions of employees, including 85% of Fortune 500 companies use Yammer every day, to build community and culture, share knowledge, and connect with their leaders and each other.

Why Yammer?
Yammer was one of the first startup unicorns this past decade and was acquired by Microsoft in 2012. Today, this means we get the benefits of a startup - rapid innovation, cutting-edge technology, outsized individual impact - with the advantages of working for one of the most successful software companies in the world. We work together in small, cross-functional teams - engineers, product managers, designers, data scientists - to design, deliver and operate delightful end user experiences to our tens of millions of users spread across the world.

We’ve always been mission-driven; In this post-Covid world, Yammer has become even more indispensable than ever as employees have a deep need for connection and a sense of belonging. We’ve been growing rapidly and need your help to take Yammer to the next level.

You will have:
Autonomy and freedom to innovate
Choice of the best of open source and Microsoft-internal technology
The ability to experiment, A/B test, and make data-driven decisions
Tons of opportunity for outsized impact as part of a small but mighty team on a rapidly-growing product needed now more than ever
At the same time, you also have the benefits of working at a top-tier tech company like Microsoft:
Compensation, benefits, and perks
Internal resources, technology, and opportunities for learning and growth
Brand and networking
Opportunity for massive scale as part of a suite with hundreds of millions of users

About this job

As a Senior Applied Data Scientist, you will be building predictive models that help connect individuals with each other and knowledge across organizations. We focus on discovery, recommendations, and relevance across Yammer by building machine learning models that leverage both Yammer data and data from across Office 365.

What makes this role special?

Opportunity to create a vision around the Yammer machine learning platform and roadmap and help us make it a reality.
Opportunity for massive scaleas Yammer has tens of millions of users today and is expanding rapidly to reach all of Office 365 (100 million+)
Tight-knit, high performing team means tons of ability to have impact.
Social enterprise = unique and interesting analytics problems (lots of independent social networks)
Responsibilities
Build and iterate on machine learning models to be used to power recommendations for the Yammer Feed.
Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed; conduct end-to-end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables and presentations.
Utilize excellent communication skills to clearly distill the essence of your technical work to audiences of all levels and across multiple functional areas.
Develop deep product intuition that you leverage to influence future product roadmaps and drive decision making.
Work with product and engineering to craft experiments and test hypotheses.
Navigate complex situations and influence across multiple product areas by leveraging leadership acumen.
Qualifications

Required Qualifications

Bachelors, Masters or advanced degree in Computer Science or related field (including Mathematics and Physics)
5+ years of industry experience applying Machine Learning techniques
2+ years of experience coding in Python, C++, C#, C or Java

Preferred Qualifications

Masters or PhD with 5+ years work experience doing quantitative analysis.
Work experience in the social networking space.
Applied experience with machine learning on large datasets.
Built recommender systems used in production at scale.
Customer focused, strategic, drives for results, is self-motivated, and has a propensity foraction.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
326,Senior Applied Data Scientist,"What is Yammer?
Microsoft Yammer is the industry-defining social network for the enterprise. Millions of employees, including 85% of Fortune 500 companies use Yammer every day, to build community and culture, share knowledge, and connect with their leaders and each other.

Why Yammer?
Yammer was one of the first startup unicorns this past decade and was acquired by Microsoft in 2012. Today, this means we get the benefits of a startup - rapid innovation, cutting-edge technology, outsized individual impact - with the advantages of working for one of the most successful software companies in the world. We work together in small, cross-functional teams - engineers, product managers, designers, data scientists - to design, deliver and operate delightful end user experiences to our tens of millions of users spread across the world.

We’ve always been mission-driven; In this post-Covid world, Yammer has become even more indispensable than ever as employees have a deep need for connection and a sense of belonging. We’ve been growing rapidly and need your help to take Yammer to the next level.

You will have:
Autonomy and freedom to innovate
Choice of the best of open source and Microsoft-internal technology
The ability to experiment, A/B test, and make data-driven decisions
Tons of opportunity for outsized impact as part of a small but mighty team on a rapidly-growing product needed now more than ever
At the same time, you also have the benefits of working at a top-tier tech company like Microsoft:
Compensation, benefits, and perks
Internal resources, technology, and opportunities for learning and growth
Brand and networking
Opportunity for massive scale as part of a suite with hundreds of millions of users

About this job

As a Senior Applied Data Scientist, you will be building predictive models that help connect individuals with each other and knowledge across organizations. We focus on discovery, recommendations, and relevance across Yammer by building machine learning models that leverage both Yammer data and data from across Office 365.

What makes this role special?

Opportunity to create a vision around the Yammer machine learning platform and roadmap and help us make it a reality.
Opportunity for massive scaleas Yammer has tens of millions of users today and is expanding rapidly to reach all of Office 365 (100 million+)
Tight-knit, high performing team means tons of ability to have impact.
Social enterprise = unique and interesting analytics problems (lots of independent social networks)
Responsibilities
Build and iterate on machine learning models to be used to power recommendations for the Yammer Feed.
Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed; conduct end-to-end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables and presentations.
Utilize excellent communication skills to clearly distill the essence of your technical work to audiences of all levels and across multiple functional areas.
Develop deep product intuition that you leverage to influence future product roadmaps and drive decision making.
Work with product and engineering to craft experiments and test hypotheses.
Navigate complex situations and influence across multiple product areas by leveraging leadership acumen.
Qualifications

Required Qualifications

Bachelors, Masters or advanced degree in Computer Science or related field (including Mathematics and Physics)
5+ years of industry experience applying Machine Learning techniques
2+ years of experience coding in Python, C++, C#, C or Java

Preferred Qualifications

Masters or PhD with 5+ years work experience doing quantitative analysis.
Work experience in the social networking space.
Applied experience with machine learning on large datasets.
Built recommender systems used in production at scale.
Customer focused, strategic, drives for results, is self-motivated, and has a propensity foraction.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
327,Data Engineer,"Data Engineer
Halifax, NS, Canada Montreal, QC, Canada Ottawa, ON, Canada Toronto, ON, Canada Winnipeg, MB, Canada Req #20

Wednesday, April 14, 2021

The Company:

AudienceView is an organization of people who are passionate about the business of live events. We create industry-leading software solutions that fuel attendee engagement, ticket sales, and advertising solutions for close to 8,000 higher education, music, and theatre venues in 15 countries around the world. AudienceView employees share a vision to help entertainment organizations deliver exceptional experiences for people who love live events. We achieve this through innovative technology, popular media brands, effective distribution strategies and a dedicated team of experts that help propel our clients’ success every single day.

The Position:

We are looking for a Senior Data Engineer who will support a small team of developers to deliver a data warehouse solution working within the Agile Scrum framework. As a successful candidate, you will bring extensive expertise in the design, framework & methodology of data warehousing, and possess experience in the full stack life cycle from ETL to the Visualization. Additionally, you must possess a unique blend of business and industry savvy; a big-picture vision, and the drive to make that vision a reality. You must enjoy spending time in all business areas to understand their problems, and find innovative solutions for the organization.




Responsibilities:


Design & Implement a Data Warehouse Solution using Best Practices and Reusable Design Patterns and Processes.
Create and implement Full Stack Framework and Methodology
Understand and manage the implementation of any tools required to bring value to the process of product and feature creation
Work with a cross section of teams including Architects & Engineering to define and fill knowledge gaps, to ensure the best possible solution for a solution that satisfies the business.
Work with the business to identify feature gaps
Support the Director, Business Data where necessary


Qualifications:


5 years experience as a senior Data Engineer with Azure data components eg: Spark/Databricks, Delta Lake, Data Factory, Python and SQL.
Designing & Implementing data pipelines, ETL/ELT processes
Writing unit & integrations tests
Good knowledge of SQL and Transact-SQL
Ability to effectively collaborate with diverse groups of people
Ability to thrive in a fast paced rapid development environment
Excellent written and verbal communication skills
Excellent public speaking skills
Experience in the ticketing or live event industry advantageous
Results driven and focused, proving the success of any initiative you take part in.
Why AudienceView:

AudienceView is the leading provider of e-commerce solutions to some of the world’s biggest ticket resellers and venues who are shaping the future of ticket sales and event promotions.
Specialized in end-to-end e-commerce ticketing and event CRM across multiple markets.
Company repositioning for rapid-paced growth ensuring great career opportunities for motivated professionals.
Located in the heart of downtown Toronto a respected hub of the Toronto tech community.
Competitive salary with performance review and personal growth.
Excellent benefits.
Flexible hours and work remote opportunities.
Employee social lounge and dynamic Social Events team.
Partner with Customers who are leaders in online ticketing sales around the world.
Exciting customer markets in sports, performing and more

Diversity and inclusion have always been at the core of our values at AudienceView. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.
Persons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e-mail a request to peopleteam@audienceview.com.

Other details

Pay Type

Salary","AudienceView
3.4",Halifax
328,Data Engineer,"Appnovation helps brands thrive through innovative, people-inspired experiences and solutions. By embracing the powerful combination of technology and agility, we seamlessly integrate strategy, experience, design, development and analytics.

We create standout digital experiences by collaborating with brands to understand the individual challenges and goals for every initiative. Focusing on our clients' customers, we effectively combine empathy, evidence and real-world insight so that solutions are derived from truth and meaning. Appnovation is an award-winning team dedicated to inspiring possibility. YOU WILL HAVE AN OPPORTUNITY TO:

Design, develop, and maintain cloud-based data solutions and file-based data repositories to support analysis, visualization, and decision-making for the owners of digital assets and IT operations.

Create and maintain essential metadata (data models, data dictionaries, and data flow diagrams)

Establish master data management practices for core data shared across projects

Provide hands-on leadership and oversight for internal Data Quality, Insights, and Predictive services within the Service Development and Innovation team at Appnovation

Support return on investment ('ROI') measurement for investments in our operations, frameworks, processes, and infrastructure, and for investments in optimizing our clients' digital assets with closed-loop data-driven testing of our initiatives' success

Lead cross-functional working sessions to understand stakeholder data and insight challenges

Operational analytics to support Lean Six Sigma principles including dashboard and framework management, process evolution, tool integration and tool configuration

Build manage and refine control thresholds and develop predictive models

Design and publish interactive control centres, dashboards, and reports leveraging data visualization techniques and real-time alerts

Partner with internal and client teams to cleanse, analyze and find insights in data and influence ways of working to improve data hygiene

Conceive, plan, and prioritize data projects across a variety of business verticals and levels of complexity

Research and evaluate leading and visionary new models, tools and techniques, perform experiments and develop the business case for bringing them to Appnovation

WHO YOU ARE:
Regularly create dashboards, queues, and data visualizations in Looker, Data Studio, and Tableau.

Happy to work alone or with other data analysts and stakeholders to solve problems

Excellent attention to detail with the ability to take in the bigger picture

Familiarity with digital web presence analytics and agile software development practices and metrics.

Comfortable with working in a global company with stakeholders in different timezones

Proficient with Relational Database Management, VBA, JavaScript, SQL, ETL, REST APIs, Big Data, Data Integration, Data Warehousing, Data Governance, Data Lakes, and Batch and Streaming Data Pipelines

Proficient in performing statistical analysis and machine learning using tools like Einstein, Databricks, RapidMiner, DataRobot, H2O.ai or similar tools

Familiarity with RedShift and Salesforce preferred

Strong collaborative and communication skills (written and verbal)

Degree in a related field and 5+ years experience working in a data analytics environment
Thank you for your interest in a career with Appnovation Technologies! Please note that only those selected for an interview will be contacted.

Appnovation is an equal opportunity employer and committed to diversity and inclusion. We encourage applications from all qualified candidates and accommodations are available upon request throughout the recruitment process.","Appnovation Technologies
4.1",Midtown Toronto
329,Data Engineer,"UNCAGE YOUR AMBITION as a Data Engineer

We are FlightHub Group , an ambitious team of people that created FlightHub and Justfly . Our brands have grown to become two of the top-ranked travel agencies in North America. We now serve over 3 million customers per year, totaling 3 billion dollars in sales, and, whereas the pandemic may have slowed us down a little, we are coming back even stronger. We dream big, pursue passionately, and follow through with resolute self-belief and rigorous commitment. We are a group of individuals sharing a common vision and values, having come together to pursue a collective mission: overtaking the #1 spot in the world.

We are looking for a Data Engineer with 3+ years of experience to join our team. Working alongside Henri, CRO, in our Revenue team, you will be responsible for contributing to our data engineering roadmap in an effort to support our company's growing data needs and volume. Play a key role in building solutions to help various teams access data via 3rd party analytics platforms (Looker), while managing and structuring data that will encourage collaboration. Monitor overall performance and stability of systems, while simultaneously supporting our marketing automation tools and running ad hoc queries and reports as needed.

Many career paths can prepare you for this life-changing opportunity, but preferably, you're highly skilled in:

Working with cloud platforms such as Kubernetes & Kafka, and databases such as MySql, Clickhouse;
Building analytics tools that utilize the data pipeline to provide actionable insights;
Identifying ways to improve data reliability, efficiency and quality;
Auditing data to validate accuracy;
Working with stakeholders including the Executive, Product, Data and Design teams to assist with data acquisition, data-related technical issues and other analytics needs;
Working in a fast-paced and technological environment, with strong communication skills.


Please note this position is in Montreal, Quebec.
Show us your drive and join our team!

Check us out https://flighthubgroup.com/takeoff

#LI-CV1","FlightHub
4.2",Montreal
330,Sr. Data & Applied Scientist,"Do you want to be on the leading edge of using big data and help drive development decisions for the biggest productivity software on the planet? Office Experience Organization (OXO) has embarked on a mission to delight our customers by using data informed engineering to develop compelling products and services. OXO is looking for an experienced Data Scientist with a passion for maximizing the return on investment from collecting petabytes of telemetry data to infer deep user and product insights. The Data Scientist would leverage statistical modeling, experimentation, forecasting and data visualization techniques to identify core drivers of user engagement in productivity applications. The role involves working with application teams (like Word, Excel, and Power Point), other data scientists, data engineers and program managers to continuously improve understanding usage, retention and user satisfaction.
We are looking for a strong Data Scientist with a proven track record of solving large, complex data analysis and machine learning problems in a real-world product development setting. Ideal candidates should be able to identify a business or engineering problem and translate it to a data science problem, dig out sources of data, conduct the analysis that would reveal useful nuggets and help engineering teams to operationalize the solution.
Responsibilities
Core Skills:
Identifies data sources, integrates multiple sources, or types of data, and applies expertise within a data source to develop methods to compensate for limitations and extend the applicability of the data.
Applies (or develops if necessary) tools and pipelines to efficiently collect, clean, and prepare massive volumes of data for analysis.
Transforms formulated problems into implementation plans for experiments by applying (and creating when necessary) the appropriate methods, algorithms, and tools, and statistically validating the results against biases and errors.
Interprets results and develops insights into formulated problems within the business/customer context and provides guidance on risks and limitations.
Acquires and uses broad knowledge of innovative methods, algorithms, and tools from within Microsoft and from the scientific literature and applies his or her own analysis of scalability and applicability to the formulated problem.
Validates, monitors, and drives continuous improvement to methods, and proposes enhancements to data sources that improve usability and results.
Qualifications
Requirements:
Expert in one or more statistical software like R, SAS, etc.
Expert in one or more scripting languages like Perl, Python, Scala, or SQL
Solid foundation of statistical modeling and machine learning algorithms and experimental design
Deep understanding of big data systems including map reduce technologies like Hadoop and Spark.
B.S. and/or M.S. (Ph.D. Preferred) in Computer Science, Statistics, Operations Research, or similar quantitative field.
5 years plus of applying statistical modeling, ML, and data mining algorithms to real world problems.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
331,Sr. Data & Applied Scientist,"Do you want to be on the leading edge of using big data and help drive development decisions for the biggest productivity software on the planet? Office Experience Organization (OXO) has embarked on a mission to delight our customers by using data informed engineering to develop compelling products and services. OXO is looking for an experienced Data Scientist with a passion for maximizing the return on investment from collecting petabytes of telemetry data to infer deep user and product insights. The Data Scientist would leverage statistical modeling, experimentation, forecasting and data visualization techniques to identify core drivers of user engagement in productivity applications. The role involves working with application teams (like Word, Excel, and Power Point), other data scientists, data engineers and program managers to continuously improve understanding usage, retention and user satisfaction.
We are looking for a strong Data Scientist with a proven track record of solving large, complex data analysis and machine learning problems in a real-world product development setting. Ideal candidates should be able to identify a business or engineering problem and translate it to a data science problem, dig out sources of data, conduct the analysis that would reveal useful nuggets and help engineering teams to operationalize the solution.
Responsibilities
Core Skills:
Identifies data sources, integrates multiple sources, or types of data, and applies expertise within a data source to develop methods to compensate for limitations and extend the applicability of the data.
Applies (or develops if necessary) tools and pipelines to efficiently collect, clean, and prepare massive volumes of data for analysis.
Transforms formulated problems into implementation plans for experiments by applying (and creating when necessary) the appropriate methods, algorithms, and tools, and statistically validating the results against biases and errors.
Interprets results and develops insights into formulated problems within the business/customer context and provides guidance on risks and limitations.
Acquires and uses broad knowledge of innovative methods, algorithms, and tools from within Microsoft and from the scientific literature and applies his or her own analysis of scalability and applicability to the formulated problem.
Validates, monitors, and drives continuous improvement to methods, and proposes enhancements to data sources that improve usability and results.
Qualifications
Requirements:
Expert in one or more statistical software like R, SAS, etc.
Expert in one or more scripting languages like Perl, Python, Scala, or SQL
Solid foundation of statistical modeling and machine learning algorithms and experimental design
Deep understanding of big data systems including map reduce technologies like Hadoop and Spark.
B.S. and/or M.S. (Ph.D. Preferred) in Computer Science, Statistics, Operations Research, or similar quantitative field.
5 years plus of applying statistical modeling, ML, and data mining algorithms to real world problems.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
332,Data Engineer,"Celtx is an ambitious and fast growing software development company that offers an industry leading, one of a kind product. Our cloud-based Celtx Studios brings together creative teams and facilitates full-spectrum collaboration on film, video and game production.

Our Data team is responsible for all of the reporting, analytics and data driven insights within our quickly growing company. We've got a lot of data, and we're looking for someone to help us get the most out of it.

As a Data Engineer, you will work with our Data Analysts, Data Scientists and Development team to build and maintain a world-class data infrastructure. Your work here will directly help our business grow, help our customers succeed, and continuously improve the way we operate.

What You'll Do in this Role:

Work extensively with Google Cloud Platform and Amazon Web Services where our data and product infrastructure is hosted.
Approve pull requests of other team members and help inform best practices on data structures that optimize for performance and cost
Work closely with our development team to ensure that new and existing features are enabled for tracking and monitoring, by directly contributing to aspects of the code base and technical integrations

Key Skills and Experience:

5+ Years experience working as a data engineer/architect
Prior experience architecting solutions on any of the major cloud data platforms - Google Cloud Platform, AWS or Azure
Strong SQL skills
Fluent in Python, Node.js, or other scripting languages
A good understanding of query optimization and data lake performance

Nice to Have:

Previous experience working in a high growth SaaS business
Experience using a dashboarding tool such as Looker, Data Studio, Tableau, etc.

Work remotely:

We are open to candidates who can work physically from our St. John's office (when it reopens) or who are willing to work remotely in the Eastern or Atlantic time zones.

This is a new, permanent, full-time position to join our dedicated and energetic team. We offer generous health and dental benefits, extended maternity and parental leave, competitive pay and flexible vacation time. Our main offices are based in St. John's, Newfoundland and Labrador, however consideration will be given to remote applicants within the Eastern or Atlantic time zones.

We foster an open, innovative, and forward-thinking atmosphere. At Celtx, everyone is given a seat at the table and an opportunity to have their voices heard. We all share a common mission to cultivate a workshop of ideas that will help keep Celtx ahead of the curve. It's engaging, dynamic, and fun.

We offer competitive compensation and generous perks.","Celtx Inc
5.0",St. John's
333,Data Engineer,"StreetLight Data, the pioneer in Big Data for mobility, is revolutionizing transportation and urban planning to help the world better deploy infrastructure and adapt to new forms of mobility. From legacy systems to ride sharing and bike sharing to autonomous vehicles, our platform powers 6,000+ mobility projects every month for government and private clients, and we're just getting started.

StreetLight Data is seeking a strong Data Engineer to be part of our growing Engineering team. This team member will work on processing data at scale, and productizing new analytics into the StreetLight InSight platform. This position reports to the Manager of Data Science.
Key Responsibilities:
Design and implement components within the StreetLight InSight data processing pipeline (from raw input files to optimized tables used for analyses)
Tune the StreetLight InSight processing pipeline for performance and scalability, and automate it to allow for hands-off operations
Develop new analytics algorithms, using a deep understanding of the raw data
Implement customized analytics for clients in collaboration with Sales
Work with Product Management and Application teams to productize data analytics algorithms into the StreetLight InSight web application
Contribute to data science projects as appropriate.
Skills & Qualifications:
BS / MS in Computer Science, Mathematics, or an Engineering discipline from a top university
5+ years experience as a software or data engineer at an enterprise software/analytics company
5+ years experience with relational databases (PostgreSQL preferred) and SQL, including strong understanding of concepts
Strong understanding of algorithms, and 3+ years experience in Java and/or Python
Good communication skills - both written and verbal
Knowledge of geospatial data is a plus
Knowledge of statistics and/or science is a plus
Quick learner, and a strong team player
StreetLight Data is an equal opportunity/affirmative action employer. StreetLight Data provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.","StreetLight Data
4.9",Vancouver
334,Data Engineer,"StreetLight Data, the pioneer in Big Data for mobility, is revolutionizing transportation and urban planning to help the world better deploy infrastructure and adapt to new forms of mobility. From legacy systems to ride sharing and bike sharing to autonomous vehicles, our platform powers 6,000+ mobility projects every month for government and private clients, and we're just getting started.

StreetLight Data is seeking a strong Data Engineer to be part of our growing Engineering team. This team member will work on processing data at scale, and productizing new analytics into the StreetLight InSight platform. This position reports to the Manager of Data Science.
Key Responsibilities:
Design and implement components within the StreetLight InSight data processing pipeline (from raw input files to optimized tables used for analyses)
Tune the StreetLight InSight processing pipeline for performance and scalability, and automate it to allow for hands-off operations
Develop new analytics algorithms, using a deep understanding of the raw data
Implement customized analytics for clients in collaboration with Sales
Work with Product Management and Application teams to productize data analytics algorithms into the StreetLight InSight web application
Contribute to data science projects as appropriate.
Skills & Qualifications:
BS / MS in Computer Science, Mathematics, or an Engineering discipline from a top university
5+ years experience as a software or data engineer at an enterprise software/analytics company
5+ years experience with relational databases (PostgreSQL preferred) and SQL, including strong understanding of concepts
Strong understanding of algorithms, and 3+ years experience in Java and/or Python
Good communication skills - both written and verbal
Knowledge of geospatial data is a plus
Knowledge of statistics and/or science is a plus
Quick learner, and a strong team player
StreetLight Data is an equal opportunity/affirmative action employer. StreetLight Data provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.","StreetLight Data
4.9",Vancouver
335,"Data and Analytics, Student","Job Title: Data and Analytics
Location: Toronto, Oakville and/or Calgary
Term: Fall 2021 (4 or 8 month terms available)

Canadian Tire Corporation is adhering to government regulations for COVID-19 as we are taking all actions and protocols to ensure our employees are safe. As this pandemic is unpredictable, we have listed the office location of this current opportunity but will continue to follow safety protocols and will provide further information closer to the Fall 2021 term.

Help us boldly shape retail in Canada

Canadian Tire Corporation’s (CTC) rich heritage of serving Canadians from coast-to-coast dates back to 1922. Our vision is to become the #1 retail brand in Canada by 2022 and we are focused on innovating and making important investments in our business, especially when it comes to our people. To reach our goal, we need the best talent to help us evolve and drive change across the business – and boldly help shape Canada’s retail industry. As we strive to be at the forefront of a complex and vastly changing retail industry, it is an exciting time to join the Canadian Tire family of companies.

Our Data & Analytics team is embedded into all areas of our business including IT, Marketing, Loyalty, Supply Chain, and Human Resources; and is comprised of a diverse and dynamic team of analysts, data scientists, developers, and consumer researchers who deliver customer-focused analytical solutions and insights that enable lasting and meaningful customer and employee relationships. Using the latest data technologies and advanced analytical techniques, they demystify shopper behaviour and embed those insights deep within the fabric of the business.

What you’ll do

As a Data & Analytics Student you’ll gain valuable insight into how predictive analytics, modelling and insights are used to us make more informed business decisions across our entire enterprise. Whether you’re assisting with data preparation, reconciliation and analysis, developing reports, or making data supported recommendations that drive business change you’ll play a part in helping us deliver better, faster, and in more meaningful and impactful ways to our customers and employees.

Roles we are currently recruiting for:


Retail Insights, Student


This team is focused on using data driven approaches to increase space productivity across the retail network. We are a team that is constantly evolving to better suit our associate dealers’ needs.

What you'll do:

Work with Senior Analysts to conduct comprehensive store level analysis to generate actionable insights and recommendations.
Create presentations and supporting documents to summarize analysis for key business stakeholders and decision makers.
Enhance team understanding of retail execution by analyzing and summarizing store level data.
Assist in the development of new reports or tools that capitalize on better understanding retail execution across the retail network.




Data Insights, Student


The co-op role will support our objective of driving linear productivity through collaborating with product owners on the design, testing and implementation of productivity reporting tools including our Productivity Dashboard, Pulse Objective Reporting and SmartPack POG packing model.

What you'll do:

Collaborate with Senior Consultants on the development and testing of priority projects
Contribute to the identification of potential opportunities within our current process
Pull and analyze data as required



Who you are:

Exceptional communication skills with the confidence and passion to share knowledge
Creative thinker who is observant to seek new opportunities and perceptive to abstract ideas
Goal driven individual to seek out continuous improvement opportunities
The ability to take a collaborate approach to build strong relationships and have positive team experiences
Flexible and dynamic individual who is able to adjust and prioritize accordingly to adapt to business demands and requirements
Solid foundation of relevant technical skills
Demonstrates behaviours of transparency, accountability, agility and learning from others that will support your success

What you bring

Undergraduate degree in CS, Math, Statistics, Information Technology or Engineering;
Experience querying large databases using Python, SQL, KNIME and/or Spark;
Experience building machine learning and mathematical models
Competency in data analysis and interpretation of results
Detail oriented with a problem-solving mind set and impeccable attention to detail
Ability to prioritize tasks with some guidance
Working knowledge of standard desktop tools (Excel, PowerPoint, Outlook)
Experience with other analytical platforms and tools (e.g. Hadoop, Azure, GCP, BigQuery, Power BI, Data Studio, Airflow, Snowflake, etc.) considered an asset
Some experience (e.g. other co-op placements) in a retail or loyalty analytics role is desirable

About Canadian Tire Corporation

Canadian Tire and its family of companies are boldly shaping retail in Canada and we continue to deliver a positive experience for our customers. As one of the most trusted brands in Canada, our employees take pride in the work we do across the country. It’s more than the iconic triangle that keeps our employees around. From benefits and perks, to learning and development opportunities, to our commitment to Jumpstart – these are some of the many reasons why Canadian Tire Corporation is one of Canada’s Top Employers.

To learn more about this team and the Canadian Tire family of companies follow us on LinkedIn.

Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.

Store Support & Operations
Ontario-Toronto
Temporary Work
Full-time
Job Posting
: May 12, 2021, 11:33:40 AM","Canadian Tire
3.8",Midtown Toronto
336,"Data and Analytics, Student","Job Title: Data and Analytics
Location: Toronto, Oakville and/or Calgary
Term: Fall 2021 (4 or 8 month terms available)

Canadian Tire Corporation is adhering to government regulations for COVID-19 as we are taking all actions and protocols to ensure our employees are safe. As this pandemic is unpredictable, we have listed the office location of this current opportunity but will continue to follow safety protocols and will provide further information closer to the Fall 2021 term.

Help us boldly shape retail in Canada

Canadian Tire Corporation’s (CTC) rich heritage of serving Canadians from coast-to-coast dates back to 1922. Our vision is to become the #1 retail brand in Canada by 2022 and we are focused on innovating and making important investments in our business, especially when it comes to our people. To reach our goal, we need the best talent to help us evolve and drive change across the business – and boldly help shape Canada’s retail industry. As we strive to be at the forefront of a complex and vastly changing retail industry, it is an exciting time to join the Canadian Tire family of companies.

Our Data & Analytics team is embedded into all areas of our business including IT, Marketing, Loyalty, Supply Chain, and Human Resources; and is comprised of a diverse and dynamic team of analysts, data scientists, developers, and consumer researchers who deliver customer-focused analytical solutions and insights that enable lasting and meaningful customer and employee relationships. Using the latest data technologies and advanced analytical techniques, they demystify shopper behaviour and embed those insights deep within the fabric of the business.

What you’ll do

As a Data & Analytics Student you’ll gain valuable insight into how predictive analytics, modelling and insights are used to us make more informed business decisions across our entire enterprise. Whether you’re assisting with data preparation, reconciliation and analysis, developing reports, or making data supported recommendations that drive business change you’ll play a part in helping us deliver better, faster, and in more meaningful and impactful ways to our customers and employees.

Roles we are currently recruiting for:


Retail Insights, Student


This team is focused on using data driven approaches to increase space productivity across the retail network. We are a team that is constantly evolving to better suit our associate dealers’ needs.

What you'll do:

Work with Senior Analysts to conduct comprehensive store level analysis to generate actionable insights and recommendations.
Create presentations and supporting documents to summarize analysis for key business stakeholders and decision makers.
Enhance team understanding of retail execution by analyzing and summarizing store level data.
Assist in the development of new reports or tools that capitalize on better understanding retail execution across the retail network.




Data Insights, Student


The co-op role will support our objective of driving linear productivity through collaborating with product owners on the design, testing and implementation of productivity reporting tools including our Productivity Dashboard, Pulse Objective Reporting and SmartPack POG packing model.

What you'll do:

Collaborate with Senior Consultants on the development and testing of priority projects
Contribute to the identification of potential opportunities within our current process
Pull and analyze data as required



Who you are:

Exceptional communication skills with the confidence and passion to share knowledge
Creative thinker who is observant to seek new opportunities and perceptive to abstract ideas
Goal driven individual to seek out continuous improvement opportunities
The ability to take a collaborate approach to build strong relationships and have positive team experiences
Flexible and dynamic individual who is able to adjust and prioritize accordingly to adapt to business demands and requirements
Solid foundation of relevant technical skills
Demonstrates behaviours of transparency, accountability, agility and learning from others that will support your success

What you bring

Undergraduate degree in CS, Math, Statistics, Information Technology or Engineering;
Experience querying large databases using Python, SQL, KNIME and/or Spark;
Experience building machine learning and mathematical models
Competency in data analysis and interpretation of results
Detail oriented with a problem-solving mind set and impeccable attention to detail
Ability to prioritize tasks with some guidance
Working knowledge of standard desktop tools (Excel, PowerPoint, Outlook)
Experience with other analytical platforms and tools (e.g. Hadoop, Azure, GCP, BigQuery, Power BI, Data Studio, Airflow, Snowflake, etc.) considered an asset
Some experience (e.g. other co-op placements) in a retail or loyalty analytics role is desirable

About Canadian Tire Corporation

Canadian Tire and its family of companies are boldly shaping retail in Canada and we continue to deliver a positive experience for our customers. As one of the most trusted brands in Canada, our employees take pride in the work we do across the country. It’s more than the iconic triangle that keeps our employees around. From benefits and perks, to learning and development opportunities, to our commitment to Jumpstart – these are some of the many reasons why Canadian Tire Corporation is one of Canada’s Top Employers.

To learn more about this team and the Canadian Tire family of companies follow us on LinkedIn.

Canadian Tire is an equal opportunity employer. We are committed to a diverse and inclusive workplace for all. We recognize that our future success depends on the perspectives and contributions of all our employees - their diverse backgrounds, abilities and experiences make our business stronger. If you are contacted for a job opportunity, please advise us of any accommodations needed to ensure fair and equitable access throughout the recruitment and selection process. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.

Store Support & Operations
Ontario-Toronto
Temporary Work
Full-time
Job Posting
: May 12, 2021, 11:33:40 AM","Canadian Tire
3.8",Midtown Toronto
337,Data Engineer,"UNCAGE YOUR AMBITION as a Data Engineer

We are FlightHub Group , an ambitious team of people that created FlightHub and Justfly . Our brands have grown to become two of the top-ranked travel agencies in North America. We now serve over 3 million customers per year, totaling 3 billion dollars in sales, and, whereas the pandemic may have slowed us down a little, we are coming back even stronger. We dream big, pursue passionately, and follow through with resolute self-belief and rigorous commitment. We are a group of individuals sharing a common vision and values, having come together to pursue a collective mission: overtaking the #1 spot in the world.

We are looking for a Data Engineer with 3+ years of experience to join our team. Working alongside Henri, CRO, in our Revenue team, you will be responsible for contributing to our data engineering roadmap in an effort to support our company's growing data needs and volume. Play a key role in building solutions to help various teams access data via 3rd party analytics platforms (Looker), while managing and structuring data that will encourage collaboration. Monitor overall performance and stability of systems, while simultaneously supporting our marketing automation tools and running ad hoc queries and reports as needed.

Many career paths can prepare you for this life-changing opportunity, but preferably, you're highly skilled in:

Working with cloud platforms such as Kubernetes & Kafka, and databases such as MySql, Clickhouse;
Building analytics tools that utilize the data pipeline to provide actionable insights;
Identifying ways to improve data reliability, efficiency and quality;
Auditing data to validate accuracy;
Working with stakeholders including the Executive, Product, Data and Design teams to assist with data acquisition, data-related technical issues and other analytics needs;
Working in a fast-paced and technological environment, with strong communication skills.


Please note this position is in Montreal, Quebec.
Show us your drive and join our team!

Check us out https://flighthubgroup.com/takeoff

#LI-CV1","FlightHub
4.2",Montreal
338,Data Engineer,"Position Description:

CGI helps clients take an enterprise approach to accelerate and maximize their return on technology investments through relevant applied innovation.

We are looking for an exceptional Data Engineer to join our team.

Your future duties and responsibilities:
Undergraduate or master’s degree in Math, Engineering, or Computer Science
4+ years work experience in a data analytics or data engineering role designing/architecting/maintaining data pipelines for ETL / ELT
Passionate about producing clean, maintainable and testable code
Experience with developing pipelines that ingest and transform > 10 ^6 events per minute and terabytes of data per day.
Experience developing pipelines with unstructured data
Experience working with cloud technologies (e.g. AWS, Azure, GCP, etc)
Required qualifications to be successful in this role:
Experience in structured problem solving
Ability to communicate complex ideas effectively – both verbally and in writing – in English.
Exceptional research and information gathering skills; equipped with the ability to distill knowledge.
Active listening skills, exposure to client-facing environments an asset.
Ability to work effectively with people at all levels in an organization.
Proven record of leadership in a work setting and/or through extracurricular activities.
Ability to work collaboratively in a team environment.
Highly motivated, highly ambitious, and able to work with little direction.
Independent, self-starter, experience writing and delivering reports.
Skills:
Engineering
What you can expect from us:

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer. In addition, CGI is committed to providing accommodations for people with disabilities in accordance with provincial legislation. Please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.","CGI Inc
3.8",Midtown Toronto
339,Scientifique des données / Data Scientist,"Role and Responsibilities


(English message to follow)

Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Nous sommes le partenaire de choix en formation partout dans le monde. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.

Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.

Voici quelques raisons pour lesquelles les membres de notre personnel aiment travailler au sein de notre entreprise :

Travail significatif qui favorise le perfectionnement professionnel.
Possibilité d’entrer dans l’industrie technologique et de s’y épanouir.
Environnement de travail axé sur la collaboration.
Équipe de haut niveau.

Ce que nous avons à offrir :

Régime d’assurance collective souple
Régime de retraite à prestations déterminées
Régime d’achat d’actions du personnel
Régime enregistré d’épargne-retraite collectif
Programme pour le bien‑être physique
Programme d’aide aux employés
Prestations de maternité complémentaires
Horaire de travail variable
« Vendredis Californie » tout au long de l’année

Votre mission :

En tant que membre de l’équipe de la science des données, vous analyserez et résumerez l’information pour comprendre les enjeux, déterminer les options, et soutenir une prise de décision éclairée. Vous produirez des méthodes et des solutions novatrices et viables. Vous comprenez comment appliquer des connaissances et des compétences fonctionnelles et techniques en vue d’atteindre des objectifs de travail dans un environnement Agile. En tant que candidat(e) idéal(e), vous êtes adepte de l’utilisation de grands ensembles de données pour chercher à optimiser les produits et les processus, et de l’utilisation de modèles pour évaluer l’efficacité de différents plans d’action.

Nous sommes à la recherche d’une personne capable de réaliser les tâches suivantes :

Extraire et analyser les données se trouvant dans les bases de données de l’entreprise afin d’optimiser et d’améliorer le développement des produits, les techniques de marketing et les stratégies commerciales.
Évaluer l’efficacité et l’exactitude des nouvelles sources de données et techniques de collecte de données.
Élaborer des algorithmes et des modèles de données personnalisées à appliquer aux ensembles de données.
Utiliser une modélisation prédictive pour accroître et optimiser l’expérience des clients, les revenus générés, le ciblage publicitaire et d’autres résultats opérationnels.
Élaborer un cadre de tests A/B pour l’entreprise et mettre à l’essai la qualité du modèle.
Coordonner différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats.
Élaborer des processus et des outils pour le contrôle et l’analyse du rendement des modèles et de l’exactitude des données.

Voici les caractéristiques de notre candidat(e) idéal(e) :

Titulaire d’une maîtrise ou d’un doctorat en statistique, informatique, analyse des systèmes de gestion ou autre domaine connexe.
Au moins 5 ans d’expérience en science des données ou en statistiques appliquées.

Bilinguisme requis

Solides aptitudes pour la résolution de problèmes, et surtout le développement de produits.
Expérience dans l’utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler les données et extraire des renseignements de grands ensembles de données.
Expérience dans la manipulation d’ensembles de données et l’élaboration de modèles statistiques.
Connaissance de diverses techniques d’apprentissage automatique (algorithme Random Forests, remontée de gradient, réseaux de neurones artificiels, etc.) et de leurs avantages et inconvénients dans le monde réel.
Connaissance de techniques et de concepts statistiques sophistiqués (MLG/régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation conforme, etc.), expérience dans leur application.
Expérience dans l’utilisation et la création d’architectures de données.
Expérience dans l’utilisation de services Web : Redshift, S3, Azure, Spark, DigitalOcean, etc.
Expérience dans l’analyse de données provenant de fournisseurs tiers : Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Expérience dans la visualisation et la présentation de données pour des intervenants, à l’aide de : Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
Penchant naturel pour l’apprentissage et la maîtrise des nouvelles technologies et techniques.
Expérience de direction d’initiatives axées sur le client.
Expérience de travail dans un environnement Agile, un atout.
Excellentes aptitudes pour la communication verbale et écrite en vue de la coordination des équipes.

Rejoignez une organisation qui fait la différence chaque jour!

****************************************************************************

If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. Our company is the worldwide training partner of choice, and with good reason. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.

Here are the reasons why folks love working here!

Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Working in a collaborative environment
Being part of a high performance team

What we have to offer:

Flexible Group Insurance Plan
Defined Benefits Retirement Plan
Employee Stock Purchase Plan
Group Registered Retirement Savings Plan (RRSP)
Physical Wellness Plan
Employee Assistance Plan
Supplementary Maternity Plan
Flextime
California Fridays all year

Your Mission:

As a member of the Data Science team, you will analyze and synthesize information to understand issues, identify options, and support sound decision-making. You will be generating viable, new approaches and solutions. You have an understanding of applying functional and technical knowledge and skills to accomplish work objectives in an agile environment. As the ideal candidate, you are adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.

We are looking for people who can:

Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework and test model quality.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.

As our ideal candidate you will also:

Have a Master or PhD in Statistics, Computer Science, Business Analytics or a related field
Possess at least 5 years experience in Data Science or applied statistics.

Bilingualism required

Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience manipulating data sets and building statistical models.
Knowledge of a variety of machine learning techniques (Random Forests, Gradient boosting, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (GLM/Regression, Time Series, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Experience working with and creating data architectures.
Experience using web services: Redshift, S3, Azure, Spark, DigitalOcean, etc.
Experience analyzing data from 3rd party providers: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
A drive to learn and master new technologies and techniques.
Experience leading customer driven initiatives.
Experience working in an Agile environment an asset.
Excellent written and verbal communication skills for coordinating across teams.

Join an organization making a difference everyday!

Position Type


Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.","CAE Inc.
3.8",Saint-Laurent
340,Software Data Engineer - Analytics Engineering,"Summary

Posted: May 21, 2021
Role Number:200196998
The Apple Media Products Engineering team is one of the most exciting examples of Apple’s long-held passion for combining art and technology! These are the people who power the App Store, Apple TV, Apple Music, Apple Podcasts, and Apple Books. And they do it on a massive scale, meeting Apple’s high expectations with high performance to deliver a huge variety of entertainment in over 35 languages to more than 150 countries.These engineers build secure, end-to-end solutions. They develop the custom software used to process all the creative work, the tools that providers use to deliver that media, all the server-side systems, and the APIs for many Apple services. Thanks to Apple’s unique integration of hardware, software, and services, engineers here partner to get behind a single unified vision. That vision always includes a deep commitment to strengthening Apple’s privacy policy, one of Apple’s core values. Although services are a bigger part of Apple’s business than ever before, these teams remain small, forward-thinking, and cross-functional, offering greater exposure to the array of opportunities here.
Key Qualifications
5+ years experience in high level programming languages such as Java, Scala.
Proficiency with databases and SQL is required.
Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.
Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.
Experience with large scale data warehousing, mining or analytic systems.
Ability to work with analysts to gather requirements and translate them into data engineering tasks
Aptitude to independently learn new technologies.
Description
As a senior member of the Data Engineering team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional and the ideal candidate will work across disciplines. We are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline.This position involves working on a small team to develop large scale data pipelines and analytical solutions using Big Data technologies. Successful candidates will have strong engineering skills and communication, as well as, a belief that data driven processes lead to phenomenal products. You will need to have a passion for quality and an ability to understand sophisticated systems.
Education & Experience
Bachelor's degree or equivalent work experience in Engineering, Computer Science, Business Information Systems.Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other legally protected characteristics.","Apple
4.3",Vancouver
341,Data Engineer,"# 14787 - bev123




Data Engineer

contract

Toronto

Strong knowledge of Python, Spark, and SQL
Database, storage, collection and aggregation models, techniques and technologies – and how to apply them in business
Experience in structured problem solving
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning



About Bevertec:

For 35 plus years Bevertec has been at the forefront of providing top level technology professionals to our clients across the Greater Toronto Hamilton Area, Canada and beyond. Bevertec specializes in technology professionals but looks to fill all professional roles that help expand and grow our client’s business and advance our candidates careers.


Remaining at the forefront of providing staffing solutions has been no easy task for us, that why we depend on top caliber candidates like yourself and our team of business development managers to provide you with the opportunities to work with leaders within the IT realm to meet your aspirations. As proof of our continued success Bevertec places candidates with leaders in the public and private sector and continuous remains a vender of record with large organizations across the country.

Learn more at www.bevertec.com


How to Apply

Click the “Apply to Job” button and follow the instructions to submit your resume or contact : Nizam Hafiz at nhafiz@bevertec.com or 416-695-7525 ext 2227




Thank you for your interest in your next great opportunity with Bevertec

Only those selected for an interview will be contacted, Bevertec is committed to Employment Equity and encourages applications from all qualified candidates. In accordance with the Accessibility for Ontarians with Disabilities Act Bevertec will provide accommodations throughout the recruitment process, should you require such accommodations please contact our Human Resources department.","Bevertec CST Inc
3.7",Midtown Toronto
342,Data Engineer,"# 14787 - bev123




Data Engineer

contract

Toronto

Strong knowledge of Python, Spark, and SQL
Database, storage, collection and aggregation models, techniques and technologies – and how to apply them in business
Experience in structured problem solving
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning



About Bevertec:

For 35 plus years Bevertec has been at the forefront of providing top level technology professionals to our clients across the Greater Toronto Hamilton Area, Canada and beyond. Bevertec specializes in technology professionals but looks to fill all professional roles that help expand and grow our client’s business and advance our candidates careers.


Remaining at the forefront of providing staffing solutions has been no easy task for us, that why we depend on top caliber candidates like yourself and our team of business development managers to provide you with the opportunities to work with leaders within the IT realm to meet your aspirations. As proof of our continued success Bevertec places candidates with leaders in the public and private sector and continuous remains a vender of record with large organizations across the country.

Learn more at www.bevertec.com


How to Apply

Click the “Apply to Job” button and follow the instructions to submit your resume or contact : Nizam Hafiz at nhafiz@bevertec.com or 416-695-7525 ext 2227




Thank you for your interest in your next great opportunity with Bevertec

Only those selected for an interview will be contacted, Bevertec is committed to Employment Equity and encourages applications from all qualified candidates. In accordance with the Accessibility for Ontarians with Disabilities Act Bevertec will provide accommodations throughout the recruitment process, should you require such accommodations please contact our Human Resources department.","Bevertec CST Inc
3.7",Midtown Toronto
343,Data Engineer,"Dawn InfoTek Inc. is a professional IT consulting team that partners with major financial institutions, investment firms and government sectors. We have been dedicated in delivering cutting-edge consulting services and recruiting all levels of IT positions for our clients.

We are looking for a meticulous and enthusiastic Data Engineer to join our dynamic team to work at our bank client.

Type: Contract / Permanent
Location: Toronto

Requirements

Must-have:

4-6 years of experience with data engineering skills
4-6 years of hands on experience with SQL, Shell Scripting and Python (TensorFlow, Pandas, Numpy, Keras)
4-6 years of hands on experience ingesting data using APIs
4-6 years of hands on experience with BI tools / Big data technologies like Hadoop, Spark, Scala

Nice-to-Have:

Knowledge of Dialogflow ES and CX APIs, BigQuery, Google Cloud Data Loss Prevention, DataFlow

For immediate consideration, please apply as soon as possible to this posting by submitting your Resume along with your Availability Date

Referrals are more than welcome! We thank all applicants for your interest and referral. However, only qualified candidates selected for an interview will be contacted. Must reside in Toronto area.

For further information on our company, please visit: www.dawninfotek.com

Contract length: 4 months

Job Types: Full-time, Contract

Salary: $65.00-$75.00 per hour

Benefits:

Work from home

Schedule:

Monday to Friday

Experience:

data engineering: 4 years (required)
SQL, Shell Scripting and Python: 4 years (required)
ingesting data using APIs: 4 years (required)
BI tools / Big data technologies (Hadoop, Spark, Scala): 4 years (required)
Dialogflow ES and CX APIs, BigQuery, DataFlow: 1 year (preferred)

Work remotely:

Temporarily due to COVID-19","Dawn InfoTek Inc.
4.0",Midtown Toronto
344,Lead Data Scientist,"EPAM is committed to providing our global team of more than 41,150 EPAMers with inspiring careers from day one. EPAMers think creatively and lead with passion and honesty. Our people are the source of our success. We value collaboration, work in partnership with our customers, and strive for the highest standards of excellence. In today’s market conditions, we’re supporting operations for hundreds of clients around the world remotely. No matter where you are located, you’ll join a dedicated, diverse community that will help you discover your fullest potential.



Description

You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Lead Data Scientist. Scroll down to learn more about the position’s responsibilities and requirements.

We are looking for Lead Data Scientist to join our growing team remotely working in EST or CST time zone only.

REQ #: 230398628
What You’ll Do
Convert large volumes of structured and unstructured customer data using. advanced analytical solutions
Use and fit different mathematical and econometric models, develop descriptive and predictive models that deliver better decisions
Turn analyzed data into actionable insights and business value
Create high-quality data visualizations
Communicate effectively with different departments and roles (product managers, engineers) to discuss complex data-driven findings and technical matters
Educate and train others on Data Science related matters
Estimate, plan and coordinate the delivery of large projects
Create Data Science solution architecture
Propose Data Science holistic solutions for customer problems
Requirements
BS degree in an associated field or other advanced certification along with equivalent experience
Aptitude for problem solving
Data focused applied mathematics (statistical analysis, machine learning)
Decent communication / presentation skills (including working English fluency)
RDBMS/SQL knowledge
Programming experience (Python preferred)
Data analysis tools and libraries such as Python (NumPy / SciPy / scikit-learn / pandas / matplotlib), R, SAS, SPSS, MATLAB, etc
Big Data stack; Spark / MLlib
Proficiency with at least one of the Cloud providers
Experience with Data Science solutions productionalization
Data visualization skills
NLP/text mining
Bachelor’s/Master’s Degree in Computer Science, Math, Applied Statistics or a related field
A few years of experience in data mining, statistics or machine learning
In-depth domain understanding and ability to acquire new
What We Offer
Extended Healthcare with Prescription Drugs, Dental and Vision Insurance (Company Paid)
Life and AD&D Insurance (Company Paid)
Employee Assistance Program (Company Paid)
Unlimited access to LinkedIn learning solutions
Long-Term Disability
Registered Retirement Savings Plan (RRSP) with company match
Paid Time Off
Critical Illness Insurance
Employee Discounts","EPAM Systems
4.2",Canada
345,Data Engineer,"As a Data Engineer, you’d be involved in projects and work with the team to achieve high quality data integrations and responsible for design and development of scalable data solutions.

This is your chance to contribute to the ongoing Data Platform enhancements to support strategic business initiatives. Grab the opportunity by applying now.

A typical day would involve:

Design and develop data ingestion pipelines, cleanse, and normalize diverse datasets and build structure for previously unstructured data
Troubleshoot and resolve problems of data services that support business & applications systems and provide solutions to pro-actively prevent problems from happening.
Help drive transformation by continuously looking for ways to automate existing processes and optimize for efficiency and data quality

You are:

Customer-centric: You define and measure success through the eyes of your internal customers and anticipate, understand and respond to their evolving needs. Demonstrate strong follow through and consistently keep commitments to members and team.
Results-oriented: You have a demonstrated ability to engage stakeholders to elicit requirements, analyze findings, generate appropriate solutions, and build deliverables all while securing the team's commitment to these solutions.
Technology savvy: You have education and/or experience supporting technology development/implementation efforts.
Curious & innovative: You always do your research and analysis to assess and recommend a course of action based on industry, political and economic trends, you can identify risks and opportunities that may impact the business unit and or designated area.

You have:

Bachelor's degree in Computer Science or a related technical discipline.
3+ years of industry experience in Data Engineering or related field handling data processing and transformation of disparate datasets
Willingness to work in a highly flexible environment with multiple competing priorities.
Proven ability to innovate and adapt to the latest development in area of expertise. Ability to adapt and grasp new skills and content.

Bonus points, if you have:

Experience in design and implementation of data integrations in Azure data stack such as Azure Data Lake, Azure Data Factory, Azure Databricks.
Good understanding of data storage, data mapping and modelling, real-time data handling

The team: In this role, you will report into Manager, Data Engineering

Posting Deadline: Please apply by 04:00 PM PST, July 5, 2021

About Vancity:

When you join Vancity as an employee and a member, you join a movement that believes that when we use money for what’s right, we truly are a financial force for change.
Our vision is to redefine wealth—and we are doing so by using the tools of finance to prioritize the wellbeing of our members and our communities by tackling the climate crisis and we are proving every day that sustainable is profitable.
We are the largest private-sector Living Wage Employer in Canada and have been consistently recognized as one of the Top Employers in Canada. Come join our team of 2,600 diverse individuals and access competitive rewards & benefits, all while knowing you are apart of a greater movement.
Start your Vancity career journey with us even if you’re new to financial services! We provide in-house paid training to gain general financial knowledge, and to learn about our products & services. We encourage opportunities to learn & develop to prepare you for career success, which in turn continuously impresses how we serve our membership.
Vancity is committed to a diverse workplace and values Integrity, Innovation, Responsibility and Reconciliation. While we review all applicants, we will be prioritizing applicants who self-identify as Indigenous peoples (First Nations, Inuit, and Metis), Members of visible minorities, and Persons with disabilities.
To learn more about Vancity, please visit www.vancity.com/AboutVancity.","Vancity
3.5",Vancouver
346,Data Engineer,"Hey there! Just in case you were wondering, this role will be remote and we will revisit the possibility of working back in our HQ office come July 2021. A member from our recruitment team can explain this in more detail if selected to move forward to the initial phone screen. We look forward to hearing from you!

WHO WE ARE:

Compass Digital Labs is an organization that drives innovation for Compass Group NA, an $18 billion food hospitality organization. Compass Group serves over 3 billion meals per year in award winning restaurants, corporate cafes, hospitals, schools, arenas, museums, and more. As the innovation branch of Compass Group, we’re custom-built for fast-paced transformation at the intersection of hospitality and technology. We’re focused on delivering the best experiences possible for our customers and consumers.

WHAT WE DO:

We are a team of high performing problem solvers with the same vision: to drive the digital future in hospitality. As digital experts we are focused on building a diverse set of products and solutions for our consumers. Our core products include mobile apps, self-serve kiosks, POS and delivery. We also invest in areas like AI, IoT and frictionless retail. Here we work with the “art of the possible” ideas, where we explore and develop the future of hospitality and technology.

We are looking for a Data Engineer to join our cross functional teams that is supporting one of our newest data focussed projects. This will be a great opportunity to join a truly passionate team, working on one of our most advanced-tech projects in our pipeline!

WHAT YOU'LL BE DOING:

Assemble large, complex data sets that meet functional/non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies
Create data tools for analytics and data scientist team members that assist them in building and optimizing our products
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs

WHAT YOU’LL BRING:

At least 2 years of experience in a similar role or function
Skills with: Python, SQL and Docker
AWS familiarity, Cloud Formation experience is an asset. Looking for: AWS Lambda, AWS CDK, API Gateway, Fargate

ABOUT YOU:

Strong oral and written communication skills
Excellent people and management skills to interact with colleagues, cross-functional teams and stakeholders
A go getter attitude and a passion for your work!

PlMK19YaJX","Compass Digital Labs
3.9",Mississauga
347,Data Engineer,"Hey there! Just in case you were wondering, this role will be remote and we will revisit the possibility of working back in our HQ office come July 2021. A member from our recruitment team can explain this in more detail if selected to move forward to the initial phone screen. We look forward to hearing from you!

WHO WE ARE:

Compass Digital Labs is an organization that drives innovation for Compass Group NA, an $18 billion food hospitality organization. Compass Group serves over 3 billion meals per year in award winning restaurants, corporate cafes, hospitals, schools, arenas, museums, and more. As the innovation branch of Compass Group, we’re custom-built for fast-paced transformation at the intersection of hospitality and technology. We’re focused on delivering the best experiences possible for our customers and consumers.

WHAT WE DO:

We are a team of high performing problem solvers with the same vision: to drive the digital future in hospitality. As digital experts we are focused on building a diverse set of products and solutions for our consumers. Our core products include mobile apps, self-serve kiosks, POS and delivery. We also invest in areas like AI, IoT and frictionless retail. Here we work with the “art of the possible” ideas, where we explore and develop the future of hospitality and technology.

We are looking for a Data Engineer to join our cross functional teams that is supporting one of our newest data focussed projects. This will be a great opportunity to join a truly passionate team, working on one of our most advanced-tech projects in our pipeline!

WHAT YOU'LL BE DOING:

Assemble large, complex data sets that meet functional/non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies
Create data tools for analytics and data scientist team members that assist them in building and optimizing our products
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs

WHAT YOU’LL BRING:

At least 2 years of experience in a similar role or function
Skills with: Python, SQL and Docker
AWS familiarity, Cloud Formation experience is an asset. Looking for: AWS Lambda, AWS CDK, API Gateway, Fargate

ABOUT YOU:

Strong oral and written communication skills
Excellent people and management skills to interact with colleagues, cross-functional teams and stakeholders
A go getter attitude and a passion for your work!

PlMK19YaJX","Compass Digital Labs
3.9",Mississauga
348,Digital Data Engineer,"Digital Data Engineer-MON17888

Description

BOMBARDIER

Bombardier is a global leader, creating innovative and game-changing planes. Our products and services provide world-class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. We are a global organization focused on working together with a team spirit.

In your role, you will:

Support the End to end process of designing, developing, testing and deploying data integration workflows (ingest, transformation, storage, consumption).

Support the planning and execution and secure best practice data strategies and approaches.

Collaborate with stakeholders (business analysts, data scientists, marketing, engineering, developers, architects) to develop and improve the current data architecture, data quality, monitoring and data availability schemas.

Design and building robust data ingest & transformation pipelines and solutions needed to acquire, ingest, and process data from multiple sources and systems into modern data platforms.

Support the restructuration and wrangling data into forms suitable and valuable for a variety of downstream usage including business analytics, machine/ deep learning model development, as well as in systems and applications for operational, business and commercial purposes.

Create and maintaining underlying cloud data infrastructure responsible for managing data flow from ingestion to storage, and to consumption.

Work cross-functionally with our consultants and tech leads to ensure solutions developed aligns comfortably within the organizational preferences on basis of technology and methodology.

Keep up to date with advancements in data technologies and leveraging the initiatives to improve and scale existing data architectures leading to improved Bombardier Aviation customers’ experience.

Qualifications

As our ideal candidate,

You possess a bachelor's/ Master’s degree in Computer Science, Engineering, Mathematics, or a related technical discipline.

You have a minimum of 2 to 6 years of industry experience in data engineering, software development, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.

You have experience with different ETL techniques & data modeling approaches.

You have industry experience using Java, Scala, Python, SQL, or similar for data manipulation.

You have expertise with data technologies such as S3, Parquet, Athena, Redshift, RDS, as well as with integrating with REST APIs using JSON/XML.

You possess effective interpersonal, communication and leadership skills, and have the ability to work under pressure and meet strict deadlines

You have strong analytic skills related to working with structured/unstructured datasets.

You have the ability to effectively articulate recommendations/conclusions verbally and in writing

You have an expertise in data engineering or architecture role in a company with large, complex data sources, and have experience working with AWS data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda, Athena).

You have expertise building/operating highly available, distributed systems of data extraction, ingestion, and processing of large datasets, as well as ETL, data modeling, data injection, transformation and processing.

Bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected Characteristics to apply.

Whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone.

Join us at https://bombardier.com/en/careers/career-opportunities

Your ideas move people.

Job: Project/Program Management
Primary Location: CA-QC-Montreal Dorval
Organization: Aerospace
Schedule: Full-time
Employee Status: Regular

Job Posting: 15.06.2021, 5:18:39 PM

Unposting Date: Ongoing","Bombardier
3.4",Dorval
349,Product Data Scientist,"In February 2021, Sharethrough and district m entered into a definitive merger agreement to become one of the leading modern omnichannel advertising exchanges. The combined business mission is to build a sustainable advertising ecosystem for journalists, content creators and app developers, connecting publishers and advertisers with true technological innovation supporting all ad formats, devices. and user experiences.


We’re looking for data scientists who share our passion for building data-driven products, as well as the belief data science should be tightly integrated into the engineering and product flow.


In this role, you’ll pair with your data science and product peers to explore new ways to optimize the 20 billion impressions flowing through our exchange every day. You’ll have a dedicated optimization team to implement your ideas. We believe in an experiment-driven approach that enables you to test out your ideas. While we’ve implemented some tremendously impactful optimization products already, we believe we’ve just scratched the surface.


About the Role



Analyze Sharethrough data to discover patterns, abnormalities, and increased revenue opportunities
Present findings to key leadership to influence product roadmaps
Designing and developing algorithms to track important metrics in real time to feed into ML models that power our platform
Designing and developing machine learning models that classify content, predict behavior, and forecast supply and demand equilibriums
Work closely with business leadership to integrate data into every part of the product



About You



5+ years of experience working in an analytics organization
Degree in Statistics, Computer Science, Econometrics, or similar domain
Competent performing statistical analysis using a scripting language (Python, R, Julia)
Proficient with SQL
Able to create intuitive and readable dashboards using visualization tools (Tableau, Looker, etc.)
Strong familiarity with experimental design
Comfortable pairing with product



Bonus Points



Experience or familiarity with the adtech ecosystem
Experience working closely with Product teams
Comfortable collaborating with leadership to distill down high level business goals and provide data driven recommendations
Experience with machine learning techniques and how they are applied in production systems",District M,Montreal
350,"Associate Educator, Data Scientist","BrainStation is a global leader in digital skills training and development, offering a 12-week Diploma program in Data Science. BrainStation is currently seeking a Data Science professional to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities

Lead our 12-week Data Science Diploma program

Help build a world class technical team

Deliver lectures and mentor the next wave of Data Science talent

Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses

Actively work on writing and researching new content to teach the most up to date skills in data science to our students

Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students

Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material

Define the education experience of the future

Successful candidates will have

2+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years experience as a Data Scientist or Analytics professional

Experience building and leading teams

Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles

Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner

Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job

An empathetic, friendly, and approachable demeanor

A proven ability to work under pressure and meet deadlines

About BrainStation

BrainStation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, London, Toronto, and Vancouver. Founded in 2012, BrainStation has worked with over 400 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 100,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.


Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings .
NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.",BrainStation,Vancouver
351,"Associate Educator, Data Scientist","BrainStation is a global leader in digital skills training and development, offering a 12-week Diploma program in Data Science. BrainStation is currently seeking a Data Science professional to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities

Lead our 12-week Data Science Diploma program

Help build a world class technical team

Deliver lectures and mentor the next wave of Data Science talent

Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses

Actively work on writing and researching new content to teach the most up to date skills in data science to our students

Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students

Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material

Define the education experience of the future

Successful candidates will have

2+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years experience as a Data Scientist or Analytics professional

Experience building and leading teams

Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles

Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner

Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job

An empathetic, friendly, and approachable demeanor

A proven ability to work under pressure and meet deadlines

About BrainStation

BrainStation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, London, Toronto, and Vancouver. Founded in 2012, BrainStation has worked with over 400 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 100,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.


Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings .
NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.",BrainStation,Vancouver
352,Development Engineer/Scientist,"Be part of something altogether life-changing
Working at Cytiva in the Life Sciences industry means being at the forefront of providing new solutions to transform human health. Our incredible customers undertake life-saving activities ranging from fundamental biological research to developing innovative vaccines, new medicines, and cell and gene therapies.
At Cytiva you will be able to continuously improve yourself and us – working on challenges that truly matter with people that care for each other, our customers, and their patients. With associates across 40 countries, Cytiva is a place where every day is a learning opportunity – so you can grow your career and expand your skills in the long term. Cytiva is proud to work alongside a community of nine fellow Danaher Life Sciences companies. Together, we’re pioneering the future of science and medicine, developing products that enable researchers in the fight to save lives.

What you’ll do
Project execution, as part of a diverse and multi-disciplinary team, for process optimization and technology development programs in cell and gene therapy, and regenerative medicine. This includes definition of tasks, experimental planning and execution, data analysis, documentation, standard operating procedures (SOP) preparation, reporting and preparation of technical recommendations.
Work closely with cell biologists and bioprocess engineers in the development of new cell therapy processes and product challenges in an emerging industry.
Engage external customers and partners to understand and overcome workflow challenges.
Demonstrate continuous integrity, credibility and positivity, and motivate others to do the same.
Continuously grow and adapt in a fast-moving field to keep yourself and the organization at the forefront of the cell and gene therapy and regenerative medicine fields.

Who you are
Ph.D., or Master's with 5+ years of experience with a degree in bioengineering, chemical engineering, bioprocess, biotechnology, cell biology or a related field.
Expertise in one or more of the following areas: immune cells, viral vectors, bioprocess development, pluripotent stem cells and derived progeny, hematopoietic stem cells, or mesenchymal stromal cells.
Hands-on experience working with human primary and/or stem cell cultures. Hands-on experience working with process-controlled bioreactors. Experience with cell characterization (microscopy, cell counting, flow cytometry, etc.).
Demonstrated expertise operating in a CL2 facility. Familiarity with developing protocols amenable to a cGMP environment.
Detail-oriented self-starter with excellent problem-solving, analytical skills and the ability to multitask and succeed in a team environment.
Excellent English written and oral communication with strong record-keeping and documentation skills.
Excellent proficiency with computer productivity software (e.g. O365, SharePoint, Excel, PowerPoint, Word) and a range of technical

When you join us, you’ll also be joining Danaher’s global organization, where 68,000 people wake up every day determined to help our customers win. As an associate, you’ll try new things, work hard, and advance your skills with guidance from dedicated leaders, all with the support of powerful Danaher Business System tools and the stability of a tested organization.
Danaher is committed to a diverse and inclusive culture where everyone feels they belong and all voices are heard. We believe in our associates and the unique perspectives they bring to every challenge, which is why we’ll empower you to push the boundaries of what’s possible.
If you’ve ever wondered what’s within you, there’s no better time to find out.
Danaher Corporation and all Danaher Companies are equal opportunity employers that evaluate qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender identity, or other characteristics protected by law. The “EEO is the Law” poster is available here .","Cytiva
3.8",Midtown Toronto
353,Data Engineer,"Procogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.


At Procogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.


We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.


Position Details



Our team is establishing cutting edge AI Capabilities to support drug discovery, research and development initiatives. This requires an enablement of world class Cloud infrastructure and Data Engineering technologies and practices. The candidate will join our existing Data Engineering team to build and deploy the Data solutions on gCORE platform. This platform is built on AWS Cloud with Redshift, S3, Glue, Talend, Alation along with other AI capabilities



Responsibilities



Ensuring availability, performance, security, and scalability of AWS production systems.
System troubleshooting and problem resolution across various application domains and platforms including integrations of data center systems.
Integrate AWS services with enterprise tooling that enable monitoring, alerting, and retention of critical event information.
Monitoring, triaging and responding to alerts from systems for detected operational issues.
Creation of documentation for existing automation, systems, processes and services.
Proactive team member of an agile team



Education



Bachelor/Master degree in related fields (Computer Science, Computer Engineering, Mathematical Engineering, Information Systems) or related fields (or equivalent work-related experience)



Required Skills



Experience with Data Engineering in Cloud Data Solutions (AWS preferred).

Experience with scripting, such as Python, R, or Bash.
Exquisite attention to details; the curator will be responsible for maintaining healthy datasets on which several research projects will depend.
Experience with High Performance Computing and proficiency with git.
Experience with data wrangling, pre-processing and handling of large datasets.
Experience of processing WGS, RNA-seq, ChIP-seq, ATAC-seq and/or other NGS data
Good understanding of biological concepts and biostatistical approaches commonly used in molecular biology (genetics) and interest to learn more
Excellent communication and organizational skills and ability to work in a highly interactive group.
Domain knowledge in Safety(Toxicology) and/or Epigenetics.
Nice to have skills
Experienced working with ontologies, example: UBERON, Cell Ontology and Experimental Factor Ontology (EFO).","ProCogia
4.7",Midtown Toronto
354,"Data Engineer with Backend Java Experience - Spark, AWS, SQL, Java, Linux","The US Equites Development group is responsible for the architecture, development and support of NASDAQs North American equities market systems, which includes the core trading and post-trade systems, surrounding applications, market data feeds, ticker plants, gateways, smart order routers, and monitoring suite. It is a rich and challenging environment as these systems are subject to requirements of high availability, high throughput, ultralow latency, and also have both rich and innovative functionality. Development is primarily in Java, running on a Linux-based environment.

The position demands a meticulous Java software developer with strong SQL skills and extensive object-oriented programming experience on real time, mission critical systems. The person will work on our data infrastructure team and help design, build and maintain our data pipeline and data lake solutions, as well as ETL processing, and reports generation. Prior experience with financial data handling is a plus.

Responsibilities:

Write code to implement new features and improve performance on existing systems;
Actively participate and contribute to the design process;
Enforce best practices and high code standard;
Document new features and associated test scenarios for other teams and stakeholders including the quality assurance and production support groups;
Able to analyze data to identify potential problems and troubleshoot production issues.

Must Have:

Minimum 6+ years of experience with Java programming on low latency systems;
SQL Experience 3+ years;
Experience with communication protocols;
Experience working on complex distributed information systems projects;
Experience with Linux;
Solid understanding of data types, access and manipulation, strong experience with more than 1 database - SQL SERVER/MY SQL/Cloud - AWS/Mongo DB/NoSQL, etc. - This includes proficient SQL experience user with some ETL processing background;
Strong business and data analysis skills;
Good communication skills.

Preferred:

AWS cloud experience;
Hadoop/Spark experience;
Parquet and/or Avro experience;
Strong Linux scripting skills;
Strong background in unit and performance testing techniques;
Working knowledge of a real time transactions processing platform (preferably an ATS and / or equities trading).

Nasdaq is an equal opportunity employer. We positively encourage applications from suitably qualified and eligible candidates regardless of age, color, disability, national origin, ancestry, race, religion, gender, sexual orientation, gender identity and/or expression, veteran status, genetic information or any other status protected by applicable law.","Nasdaq, Inc.
4.1",Midtown Toronto
355,"Data Engineer with Backend Java Experience - Spark, AWS, SQL, Java, Linux","The US Equites Development group is responsible for the architecture, development and support of NASDAQs North American equities market systems, which includes the core trading and post-trade systems, surrounding applications, market data feeds, ticker plants, gateways, smart order routers, and monitoring suite. It is a rich and challenging environment as these systems are subject to requirements of high availability, high throughput, ultralow latency, and also have both rich and innovative functionality. Development is primarily in Java, running on a Linux-based environment.

The position demands a meticulous Java software developer with strong SQL skills and extensive object-oriented programming experience on real time, mission critical systems. The person will work on our data infrastructure team and help design, build and maintain our data pipeline and data lake solutions, as well as ETL processing, and reports generation. Prior experience with financial data handling is a plus.

Responsibilities:

Write code to implement new features and improve performance on existing systems;
Actively participate and contribute to the design process;
Enforce best practices and high code standard;
Document new features and associated test scenarios for other teams and stakeholders including the quality assurance and production support groups;
Able to analyze data to identify potential problems and troubleshoot production issues.

Must Have:

Minimum 6+ years of experience with Java programming on low latency systems;
SQL Experience 3+ years;
Experience with communication protocols;
Experience working on complex distributed information systems projects;
Experience with Linux;
Solid understanding of data types, access and manipulation, strong experience with more than 1 database - SQL SERVER/MY SQL/Cloud - AWS/Mongo DB/NoSQL, etc. - This includes proficient SQL experience user with some ETL processing background;
Strong business and data analysis skills;
Good communication skills.

Preferred:

AWS cloud experience;
Hadoop/Spark experience;
Parquet and/or Avro experience;
Strong Linux scripting skills;
Strong background in unit and performance testing techniques;
Working knowledge of a real time transactions processing platform (preferably an ATS and / or equities trading).

Nasdaq is an equal opportunity employer. We positively encourage applications from suitably qualified and eligible candidates regardless of age, color, disability, national origin, ancestry, race, religion, gender, sexual orientation, gender identity and/or expression, veteran status, genetic information or any other status protected by applicable law.","Nasdaq, Inc.
4.1",Midtown Toronto
356,Data Engineer,"Hope you are doing well, We are urgently looking for the following role.


Looking for a Data Engineer resource for our Client Thoughtworks.


If you have the mentioned skill set, please send me resume at daninarang@smsoftconsulting.com


Duration: 6 months Contract with a possibility of extension.

Location: Canada (Remote)

Job Description:

Analyzing the method of transforming existing data into a format for the new environment and the loading of this data into other database structures.

Reviewing existing migration tools and providing recommendations for improving performance of the migration process.

Develop best practice, processes, and standards for effectively carrying out data migration activities.

Perform source system data analysis in order to manage source to target data mapping.

Perform migration and testing of static data and transaction data from one database to another.

Perform data migration audit, reconciliation, and exception reporting.

Hands on experience on Microservices and event driven architecture.

Knowledge of Perl, Python, Java and Kafka is a must.

Knowledge on RDBMS and related toolsets.

Knowledge on database systems such as PostGreSQL and MySQL.

Providing necessary change and support documentation.




629W4ZPcdk","S M Software Solutions Inc
5.0",Remote
357,"Senior Data Scientist, AWS Security- Ottawa/Toronto","BS degree and 6 years of relevant experience or MS degree and 4 years of experience
Hands-on professional experience with applying machine learning and other data science techniques to mitigate threats at scale in a production environment
2+ years of work experience in applying data science to physical security, network security, or fraud related problems
Industry experience using database languages, such as SQL, and common data science software development and statistical analysis tools (e.g., Python, R, Scikit-learn)
Demonstrated technical leadership in data science and/or machine learning (e.g., tech lead, data science leader, led analytic development effort, etc.)
Experience leading and coaching junior data scientists to improve their skills and effectiveness
Come and build innovative services that protect our cloud from security threats.

As an AWS Security Senior Data Scientist, you’ll help to build and manage services that detect and automate the mitigation of cybersecurity threats across Amazon’s infrastructure. You’ll work with security engineers, software development engineers, and other data scientists across multiple teams to develop innovative security solutions at massive scale. Our services protect the AWS cloud for all customers and preserves our customers’ trust in us. You’ll get to use the full power and breadth of AWS technologies to build services that proactively protect every single AWS customer, both internally and externally, from security threats – not many teams can say that!

Mentorship & Career Growth

Our team is dedicated to supporting new team members. The team has a mix of experience levels, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior engineers, data scientists, and managers truly enjoy mentoring junior engineers, junior data scientists, and engineers from non-traditional backgrounds through one-on-one mentoring and thorough, but kind, code reviews.

We care about your career growth. We assign projects and tasks based on what will help team members develop into a more well-rounded data scientist and enable them to take on more complex tasks in the future.

Inclusive and Diverse Culture

Our team is intentional about attracting, developing, and retaining amazing talent from diverse backgrounds. Yes, we do get to build a cool service, but we also believe a big reason for that is the inclusive and welcoming culture we cultivate every day.

We’re looking for a new teammate who is enthusiastic, empathetic, curious, motivated, reliable, and able to work effectively with a diverse team of peers. We want someone who will help us amplify the positive & inclusive team culture we’ve been building.

Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance

Our team values work life balance. We are passionate about the capabilities we build, and we are responsible for our on-call rotation to ensure our services bring value to our customers. We understand that life is challenging and we have a flexible work environment that enables individuals to adjust their work schedule to accommodate personal needs.


MS or PhD in a STEM field
Experience extracting large sets of data, and designing ETL flows
Experience designing and deploying large scale analytic processing solutions using Spark, Scala, etc.
Strong sense of ownership combined with collaborative approach to overcoming challenges and influencing organizational change
Meets/exceeds Amazon’s leadership principles requirements for this role
Meets/exceeds Amazon’s functional/technical depth and complexity for this role
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us","Amazon Dev Centre Canada ULC
3.8",Ottawa
358,Data Scientist – Automated Market Making Team,"Data Scientist – Automated Market Making Team

Job Number:

3169214

POSTING DATE: May 31, 2021
PRIMARY LOCATION: Americas-Canada-Quebec-Montreal
JOB: Investment Banking/Sales/Trading/Research
EMPLOYMENT TYPE: Full Time
JOB LEVEL: Associate

DESCRIPTION

We offer:


- To work with some of the best professionals in the business - for a firm that values individual intellect as much as teamwork

State-of-the-art offices that are designed to maximize collaboration
Flexible working arrangements
Enriching challenges that provide opportunity for constant learning and advancement
An environment which is leveraging technology to its highest potential



Team Profile:


The Institutional Equity Division (IED) is a global leader in the origination, distribution and trading of cash and derivative products. The Firm’s Automated Market Making (AMM) group provides liquidity for options in automated markets worldwide. The AMM Team consists of quantitative traders, strategists, analysts, software developers, hardware developers, infrastructure and networking specialists, and data architects all collaborating to build and expand a cutting-edge system that trades over 1,000,000 securities on 2,500 underliers across 16 options exchanges. The desk operates at the intersection of finance and technology, and many of the models and system designs used to drive the engine sit on the forefront of innovation.


Position Description:


We are looking for truly exceptional talent to join the Automated Market Making team (AMM). AMM is one of the industry leading on-screen market makers for equity options globally.


AMM is made up of software and hardware developers, traders, data scientists and quantitative strategist. Together we train a system to make markets across 14 exchanges in the US and 2 in Europe. The system automatically prices, quotes, hedges, and risk manages the position.


The data scientist will:


Create innovative solutions to model various aspects of the electronic options market making, such as risk management, volatility fitting, microstructure analysis, and algorithmic trading
Analyze terabytes of equity and options market data to derive actionable intelligence to improve trading performance
Develop reporting, analytics, and visualization tools
Work together with other strategists, traders, and technology



ORGANIZATION

Skills Required:


Bachelor’s with 3+ years of experience or advanced degree in a related field
Prior programming experience in a scripting language such as Python/R
Interest in quantitative work and data analytics
Excellent communication skills and ability to interact with traders and technology


Nice to have:


Previous experience in machine learning/modeling is a plus
Strong programming skills in kdb+/Q
Knowledge of C++



About us:


Morgan Stanley is a global financial services firm and a market leader in investment banking, securities, investment management and wealth management services. At Morgan Stanley Montreal, we are shaping the future of our global business and contributing to our local community. Our team works across numerous areas.


Morgan Stanley is an equal opportunities employer. We work to provide a supportive and inclusive environment where all individuals can maximise their full potential. Our skilled and creative workforce is comprised of individuals drawn from a broad cross section of the global communities in which we operate and who reflect a variety of backgrounds, talents, perspectives and experiences. Our strong commitment to a culture of inclusion is evident through our constant focus on recruiting, developing and advancing individuals based on their skills and talents.


Knowledge of French and English is required.


Spotlight on our Montreal Technology Centre: https://www.youtube.com/watch?v=oo5GaXpCwKs

Video dated October 2019.


Build a career with impact. Visit morganstanley.com for more information.","Morgan Stanley
4.0",Montreal
359,Senior Data Scientist,"At Interac, we design products and solutions that give Canadians control over their money so they can get more out of life. But that’s not all.

Whether we’re leading real-time money movement, driving innovative e-commerce or commerce solutions like open payments for transit systems, or making advancements in payments fraud detection and new areas like digital identity and open banking, we are playing a key role in shaping the future of the digital economy in Canada.

Want to make a lasting impact amongst a community of creative thinkers, problem solvers, technical gurus and innovators? We want to hear from you.

Interac is on a fast growth path in a very demanding and rapidly changing payments ecosystem - and so is the evolution of our Data Analytics team. Our data scientists analyze billions of transactions and signals from across our ecosystem, leveraging advances in machine learning and cloud-based technologies to detect emerging threats and respond with solutions that augment our real-time decisioning and mitigate fraud. Through collaboration with teams across data science, BI, data engineering and architecture, data governance, technology and business groups, we deliver world-class analytical products that democratize data, advance learning, prevent financial crimes and accelerate sustainable growth for Interac.

Senior Data Scientist

The Senior Data Scientist will be responsible for providing actionable insights for the business primarily for Fraud management and Financial Crimes practice and be the liaison/relationship management lead for the Fraud/Financial Crimes Analytics function. Research and analytics related to fraud management will focus on working with the Fraud Mitigation & Strategy team to provide actionable insights into rule-based fraud detection, feature development, and statistical analysis of new and existing fraud trends. The Data Scientist will work with the fraud teams to provide deliverables including research insights, data assets, and visualizations to help the end-user develop a better understanding of the topic.


The Senior Data Scientist has effective Consulting, Product Management & Relationship Management skills to work alongside cross-functional teams including product, innovation, fraud strategy etc. to identify, design, develop, execute, and maintain new enterprise grade data analytics product offerings aligned to Interac’s growth as well as Fraud strategy. They may be required to facilitate business requirements, design sessions with large group of participants.


You’re great at…

Managing challenging and fraud/financial crimes-based initiatives or research using advanced machine learning methods focusing on tangible outcomes of fraud detection and prevention.
Gathering and using business insights to direct root cause analysis of critical operational issues.
Collaborating proactively with various business units, product owners to identify business opportunities and designing innovative analytical solutions to optimize processes, promote informed decision-making
Producing data-driven insights and business recommendations to help in informed decisions and actions by telling a convincing story and effectively communicate findings to business partners and executives

Leading research work related to Machine Learning, computational statistics, analytics practices/techniques as it relates to improving our data-driven Financial Crimes/Fraud detection and protection capabilities

Forming key relationships with the Fraud Strategy team to streamline data analytics delivery.
Developing subject matter expert of Interac products and processes.
Understanding of connection and interaction between production systems, processes and data
Playing a key role in driving corporate priorities and play critical role developing capabilities for market launches of new product offerings .
Quickly learning and adopting new methods, tools and technologies presented in research communities to implement and adapt within the daily analytics exercises.
Working with large complex data sets to solve difficult, non-routine analysis problems applying advanced analytical methods as needed.
Conducting end-to-end analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables and presentations.
Developing, consulting on, deploying and analyzing testing strategies to leverage learnings for future business endeavors.
Preparing detailed documentation to transfer knowledge and satisfy governance and regulatory concerns.
Recommending data modeling and design standards, tools, best practices, and related development for enterprise data models
Working extensively with end-users to create plan on how to approach a given problem


Who are you?

You have a degree in Business, Mathematics, Computer Science or equivalent combination of education and industry experience.
You have 3-5 years or more of experience in Data Science
You have 3 years or more of experience using Machine Learning
You have 3+ years experience developing comprehensive business cases for data analytics capabilities, strategies, KPI's
You are able to understand complex issues and dissect, digest, then generate a data product to help address issues
You have sound familiarity with Product Management, Design Thinking concepts
You have experience with Python, Oracle, Cloudera, PySpark, Jupyter, Github, AWS, Redshift
5 or more years of experience in the Financial industry is an asset
Prior Consulting experience is preferred
Financial crimes or fraud analytics/data Science experience is an asset
You have significant experience working with implementing concepts, such as predictive modeling, profiling, segmentation forecasting, operations research and data mining.
You have mathematics, algorithms, and leadership skills,
You have excellent oral/written and presentation skills.
You have strong Data Storytelling skills
You have strong relationship management and facilitation skills
You have expert knowledge of Data Mining, Databases, SQL, Machine learning
You have experience with the following technologies/databases: Oracle, HDFS, Hive, Redshift, Spark (PySpark), ETL Tools (Talend), BI Tools (Tableau), Python
You have strong knowledge of Canadian Payment Industry, payments transaction data and process flows.
You have knowledge of IT processes and infrastructure required to support analytics.
You have experience in developing data analytics strategy

How we work...
We know that exceptional people have great ideas and are passionate about their work. Our culture encourages excellence and actively rewards contributions with:


Connection:


You’re surrounded by talented people every day who are driven by their passion of a common goal.


Core Values:


They define us. Living them helps us be the best at what we do.


Compensation
& Benefits:


Pay is driven by individual and corporate performance and we provide a multitude of benefits and perks.


Education:


To ensure you are the best at what you do we invest in you.


About Interac

Interac Corp. operates an economical, world-class debit payments system with broad-based acceptance, reliability, security, and efficiency. The organization is one of Canada's leading payments brands and is chosen an average of 16 million times daily to pay and exchange money. For more than 30 years, Interac Corp. and its predecessors, Interac Association and Acxsys Corporation, have facilitated secure financial transactions through the development of innovative and convenient debit and money transfer solutions. A leader in the prevention and detection of fraud, the organization has one of the lowest rates of fraud globally. Visit interac.ca or follow @INTERAC on Twitter. Interac Corp. has a diverse group of shareholders that includes banks, credit unions, caisses populaires, payment processors and merchants.


Interac Corp. believes in providing an inclusive workplace where all individuals have the opportunity to succeed. We are committed to doing so by providing accessible employment practices. Contact a member of the Human Resources department if you need accommodation at any point in the application process or want more information about our Accessibility Policy, which is also available online here.




cJXLm5vn6Y","Interac
4.9",Midtown Toronto
360,Specialist - Data Development / Big data,"At CN, we work together to move our company—and North America—forward. Be part of our Information & Technology (I&T) team, a critical piece of the engine that keeps us in motion. From enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value-added tasks. You will be able to develop your skills and career in our close-knit, safety-focused culture working together as ONE TEAM. The careers we offer are meaningful because the work we do matters. Join us!




We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of huge sets of data. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.




RESPONSIBILITIES

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Extraction, transformation, and loading of data from a wide variety of data sources using SQL and Hadoop technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across the data lake to adhere to industry and regulatory requirements
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Report progress status and issues.
Apply, and ensure compliance with, all appropriate CN IT standards (e.g. Code quality, Security, Architecture, Project Delivery Methodology, SOX, etc.)



REQUIREMENTS

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (ADX)
Experience building and optimizing hadoop data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong organizational skills and can work autonomously to provide data solutions
Experience supporting and working with cross-functional teams in a fast paced environment.
10+ years of experience in a Data Engineer role, graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Should also have experience using the following software/tools:
Experience with big data tools: ADX, Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.



ASSETS




Experience in Development Practices and proven methodologies (Agile, Iterative, Waterfall)
Experience with Cloudera/MapR/Hortonworks Hadoop distributions with a preference on Hortonworks
Hortonworks certification is a definite asset
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB is an asset
Experience with Spark is a asset



About CN

As a leading North American transportation and logistics company, CN is a true backbone of the economy. With a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. We transport US$200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000-mile network spanning Canada and mid-America. CN is the only Canadian company listed in the Transportation and Transportation Infrastructure sector of the Dow Jones Sustainability World Index (DJSI). Launched in 1999, the DJSI World represents the gold standard for corporate sustainability. At CN, we work as ONE TEAM, focused on safety, sustainability and our customers, providing operational and supply chain excellence to deliver results.


CN is an employment equity employer and we encourage all qualified candidates to apply. We thank all applicants for their interest, however, only candidates under consideration will be contacted. Please monitor your email on a regular basis, as communication is primarily made through email.","Canadian National Railway
3.3",Midtown Toronto
361,Primary Care COVID Impact Data Analyst,"Date Posted: 06/18/2021
Req ID: 4913
Faculty/Division: Temerty Faculty of Medicine
Department: Department of Family & Community Medicine
Campus: St. George (Downtown Toronto)


Description:

About us:

Home to over 40 departments and institutes, the University of Toronto's Temerty Faculty of Medicine lies at the heart of the Toronto Academic Health Science Network and is a global leader in ground-breaking research and education, spanning clinical medicine, basic science and the rehabilitation sciences sectors.

Your opportunity:

UTOPIAN is a network that brings together Department of Family and Community Medicine (DFCM) researchers, primary care clinicians and practices from all its academic sites to answer important healthcare questions and translate findings into practice.

As the Primary Care COVID Impact Data Analyst, you will play an integral role in the UTOPIAN team, which is made of data specialists and primary care physicians. You will contribute by selecting methods of analysis for research projects, developing data set creation plans, conducting data analysis using both quantitative and qualitative methods, preparing reports for a variety of audiences, and working with the DSH team to improve data processing and cleaning methods. Drawing on a knowledge of clinical epidemiology best practices, along with your solid collaborative, organizational, analytical and critical thinking skills will be key to your success in this role.

Your responsibilities will include:


Assessing needs, and analysis for research projects, and contributing to the planningof research goals
Developing project schedules including milestones, critical path, timelines, deliverables and reporting
Scheduling day-to-day project activities along with supervising the activities of research assistants, analysts, UTOPIAN scientists and other investigators
Implementing and executing primarily quantitative but possibly also qualitative research methods including conducting systematic literature reviews
Synthesizing technical, quantitative and contextualresearch data as well as preparing draft statistical reports and summaries
Planning and estimating financial resources required for programs and/or projects


Essential Qualifications:


Master's Degree in health services research, clinical epidemiology or related field or equivalent combination of education and experience
Minimum five years of relevant and related experience
Experience working with researchers and research teams.
Experience working with a variety of data sources.
Experience writing and contributing to proposals and publications and delivering presentations to large audiences.
Knowledge of ethical aspects of research, data security and privacy.
Knowledge and expertise in the principles and methods of clinical epidemiology.
Strong applied knowledge of statistical techniques such as tests of significance, regression analysis, categorical data analysis, and analysis of variance is required.
Strong SAS and VBA programming is required. Familiarity with SPSS, R, STATA, or other statistical software is an asset.
Extensive computer skills in word-processing (MS Word), database management (Excel or Access); Internet, and presentation packages (Power Point).
Strong verbal and written communication skills are required.
Ability to balance multiple priorities and simultaneously working with on several projects.
Strong interpersonal skills with the ability to establish positive working relationship with research scholars and colleagues.
Self-motivated, team player with strong organizational skills.
Demonstrated ability to effectively interact with all levels of faculty, staff, researchers, clinicians, healthcare professionals and other collaborators.
Tact, initiative, good judgment and patience.
Ability to handle matters of a sensitive and confidential nature.


Assets (Nonessential):


Experience with EMR data and/or administrative data is an asset
Ph.D is an asset


To be successful in this role you will be:


Accountable
Communicator
Multi-tasker
Organized
Team player


This is a one year term position

Closing Date: 06/28/2021, 11:59PM ET
Employee Group: USW
Appointment Type: Grant - Term
Schedule: Full-Time
Pay Scale Group & Hiring Zone:
USW Pay Band 13 - $74,781 with an annual step progression to a maximum of $95,634. Pay scale and job class assignment is subject to determination pursuant to the Job Evaluation/Pay Equity Maintenance Protocol.
Job Category: Research Administration & Teaching
Recruiter: Aarthiga Sivakumar","University of Toronto
4.3",Midtown Toronto
362,Data Analyst - Data Products (15 Month Contract),"Join Unbounce and help the world experience better marketing. We’re a people first, customer obsessed company focused on helping employees do their best work. Our landing page and conversion platform empowers digital marketing teams and agencies to launch campaigns, increase conversions and get significantly better ROI on their marketing spend in a way that nobody else does today.


We’re looking for a Data Analyst to join our growing efforts to deliver actionable insights and deep analysis findings to our current and future customers. You’ll be part of the Data Products team, working with our Data Scientists, Machine Learning Developers and UX Designers to mine our datasets for insights, and work with teams such as Marketing and Engineering to deliver those insights to the market and our customers.


What you’ll be Doing:

Pro-actively mine and perform statistical analyses on our varied datasets to find actionable and valuable insights
Work with multiple teams to ideate and deliver market facing content, utilities and customer facing features
Act as the bridge and advocate between Data Products and the market facing teams
Work as an integral part of our ‘Data Analyst Chapter’ and Data Organization by contributing to the overall data ecosystem and improving data literacy throughout Unbounce


A Little Bit about You:

2 or more years experience as a technical Data Analyst with a proven track record of generating understandable and actionable insights from the data
Programming with Python and the associated data analysis packages (e.g. pandas, numpy, scipy)
Fluent and experienced with SQL
You are comfortable working independently and finding the place to make the most impact
You excel at translating data findings into insights for non-technical stakeholders
Agile development, version control, and code review processes


What’s in it for you:

A remote friendly office with flexible hours - for this role we will consider all applications from those based in Canada with the option to work from our Vancouver office
4 weeks vacation plus Christmas Holiday Closure - you're entitled to the week of Christmas off with pay through to and including Jan 1st
Vacation bonus - $1,000.00
12 Personal Wellness Days (This includes: Personal day, Moving day, Sick day, etc)
Health and Wellness budget - $500.00
Networking budget - $500.00
A paid day off for your birthday
One paid Volunteer day per year
One day every 2 weeks of dedicated professional development time


Unbounce Welcomes Everyone to Apply

At Unbounce we celebrate everyone and their multiple intersecting identities. We believe a panorama of experience allows us to make better decisions together and inspires innovation so that we can better serve our customers and community. Our goal is for every Unbouncer to feel deeply connected to their team through mutual value, respect, and understanding.


Please let us know if you require any accommodations or support during the recruitment process.




ifJjHKNIGx","Unbounce
3.8",Vancouver
363,Senior Data Scientist ML & NLP expert,"Senior Data Scientist ML & NLP expert-32711
Profession
Solution Development
Work Location
Americas-Canada-Montreal
Schedule
Full-time


Description


As a Sr Data Scientist NLP & ML Expert, you will be working in a fast-paced environment which needs a mindset of a startup and an entrepreneur that is not hesitant to constantly shift gears, test and learn.
You will be part of the company Center of Excellence (CoE) in Data Science & AI and you will be working with stakeholders by Agile and Design Thinking Methodologies, innovating and improving ATI industry with Data Science AI Technology. Together with the CoE you will deliver everything from state-of-the-art solutions to quicker value proving solutions

What you will do:

Build and implement advanced machine learning models for flight Arrival and Departure Prediction
Research, develop and evaluate advanced text speech processing algorithms and implementations.
Research, develop and evaluate advanced ATI Messaging processing algorithms and implementations.
Utilize Machine Learning (ML) technology for speech processing and air transport messages processing
Prototype and develop algorithms and advanced machine learning techniques for applications such as speech modeling, QAR data modelling rendering, speech recognition, blind source separation, and speaker ID.
Stay up to date with tech, prototype with and learn new technologies, proactive in technology communities
Learn from peers in data science and engineering community
Deliver on time with a high bar on quality of research, innovation and engineering
Create Advanced OCR and Cognitive Data Extraction capability as well as its execution
Responsible for Cognitive extraction, technology delivery and operating model setup
Develop innovative solutions in areas such as machine learning, computational linguistics, Natural Language Processing (NLP), advanced and semantic information search, extraction, induction, classification and exploration
Develop & maintain Client & NLP Pipeline for Document Data Extraction semantics and sentiment processing and understanding
Create products that provide a great user experience along with high performance, security, quality, and stability


Qualifications

Who you are:

Master’s or PhD degree in STEM or AI/ML areas
5+ years of professional experience as a data scientist or related roles
3+ years of work experience in voice related projects and 3+ years of work experience in software development
Experience in setting up supervised & unsupervised learning Client/NLP models including data cleaning, data analytics, feature creation, model selection & ensemble methods, performance metrics & visualization
Knowledge in signal processing techniques including adaptive filtering, filter banks and wavelet processing, speech analysis and synthesis, speech and audio coding.
Experience in text classification topic mining speech enhancement and speech/audio coding and compression.
String experience in prediction using Machine Learning and Deep Learning
Hand on experience in feature extraction techniques (GMM, HMM, NMF / spectrograms, MFCC etc) for voice recognition and audio event classification.
4+ years of work experience with at least one of the following languages: Python, Java, and R, Ph. D. preferred
3+ years of experience working in Agile team environment
Hand on experience with machine learning techniques such as deep neural nets (DNN, CNN, LSTM-RNN)
Published research on signal processing NLP , NLU or machine learning related to voice technology or messaging
Experience working in a cloud environment (AWS, Azure, GCP) or a containerized environment (Mesos, Kubernetes)
Good understanding of the complexity of developing and productizing real-world AI/ML applications such as prediction, recommendation, computer vision, bots, NLP, sentiment, knowledge and content intelligence, etc.
Knowledge of Text Analytics with a strong understanding of Client & NLP algorithms and models (GLMs, SVM, PCA, NB, Clustering, DTs) and their underlying computational and probabilistic statistics
Deep knowledge of some of the popular ML frameworks such as TensorFlow, Pytorch Keras, SparkML, scikit-learn, XGBoost, H2O etc
Designing and documenting data architecture at multiple levels (high-level to detailed) and across multiple views (conceptual, logical, physical, data flow and sequence diagrams)
Providing active hands-on architectural guidance and leadership through the entire lifecycle of development projects
Ability to translate business requirements into conceptual and detailed system architecture and technology solutions
Ability to develop and lead proof-of-concepts, deliver practical, working solutions
Experience in building modern Machine Learning platforms a big plus
Being a committer or a contributor to an open source project is a plus
Design, implement and deploy scalable, distributed solutions to support real-time NLP data analytic platform using modern engineering principles and techniques
At least 4 years' experience building Machine Learning & NLP solutions over open source platforms such as SciKit-Learn,Tensorflow, SparkML, Torch, Caffe, H2O
Excellent knowledge and demonstrable experience in using open source NLP packages such as NLTK, Word2Vec, SpaCy, Gensim, Standford CoreNLP.
At least 2 years' experience in designing and developing enterprise-scale NLP solutions in one or more of: Named Entity Recognition, Document Classification, Document Summarization, Topic Modelling, Dialog Systems, Sentiment Analysis, OCR text processing

What we offer
SITA’s workplace is all about diversity: many different countries and cultures are represented in our workforce, and colleagues who’ve been working here for decades collaborate with those just out of college and early in their careers. SITA is a place of change and constant improvement, where we're always pushing ourselves to find better ways of doing things: smarter, quicker, easier, for us and our customers and for their customers too.
And we offer all the good stuff you’d expect like holidays, bonuses, flexible benefits, medical policy, pension plan and access to world-class learning.

Welcome to SITA
SITA is the world’s leading specialist in air transport communications and information technology. We don’t just connect the global aviation industry. We apply decades of experience and expertise to address almost every core business, operational, baggage, and passenger process in air transport.
We design, build and support technology solutions all with one vision to create easy air travel every step of the way. As an organization, we cover 95% of all international air travel destinations and work with over 2,800 air transport and government customers in every corner of the globe. Are you ready to explore the opportunities?

SITA is an Employment Equity Employer and values a diverse workforce. In support of our Employment Equity Program, women, Aboriginal people, members of visible minorities, and/or persons with disabilities are encouraged to apply and self-identify in the application process.

#LI-SITA-JG2


Job Posting
Mar 12, 2021, 3:11:50 PM","SITA
3.9",Montreal
364,"Senior Data Scientist, Artificial Intelligence Research","In a world of disruption and increasingly complex business challenges, our professionals bring truth into focus with the Kroll Lens. Our sharp analytical skills, paired with the latest technology, allow us to give our clients clarity—not just answers—in all areas of business.

We embrace diverse backgrounds and global perspectives, and we cultivate diversity by respecting, including, and valuing one another. As part of One team, One Kroll, you’ll contribute to a supportive and collaborative work environment that empowers you to excel.

Kroll is building an artificial intelligence and machine learning group, and we’re looking for you to join our portfolio of AI projects. You will be critical in achieving our vision and strategy for solving complex business problems with cutting-edge solutions driven by the latest advancements in artificial intelligence and machine learning. Some of our current projects focus on NLP and machine learning for cyber security and due diligence, quantitative analysis and we are actively scaling up across multiple other lines of business.

At Kroll, your work will help deliver clarity to our clients’ most complex governance, risk, and transparency challenges. Apply now to join One team, One Kroll.

RESPONSIBILITIES:

Research, explore, implement, and evaluate new machine learning models
Implement and compare existing cutting-edge research works to solve business problems
Test the model performance with business use cases
Build prototype models
Publish research papers
Produce open-source software and packages
Present AI solutions to the business sponsors

REQUIREMENTS:

PhD degree in machine learning or related field or PhD Student
Research experience
Python experience is preferred
Technical and business communication in English
Team and technical leadership



In order to be considered for a position, you must formally apply via careers.kroll.com.

Kroll is committed to equal opportunity and diversity, and recruits people based on merit.","SITA
3.9",Midtown Toronto
365,"Senior Data Scientist, Artificial Intelligence Research","In a world of disruption and increasingly complex business challenges, our professionals bring truth into focus with the Kroll Lens. Our sharp analytical skills, paired with the latest technology, allow us to give our clients clarity—not just answers—in all areas of business.

We embrace diverse backgrounds and global perspectives, and we cultivate diversity by respecting, including, and valuing one another. As part of One team, One Kroll, you’ll contribute to a supportive and collaborative work environment that empowers you to excel.

Kroll is building an artificial intelligence and machine learning group, and we’re looking for you to join our portfolio of AI projects. You will be critical in achieving our vision and strategy for solving complex business problems with cutting-edge solutions driven by the latest advancements in artificial intelligence and machine learning. Some of our current projects focus on NLP and machine learning for cyber security and due diligence, quantitative analysis and we are actively scaling up across multiple other lines of business.

At Kroll, your work will help deliver clarity to our clients’ most complex governance, risk, and transparency challenges. Apply now to join One team, One Kroll.

RESPONSIBILITIES:

Research, explore, implement, and evaluate new machine learning models
Implement and compare existing cutting-edge research works to solve business problems
Test the model performance with business use cases
Build prototype models
Publish research papers
Produce open-source software and packages
Present AI solutions to the business sponsors

REQUIREMENTS:

PhD degree in machine learning or related field or PhD Student
Research experience
Python experience is preferred
Technical and business communication in English
Team and technical leadership



In order to be considered for a position, you must formally apply via careers.kroll.com.

Kroll is committed to equal opportunity and diversity, and recruits people based on merit.","Kroll
3.6",Midtown Toronto
366,Intermediate Engineer/Scientist – Quality Assurance Operations (Software),"Adecco is currently hiring for an Intermediate Engineer/Scientist-Quality Assurance Operations (Software) for our Medical Manufacturing client in Ottawa West. This is a 2 year contract opportunity offering full time hours, Monday – Friday. The salary for this position will be determined based on education and experience.

Our client is a diversified health care innovator with a legacy of pioneering work in medical diagnostics and devices. They are dedicated to advancing innovative with-patient diagnostic technology to improve patient care and system efficiency by fundamentally changing the way health care professionals process patients through their system.

We are seeking an energetic and driven Intermediate Engineer who will play a key role on the quality operations team supporting validations, verifications and security assessments pertaining to non-product software. The successful candidate must have strong attention to detail, excellent communication skills and strong organization skills and ability to follow the quality management system and ensure that protocols and reports meet the intended requirements of the quality management system.

Responsibilities:

Review protocols and reports pertaining to clinical software changes and updates
Follow the software validation and verification protocols as outlined in the quality management system
Assess work completed against the software validation and verification requirements and ensure that gaps are identified and addressed
Participate in defining, identifying, and classifying critical information assets, assess threats and gaps regarding those assets and implement safeguard recommendations
Perform threat management, threat modelling, identify threat vectors, and develop use cases for security monitoring
Coordinate the planning and execution of cybersecurity deliverables with cross-functional teams
Assess quality documentation protocols and reports as required
Author quality documents (protocols and reports)
Provide feedback on operational and procedural documentation with regards to cybersecurity
Independently execute assigned tasks
Attend cross-functional team meetings to share information
Keep up-to-date with the latest technical developments in related areas, assess and integrate appropriate changes to work practices

Requirements:

Minimum 1-3 years in a scientific or engineering role.
Bachelor’s Degree in Computer Science, Information Technology, or Engineering with software or other scientific focus, or equivalent
Strong working knowledge of software validation requirements and the software lifecycle
Strong working knowledge of data analysis and data mining techniques (SAS JMP or Minitab experience an asset)
Knowledge of cybersecurity tools, technologies and methods
Ability to assess system vulnerabilities and recommend protective measures
Familiarity with security frameworks (e.g. NIST) and risk management methodologies is an asset
Some understanding of networking principles including TCP/IP, WANs, LANs is an asset
Demonstrated initiative and problem-solving skills; critical thinking skills
Analytical skills, creativity and innovative approach to problem solving
Ability to collaborate effectively with multidisciplinary team members and also to work independently
Willingness to work in labs, manufacturing areas, and office environments
Very strong investigational skills, drive to understand and solve problems
Propensity to continuous learning and experimentation.

To be considered for the Intermediate Engineer/ Scientist-Quality Assurance Operations (Software) position, please click on Apply!

AP1956

#A1956","Adecco
3.7",Ottawa
367,Data Engineer,"Description
Hey there, we’re Article. We’re a digital-first furniture brand that’s working to make everyday living better by providing an easy way for people to furnish their space. We don’t have brick-and-mortar stores, so we’re able to deliver better value on beautiful, modern furniture. We've ranked as one of Canada’s Fastest-Growing Companies for the last three years, we’re on the hunt for talented, enthusiastic team members who want to solve meaningful problems, in pursuit of being remarkably better for our customers.

We’re looking for a Data Engineer who will help us design, build, and maintain the data foundation that powers our Data Warehouse. You’ll be responsible for building scalable data pipelines infrastructure to deliver data to Analytics Engineers and Data Scientists as well as supporting the development of tools for delivery of transformed data to the data analysis and data science teams and other stakeholders.

This role can be remote-based anywhere in Canada.

What you'll be doing
You’ll also build instrumentation for end-to-end data observability to ensure accurate, timely and high-quality data.
You’ll be collaborating with cross-functional engineering teams to create and utilize shared standards to reduce waste.
You will be responsible for any data projects driven either by new systems being added, updated or by a new way of delivering large data files etc.
You will have significant responsibility and influence in shaping the Article Data Engineering team’s future direction.
This role reports into Software Engineering Manager and is part of a cross-functional Technology department.




Skills Knowledge and Expertise
Proficiency in Python programming language and SQL for data processing.
Experience working with large data sets - both SQL and NoSQL databases (e.g. MySQL, PostgreSQL, DynamoDB, etc.) in Linux environment
Strong fundamental data integration background working in multiple development environments
Experience building ETLs and data pipelines using tools such as Apache Airflow and PySpark
Experience with Amazon Web Services - RDS, EC2, S3, Lambda, Amazon Redshift.
Experience integrating with real time data feeds using Apache Kafka
Demonstrated ETL/data programming skills (using scripts or products like Informatica, DataStage)
Experience with DevOps practices, CI/CD, managing production deployments, Git and GitHub
Awareness of security, performance, high-availability and fault-tolerance and best practices
Ability to communicate design, concepts and decisions both verbally and in writing

Nice to have skills:
Retail Domain Experience
Experience with virtualization, containers, and orchestration (Docker, Kubernetes)
Knowledge of data visualization and reporting tools like Tableau
AWS EMR, AWS DMS, Talend, Apache Airflow, Stitch
Atlassian Bitbucket, JIRA, Confluence
Education and Experience:
Bachelor of Computer Science or a similar technical degree
3+ years of Data Engineering experience




Benefits
At Article, we believe in an “Ownership Mindset” where you’ll be given autonomy and the ability to own your work. Beyond a competitive salary:

We reward that ownership mindset, so we offer stock options after one year of employment
With our fast growth, we have a culture of curiosity, where learning happens on the fly — and while having a lot of fun
Access to dental and health benefits package plus a health/lifestyle spending account for your total physical and mental well-being
45% discount on our products so you can experience first-hand why our customers love Article
Your choice of state-of-the-art laptops with the tech and tools to easily collaborate

Most HQ employees are working from home due to COVID-19. When it’s safe to return to the office, we have flexible solutions if you want to be in the office a lot, sometimes, or not at all.

When our office is safe to reopen, you’ll love that:
The Article HQ is a converted warehouse with in-house photo studios, an airy open layout, an open kitchen filled with snacks, premium coffees and teas (and ALL the milks).
A dog-friendly office. We love our dog friends here at Article. If you have a well-behaved, well-socialized pup, we’d love to have them in the office too.
Onsite fitness equipment, change rooms (including towel service!) and bike storage
Regular extra-curricular activities, such as socials, open-mics, picnics... even cross-country skiing! For now, we've replaced them with creative virtual events for the time being - like virtual trivia night or a cooking class through Zoom!
Ready to become a Particle? Apply today. We're excited to meet you




Article is the easiest way to create a beautiful modern space.

Article started from a desire to improve efficiency and make furniture less expensive for everyone. In 2014 we had 4 employees; now we have over 700 and have been growing at about 50% yearly.

Our office and warehouse space has grown from under 15,000 sq ft to over 1,200,000 sq ft, and our yearly revenue has grown to match.

Our head office is based in Vancouver, Canada, an office in Ho Chi Minh City, and warehouses in Seattle, Los Angeles, San Francisco, Jacksonville, Austin, Dallas, Portland, Houston, Denver, Baltimore, Toronto, Boston, and New Jersey.","Article
4.2",Vancouver
368,Market Data Engineer,"What is the opportunity?

This is a MDOE position – FTE. To provide solution and support for Market Data and Messaging Middleware platforms for RBC business users and applications globally. Contribute to the global technical strategies and engineering of those platforms. Liaison between developers, technology staff and management to ensure high quality requirements and engineering of Market Data and messaging platforms.


What will you do?

Provide services on all areas of Market Data technology –architecture, engineering, implementation and support.
Partner with application development team to ensure that market data/Messaging dependency risk are minimized and that needs are fully understood and met.
Participation from stakeholders beyond just the development and operation teams.
Responsible for the operational support of Market Data Monitoring systems. This includes assessment and communication of outages and incidents to the correct audience
Partner with ITRS monitoring team to ensure monitoring requirements are fully understood and met.
Ensure documentation on all systems in use for production and disaster recovery and regulatory purposes.
Ensure production problems, bugs, system problems/changes are documented and requests are acted upon promptly. Keep Senior Management advised of situations that may compromise agreed deliverables and/or affect production systems
Provide on-call support for global clients, rotating amongst all global engineers


What do you need to succeed?

Must Have

Hands on knowledge of Symphony, Reuters TREP, Bloomberg BPIPE, DACS, Tibco RV, Solace, Kafka, and/or other low latency Direct Exchange feed handlers and distribution platforms.
Programming knowledge and shell scripting
Programming with Messaging ChatBot
Understanding of Market Data concepts: Datafeeds, stock exchanges, Market Data and messaging middleware/distribution, IDBs and vendor reporting requirements


Nice to Have

Experience of underlying networking and server technologies used in low latency infrastructures (10/40/100GbE, Linux, TCP/UDP Offloading cards, etc.)
Unix/Linux, Windows, Android, iOS, Database
Knowledge of Exchange Datafeeds provided by the main North American Equity markets (NYSE, Nasdaq, BATS, DirectEdge, CME etc.) and the technologies used to deliver those feeds in both client and co-located facilities.
Experience with data visualization tools (e.g. Tableau and/or Grafana).


What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.


A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Ability to make a difference and lasting impact
Work in a dynamic, collaborative, progressive, and high-performing team
A world-class training program in financial services
Flexible work/life balance options
Opportunities to do challenging work
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with clients
Access to a variety of job opportunities across business and geographies
The successful candidate will need to establish and maintain productive working relationships with Advisors and individuals at all levels, both internally and externally.


Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com.

JOB SUMMARY
City: Toronto
Address: 155 Wellington St West
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel (%): 0
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 06/23/2021
Platform: Capital Markets
Req ID: 374136
Ad Code(s):","RBC
4.1",Midtown Toronto
369,Principal Data Scientist,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it’s up to you.

The Role

Veeva Data Cloud is a family of data products aimed at bringing more innovative solutions and greater choice to the life sciences data market. Life sciences companies license our data to inform high-impact commercial initiatives, such as patient journey mapping, healthcare professional (HCP) targeting, and field force alignment. Veeva Data Cloud leverages software and cloud technology to develop and deliver better data, faster.

As the Principal Data Scientist for the Veeva Data Cloud team, you will be focused on designing and building our methodologies to bring Projected Data Products to life for our customers.
You are excited about statistics and data science at scale on big data and taking billions of records to tell a story, from sample curation, projection methodologies, anomaly detection, scaling approaches, clustering, and more. You design and build algorithms in a computationally efficient and statistically effective manner, while being able to keep the business problems we are working to solve in mind. While ML is an important part of your toolkit, it's not your only skill. The ability to dissect the problem and to select from a variety of techniques is key.
This is a great opportunity for someone who is excited about using their statistics and data science expertise to design and build the algorithms and models used at the core of launching Veeva’s Projected Data Products. You’ll collaborate closely with the Product Management and Engineering team to productize the methodologies and get to see enterprise Life Science customers leverage your work every day.
What You'll Do
Apply statistical, machine learning, and data mining techniques to large health data sets to build new products and methodologies
Collaborate closely with a team of Data Scientists, Product Managers, Software Engineers and Data Engineers to discover and deliver product offerings from prototype to scale, then iterate and enhance
Explore and find meaning in high volumes of data, identify signals and patterns to identify relationships to infer the universe from imperfect data. Important skills include querying, data cleansing, experiment design, solution assessment, identifying scaling challenges.
Rapidly build prototype product solutions, communicate findings, and iterate
Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved
Requirements
10+ years of hands-on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects
M.S. or Ph.D. in Applied Statistics, Mathematics, Computer Science, Machine Learning or other quantitative discipline
Highly proficient in Python (packages: pandas, scikit-learn, statsmodels) and SQL; experience working with AWS preferred
Experience working with large quantities of data to develop models that work in a stable, production approach with live data
Advanced knowledge of statistical analysis and data mining techniques (regression, multilevel regression, poststratification, semi-supervised learning, forecasting, decision trees, clustering, A/B testing, etc.)
Experience working with engineering to productionalize models including scaling, monitoring, and documentation
Comfortable (and excited!) about ambiguity and breaking goals down into tangible and actionable workplans
Strong communication skills and ability to work across internal teams
Nice to Have
Statistician in health-related field, such as epidemiology
Perks & Benefits
Flexible PTO
Allocations for continuous learning & development
Health & wellness programs
Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.



Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
370,Senior Data Scientist,"Tiger Analytics is looking for experienced Data Scientists to join our fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.
As a Data Scientist, you will apply strong expertise in AI through the use of machine learning, data mining, and information retrieval to design, prototype, and build next generation advanced analytics engines and services. You will collaborate with cross-functional teams and business partners to define the technical problem statement and hypotheses to test. You will develop efficient and accurate analytical models which mimic business decisions and incorporate those models into analytical data products and tools. You will have the opportunity to drive current and future strategy by leveraging your analytical skills as you ensure business value and communicate the results.

Key Responsibilities
Collaborate with business partners to develop innovative solutions to meet objectives utilizing cutting edge techniques and tools.
Effectively communicate the analytics approach and how it will meet and address objectives to business partners.
Advocate and educate on the value of data-driven decision making; focus on the “how and why” of solutioning.
Lead analytic approaches; integrate solutions collaboratively into applications and tools with data engineers, business leads, analysts and developers.
Create repeatable, interpretable, dynamic and scalable models that are seamlessly incorporated into analytic data products.
Engineer features by using your business acumen to find new ways to combine disparate internal and external data sources.
Share your passion for Data Science with the broader enterprise community; identify and develop long-term processes, frameworks, tools, methods and standards.
Collaborate, coach, and learn with a growing team of experienced Data Scientists.
Stay connected with external sources of ideas through conferences and community engagements.
Requirements
Bachelors Degree in Data Science, Computer Science, or related field
6+ years of Data Science and Machine Learning experience required
Proficiency in Python or R. Ability to write complex SQL queries
Proficiency with Machine Learning concepts and modeling techniques to solve problems such as clustering, classification, regression, anomaly detection, simulation and optimization problems on large scale data sets
Ability to implement ML best practices for the entire Data Science lifecycle
Ability to apply various analytical models to business use cases (NLP, Supervised, Un-Supervised, Neural Nets, etc.)
Exceptional communication and collaboration skills to understand business partner needs and deliver solutions
Bias for action, with the ability to deliver outstanding results through task prioritization and time management
Experience with data visualization tools — Tableau, R Shiny, etc. preferred
Benefits
This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",Tiger Analytics,Midtown Toronto
371,Senior Data Scientist,"The Data Science team is responsible for improving business operations and user experiences. Billions of data points are recorded daily from our products. Projects include content recommendation and surfacing engines, computer vision tasks, bidding systems, and credit card fraud detection among others. We seek a Data Scientist to help enhance our current projects and work on fascinating new projects. The ideal candidate should be experienced and interested in owning data-driven projects from the first stages of research to the later stages of development and deployment.

What you'll be doing:
Research: Discover solutions to unique data science challenges while satisfying business needs

Develop and Implement full solutions

Load and clean the data

Prepare and train the model

Deploy, monitor and maintain the solution

What you'll need to be successful:
Must Haves:
PhD in a quantitative STEM field with an important data analysis component OR Msc. in a quantitative STEM field with 3+ years of experience as a Data Scientist

Strong programming skills in Python and experience with Machine Learning tools (numpy, scipy,scikit-learn, pandas, pytorch/ tensorflow, ...)

Strong knowledge of data science algorithms and their limitations (execution speed, memory considerations, etc)

Experience dealing with very large datasets

Familiarity with database environments (including distributed big data solutions) and functional SQL knowledge
Experience with UNIX/Linux environments
Good team player and open to give and receive constructive feedback

Ability to communicate clearly to non-experts

Nice to Haves:
Understanding and/or familiarity with non-interpreted (compiled) programming languages

Experience with cloud providers (AWS, GCP, Azure)

Data science side projects or Kaggle competitions

As an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees

In this role you may be exposed to adult content","MindGeek Careers
3.6",Montreal
372,Data Engineer,"Gamesys Group is one of the world's leading gaming operators, with millions of players and 1500+ employees. We believe passionately in what we do. Quite simply, we craft entertainment with care, building trusted brands and creating great experiences that always put the player first.

Our award-winning ventures – including Virgin, Jackpotjoy, Monopoly, Heart and Vera&John – are some of the best known in the industry. Join us and you'll be joining a big, international group with some great brands and an exciting future. You'll feel part of one global family, working with smart people, and delivering a great experience for our players. There's one thing we expect from you, over and above everything else. Be yourself. One of the values in our DNA is 'stay wonderfully weird' – and that applies to all of us.

Gamesys plans to expand into new markets across North America . We are building a new technology team in Toronto to accelerate the development of Gamesys's internal Excite gaming p latform , which will drive our growth across the USA and Canada .

We're looking for a hands-on engineer with a passion for data to work alongside other developers, architects and machine learning engineers in an agile environment. You will be working in a team delivering batch and streaming data pipelines and services on our Cloud Data Platform (GCP).

You will work with data scrum team members, data architects, product owners and business analysts delivering elegant solutions and troubleshooting problems. You will get to work with large data sets and learn to apply the latest big data technologies on a range of cloud and on-premise platforms. An interest or experience in the gaming industry is desirable.

Responsibilities:
Coding resilient, scalable and elegant strategic solutions which are reusable and easily maintainable.

Peer reviewing other team member's code.

Cooperating with architects and other data engineers to develop technical designs and to propose solutions to key stakeholder requirements.

Attending stand-ups with key stakeholders, communicating the status of development and raising any potential risks as early as possible.

Producing clear and concise documentation where required.

Attending training as required related to Google Cloud Platform, ETL and data pipelines generally.

Showing an interest in the Gaming industry and in playing our games to understand the impact of data on the player experience.

Some 2nd line on-call support.

Skills required:
Strong SQL/Procedural SQL/Data Warehousing experience.

Unix shell scripting (or alternative) experience.

Knowledge of TDD and CI/CD

Has worked in a team that adhered to agile principles.

Has demonstrated self-motivation/pro-activeness on a previous role.

Good communication skills, and an ability to explain work well to other team members.

A keenness to understand how the technical task at hand translates into business value.

Someone who is not afraid to put forward ideas for improving team process or suggest new features to the Product Owner

Desired Skills:
One or more of the following languages Java, Python.

Public cloud experience, Google highly desirable.

Experience of data reporting or Business Intelligence solutions like Tableau, Data Studio or Cognos.

Experience or demonstrable interest in analytics and/or machine learning.

Experience with streaming technologies such as Kafka, and REST APIs.

Experience building Data lakes.

Benefits:
We believe this process works both ways, so what can we do for you?

We offer some of the most competitive benefits in the market including continued personal growth, career development plans and performance bonus. We also believe in providing an environment where employees can flourish – you'll be working in a very modern work environment – and we will make sure you will also have enough time to unwind with our monthly office events and team-building activities.

T his is Gamesys Group and we're here to make gaming everything it should be. You'll have fun making fun every day, and that's a promise.","Gamesys
4.1",Midtown Toronto
373,Data Engineer,"As a leading mobile games developer, Jam City is looking to “level up” our talent for our Bingo team in Toronto. We’re on the hunt for innovators who consider themselves dynamic, collaborative and thrive in a fast-paced environment.

PERKS & BENEFITS
Unlimited Vacation*
Employer Paid Benefits*
Parental leave and Kin care*
RRSP Matching*
In office lunch and snacks
Company Events such as movie night, trivia, game shows & more…
Fitness Allowance, Training Allowance, Phone Allowance & More!*

Only applies to full-time positions.

*
ABOUT THE ROLE*
We’re currently looking for a Data Engineer to join our Jam City Toronto team! In this role, you will have the opportunity to work alongside a small team of talented individuals using cutting-edge technologies to build top-notch data pipelines and analytics tools. Every day, we strive to break the mold, helping to create better experiences for our players.

RESPONSIBILITIES

Enable our data-centric approach to decisions via our in-house Data and Service platforms.
Think across domains as we build and manage our infrastructure, automation pipelines, and Data systems.
Play a meaningful role in our nimble yet disciplined approach to system architecture and team processes which empowers our small team to manage large systems.
Analyze and improve efficiency, scalability, and stability of various system resources.
Automate tasks and streamline processes to easily manage a growing server farm.
Participate in an on-call schedule to ensure optimal uptime.
Our infrastructure is constantly evolving. You will have the opportunity to learn, build and suggest new tools!

QUALIFICATIONS

Passion for the tech industry. Whenever there was a technology you did not understand, you've researched to become familiar with it.
Enjoys collaborative work, challenging ideas, and being challenged.
Proven software engineering experience in building maintainable systems.
Expertise in at least some languages and tools like Java, Scala, Python, Docker, Spark/Hadoop, relational and document databases, and AWS services in general.

NICE TO HAVE

Experience working at a gaming studio, or on games generally.
Knowledge of measuring, optimizing, and automating everything.
Strong system admin skills, including Linux, networking, databases admin, security, and infrastructure as code tools.

OUR COMMITMENT TO EQUITY, DIVERSITY, & INCLUSION
We believe in creating games that unite people across the world and that showcase our commitment to providing an environment that is both inclusive and diverse for our players and employees. We strive to create a workforce that is reflective of our global player community as we know that we are stronger and better when we play together. To help promote an inclusive culture, we celebrate the visible and invisible diversity of our Jam Citizens through initiatives including Employee Resource Groups, cultural events, trainings, speaker series, and more.

Jam City is an equal opportunity employer. We enthusiastically accept our responsibility to make employment decisions without regard to race, age, sex (including pregnancy), national origin, ancestry, religion, ethnicity, marital, or domestic partnerships status, disability, genetic information (including the refusal to submit to genetic testing), predisposing genetic characteristics, military status, veteran status, domestic violence victim status, sexual orientation, gender identity or expressions, or any other classification protected by federal, state, and local laws. Our management is committed to following this policy with respect to hiring, placement, promotion, transfer, demotion, layoff, termination, recruiting, pay, and other forms of compensation, training, and general treatment during employment.

*
ABOUT JAM CITY*
Jam City is an award-winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience.

Led by CEO Chris DeWolfe, former MySpace co-founder and CEO, and COO Josh Yguado, former 20th Century Fox executive, Jam City is the creative powerhouse behind some of the highest-grossing and most enduring mobile games. Jam City’s global franchise Cookie Jam has generated more than half a billion dollars, and Panda Pop has more than 120 million downloads to date.

The company also is the go-to studio for Hollywood, having developed immersive, narrative-rich mobile games around iconic entertainment brands. The company’s popular RPG game Harry Potter: Hogwarts Mystery was the #1 game in more than 40 countries at its launch in April 2018.

Jam City has nine studios located in Los Angeles (HQ), Berlin, Buenos Aires, Bogotá, Burbank, Cedar Falls, San Diego, San Francisco, and Toronto.

Job Type: Full-time","Jam City
4.4",Midtown Toronto
374,Data Engineer,"Why join us?

Are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor? If so, we would love to tell you our story.

At OMERS we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in Toronto, London, New York, Singapore, Sydney and other major cities across North America and Europe. Our culture is truly one of a kind. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live with an ever-constant eye to the global investment markets.
As a key member of the Enterprise Data & Advanced Analytics team, the Data Engineer is passionate, down to earth, takes great pride in delivering next generation full stack solutions that meet and exceed our strategic business goals. Driving innovation in the development of advanced capabilities, you are leading with a product management & system-thinking approach.

The candidate will develop end-to-end data pipelines, with a focus on system integration and cloud to support OMERS decision makers and collaborate with a community of designers, product managers, data engineers and architects in ideation, design, development, testing, technical support, research and knowledge-sharing through the implementation lifecycle.

As a member of this team, you will be responsible for:
Designing, d eploying and s ustaining scaled data pipelines to achieve a high level of reliability, scalability and security in supporting business objectives.

Sourcing, transforming and delivering structured and unstructured assets for use in Azure Databricks, Synapse Analytics, Power BI, and more.

Operating in an Agile development environment.

Communicating effectively with other engineers in the same team, with other teams and with various other partners such as product managers, data analysts, IT infrastructure specialists, security specialists, enterprise architects and members of senior management.

Participating in solution build, delivery, support and troubleshooting.

Leading change and communicating impacts to business partners and fellow team members.

Exhibiting the ability to work on multiple projects simultaneously and ensuring delivery on time, within scope and within budget.

Participating in establishing sound data management practices for the team and the organization.

Identifying, defining and implementing opportunities for improving existing processes.

Defining and executing technical test plans, perform unit, performance and integration testing and automate regression testing.

​ To succeed in this role, you have:
Professional

Experience . 3+ years solving complex technical data projects using the Microsoft Azure data stack or equivalent work experience is required . Financial industry application is preferred.

Industry Knowledge . The a bility to quickly propose Azure Data Platform solutions by recalling the latest best practices learned from MVP & Product Team articles, MSFT documentation, whitepapers, and community publications is required.

Relationship Building . Proven track record of building deep technical relationships. Experience in aligning expectations across various partners .

​ Problem - Solving. The ability to trace data lineage / workflows and resolve technical issues with minimal direction . Demonstrated proficiency in understanding and implementing business workflows is a plus.

Teamwork . Motivated and keen to work in a collaborative environment with a focus on team success over and above individual success.

Technical

Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs, and technology management is required .

Breadth of technical experience and knowledge across the Azure Data Platform, with depth / Subject Matter Expertise in two or more of the following Data Platform resources is required : ​ ​ Azure Data Factory, Dedicated Synapse SQL (SQL DW), Azure Databricks, Azure Functions using C#, PowerShell or Python, Kubernetes and containerization

Experience automating CI/CD pipelines using Azure DevOps or equivalent work experience is required .

Experience with the Microsoft Power Platform is preferred .

Experience developing star schema reporting pipelines using Kimball or Data Vault v2.0 methodologies .

Experience with GCP and BigQuery is preferred.

Education

Bachelor’s Degree in an appropriate field of study or equivalent work experienc e

Candidates with Microsoft Azure certifications are desired

Our story:
Founded in 1962, OMERS is one of Canada’s largest defined benefit pension plans, with $105 billion in net assets as at December 31, 2020. OMERS is a jointly-sponsored pension plan, with 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. OMERS members include union and non-union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children’s aid societies across Ontario. Contributions to the Plan are funded equally by members and employers. OMERS teams work in Toronto, London, New York, Amsterdam, Luxembourg, Singapore, Sydney and other major cities across North America and Europe – serving members and employers and originating and managing a diversified portfolio of high-quality investments in public markets, private equity, infrastructure and real estate.

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","OMERS
3.5",Midtown Toronto
375,Data Quality Analyst,"AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease.

We are seeking a motivated and dynamic Data Quality Analyst to join our Data Management team, where they will work closely with a highly proficient team of lab scientists, data scientists, and software developers to maintain high Data Quality (DQ) levels through extensive data quality rules implementation, wrangling and testing activities, and data analysis. The role will focus on understanding data lifecycle and data transformation layers within various data pipelines and advancing data quality best practices throughout the company. Contributions by the successful candidate will help build automated data quality management solutions that meet the needs of a rapidly growing and innovative company today and in the future. The successful candidate will be at ease with ambiguity and change, embracing the opportunities and challenges that a quickly evolving and dynamic work environment presents.

How you might spend your days:
Developing, operationalizing, and maintaining automated data profiling and DQ processes.
Ensuring DQ rules are accurately built using validation tools (e.g. Informatica Data Quality, Talend, or other custom-built scripts) or custom scripts; developing in-depth understanding of source systems and EDW data structures to further define rules.
Tracking, investigating, and analyzing the root cause of DQ issues, ensuring DQ issues and remediation plans are communicated to all Data Stewards.
Engaging with and supporting the Data Stewards and other internal stakeholders, as required, to correct and/or remediate DQ issues in systems of record based on business priorities.
Engaging Data Stewards and other internal stakeholders to develop and implement data-wrangling scripts, DQ tests, DQ reports and identify defects using DQ rules based on prescribed DQ dimensions.
Evaluating the impact of system performance and design on DQ.
Collaborating with Data Engineers and Database Administrators to improve data collection and storage processes.
Documenting processes and maintaining data records.
Keeping abreast of developments and trends in data quality analysis

We'd love to hear from you if you have:
A Bachelor's Degree in quantitative areas such as Computer Science, Mathematics, Statistics, or related fields.

Minimum 3 years of related experience in data quality management, data analysis and ETL procedures with a s trong understanding of data quality monitoring procedures

Hands-on experience writing complex SQL queries, including extensive experience querying large, complex datasets

Demonstrated knowledge of Data Management and Data Governance principles and practices.

Hands-on experience writing REST APIs

Experience in one or more programming languages, preferably Python .

Familiarity with data visualization software package such as Power BI

Exceptional analytical and conceptual thinking skills.The ability to work closely with stakeholders to determine acceptable solutions.

Excellent documentation, organization, and communication skills.

Experience creating detailed reports and presentations.

Excellent planning, organizational, and time management skills.

Competency in Microsoft applications including Word, Excel, and PowerPoint.

Competency in Google Workspace applications (Sheets, Docs, Drive, etc.).

Preferred Qualifications:
Familiarity with native AWS technologies for data and analytics such as Redshift Spectrum, Athena, S3, Lambda, Glue, EMR, Kinesis, SageMaker, etc. or equivalent relevant technologies (e.g. Snowflake, Alteryx, Matillion, Boomi, etc.)
Experience utilizing Data Quality tools such as Talend, Informatica Data Quality, etc.
Knowledge of data sourcing from NoSQL databases
Familiarity with or previous experience in the biotechnology industry

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks' vacation
Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research, and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please send us your application through our website and refer to Job ID 21234 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera
4.8",Vancouver
376,Senior Data Scientist - Toronto Hub,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or in our Toronto office - it’s up to you.

Veeva is looking for an all-star Senior Data Scientist to join the Vault Outside Life Science (OLS) team. We’re looking for a high-energy, passionate individual with a deep technical background who is eager to drive product advancement and innovation. In this role, you will be responsible for creating game-changing products in the manufacturing industries such as Consumer Packaged Goods, Chemical, and Cosmetics.
If you have a passion for creating world-class products and enjoy solving complex problems with simple, elegant solutions, you may be a good fit for this position.
What You'll Do
Be involved in sales discussions, potentially fueling the conversation about what AI can do and bringing clarity to the discussion
Work with customers and implementation teams to build out custom solutions
Build POCs with AWS assistance and consulting PMs on opportunities
Be hands-on. Design, Prototype, Configure - validate solutions rapidly to ensure we solve the right problems, in the right order
Be a storyteller. Author & design high-quality specifications and communicate specific, actionable requirements to your engineering teammates
Be a leader. Look for opportunities to innovate, keep up with the latest software, machine learning, manufacturing industries trends, and distill them into product requirements
Be agile. Design, implement, iterate
Take pride in your work
Requirements
2+ years of software development/architect, product management, or technical consulting role in AI
5+ years of professional work experience in agile software development environments
Demonstrated skills in design, product development, and planning
Ability to work independently in a fast-paced environment, with little direct supervision
Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to Engineering and customers
Degree in computer science or engineering
Experience with AI and Machine Learning Models
Experience with Natural Language Processing

Qualified candidates must be legally authorized to be employed in Canada. Veeva does not provide sponsorship of employment visa for this position.
Nice to Have
Experience working in the following industries: Consumer Packaged Goods, Chemical and Cosmetics
Experience working on SaaS enterprise applications or content management systems
Experience with API and data exchange schemas
Experience with data migration
Experience with Search matching algorithms and heuristics
Experience with Python, SQL, XML, and JSON
Perks & Benefits
Conveniently located in downtown Toronto
Snacks, beverages, and weekly lunches from local restaurants
Team events and rec league sports teams
Allocations for continuous learning & development
Health & wellness programs
Weekly yoga classes
Ping pong and other games
#LI-Remote

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
377,Senior Data Scientist - Toronto Hub,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or in our Toronto office - it’s up to you.

Veeva is looking for an all-star Senior Data Scientist to join the Vault Outside Life Science (OLS) team. We’re looking for a high-energy, passionate individual with a deep technical background who is eager to drive product advancement and innovation. In this role, you will be responsible for creating game-changing products in the manufacturing industries such as Consumer Packaged Goods, Chemical, and Cosmetics.
If you have a passion for creating world-class products and enjoy solving complex problems with simple, elegant solutions, you may be a good fit for this position.
What You'll Do
Be involved in sales discussions, potentially fueling the conversation about what AI can do and bringing clarity to the discussion
Work with customers and implementation teams to build out custom solutions
Build POCs with AWS assistance and consulting PMs on opportunities
Be hands-on. Design, Prototype, Configure - validate solutions rapidly to ensure we solve the right problems, in the right order
Be a storyteller. Author & design high-quality specifications and communicate specific, actionable requirements to your engineering teammates
Be a leader. Look for opportunities to innovate, keep up with the latest software, machine learning, manufacturing industries trends, and distill them into product requirements
Be agile. Design, implement, iterate
Take pride in your work
Requirements
2+ years of software development/architect, product management, or technical consulting role in AI
5+ years of professional work experience in agile software development environments
Demonstrated skills in design, product development, and planning
Ability to work independently in a fast-paced environment, with little direct supervision
Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to Engineering and customers
Degree in computer science or engineering
Experience with AI and Machine Learning Models
Experience with Natural Language Processing

Qualified candidates must be legally authorized to be employed in Canada. Veeva does not provide sponsorship of employment visa for this position.
Nice to Have
Experience working in the following industries: Consumer Packaged Goods, Chemical and Cosmetics
Experience working on SaaS enterprise applications or content management systems
Experience with API and data exchange schemas
Experience with data migration
Experience with Search matching algorithms and heuristics
Experience with Python, SQL, XML, and JSON
Perks & Benefits
Conveniently located in downtown Toronto
Snacks, beverages, and weekly lunches from local restaurants
Team events and rec league sports teams
Allocations for continuous learning & development
Health & wellness programs
Weekly yoga classes
Ping pong and other games
#LI-Remote

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
378,Associate Scientist - Synthetic Organic/ Medicinal Chemistry,"About adMare BioInnovations:




adMare BioInnovations is Canada’s global life sciences venture, building the Canadian life sciences industry from sea to sea. We do this by sourcing therapeutically and commercially promising research from leading academic and biotech partners to create new companies of scale, providing specialized expertise, infrastructure, and capital to help existing companies scale up, and driving the growth of those companies into Canadian anchors by training the next generation of highly qualified personnel. adMare’s ~20 portfolio companies have attracted more than $1.2B of investment and have a combined worth of over $3B.




Job Summary:




We are seeking highly motivated PhD and MSc level synthetic organic and/or medicinal chemists to join our drug discovery team. Associate Scientists positions are available to join our Montreal facility. Highly qualified individuals are expected to have experience in modern organic synthesis with good laboratory skills and a record of high productivity. Key requirements of the role include being able to work within a team structure, propose new targets, execute synthetic routes, engage in troubleshooting exercises as needed, and effectively communicate with biology, pharmacology and DMPK colleagues.


Associate Scientists are expected to demonstrate laboratory and scientific proficiency, creativity and a willingness to work in a dynamic group environment. The associate scientist is expected to carry out multistep organic synthesis, purification, and characterization of new molecules. The candidate will be part of a research team and will be expected to interpret SAR and ADME data and contribute to the design of new targets and to the chemistry strategy.


We are a dynamic team that fosters a positive, curiosity driven culture that encourages everyone to contribute intellectually and experimentally to solving complex challenges in drug discovery. We have state-of-the-art laboratories, and we promote a cross-functional research environment where colleagues form chemistry, biology, pharmacology and DMPK work closely together to advance drug discovery projects. We offer flexible working hours, competitive salaries, bonuses and benefit package.


Key Duties and Responsibilities:




Proficiency in modern organic synthesis and ability to independently perform complex, multi-step procedures.
Experience in the purification of small molecules using a variety of methods such a flash chromatography, HPLC purification, distillation and others as needed.
Structural characterization of small molecules using modern spectroscopic instruments and techniques such as LC-MS, 1 and 2D NMR methods and others.
Contributes signiﬁcantly to patent and/or publication preparation.
Independently prepares project presentations and presents experimental conclusions at Group/Department or Project Team research meetings.
Interprets SAR and ADME data and able to propose new targets to address chemistry and/or project issues
Stays abreast of scientific literature and incorporates new methods and technologies in his/her research.
Performs other duties as assigned.



Education and Experience:




Ph.D. in chemistry or medicinal chemistry, or

Master’s Degree in chemistry or medicinal chemistry with 3+ years of relevant employment experience



At adMare, we are driven by our vision and united by our shared values of Courage, Collaboration, Objectivity, Judgment, Excellence, and Reach.




We are committed to growing the talent and potential of our people to drive the development of innovations. We provide a community where you can work with multidisciplinary individuals, explore new ways of thinking, and expand your capabilities through the array of development programs we offer our employees.




adMare is a diverse community where employees feel a sense of belonging and are valued for the experience and unique perspectives they bring.




Be a part of life at adMare. Join our team!


À propos d’adMare BioInnovations:




adMare BioInnovations est le partenaire d’affaires en sciences de la vie au Canada, en soutien à l’industrie d’un océan à l’autre. Pour ce faire, nous identifins auprès de partenaires académiques et biotechnologiques de premier plan les découvertes les plus prometteuses sur les plans thérapeutique et commercial afin de créer de nouvelles entreprises d’envergure. Nous fournissons une expertise et les infrastructures adéquates dans le but d’aider les entreprises existantes à se développer, en favorisant leur croissance afin qu’elles deviennent des piliers canadiens tout en formant la prochaine génération de personnel hautement qualifié. Le portefeuille d’adMare, qui compte près de 20 sociétés, a généré plus de 1,2 milliard de dollars d’investissements et représente une valeur totale de plus de 3 milliards de dollars.




Résumé du poste :




Nous sommes à la recherche de chimistes organiques synthétiques et/ou médicinaux possédant un doctorat ou une maîtrise en sciences qui aimeraient faire partie de notre équipe de découverte de médicaments. Les postes de scientifiques associés disponibles sont offerts dans nos installations de Montréal. Les individus très qualifiés devraient posséder une expérience en synthèse organique moderne et des aptitudes marquées en laboratoire en plus d’avoir démontré une capacité de productivité élevée. Les principales exigences du poste consistent, entre autres, à pouvoir fonctionner au sein d’une équipe, à proposer de nouvelles cibles, à suivre une voie de synthèse, à participer à des exercices de diagnostic des pannes en fonction des besoins et à communiquer de manière efficace avec des collègues dans les domaines, comme la biologie, la pharmacologie, ainsi que le métabolisme des médicaments et pharmacocinétique.


Les scientifiques associés devront démontrer une maîtrise des techniques en laboratoire et dans le domaine scientifique, de la créativité et la volonté de travailler dans un environnement de groupe dynamique. Le scientifique associé devra réaliser une synthèse organique en plusieurs étapes, la purification et la caractérisation des nouvelles molécules. Le candidat fera partie d’une équipe de recherche et devra interpréter les données sur les rapports structure-activité et les données des études absorption-distribution-métabolisme-excrétion et contribuer à la définition de nouvelles cibles et à la stratégie relative aux produits chimiques.


Nous sommes une équipe dynamique qui favorise une culture positive et axée sur la curiosité en plus d’encourager tout un chacun à contribuer sur le plan intellectuel et par des expériences à relever des défis complexes dans le domaine de la découverte des médicaments. Nous possédons des laboratoires ultramodernes et nous encourageons un environnement de recherche interfonctionnel où les collègues dans les domaines, comme la chimie, la biologie, la pharmacologie et le métabolisme des médicaments et pharmacocinétique travaillent en étroite collaboration pour favoriser les projets de découverte de médicaments. Nous offrons des heures de travail flexibles, des salaires concurrentiels, des bonis et un programme d'avantages sociaux.


Tâches et responsabilités principales:




Maîtrise de la synthèse organique moderne et capacité de réaliser de manière indépendante des procédures complexes comportant plusieurs étapes.
Expérience dans la purification de petites molécules en ayant recours à des méthodes variées, comme la chromatographie rapide sur colonne, la purification CLHP, la distillation et autres en fonction des besoins.
Caractérisation structurale des petites molécules en faisant appel à des instruments et des techniques de spectroscopie modernes, comme les méthodes LC-MS 1 et RMN 2D.
Contribuer grandement à la préparation des brevets et/ou des publications.
Préparer de manière indépendante des présentations de projet et présenter les conclusions des expériences lors des réunions de groupe/service ou des réunions de recherche des équipes de projet.
Interpréter les données sur les rapports structure-activité et les données des études absorption-distribution-métabolisme-excrétion, et proposer ensuite de nouvelles cibles visant à résoudre les problèmes de nature chimique et/ou en lien avec les projets.
Se tenir au fait de la documentation scientifique et intégrer les méthodes et les technologies nouvelles à ses recherches.
Réaliser d’autres tâches sur demande.



Éducation et expérience :




Doctorat en chimie ou en chimie médicinale; ou
Maîtrise en chimie ou en chimie médicinale et au moins 3 années d'expérience de travail pertinente.



Chez adMare, nous sommes motivés par notre vision et unis par nos valeurs communes que sont le courage, la collaboration, l’objectivité, le jugement, et l’excellence.


Nous sommes déterminés à accroître le talent et le potentiel de nos employés lorsqu’il s’agit de promouvoir l'innovation. Nous offrons une communauté où vous pourrez évoluer aux côtés d’employés multidisciplinaires, explorer de nouvelles méthodes de réflexion et accroître vos capacités grâce à l’éventail des programmes de perfectionnement que nous offrons à nos employés.


adMare est un univers diversifié où les employés éprouvent un sentiment d’appartenance et où ils se sentent valorisés en raison de l'expérience et des points de vue uniques qu’ils apportent.


Venez participer à la vie chez adMare. Faites partie de notre équipe!","adMare BioInnovations
3.7",Montreal
379,Data Engineer,"On the Data Engineer skillsets, here are the must have skills:

Azure Data Factory
Azure Data Lake
Azure Kubernetes
Azure Blob Storage
Azure Databtricks (delta)
SQL
Python/C#

Nice to Have:

Azure Event Hub
Azure IoT Hub
Azure DevOps
Computer Science and Statistics backgrounds will be a huge bonus to the work we do for Turing

""IMPJOB""

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

Experience:

Data Engineer: 8 years (preferred)","Maarut Inc
1.0",Calgary
380,Environmental Lead Scientist,"Salary: $40.00/Hourly
Job Type: Full Time, Permanent
Start Date: As soon as possible



Language: English
Minimum Education: Bachelor's Degree
Positions Available: 4



NOC Group: Natural and Applied Science Policy Researchers, Consultants and Program Officers (4161)
NOC Job Title: Environmental Consultant (Except Engineer)
Expires in 9 days
Expires: 2021-06-30
Posted: 2021-04-07
Last Updated: 2021-05-31



Job Location(s)
Port Moody, British Columbia
Fort St. John, British Columbia

Job Description

As the Environmental Lead Scientist, you are responsible for assisting the Environmental Project Manager to plan and complete a project. You may be responsible for project budgets, timelines, deliverables, field completion of advanced programs and preparation of technical reports. You will maintain direct connection to the field staff, and work in the field may be required as determined by each project. You will provide direction to the Environmental Scientist and report to the Environmental Project Manager or Environmental Account Manager.

Your Key Responsibilities

Provide an exceptional client experience consistent with SynergyAspen standards.
Manage project's contract documents, drawings, specifications, and scope of work.
Support field operations in aspects which may include cost controls, planning, scheduling, and estimating.
Complete technical report writing and signature on factual technical reports.
Maintain current knowledge with governing regulatory bodies as it applies to the OGC, MECCS.
Manage data and file compilation for internal and client databases.
Maintain billable targets as set by Supervisor.
Coordinate with and manage Contractors.
Coordinate and facilitate successful project deliverables.

What You Offer to SynergyAspen

Energy, intelligence, and integrity. Your drive for exceptional client experience is relentless.
Reliable attention to detail, remarkable accuracy, and professional organizational skills.
Excellent communication, technical writing, and problem-solving skills.
Demonstrate our corporate values and behaviours.
You have knowledge of project execution activities such as planning, project controls, scheduling, and costing.
Collaborate successfully with your team on various projects of differing complexity.
Communicate and work effectively with environmental subcontractors.
Ability to work outside in adverse weather conditions, when required; travel for work in potentially remote locations, as needed, according to project demands.
B.Sc. or M.Sc. in a related discipline.
Registration, or eligibility to register as a Professional EIT, GIT, AIT, BIT, CET.
Minimum of 4 + years industry experience
Experience in contaminated sites, natural sciences, and reclamation, with preference given to candidates with practical knowledge of BC OGC Regulatory Guidelines.
Proficiency in Microsoft Windows, Office, and Teams. Proficiency with Android / IOS.

What SynergyAspen Offers to You

Autonomy, an opportunity to expand your expertise, and work for a company with integrity of purpose.
Competitive compensation and comprehensive extended health benefits.
Flexible work hours and remote work options.
Pet friendly offices.
Business-casual dress code.
Eligibility for educational and professional membership dues reimbursements.

Related Document(s)
Lead Scientist Posting.pdf


How to Apply

Expiring: Jun 30, 2021

Email: careers@synergyaspen.ca","SynergyAspen Environmental Inc.
5.0",Port Moody
381,Senior Data Scientist,"About SecurityScorecard

Funded by world-class investors including Silver Lake Waterman, Moody's, Sequoia Capital, GV, Riverwood Capital, and others with over $290 million in funding, SecurityScorecard is the global leader in cybersecurity ratings and the only service with over 2M+ companies continuously rated. Founded in 2013 by security and risk experts Dr. Aleksandr Yampolskiy and Sam Kassoumeh, SecurityScorecard's patented rating technology is used by over 16,000 organizations for enterprise risk management, third-party risk management, board reporting, due diligence, and cyber insurance underwriting. This is done by measuring your and your vendors' cyber-health by assigning a security rating of ""A"" through ""F"" based on outside-in, non-intrusive data. SecurityScorecard continues to make the world a safer place by transforming the way companies understand, improve and communicate cybersecurity risk to their boards, employees, and vendors.

SecurityScorecard is headquartered in NYC with over 260+ employees globally. Our culture has helped us be recognized by Inc Magazine as a ""Best Workplace,"" ""Best Places to Work in NYC"" by Crain's NY, and one of the 10 hottest SaaS startups in NY for two years in a row.

About the team

The DS team at SecurityScorecard is composed of highly motivated professionals with diverse technical backgrounds spanning from physics to neuroscience. The team maintains a collaborative style encouraging shared learning, mentoring, and cross-team communication and support of other company departments. Projects span a wide range from crafting queries to support marketing research to applying advanced machine learning techniques to improve accuracy and draw new insights on cybersecurity risk, to developing AI-based capabilities to unlock new functionality that help our users assess and reduce their cybersecurity risk.

What you will do

We're looking for Data Scientists to work on our core products (Ratings Platform and Atlas) to develop new analtyics based on ML and AI.. You will work with one of the largest sets of cybersecurity data in the world, and turn your insights into product enhancements on a continuous basis. The ideal candidate will be a self-starter with an advanced degree and background working with data in a quantitative or technical field, experience working with big data, and a proven record in machine learning, from concept development to proof-of-concept to final implementation.

Basic Qualifications

4+ years experience in Data Science.

4+ years of experience manipulating large data sets through SQL or Python

Experience with Neural Network and Natural Language processing (NLP) with large data sets.

1 year experience in big data technologies like Spark

Excellent understanding of machine learning techniques and algorithms

Qualifications

Proven ability to take a project from concept stage to proof-of-concept to production

team player

PhD or Master's in a technical field preferred

Experience with common data science toolkits and libraries

Benefits : We offer a competitive salary, stock options, a comprehensive benefits package, including health and dental insurance, unlimited PTO, parental leave, tuition reimbursements, and much more!

SecurityScorecard embraces diversity. We believe that our team is strengthened through hiring and retaining employees with diverse backgrounds, skillsets, ideas, and perspectives. We make hiring decisions based upon merit and do not discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status.","SecurityScorecard
4.3",Quebec
382,Senior Data Scientist,"Hölmetrics is a growing data analytics company in Calgary, Alberta, seeking to make a difference in the lives of millions of people every day. Using Machine Learning, Hölmetrics provides a deep insight into the wellbeing of employees and organizations. Hölmetrics helps organizations reduce costs associated with turnover and disengagement, reduce risk around mental health injury, promote healthy workplace culture, and helps companies attract and retain great talent.


Day-to-Day Responsibilities

Contribute in defining vision and strategy for science aspects of the Engineering department
Innovative solution proposal to translate customer needs into technical specifications
Constant R&D to increase reliability and effectiveness of the product
Assist in the design and management of data pipelines to ensure proper execution, data cleanliness, and statistical significance of results
Design and build Machine Learning models to find patterns across disparate data sources, discover relationships, and test hypotheses
Work closely with our Product Team to determine the best course of action for the development



Technical Requirements

Strong background and professional experience in data science and software development
Professional experience in all phases of Machine Learning projects including designing data pipelines, preprocessing mechanisms (such as data cleaning, feature engineering, and feature selection methods), modelling, refinement, and deployment
Strong Python programming knowledge and experience in working with data analysis libraries, like pandas, numpy, scikit-learn, and data visualization libraries
Experience in data engineering practices along with strong SQL knowledge
Experience in developing Statistical ML models and Deep Neural Networks with strong understanding about underlying statistics
Experience with cloud computing services and ability to architect solutions by them (preferably AWS)
Familiarity with NLP main concepts
Experience in Git, Version Control, and CI/CD



Soft Skills

Ability to lead other data scientists, communicate effectively, and determine priorities
Ability to learn about cutting-edge technologies, adapt, discover and test new ideas
Desire to work in a fast-paced and collaborative Startup environment",Holmetrics,Calgary
383,Machine Learning Scientist - Sequence Space,"AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease.

We are seeking a Machine Learning Scientist - Sequence Space to join our rapidly growing Machine Learning team. We are a group of motivated people who work in collaboration with life scientists to constantly improve our discovery pipeline. We have a multi-faceted antibody discovery and characterization pipeline that is able to rapidly discover next-generation antibody therapies. Our pipeline generates an immense amount of valuable data which can be used to further develop our pipeline through state-of-the-art machine learning techniques. Ultimately, we are all working towards a common goal which we strongly believe will make the world a better place. Come join AbCellera and help bring new therapeutics to patients around the world!

How you might spend your days:
Develop NLP-style sequence models to automate and improve our drug discovery pipeline

Investigate data in creative ways to pull out exciting trends and discover useful features

Work on novel research and development projects to expand our capabilities

Optimize machine learning and data science pipelines with a focus on scalability

Work collaboratively with life scientists, bioinformaticians, and software engineers

Shepherd your machine learning projects from inception all the way through to in-house production use

We'd love to hear from you if:
Bachelor's Degree +8 years of work experience in machine learning and/or data science, or Master's Degree +7 years of work experience in machine learning and/or data science, or PhD +5 years of work experience in machine learning and/or data science

Experience developing production grade machine learning models

Experience dealing with big data

Expert in bioinformatics, NLP, tensorflow/keras/pytorch etc.

Python expertise

Strong ability to present work and communicate ideas to technical and non-technical coworkers

A strong desire to work in a collaborative, multidisciplinary environment

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter

An attractive compensation package, including health and lifestyle benefits

A minimum of 3 weeks' vacation

Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please send us your application through our website and refer to Job ID 21214 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera
4.8",Vancouver
384,Data Engineer/Tableau Developer,"We are looking for a savvy Big Data Engineer / Tableau Developer to join our growing team of Enterprise Data and Advanced Analytics Platform. The ideal candidate is an experienced data wizard who enjoys engineering data pipelines within the Data Lake and building impactful visualizations using Tableau. The candidate must have strong business acumen who enjoys working with diverse business lines to on-board data into the Data Lake and then develop visualizations and insights with the data. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. This role will report into the Manager of Enterprise Data Platform.


Responsibilities:

Create and maintain optimal data pipeline architecture to on-board data into the Data Lake.

Assemble large, complex data sets that meet functional / non-functional business requirements.

Enhance the existing and build new data pipelines to extract & transform data for business users to build data analytics

Practice established development disciplines such as good code management, branching and merging of code in a GIT repository.

Has relevant and highly developed professional and technical skills; experienced level of knowledge in field of expertise and strong knowledge of business/context

Apply Tableau development capabilities to transform raw data into relevant information, and help internal clients visualize their data.

Analyze data, using measurement techniques, drafting KPIs and building reports and dashboards to address business questions.

Partner with business and Data Quality team members to design relevant data visualizations using Tableau and work with team members to build dashboards for data quality and analysis

Work with Subject Matter Experts and stakeholders to understand business problems and business requirements. Translate business requirements into functional use cases to solve business problems

Support TMX internal/external users for application related inquiries

24/7 on-call support on a rotational basis


Qualifications and Technical Skills

University degree, College diploma or relevant job experience in Computer Science, Statistics or Mathematics at minimum

5+ years of overall IT experience and 3+ years in Big Data development/design including the following Hadoop ecosystem components – HDFS, Hive, Sqoop, Flume, Pig, Kafka, Spark / Spark SQL, Oozie, Hue and Java programming

Experience working with Big data development platforms like Zaloni, Talend, Pentaho, Cloudera is key to this role

3+ years experience, beginner to intermediate, working with data visualization tools such as Tableau

A high degree of competency using SQL queries to extract and manipulate complex nested unstructured data, including the ability to use aggregate functions, subqueries, CTEs, and window functions.

Relational Database Experience: Understanding of Data Modeling concepts and SQL Performance Tuning

Experience with development using Agile methodologies

Good understanding of AWS cloud technology and hadoop implementation on AWS including S3, EC2 and EMR

Experience in Python, Scala, Ranger is required

Experience in performance tuning Hive tables is required

Experience in the configuration of YARN, MapReduce for performance, security is a plus

Experience designing a technology stack for machine learning is a plus

Basic understanding of statistical concepts is an asset


Must Have(s):

Excellent interpersonal and communication skills

Strategic thinker

Ability to multitask

Excellent analytical and problem solving skills

Strong analysis / design experience

Meticulous attention to detail

Must be a self-starter with ability to follow through on projects assigned


TMX is committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and one which reflects the diversity of the community in which we operate. We provide accommodations for applicants and employees who require it.","TMX Group Limited
4.2",Midtown Toronto
385,"Manager, Data Science","Job Description

This role will start off as work from home, gradually you will be required to work in the Markham or Toronto office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive impactful decisions. The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. This team is exploring the frontiers of the insurance business such as how to harness the data from connected cars to deliver new types of products to customers. This exciting role is at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

As a Data Science Manager, you will lead a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will lead the development of machine-learning and statistical models for practical applications that impacts millions of customers. You will manage and guide your peers in novel approaches and provide peer review for their work.

What you’ll do

Lead a squad of Actuaries, Data Scientists and Engineers in the development of meaningful conclusions and recommendations

Oversee the development of high performing machine learning and statistical models on very large datasets

Oversee the development of novel algorithms and innovative data-driven solutions to solve business problems

Help the team excel in the assigned business domain

What you need to succeed

As a manager, you will need the following skills and experience to succeed in the role:

Experience managing a Data Science Team

A teacher of technology and business in a team setting

Demonstrated ability to mentor team members in all aspects of their duties, communications and leadership

Serve as an expert throughout the full DS product lifecycle, from inception to delivery and ongoing monitoring

University Degree in Computer Science, Math, Statistics, Physics, Actuarial Science or related field or equivalent. Masters or PhD strongly preferred

2-3 years of programming experience preferably in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.

3-5 years of experience of building machine learning models for business applications

Advanced level understanding of machine learning fundamentals and model development principles (Generalization, Bias-Variance Tradeoff, GLMs, NLMs, etc.)

3-5 years experience with ML/AI technologies, such as scikit-learn, Keras. TensorFlow, PyTorch

Experience mining IoT sensor data or Telematics data will be considered an asset

Experience with Big Data Technologies such as Spark, Databricks, Scala will be considered an asset

What sets you apart

Experience leading all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment.

Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.

Experience leading or working as part of an Agile Team

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.","Aviva
3.7",Markham
386,"Manager, Data Science","Job Description

This role will start off as work from home, gradually you will be required to work in the Markham or Toronto office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive impactful decisions. The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. This team is exploring the frontiers of the insurance business such as how to harness the data from connected cars to deliver new types of products to customers. This exciting role is at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

As a Data Science Manager, you will lead a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will lead the development of machine-learning and statistical models for practical applications that impacts millions of customers. You will manage and guide your peers in novel approaches and provide peer review for their work.

What you’ll do

Lead a squad of Actuaries, Data Scientists and Engineers in the development of meaningful conclusions and recommendations

Oversee the development of high performing machine learning and statistical models on very large datasets

Oversee the development of novel algorithms and innovative data-driven solutions to solve business problems

Help the team excel in the assigned business domain

What you need to succeed

As a manager, you will need the following skills and experience to succeed in the role:

Experience managing a Data Science Team

A teacher of technology and business in a team setting

Demonstrated ability to mentor team members in all aspects of their duties, communications and leadership

Serve as an expert throughout the full DS product lifecycle, from inception to delivery and ongoing monitoring

University Degree in Computer Science, Math, Statistics, Physics, Actuarial Science or related field or equivalent. Masters or PhD strongly preferred

2-3 years of programming experience preferably in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.

3-5 years of experience of building machine learning models for business applications

Advanced level understanding of machine learning fundamentals and model development principles (Generalization, Bias-Variance Tradeoff, GLMs, NLMs, etc.)

3-5 years experience with ML/AI technologies, such as scikit-learn, Keras. TensorFlow, PyTorch

Experience mining IoT sensor data or Telematics data will be considered an asset

Experience with Big Data Technologies such as Spark, Databricks, Scala will be considered an asset

What sets you apart

Experience leading all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment.

Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.

Experience leading or working as part of an Agile Team

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.","Aviva
3.7",Markham
387,Data Engineer - TW,"The role is going to be Data Engineer with our client Thoughtworks.

Please find below the job description for the position. Please send the following documents to hr@smsoftconsulting.com if that interests you and matches your profile.

Without mandatory documents, we cannot submit a candidate.

1. Updated Resume in word format (Mandatory)
2. Skill Summary (Mandatory)

Duration: 6 months Contract with a possibility of extension.

Job Description:

Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.

You’ll spend time on the following:

You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process

Here’s what we’re looking for:

You have a good understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you can build and operate data pipelines, and maintain data storage, all within distributed systems
Assure effective collaboration between ThoughtWorks’ and the client’s teams, encouraging open communication and advocating for shared outcomes




YTrIdv9RRz","S M Software Solutions Inc
5.0",Midtown Toronto
388,Data Engineer,"We are looking for a data engineer to handle all our data operations. The hire will be responsible for collecting data, as well as connecting sources and providing data analysis for cross functional teams. The ideal candidate must be self-directed and capable of supporting the data needs across our marketing platforms.

This position is 100% remote and only eligible for those who are authorized to work in Canada.

Key Responsibilities
Create MySQL queries to retrieve metrics from our database
Work with BigQuery to create a data pipeline
Use tray.io to fetch, unify and push data
Create dashboards in our BI tool
Manage properties from intercom and Hubspot that need to be fetched and pushed
Create a system to monitor and keep data organized
Job Benefits
Profit-sharing, distributed 3 times a year
Frequent promotions
3 weeks vacation and paid sick days
Happy Hour every Friday
Extended health benefits
Continued education allowance
Annual fitness allowance
Work from anywhere in the world
Join a bootstrapped, product-focused, & customer-oriented team
Minimum 3+ years of data experience, ideally with SaaS
Experience with MySQL & BigQuery
Experience creating dashboards in a BI tool
Experience creating workflows
Experience using Tray.io (nice to have)
College / university degree
About AgencyAnalytics

AgencyAnalytics is a reporting platform that helps digital agencies automate their client reporting.




We have been in business since 2010, are 100% employee-owned, and are growing fast.




On top of being obsessed with building the best product possible and helping our customers succeed, we also pride ourselves on our company culture. From weekly happy hours, employee of the month awards, profit sharing, fitness allowances, and continued learning...we’re always looking for ways to take care of our team.




For anyone looking to continue building their career in SaaS, this is an opportunity to join a team that is dedicated to building a company you’ll want to stay at for years to come.




AgencyAnalytics is an equal opportunity employer. We are committed to providing an environment of mutual respect where equal opportunities are available to all applicants regardless of race, color, religion, sex, age, marital status, gender identity, and any other characteristic protected by applicable law. We celebrate diversity and are committed to an inclusive environment among our team.","AgencyAnalytics
4.4",Remote
389,Data Engineer,"Like the idea of supporting company-wide decisions?

Then Jobber might be the place for you! We're looking for a Data Engineer to be part of our Business Technology team in our Business Operations ( BizOps) Department.

Jobber exists to help people in small businesses be successful. As featured in the Globe and Mail , we work with home and field service companies to help them better quote, schedule, invoice and collect payments from their customers. Having been named the #2 fastest growing software company in Canada and one of Fast Company's Most Innovative Companies in 2020 , it's clear we've come a long way from our first customer in 2011 – but we've just scratched the surface of what we want to accomplish for our customers .

The team:
Business Technology is the engineering team within Business Operations, our internal consulting department - they're the decision support mechanism that connects data, business insights and an internal tech stack (systems) with the rest of the organization. In essence, BizOps is a central function that exists to drive business outcomes in all corners of Jobber's ecosystem.

The role:
Reporting to the Senior Manager, Business Technology, the Data Engineer will work on our Business Technology team which develops internal software, integrations and data infrastructure. Our work unlocks improved operational outcomes, workflow efficiencies and new business insights across our organization. We help teams leverage data, tools and technology in order to successfully execute on their own mandates. We research, develop and maintain systems which support other internal teams from an operational and analytical perspective.

We're looking for people who are ready for their next challenge, and want to use their experience to influence people, processes and decisions.

The Data Engineer will

Build the foundation of our growth. Design, build and maintain batch and real time data pipelines in cloud infrastructure (preferably AWS). Build scripts, tools, serverless applications and workflows.
Set up our internal teams for success. Internal process improvements such as automating manual processes, building alerting/monitoring tools. Collaborate closely with other teams to build tools, frameworks, reports to run experiments, analyze A/B test results, enable insights.
Be a business accelerator. Work with analysts, data scientists and product teams to extract actionable insights from data that shape the direction of the company.
Participate in strategic planning. Lead initiatives to research, analyze and propose new technologies and tooling for our data engineering stack. Participate in design and code reviews - learn from your peers and teach your peers. Solve problems with technology and make decisions backed by data.

To be successful, you should have:
3+ years of experience as a Data Engineer or a similar role
Experience in developing and maintaining data pipelines for ETL/ELT processes
Experience with data collection and ingestion from external sources, and optimizing data flow between different systems and environments
Experience in analytics data modelling and data warehousing in the cloud (preferably AWS Redshift)
Proficient in SQL including query performance debugging and tuning skills.
Solid coder with Javascript, Python and Bash
Familiar with BI tools
Experience in developing and operating high-volume, high-available and scalable environments
Strong communication skills, with the ability to collaborate with both non-technical and technical team members.

It would be really great (but not a deal-breaker) if you had:
Experience working in Agile Scrum environment
Using templated SQL in your ETL pipeline (eg. DBT)
Experience with Integrations, APIs and working within their limitations.

What you can expect from Jobber:
Having been named #8 on the Top 10 Best Workplaces in Canada by Great Place to Work , we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums, RRSP matching, and stock options.
A dedicated Learning and Development function, including Development Coach, to help you reach your career goals and fullest potential.
Support for your breaks: from three weeks vacation to rest and recharge, your birthday off, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and make an impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring.

A bit more about us:
Job by job, we're transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We're bringing tens of thousands of people together with technology to deliver over $6-billion a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they're successful we all win!","Jobber
4.5",Edmonton
390,Data Engineer,"Like the idea of supporting company-wide decisions?

Then Jobber might be the place for you! We're looking for a Data Engineer to be part of our Business Technology team in our Business Operations ( BizOps) Department.

Jobber exists to help people in small businesses be successful. As featured in the Globe and Mail , we work with home and field service companies to help them better quote, schedule, invoice and collect payments from their customers. Having been named the #2 fastest growing software company in Canada and one of Fast Company's Most Innovative Companies in 2020 , it's clear we've come a long way from our first customer in 2011 – but we've just scratched the surface of what we want to accomplish for our customers .

The team:
Business Technology is the engineering team within Business Operations, our internal consulting department - they're the decision support mechanism that connects data, business insights and an internal tech stack (systems) with the rest of the organization. In essence, BizOps is a central function that exists to drive business outcomes in all corners of Jobber's ecosystem.

The role:
Reporting to the Senior Manager, Business Technology, the Data Engineer will work on our Business Technology team which develops internal software, integrations and data infrastructure. Our work unlocks improved operational outcomes, workflow efficiencies and new business insights across our organization. We help teams leverage data, tools and technology in order to successfully execute on their own mandates. We research, develop and maintain systems which support other internal teams from an operational and analytical perspective.

We're looking for people who are ready for their next challenge, and want to use their experience to influence people, processes and decisions.

The Data Engineer will

Build the foundation of our growth. Design, build and maintain batch and real time data pipelines in cloud infrastructure (preferably AWS). Build scripts, tools, serverless applications and workflows.
Set up our internal teams for success. Internal process improvements such as automating manual processes, building alerting/monitoring tools. Collaborate closely with other teams to build tools, frameworks, reports to run experiments, analyze A/B test results, enable insights.
Be a business accelerator. Work with analysts, data scientists and product teams to extract actionable insights from data that shape the direction of the company.
Participate in strategic planning. Lead initiatives to research, analyze and propose new technologies and tooling for our data engineering stack. Participate in design and code reviews - learn from your peers and teach your peers. Solve problems with technology and make decisions backed by data.

To be successful, you should have:
3+ years of experience as a Data Engineer or a similar role
Experience in developing and maintaining data pipelines for ETL/ELT processes
Experience with data collection and ingestion from external sources, and optimizing data flow between different systems and environments
Experience in analytics data modelling and data warehousing in the cloud (preferably AWS Redshift)
Proficient in SQL including query performance debugging and tuning skills.
Solid coder with Javascript, Python and Bash
Familiar with BI tools
Experience in developing and operating high-volume, high-available and scalable environments
Strong communication skills, with the ability to collaborate with both non-technical and technical team members.

It would be really great (but not a deal-breaker) if you had:
Experience working in Agile Scrum environment
Using templated SQL in your ETL pipeline (eg. DBT)
Experience with Integrations, APIs and working within their limitations.

What you can expect from Jobber:
Having been named #8 on the Top 10 Best Workplaces in Canada by Great Place to Work , we walk the talk. Here are just some of the great things you can expect from us:

A total compensation package that includes an extended health benefits package with fully paid premiums, RRSP matching, and stock options.
A dedicated Learning and Development function, including Development Coach, to help you reach your career goals and fullest potential.
Support for your breaks: from three weeks vacation to rest and recharge, your birthday off, and parental leave top-ups to support your growing family.
A unique opportunity to build, grow, and make an impact on a $400-billion industry that has no dominant player...yet.
To work with a group of people who are humble, supportive, and give a sh*t about our customers.

We believe that diverse teams perform better and that fostering an inclusive work environment is a key part of growing a successful team. We welcome people of diverse backgrounds, experiences, and perspectives. We are an equal opportunity employer, and we are committed to working with applicants requesting accommodation at any stage of the hiring.

A bit more about us:
Job by job, we're transforming the way service is delivered. Your lawn care provider, home cleaning service, plumber or painter could use Jobber to better connect with their customers, save time in the office, invoice faster, and get paid! We're bringing tens of thousands of people together with technology to deliver over $6-billion a year in services to happy customers. Jobber exists to help make these small businesses successful, and when they're successful we all win!","Jobber
4.5",Edmonton
391,Data Engineer,"We are looking for a data engineer to handle all our data operations. The hire will be responsible for collecting data, as well as connecting sources and providing data analysis for cross functional teams. The ideal candidate must be self-directed and capable of supporting the data needs across our marketing platforms.

This position is 100% remote and only eligible for those who are authorized to work in Canada.

Key Responsibilities
Create MySQL queries to retrieve metrics from our database
Work with BigQuery to create a data pipeline
Use tray.io to fetch, unify and push data
Create dashboards in our BI tool
Manage properties from intercom and Hubspot that need to be fetched and pushed
Create a system to monitor and keep data organized
Job Benefits
Profit-sharing, distributed 3 times a year
Frequent promotions
3 weeks vacation and paid sick days
Happy Hour every Friday
Extended health benefits
Continued education allowance
Annual fitness allowance
Work from anywhere in the world
Join a bootstrapped, product-focused, & customer-oriented team
Minimum 3+ years of data experience, ideally with SaaS
Experience with MySQL & BigQuery
Experience creating dashboards in a BI tool
Experience creating workflows
Experience using Tray.io (nice to have)
College / university degree
About AgencyAnalytics

AgencyAnalytics is a reporting platform that helps digital agencies automate their client reporting.




We have been in business since 2010, are 100% employee-owned, and are growing fast.




On top of being obsessed with building the best product possible and helping our customers succeed, we also pride ourselves on our company culture. From weekly happy hours, employee of the month awards, profit sharing, fitness allowances, and continued learning...we’re always looking for ways to take care of our team.




For anyone looking to continue building their career in SaaS, this is an opportunity to join a team that is dedicated to building a company you’ll want to stay at for years to come.




AgencyAnalytics is an equal opportunity employer. We are committed to providing an environment of mutual respect where equal opportunities are available to all applicants regardless of race, color, religion, sex, age, marital status, gender identity, and any other characteristic protected by applicable law. We celebrate diversity and are committed to an inclusive environment among our team.","AgencyAnalytics
4.4",Remote
392,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
393,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
394,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
395,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
396,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
397,"Data Engineer, Analytics and Business Planning - Canadian Business Banking","Requisition ID: 108086

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics and Business Planning – Canadian Business Banking


Purpose


Contributes to the overall success of Business Intelligence and MIS in Canadian Business Banking ensuring specific individual goals, plans, initiatives are executed / delivered in support of the team’s business strategies and objectives. Ensures all activities conducted are in compliance with governing regulations, internal policies and procedures.

Supports development, ongoing management and enhancement of Business Banking data infrastructure to enable development and management of Business Intelligence, Business analytics and Data Science vision for the Business Bank.

This role sits at the intersection of Business and Technology and provides the successful candidate the opportunity to make their mark on the operations of a large international bank. This position is well suited to someone who has a strong analytical background, who is looking to grow in thought leadership and who will use their knowledge and skill sets to have an impact on the organization.

Accountabilities:


Champions a customer focused culture to deepen client relationships and leverage broader Bank relationships, systems and knowledge.
Supports the development and management of database and Business Intelligence for Business Banking


 Build data architecture for Business Banking
 Develop new or enhance features across the platform: data pipelines, new datasets, efficient interfaces, and interactive visualizations using Business Intelligence tools such as Power BI and Tableau
 Architect the generation of powerful datasets to bring successful analytics to market
 Ensure data architecture encompasses all business lines and segments for Business Banking, 30+ source systems as well as all data dimensions including but not limited to client demographics, balance sheet & revenue information, operational & sales activity data
 Learn the business strategy and generate ideas for insightful tools

Ensure data integrity and timely availability of data for generation of accurate and timely Business Intelligence and analytics


 Ensure data ingested and produced in the database has gone through rigorous data integrity checks including but not limited to comparison against financial reporting systems
 Work with data users to ensure datasets produced are meet their analytic needs
 Ensure data is available on a timely basis for generation of daily, weekly, monthly Business Intelligence as well as adhoc analytic needs
 Enable quick speed to market for new data needs for the Business Bank

Manage hardware environment and analytical playground for the Business Bank


 Manage hardware environment and software requirement for the database
 Ensure analytic environment supports high powered computing, multiple software applications, multi-tenancy, data storage, data backup and other infrastructure needs for the analytics team

Bring cutting edge data solutions and next generation technology to Scotiabank


 Keep abreast with latest database technology and data solutions
 Actively bring new cutting edge solutions to Scotiabank

Understands how the Bank’s risk appetite and risk culture should be considered in day-to-day activities and decisions.

Actively pursues effective and efficient operations of his/her respective areas in accordance with Scotiabank’s Values, its Code of Conduct and the Global Sales Principles, while ensuring the adequacy, adherence to and effectiveness of day-to-day business controls to meet obligations with respect to operational, compliance, AML/ATF/sanctions and conduct risk.


Educational Requirements:


Bachelor’s degree in Computer Science or related field or relevant experience
Master’s degree in Computer Science – preferred

Experience:


5+ years of data engineering and software experience in a Banking environment required
Strong Communication skills for Internal stakeholder collaboration
Experience with large data sets and working with Hadoop, NoSQL databases, and/or graph databases
Experience with Python and/or Scala
Hands-on development in a distributed data environment an asset
Experience with RDBMs, Cassandra, HDFS, and/or graph databases an asset
Detailed experience in the following: Unix, Mainframe, SQL, SAS, other programming tools
Experience with Business Intelligence Tools: Power BI, Tableau
Advanced Proficiency with Excel (charts/graphs)
Previous banking experience is an asset

Skills:


Excellent verbal and written communication skills are required
Strong prioritizing and analytical skills
High degree of knowledge of commercial products and profit drivers
The role requires a high degree of collaboration across wide ranging groups: Global Banking & Markets (GBM); GBP; Finance, Wealth Management, Retail Small Business, and various Business Banking areas. Works with various partners using influence and negotiation skills to ensure objectives are met.
Strong technical skills in Math, Computer Science or related fields
Excellent design and delivery capabilities


Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
398,Data Engineering Intern (Fall 2021) - Toronto,"Are you ready to join a team of tech-savvy music lovers and thrive in an exciting, fast-paced, and innovative work environment?

Our team is currently looking for a Data Scientist to contribute on a variety of products, related to in-store music and digital experiences, broadcast and connected TV channels and our different product applications.

As part of the brand-new Data Science and Artificial Intelligence Team at Stingray, your mission will be to contribute to the organic growth of all of Stingray’s products. In collaboration with the product team and the development teams, you will find new and creative ways to improve Stingray’s products by using the latest AI technologies. Using a data-first approach, you will help find growth opportunities and propose innovative solutions to improve Stingray’s line of products.

What you’ll do

Analyze large datasets to find patterns.
Find opportunities in data and propose improvements to products.
Implement, train, and validate Machine Learning models.
Create dashboards and visualizations to communicate results.
Assist data engineers and software developers to integrate trained models into Stingray products.

Who you are

Degree in Data Science, Computer Science, or similar.
Experience in Python and common data science toolkits: NumPy, Pandas, etc.
Experience with machine learning frameworks such as TensorFlow, Keras, PyTorch.
Proficiency in SQL and relational databases.
Knowledge of big data processing frameworks and ETL languages: Google Cloud Dataflow, Apache Beam, Java.

Benefits

Share purchase plan (with a contribution from Stingray);
Breakfasts and snacks offered every day;
On-site cafeteria offering lunches at a very reasonable price;
Generous contribution by Stingray to the CDM GYM fees;
On-site free yoga lessons offered twice a week;
And much more!

Stingray’s offices are located in the Old Port of Montreal just minutes from the Lachine Canal bike path, a prime location for picnics or a jogging at lunch time. We are a young, energetic company committed to the well-being of our employees and who ensures it through benefits such as breakfasts, snacks, coffee for all tastes, free treats and 5@7 Fridays. We also have access to virtual health care! What else to say?

If you are looking for an exceptional workplace and have what it takes to fill this role, please send us your resume at jobsdev@stingray.com.

Not the job for you? Check out our Careers page to consult other available positions and learn more about Stingray. We’re always on the lookout for new talent.

Stingray supports the principles of Employment Equity and is committed to ensuring our workforce is representative of the communities we serve and in which we operate. Women, Aboriginal peoples, persons with disabilities and visible minorities are encouraged to apply and to self-identify so we can work towards full representation of those groups within our company.","Coursera
3.9",Remote
399,"Educator, Data Scientist","BrainStation is a global leader in digital skills training and development, offering a 12-week Diploma program in Data Science. BrainStation is currently seeking a Data Science professional to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities

Lead our 12-week Data Science Diploma program

Help build a world class technical team

Deliver lectures and mentor the next wave of Data Science talent

Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses

Actively work on writing and researching new content to teach the most up to date skills in data science to our students

Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students

Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material

Define the education experience of the future

Successful candidates will have

3+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years experience as a Data Scientist or Analytics professional

Experience building and leading teams

Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles

Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner

Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job

An empathetic, friendly, and approachable demeanor

A proven ability to work under pressure and meet deadlines

About BrainStation

BrainStation is the global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, London, Toronto, and Vancouver. Founded in 2012, BrainStation has worked with over 400 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 100,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.


Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings .
NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.",BrainStation,Vancouver
400,Data Engineer,"Build resilient systems at scale with high velocity and high-volume data flows.
Champion the practice of data democratization.
Reimagine the way we source, process, contextualize, and model our data.
Build near-real-time streaming pipelines.
Implement event-driven data ingestion methodologies with Snowflake.
Build ELT processes.

MPI does not discriminate on the basis of race, religion, sex, sexual orientation, gender identity or expression, age, disability, marital status, or based on an individual's status in any group or class otherwise protected under applicable human rights legislation. MPI encourages applications from minorities, women, the disabled and all other qualified applicants

3+ years of experience in the development and evolution of modern data pipelines, business intelligence, and advanced analytics applications.
Experience with ETL/ ELT software such as SSIS, Talend, Informatica, Snowpipe, 5tran or other preferred.
Experience working with large datasets (one or more terabytes) and volumes (millions or billions of transactions per day).
Experience in the full data pipeline, from extraction to grooming, modeling, loading, and dashboarding/BI.
Experience with data structures, encodings, and storage formats and the tradeoffs between the options.
Fluency in data modeling and warehousing.

A Leading High-Growth Start-up

A Competitive Package","Michael Page CA
3.6",York Mills
401,Data Engineer,"On the Data Engineer skillsets, here are the must have skills:

Azure Data Factory
Azure Data Lake
Azure Kubernetes
Azure Blob Storage
Azure Databtricks (delta)
SQL
Python/C#

Nice to Have:

Azure Event Hub
Azure IoT Hub
Azure DevOps
Computer Science and Statistics backgrounds will be a huge bonus to the work we do for Turing

""IMPJOB""

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

Experience:

Data Engineer: 8 years (preferred)","Michael Page CA
3.6",Calgary
402,Data Engineer - TW,"The role is going to be Data Engineer with our client Thoughtworks.

Please find below the job description for the position. Please send the following documents to hr@smsoftconsulting.com if that interests you and matches your profile.

Without mandatory documents, we cannot submit a candidate.

1. Updated Resume in word format (Mandatory)
2. Skill Summary (Mandatory)

Duration: 6 months Contract with a possibility of extension.

Job Description:

Data Engineers develop modern data architecture approaches to meet key business objectives and provide end-to-end data solutions. You might spend a few weeks with a new client on a deep technical review or a complete organizational review, helping them to understand the potential that data brings to solve their most pressing problems. On other projects, you might be acting as the architect, leading the design of technical solutions, or perhaps overseeing a program inception to build a new product. It could also be a software delivery project where you're equally happy coding and tech-leading the team to implement the solution.

You’ll spend time on the following:

You will partner with teammates to create complex data processing pipelines in order to solve our clients’ most ambitious challenges
You will collaborate with Data Scientists in order to design scalable implementations of their models
You will pair to write clean and iterative code based on TDD
Leverage various continuous delivery practices to deploy, support and operate data pipelines
Advise and educate clients on how to use different distributed storage and computing technologies from the plethora of options available
Develop and operate modern data architecture approaches to meet key business objectives and provide end-to-end data solutions
Create data models and speak to the tradeoffs of different modeling approaches
Seamlessly incorporate data quality into your day-to-day work as well as into the delivery process

Here’s what we’re looking for:

You have a good understanding of data modelling and experience with data engineering tools and platforms such as Kafka, Spark, and Hadoop
You have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, Oozie, and Airflow in a production setting
Hands on experience in MapR, Cloudera, Hortonworks and/or cloud (AWS EMR, Azure HDInsights, Qubole etc.) based Hadoop distributions
You are comfortable taking data-driven approaches and applying data security strategy to solve business problems
You’re genuinely excited about data infrastructure and operations with a familiarity working in cloud environments
Working with data excites you: you can build and operate data pipelines, and maintain data storage, all within distributed systems
Assure effective collaboration between ThoughtWorks’ and the client’s teams, encouraging open communication and advocating for shared outcomes




YTrIdv9RRz","S M Software Solutions Inc
5.0",Midtown Toronto
403,Data Engineer,"eBay Classifieds Group is an innovative leader in online classifieds. Our sites help people find whatever they’re looking for in their local communities – whether it’s a job, an apartment, a sofa, a car, a concert ticket, financial services or new friends. Every connection made or item found makes a difference by crafting a world where people share more and waste less. People who want to connect and trade visit our sites because they’re fun, easy to use and built on trust.

About the team

At eBay Classifieds Group we are re-inventing the way we approach and tackle information retrieval and findability, to transform the way we connect buyers and sellers. As a global leader in online classifieds with major properties including Kijiji.ca, Kijijiautos.ca, eBay-Kleinanzeigen.de, Mobile.de and Marktplaats.nl; the solutions of the Finding Science (FiSci) team impact millions of users across the world.

The Role

As a Data Engineer in the FiSci team, you will be instrumental in the execution of our vision, working closely with a specialized group of engineers, Machine Learning specialists and architects. Are you passionate about search technology and solving tough findability problems ? Then this role is for you!

Your primary focus will be on building and evolving Search Profiling APIs to power our local markets with real time, lightning fast search intelligence capabilities. Some of these capabilities include: Dominant Category, Popular Attributes, Trending/Popular/Related Searches and Vision.

Responsibilities:
Building mission critical search intelligence services
Prototyping and researching solutions to problems as part of product discovery and scoping
Productionizing ML solutions in Spark and Tensorflow collaboratively with ML specialists, and fellow engineers
Refining, scoping and guiding requirements with product managers
Presenting and communicating internally and sometimes externally at meetups and hosted events
Active participation in continuous improvement of FiSci's engineering processes and infrastructure
Mentoring and coaching more junior engineers and participating in code and design reviews
Travelling within Europe and the United States to assist with technical integrations and search initiatives
Minimum Qualifications:
B.Sc. or M.Sc. in Computer Science or equivalent
Demonstrated ability to learn new problem domains and technologies
Proficient in Java and Linux environments
Strong foundation in Web programming and application data formats and protocols
Well versed in micro-service architectures and concepts such as service discovery, chassis, bounded contexts, and load balancing
Basic knowledge of Machine Learning concepts in supervised and unsupervised learning
Comfortable debating ideas with others to arrive at sound decisions
Preferred Qualifications:
Professional experience in the eCommerce domain
Previous experience developing data driven platforms and use cases at scale
Professional experience with Scala, Docker and Python
Proficiency working with Big Data & ML systems such as Hadoop/Spark & Keras/Tensorflow
Benefits

Benefits are an essential part of your total compensation for the work you do every day. Whether you’re single, in a growing family, or nearing retirement, eBay offers a variety of comprehensive and competitive benefit programs to meet your needs.

We create opportunities for others by connecting people from widely diverse groups of backgrounds, perspectives and geographies. Being diverse and inclusive isn’t just something we strive for, it is who we are! We want to ensure that as an employee, you feel eBay is a place where, no matter who you are, you feel safe, included, and that you have the opportunity to bring your unique self to work. To learn about our Diversity & Inclusion click here: https://www.ebayinc.com/company/diversity-inclusion/

Covid-19

People are the heart of the eBay Classifieds business, and their health and well-being are our first priority.

We continue to monitor local government guidance and partner closely with medical advisors to determine the safest and best next steps for everyone. As a result, most teams are working remotely, with a few teams able to collaborate in person with enhanced safety procedures. We will discuss the particular case for your region during the interview process. As a general rule, interviews will be completed remotely over video calls.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.","eBay Inc.
4.0",Midtown Toronto
404,Data Engineer,"Company Description


Wish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.



Job Description


Our engineers move extremely fast, while solving unique and challenging problems. Our team is small and nimble. We release every day to ensure that engineers are able to iterate quickly, and make an impact immediately. We’re looking for engineers to work on our massive semi-structured datasets.

You'll develop software to process, transform and analyze the data to identify signals from billions of events we collect every day. You'll provide insights that improve the experience of hundreds of millions of users worldwide. You should be results-driven, highly motivated, and have a track record of using data analytics to drive the understanding, growth, and success of a product.

What you'll be doing:

Design and Develop data collecting and processing systems to handle large data sets. You’ll have the opportunity to design innovative data solutions and solve challenging problems.
Design, Develop and Support highly-parallel, and fault-tolerant applications.
Build and integrate scalable backend systems, services, platforms, and tools
Contribute to the design and code of complex data pipelines operating on production data
Optimize current approaches to efficiently handle ever-increasing volumes of data
Build proof of concept using modern technologies and convert them into production-grade implementation.
Create best-practice reports and dashboards based on data mining, analysis, and visualization


Qualifications

5 + years of experience as a Software Engineer or Data Engineer using Python, java or any other programming language
Expertise with SQL and data storage systems
Experience and knowledge of modern data warehouse, pipeline and reporting/analytic techniques and tools such as Airflow, Presto/Hive, Spark, or any other scheduling frameworks, Tableau or other reporting tools
Experience working on Amazon Web Services or other cloud computing platforms
Bachelor's degree in Computer Science or related field.

Preferred Qualifications:

Experience in data visualization a plus.

#LI-BD1


Additional Information


Wish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.","Wish
3.3",Midtown Toronto
405,Scientist - Synthetic Organic /Medicinal Chemistry,"About adMare BioInnovations:




adMare BioInnovations is Canada’s global life sciences venture, building the Canadian life sciences industry from sea to sea. We do this by sourcing therapeutically and commercially promising research from leading academic and biotech partners to create new companies of scale, providing specialized expertise, infrastructure, and capital to help existing companies scale up, and driving the growth of those companies into Canadian anchors by training the next generation of highly qualified personnel. adMare’s ~20 portfolio companies have attracted more than $1.2B of investment and have a combined worth of over $3B.




Job Summary:




We are seeking highly motivated PhD and MSc level synthetic organic and/or medicinal chemists to join our drug discovery team. Scientists positions are available to join our Montreal facility. Highly qualified individuals are expected to have experience in modern organic synthesis with good laboratory skills and a record of high productivity. Key requirements of the role include being able to work within a team structure, propose new targets, execute synthetic routes, engage in troubleshooting exercises as needed, and effectively communicate with biology, pharmacology and DMPK colleagues.


Scientists will be expected to work with a high degree of independence with a proficiency at interpreting SAR and ADME data and developing a research strategy to advance projects to meet key milestones. Responsibilities may include the design and synthesis of small molecule targets within a project. Candidates should also be able to design alternative approaches to achieve desired outcomes. Scientists may also take on project leadership responsibilities, coordinate the chemistry efforts within the project, and work within a multi-disciplinary team environment.


We are a dynamic team that fosters a positive, curiosity driven culture that encourages everyone to contribute intellectually and experimentally to solving complex challenges in drug discovery. We have state-of-the-art laboratories, and we promote a cross-functional research environment where colleagues form chemistry, biology, pharmacology and DMPK work closely together to advance drug discovery projects. We offer flexible working hours, competitive salaries, bonuses and benefit package.


Key Duties and Responsibilities:




Proficiency in modern organic synthesis and ability to independently perform complex, multi-step procedures.
Experience in the purification of small molecules using a variety of methods such a flash chromatography, HPLC purification, distillation and others as needed.
Structural characterization of small molecules using modern spectroscopic instruments and techniques such as LC-MS, 1 and 2D NMR methods and others.
Contributes signiﬁcantly to patent and/or publication preparation.
Excellent communication skills, both written and oral, and able to effectively communicate with diverse audiences.
Independently prepares project presentations and presents experimental conclusions at Group/Department or Project Team research meetings.
Stays abreast of scientific literature and incorporates new methods and technologies in his/her research.
Demonstrated ability to analyze and interpret DMPK and biological data and to establish chemistry and project strategies as needed.
Project leadership experience and ability to effectively lead a chemistry research team.



Education and Experience:




Ph.D. in chemistry and 5+ years of relevant experience in a drug discovery organization, or
Master’s Degree (in chemistry or related science and 8+ years of relevant employment experience



At adMare, we are driven by our vision and united by our shared values of Courage, Collaboration, Objectivity, Judgment, Excellence, and Reach.




We are committed to growing the talent and potential of our people to drive the development of innovations. We provide a community where you can work with multidisciplinary individuals, explore new ways of thinking, and expand your capabilities through the array of development programs we offer our employees.




adMare is a diverse community where employees feel a sense of belonging and are valued for the experience and unique perspectives they bring.




Be a part of life at adMare. Join our team!


À propos d’adMare BioInnovations:




adMare BioInnovations est le partenaire d’affaires en sciences de la vie au Canada, en soutien à l’industrie d’un océan à l’autre. Pour ce faire, nous identifins auprès de partenaires académiques et biotechnologiques de premier plan les découvertes les plus prometteuses sur les plans thérapeutique et commercial afin de créer de nouvelles entreprises d’envergure. Nous fournissons une expertise et les infrastructures adéquates dans le but d’aider les entreprises existantes à se développer, en favorisant leur croissance afin qu’elles deviennent des piliers canadiens tout en formant la prochaine génération de personnel hautement qualifié. Le portefeuille d’adMare, qui compte près de 20 sociétés, a généré plus de 1,2 milliard de dollars d’investissements et représente une valeur totale de plus de 3 milliards de dollars.




Résumé du poste :




Nous sommes à la recherche de chimistes organiques synthétiques et/ou médicinaux possédant un doctorat ou une maîtrise en sciences qui aimeraient faire partie de notre équipe de recherche de médicaments. Des postes de scientifiques disponibles sont offerts dans nos installations de Montréal. Les individus très qualifiés devraient posséder une expérience en synthèse organique moderne et des aptitudes marquées en laboratoire en plus d’avoir démontré une capacité de productivité élevée. Les principales exigences du poste consistent, entre autres, à pouvoir fonctionner au sein d’une équipe, à proposer de nouvelles cibles, à suivre une voie de synthèse, à participer à des exercices de diagnostic des pannes en fonction des besoins et à communiquer de manière efficace avec les collègues dans les domaines, comme la biologie, la pharmacologie, ainsi que le métabolisme des médicaments et pharmacocinétique.


Les scientifiques devront faire preuve d’un niveau élevé d’indépendance et maîtriser l'interprétation des données sur les rapports structure-activité et les données des études absorption-distribution-métabolisme-excrétion en élaborant une stratégie de recherche pour faire avancer les projets de manière à atteindre les jalons importants. Les responsabilités peuvent comprendre la conception et la synthèse des petites molécules ciblées dans le cadre d’un projet. Les candidats devraient aussi être en mesure d’élaborer des approches alternatives pour atteindre les résultats désirés. Les scientifiques peuvent également assumer des responsabilités en matière de leadership des projets, coordonner les efforts chimiques dans le cadre du projet et collaborer dans un environnement d'équipe multidisciplinaire.


Nous sommes une équipe dynamique qui favorise une culture positive et axée sur la curiosité en plus d’encourager tout un chacun à contribuer sur le plan intellectuel et par des expériences à relever des défis complexes dans le domaine de la découverte des médicaments. Nous possédons des laboratoires ultramodernes et nous encourageons un environnement de recherche interfonctionnel où les collègues des domaines, comme la chimie, la biologie, la pharmacologie et le métabolisme des médicaments et pharmacocinétique, travaillent en étroite collaboration pour favoriser les projets de recherche de médicaments. Nous offrons des heures de travail flexibles, des salaires concurrentiels, des bonis et un programme d'avantages sociaux.


Tâches et responsabilités principales :




Maîtrise de la synthèse organique moderne et capacité de réaliser de manière indépendante des procédures complexes comportant plusieurs étapes.
Expérience dans la purification de petites molécules en ayant recours à des méthodes variées, comme la chromatographie rapide sur colonne, la purification CLHP, la distillation et autres en fonction des besoins.
Caractérisation structurale des petites molécules en faisant appel à des instruments et des techniques de spectroscopie modernes, comme les méthodes LC-MS 1 et RMN 2D.
Contribuer grandement à la préparation des brevets et/ou des publications.
Aptitudes excellentes pour la collaboration écrite et orale et capacité de communiquer de manière efficace avec des publics variés.
Préparer de manière indépendante des présentations de projet et présenter les conclusions des expériences lors des réunions de groupe/service ou des réunions de recherche des équipes de projet.
Suivre l’actualité dans la documentation scientifique et intégrer les méthodes et les technologies nouvelles à ses recherches.
Capacité démontrée d’analyser et d’interpréter les données sur le métabolisme des médicaments et la pharmacocinétique, ainsi que les données biologiques pour établir des stratégies dans le domaine de la chimie et dans le cadre des projets.
Expérience en matière de leadership de projets et capacité de diriger de manière efficace une équipe de recherche dans le domaine chimique.



Éducation et expérience:




Doctorat en chimie et au moins 5 années d'expérience au sein d’une organisation s’occupant de la découverte de médicaments; ou
Maîtrise en chimie ou dans une science connexe et au moins 8 années d'expérience dans un emploi pertinent.



Chez adMare, nous sommes motivés par notre vision et unis par nos valeurs communes que sont le courage, la collaboration, l’objectivité, le jugement, et l’excellence.


Nous sommes déterminés à accroître le talent et le potentiel de nos employés lorsqu’il s’agit de promouvoir l'innovation. Nous offrons une communauté où vous pourrez évoluer aux côtés d’employés multidisciplinaires, explorer de nouvelles méthodes de réflexion et accroître vos capacités grâce à l’éventail des programmes de perfectionnement que nous offrons à nos employés.


adMare est un univers diversifié où les employés éprouvent un sentiment d’appartenance et où ils se sentent valorisés en raison de l'expérience et des points de vue uniques qu’ils apportent.


Venez participer à la vie chez adMare. Faites partie de notre équipe!","adMare BioInnovations
3.7",Montreal
406,Data Engineer,"Toronto, ON

MediaNet is a digital consultancy purpose-built to help our clients integrate media, data and technology to drive growth, improve efficiency and evolve the ways they work. We deliver industry-leading services and technologies to empower businesses in the areas of Marketing Intelligence, Performance Media Management and Digital Experience.

We are looking for a Data Engineer to join our growing Analytics Practice. Joining our team will feel right for you if you are passionate about turning data into capability that drives business performance. In this role, not only will you be designing, implementing and maintaining different data architectures and pipelines, you will also have the opportunity to work with internal and client stakeholders to understand data-related technical requirements and solve for their needs.

Our team will want to hear about your experience developing pipelines that drive efficiencies, and about your approach to transforming data to meet a project's needs. We'll also want you to tell us about a time when you built an automation to save yourself or someone else time.

What you'll be doing


Work with business stakeholders to understand data-related technical requirements and solve for their needs
Develop, document and maintain data pipelines
Design, document and implement ETL processes
Design, document and implement data visualizations to support self-service analytics
Write and optimize complex queries on large data sets
Transform data and map them to more valuable and understandable sets for consumption
Implement process improvements and create tooling to automate and improve the efficiency of day-to-day tasks
Troubleshoot issues related to data accuracy
Conduct research and develop new approaches and solutions to industry and client challenges
Develop your skills
Explore and analyze client data to generate insights that will improve business outcomes
Other duties and responsibilities as assigned

What you need to apply


Experience working with REST APIs and Python data analysis tools such as Pandas/Numpy
Experience building and maintaining ETL pipelines (using Python)
Experience building data visualizations using Power BI/Tableau or similar tools
A high degree of accuracy, vigilance and attention to detail
Advanced SQL knowledge
Proven ability and appetite to learn new technologies quickly
Bachelor's Degree in Computer Science, Engineering or a related technical or quantitative field
2-5 years of similar work experience
Ability to work effectively on a self-organizing team with minimal supervision
Excellent oral and written communication skills
Proactive and creative problem solver with the ability to multitask and manage tight deadlines
Excellent diagnostic, troubleshooting and data interpretation skills
GCP Cloud Architect, Data Engineer or Cloud Engineer certification
At minimum an interest in, but ideally knowledge and understanding of digital advertising and web analytics concepts
High professional standards and a commitment to service and operational excellence

What we would love to see (but not required)


Experience working with Google Cloud Platform (BigQuery, Cloud Composer, Cloud Dataflow, Cloud Pub/Sub)
Familiarity with schema design and dimensional modelling
Familiarity with Google Marketing Platform technologies

Who you are


You care about your team members and are willing to help outside your realm of expertise
No task is below you
You have strong problem-solving skills and critical thinking abilities
You take initiative communicating with co-workers and asking questions
You may not have all the answers, but you know how to get them
You enjoy a fast-paced environment and are able to pivot quickly when priorities change
You love to learn and try new things
You are able to assess both client and company needs to make good choices
You enjoy sharing knowledge with your team members

What we offer


Tight-knit, teamwork culture
Training and development
Flexible hours
Remote work options
Comprehensive benefits
Casual dress code
Team socials
Stocked office kitchen (post-Covid)
Beautiful, open, pet-friendly environment in a vibrant location (post-Covid)

Location and working conditions


While we are operating remotely, we are taking extra steps to ensure a smooth experience for new team members:

Tailored virtual onboarding
IT equipment and supplies delivered to your doorstep

About our culture


The MediaNet work environment is warm, inviting and collaborative. Everyone at MediaNet has a voice, and we encourage new ways of thinking that will lead to improved operational excellence and client success. MediaNet team members are empowered with development, support and mentoring opportunities that push critical thinking out to the edges of our organization. If you are passionate about what you do and the difference you can make in this role, then we would love to hear from you!

How to apply


Along with your resume, please apply by telling us what interests you most about this position and how you can make a difference as part of our team.

We thank all applicants for their interest, however only those candidates selected for interviews will be contacted.","MediaNet®
4.0",Midtown Toronto
407,Lead Data Scientist - RACE21,"Reporting to the Manager of Data Science as part of the RACE21 digital transformation team, the Lead Data Scientist will design, plan, develop, and deliver advanced analytics solutions as part of an integrated team to improve performance of Teck’s coal and base metals operations.

You will work closely with a variety of business and technical stakeholders to define technical problems and corresponding hypotheses, develop efficient and accurate analytical models, perform regular testing and maintenance of analytical models to improve efficiency and ensure alignment with changing business needs. This will require data exploration and preparation, modelling, implementation of the advanced analytical tools and integration into a suite of products to achieve business value.




Who You Are




You are a highly effective and customer-obsessed advanced analytics professional
You are passionate about product innovation and creating a step change leveraging the power of cloud, big data and advanced analytics
You have experience working on data-intensive projects, using modern data platforms and tools and advanced analytics methods and approaches
You are comfortable working with minimal direction and exercising considerable latitude in determining objectives and leading other data scientists



Responsibilities:




Be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures
Actively seek and assess opportunities to apply advanced analytics to optimize performance across Teck’s operations in North and South Americas
Partner with and elevate a team of data scientists, providing leadership through consulting and coaching on a regular basis
Lead end-to-end design and implementation of Machine Learning and Data Analytics solutions for 2-3 use cases at a time to optimize productivity, safety and sustainability:
Work with a variety of business stakeholders to identify and prioritize use cases
Identify, profile and analyze large, complex, multi-dimensional datasets with a variety of tools to draw relevant insights
Use data science techniques to find data patterns, anomalies and optimization opportunities through analytical solutions
Solve complex business problems by designing, developing and implementing sustainable advanced analytics solutions
Plan model operationalization and rollout of solutions to business users
Plan projects and communicate project status, emerging issues, and next steps to relevant stakeholders in the organization
Identify new ways of piloting models, actively sourcing and incorporating feedback with learnings from the field
Provide expert guidance on Teck’s data, systems and environment to external partners and vendors providing data science and data engineering services
Write highly optimized and reusable code extending our internal data science toolkit and contributing to an enterprise-wide platform for advanced analytics called Galileo
Support hiring and onboarding of new data scientists in collaboration with Manager of Data Science and HR team
Willingness to travel up to 40% of the time to Teck’s operations across North and South Americas



Key Competencies:




PhD or Master’s degree in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics or equivalent
7+ years of relevant industry work experience developing advanced analytics solutions
A deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems
Demonstrated proficiency with programming languages such as Python, R, SQL
Experience with popular machine learning frameworks, libraries and utilities
Experience with popular optimization framework and libraries (Gurobi, IBM Cplex, etc.)
Experience working with large data sets and distributed computing tools
Experience with a wide range of data collection systems including edge computing technologies
Working knowledge of at least one enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services or Google Cloud Platform
Exceptional organizational and time management skills with the ability to meet deadlines and balance multiple projects
Excellent analytical and critical thinking skills, combined with the ability to present your ideas clearly and compellingly to both technical and non-technical audiences
Demonstrated ability to work well as part of agile, multidisciplinary teams
Strong interpersonal skills and previous experience coaching and mentoring data scientists
Interest in gaining the knowledge of mining industry and systems used in engineering, operations, process control and maintenance functions
Experience or education in mineral processing, maintenance, process control or supply chain would be an asset
Experience with real-time systems that support Asset Health, Dispatch and/or Processing workflows would be an asset



At Teck, we value diversity. Our teams work collaboratively and respect each person’s unique perspective and contribution.

Qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically.

We wish to thank all applicants for their interest and effort in applying for the position; however, only candidates selected for interviews will be contacted.

Your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. Teck respects the privacy of all applicants and the confidentiality of personal information.

Teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, zinc and energy. Headquartered in Vancouver, Canada, its shares are listed on the Toronto Stock Exchange under the symbols TECK.A and TECK.B and the New York Stock Exchange under the symbol TECK.

The pursuit of sustainability guides Teck’s approach to business. Teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. In 2019, Teck was named to the Dow Jones Sustainability World Index (DJSI) for the tenth straight year, indicating that Teck’s sustainability practices rank in the top 10 per cent of the world’s 2,500 largest public companies in the S&P Global Broad Market Index.

Learn more about Teck at www.teck.com or follow @TeckResources

#LI-AN1",Teck Resources Limited,Vancouver
408,Data Engineer,"Connect with us LinkedIn, Instagram, Facebook, Twitter

Thinking about a change?

The Digital & Data Engineering division brings together the teams who enable EllisDon to leverage technology in every aspect of its business, to push beyond traditional industry positions and drive change. Our objective is simple: to be leaders in technology just as we are leaders in building. Our core values empower people to deliver great careers to one another and develop creative solutions for complex problems for our Cradle To Grave Services, Construction operation and our clients. We are a group of professionals with a variety of expertise within software engineering, product management, data management and analytics, professional services, virtual design, construction, and IT operations. To learn more, check out our Digital & Data Engineering services and hear from our team directly about what a career at EllisDon could look like for you. As you can see, we are a diverse bunch.

Above all, we are a group of individuals with unique experiences, and, at EllisDon, we choose to celebrate the strength in our differences, every day. EllisDon’s commitment to Inclusive Diversity is to work together to create an environment where every employee feels safe to be their true and authentic self. Ultimately, EllisDon’s purpose is to provide people with similar values the opportunity to achieve to their full potential; to deliver that opportunity for great careers to one another; and to contribute meaningfully to the community we share with others.

In case you’re curious, here’s what the industry thinks of us and some of the impacts we've made to the communities we work in.

You as a Data Engineer (Insight and Analytics) will:

Primarily be responsible for the delivery and availability of high quality and usable data to a variety of stakeholders and consumers across the organization;
Work with relevant stakeholders to identify sources of data and map out processes/data flow while researching opportunities for data acquisition and innovative new uses for existing data;
Design, construct, install, test, and maintain highly scalable data management systems while integrating new data management technologies and techniques into existing structures;
Develop integration processes to move internal and external data into EllisDon's external cloud-based data lake; Develop separate integration processes to move data from data lake to data warehouse(s);
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it;
Monitor and take proactive measures to ensure high availability existing pipelines and jobs;
Continually improve our data pipelines and find innovative ways to maximize automation while recommending ways to improve data reliability, efficiency, and quality.

Is this the right role for you?

Degree in Computer Science, Software Engineering, or related technical field. Minimum five (5) years of progressive experience in a similar or related role.
Proficient knowledge and extensive experience with the following:
Programming Languages: Python, Scala/Java, SQL;
Integration techniques (ETL/ELT, CDC, message-oriented data movement) and data management toolsets:
Third party (eg. Informatica);
Cloud native;
Open source (eg. Kafka, Airflow, Spark).
Cloud ecosystems (GCP, Azure, AWS) and solutions;
Data Warehousing (BigQuery, Azure Synapse), Data Storage (ALDS Gen 2, GCP Cloud Storage), Relational/Non-relational Database (MySQL, MSSQL, NoSQL (eg. MongoDB);
Data Modelling and design;
Working knowledge of concepts within the following data management domains: data governance, data architecture, security, MDM, metadata management, and data quality;
Comfortable working in a fast-paced and collaborative environment.


EllisDon is proud to provide this unique career opportunity that provides continuous learning, opportunity for growth, and a competitive compensation package within an environment that is committed to inclusion and respects diversity.

Go ahead and be yourself. We'll pay you for it!

We are an equal opportunity employer. We welcome people of any age, culture, subculture, gender identity or expression, sexual orientation, nationality, ethnicity, race, size, mental or physical status, veteran status, religion, language, political opinion, working-style preference, family status, education, and socio-economic status. The EllisDon core values of Integrity and Mutual Respect welcomes everyone, at work and in the community, and our value of Mutual Accountability, means that we all have a role to play. As an EllisDon employee, this will ultimately be your commitment to Inclusive Diversity.

Accommodation for Applicants with disabilities will be made during the recruitment process when requested.

We are committed to providing a positive candidate experience and ensuring timely updates are provided to all candidates. If you haven’t already, be sure to create a profile on our Careers page here to remain up to date on the status of your application and learn about new career opportunities as they arise.","EllisDon Corporation
4.0",Mississauga
409,Intermediate Data Engineer,"Real Estate Works

REW started as one of the largest Real Estate Newspapers of its kind anywhere in the world, circulating more than half a million copies, each with hundreds of pages, every week across Vancouver.

Today, REW.ca is the best real estate search platform in Canada, and the leading marketplace in BC with an audience twice the size of its nearest rival. It has grown by offering people simple, effective home search, augmented with relevant real estate data to empower better decision making.

But REW is more than REW.ca, it's a team of creative people, driven to improve the property process, one digital experience at a time.

Vision for the role

Data is at the heart of everything we do at REW. Every day, our data platform ingests feeds from dozens of sources to compile, composite, and augment the inventory of listings that the thousands of REW users search in their quest for the perfect home. Our listings need to be accurate, comprehensive, and highly available - or our users will go elsewhere.

Listings are only part of the puzzle. REW also tracks market behaviour to help inform our own next steps, and to empower the agents, landlords, and property developers who count on REW to give them an edge.

We are looking for a highly motivated and driven Data Engineer to join our Technology team to help us maintain REWs heart but also help us prepare for the challenges that lie ahead.

This individual would join a small team in maintaining REW’s existing platform which might include responding to upstream changes from some of our feed providers, optimizing performance to respond to increased demand, or troubleshooting integrity issues. As this individual grows in their role, they’ll earn the opportunity to take on more complex problems and own all aspects of developing end-to-end data flows including: gathering requirements, data modeling, ETL script development, and data quality control.

We work on an agile data platform built on cloud hosted databases (Amazon RDS Postgres) and data processing scripts (Python running on EC2 instances). We also use specialized services such as Google BigQuery for website event analytics.

Our Data Engineers act as key database platform technical resources, assisting with the development of the architecture, creating and executing data import & data export scripts and APIs as necessary, assessing data accuracy, and helping to ensure the ongoing data and operational integrity of the data platform.

Responsibilities

Maintaining and enhancing REW’s data platform

Debug and optimize ETL flows

Data processing, data modeling and expanding Data Platform service.

Collaborate with product development teams to provide Data Platform service to power new features

Develop reports or data visualization tools for internal use to help support the REW's sales and marketing efforts

Create visualizations and views of data to provide editorial content for information platforms

Participate in project planning and analysis as needed

Education, Skills and Experience

Minimum 2 years of professional experience with data analysis and big data tech stacks.

Bachelor of Computer Science, a similar technical degree, or equivalent experience

Proficiency in Python or a similar language for data processing with exposure to other scripting and object-oriented programming languages

Strong experience in database development and data modeling

Proven experience in one of the major cloud platforms

Strong understanding of data analysis concepts such as data visualization, dashboard design, data mining

Next Steps

If you are interested in working with a rapidly growing real estate tech company with a very well-established brand, we would very much like to hear from you.

To Apply: Please submit your cover letter and résumé to jobs@rew.ca with, “Intermediate Data Engineer”, in the subject line.


Life at REW

Mission

We believe real estate can be one of life's great adventures, and we exist to inspire and equip people for that journey.


Values

People over profits.

Profits are important, they keep the lights on, but we will not compromise the quality of our work or make ourselves miserable in pursuit of financial gain.

We solve problems.

Creativity is in our DNA, we approach problems with real enthusiasm and look for the many ways we could add value and make a positive impact on the people we serve.

The experience matters.

We do work that matters for people that care and we take pride in the work that we do. If it doesn't make the grade, we go back to the drawing board.

Adventure requires courage.

Uncertainty is part of life, we don't pull back from the edge, we take the risk and stretch ourselves. It's not only about the outcome, but the thrill that comes with the adventure of it all.

No jerks allowed, be humble.

We operate in a climate of mutual respect, and we treat each other well. We don’t elevate ideas above people, if you're a jerk then you ain't welcome here.

We show up for each other.

We hire smart people, give them great work, and treat them like adults. No matter how we each choose to approach the day, we show up when we're needed and we deliver for the team.","REW
4.3",Vancouver
410,Data Engineer,"Company Description
At Thinking Capital, we’re changing the landscape of financial technology!
Simply put, our mission is to empower Canadian small businesses through innovative financial services. At the heart of our offering is our digital experience, which is powered by our proprietary software platform, our real time connections to a multitude of data sources and our advanced data science models. We are squarely in the corner of owners and entrepreneurs, providing for them, and at the right moment, the financial support they need to grow and thrive.
We are looking for a talented Data Engineer who can bring their passion to our team!

Job Description
Where others see chaos, you see patterns and emerging structures. You have a passion for the collection, management and analysis of data to discover the patterns hidden within. You thrive on helping your teammates make sense of the data and enabling them to make effective use of the data.
As a data engineer you will be key member of our development team where your passion for data will help us design, develop and deploy our data platform, the foundation of our digital financing platform :

Data modeling, governance and stewardship
Data pipeline to support our BI, data science and machine learning activities
Maintaining data veracity and quality
Help develop and maintain ELT processes
Learn and adapt emerging data technologies and operational best practices to real problems

Qualifications*
What You Bring*

Extensive schema and data modelling experience
Development experience
Python, Pandas, Sci-Kit
Snowflake, Presto, Hive or other data warehousing technologies
Airflow, DBT
SQL
Working autonomously and being highly resourceful
Bachelors, MSC or PHD in computer science, engineering, or related field
Experience working on AWS

Other Valued Skills & Knowledge

Git or other version control systems
Security
Machine learning
Experience working with Kubernetes

Additional Information*
Why join us: *

Great Team:

Surround yourself with high-performing, energetic and passionate group of people dedicated to the Thinking Capital Mission;

FinTech Revolution:

Be part of a team that is revolutionizing the financial system and redefining how Canadian small businesses access capital;

Fast-Paced Environment:

Take on complex projects in a start-up like collaborative environment;

Amazing Culture:

Amazing work spaces, advanced technology tools and the flexibility to do your best work

Diversity of thought:

Join a team that values diversity and harmony.

Job Type: Full-time","REW
4.3",Ottawa
411,Computer scientist in Bioinformatics,"Computer scientist in Bioinformatics
My Intelligent Machines (MIMs) is looking for a highly talented computer scientist to join a dynamic team building a world-class platform for life scientists integrating bioinformatics, systems biology and AI. In this role, you will work closely with systems biologists, bioinformaticians, data scientists, AI and software engineers to build solutions for the top BioPharma and Agritech companies in the world. This full-time position will focus on workflow design, development and implementation, data visualization, quality assessment and mentoring of junior bioinformaticians in software development.
Responsibilities
Design and implement workflows using state-of-the-art bioinformatics, and biostatistics
Provide templates for data visualization for the interface and the documentationPr
Maintain MIMs common core bioinformatics libraries
Report Quality Assurance and Tests on bioinformatic and biostatistic.
Create appropriate documentation
Mentor junior team members particularly in software development
Qualifications (required)
M.Sc. or Ph.D. with 5 years of experience in Computer sciences with extensive experience in software development
At least 2 year experience in bioinformatics, biostatistics or computational biology
Experience with bioinformatics resources, databases, tools and common standard formats
Demonstrated programming skills using either Python, C++ or R in a Linux environment
Knowledge of XML, JSON and NoSQL databases
Excellent verbal and written communication skills (English/French)
Experience and enthusiasm towards mentoring junior bioinformaticians
Be highly proactive, self-motivated and detail-oriented
Demonstrated graphical representation skills would be an asset
Submission
Please submit your resume or any questions you may have to hr@mims.ai. If you are not sure you fit the requirements for this position or don't have all the qualifications, please contact us regardless.",My Intelligent Machines,Montreal
412,Senior Data Scientist,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it’s up to you.

The Role

Veeva Data Cloud is a family of data products aimed at bringing more innovative solutions and greater choice to the life sciences data market. Life sciences companies license our data to inform high-impact commercial initiatives, such as patient journey mapping, healthcare professional (HCP) targeting, and field force alignment. Veeva Data Cloud leverages software and cloud technology to develop and deliver better data, faster.

As the Senior Data Scientist for the Veeva Data Cloud team, you will be focused on designing and building our methodologies to bring Projected Data Products to life for our customers.
You are excited about statistics and data science at scale on big data and taking billions of records to tell a story, from sample curation, projection methodologies, anomaly detection, scaling approaches, clustering, and more. You design and build algorithms in a computationally efficient and statistically effective manner, while being able to keep the business problems we are working to solve in mind. While ML is an important part of your toolkit, it's not your only skill. The ability to dissect the problem and to select from a variety of techniques is key.
This is a great opportunity for someone who is excited about using their statistics and data science expertise to design and build the algorithms and models used at the core of launching Veeva’s Projected Data Products. You’ll collaborate closely with the Product Management and Engineering team to productize the methodologies and get to see enterprise Life Science customers leverage your work every day.
What You'll Do
Apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologies
Own responsibilities related to project and people leadership, including leading data scientists and analysts
Collaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale
Explore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment design
Rapidly build prototype product solutions, communicate findings, and iterate
Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved
Work with product and engineering teams to improve and implement methods and features
Master core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software
What You’ll Do
Apply statistical, machine learning, and data mining techniques to large health data sets to build new products and methodologies
Collaborate closely with a team of Data Scientists, Product Managers, Software Engineers and Data Engineers to discover and deliver product offerings from prototype to scale, then iterate and enhance
Explore and find meaning in high volumes of data, identify signals and patterns to identify relationships to infer the universe from imperfect data. Important skills include querying, data cleansing, experiment design, solution assessment, identifying scaling challenges.
Rapidly build prototype product solutions, communicate findings, and iterate
Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved
Requirements
7+ years of hands-on data science and statistics experience, demonstrating increasing responsibility and impact over time, including experience as the point person on projects
M.S. or Ph.D. in Applied Statistics, Mathematics, Computer Science, Machine Learning or other quantitative discipline
Highly proficient in Python (packages: pandas, scikit-learn, statsmodels) and SQL; experience working with AWS preferred
Experience working with large quantities of data to develop models that work in a stable, production approach with live data
Advanced knowledge of statistical analysis and data mining techniques (regression, multilevel regression, poststratification, semi-supervised learning, forecasting, decision trees, clustering, A/B testing, etc.)
Experience working with engineering to productionalize models including scaling, monitoring, and documentation
Comfortable (and excited!) about ambiguity and breaking goals down into tangible and actionable workplans
Strong communication skills and ability to work across internal teams
Perks & Benefits
Flexible PTO
Allocations for continuous learning & development
Health & wellness programs
Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.



Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
413,Développeur de données / Data Developer,"Your Privacy:
ZeniMax understands the importance of privacy. Please review the “Applicant Privacy Notice” section below, which explains how we process the personal information we collect about you when you apply for a job or submit information to us through this job portal. BY APPLYING FOR THIS JOB, SHARING THIS JOB OR OTHERWISE PROVIDING US WITH YOUR PERSONAL INFORMATION THROUGH THIS JOB PORTAL, YOU ACKNOWLEDGE THAT YOU HAVE READ AND UNDERSTOOD THE APPLICANT PRIVACY NOTICE , WHICH IS SET FORTH IN THE “APPLICANT PRIVACY NOTICE” SECTION BELOW.
Overview:
Bethesda Game Studios est à la recherche d'un développeur de données talentueux et autonome avec de solides compétences techniques pour rejoindre l'équipe qui dépasse les standards et repousse les limites du développement de jeux AAA sur les plateformes mobiles. Le développeur de données travaillera avec notre spécialiste des données et nos programmeurs pour mettre en place et maintenir des solutions de données afin de soutenir les initiatives analytiques visant à améliorer l'expérience et la performance des joueurs ainsi qu'à augmenter la rétention et la monétisation des joueurs.

Bethesda Game Studios is looking for talented and self-driven Data Developer with strong technical skills to join the team that is pushing the bleeding-edge AAA game development for mobile platforms. The Data Developer will work with our Data Scientist and programmers in building and maintaining data solutions to support analytics initiatives to improve player experience and game performance as well as increase player retention and monetization.
Responsibilities:
Construire de nouvelles structures de données et étendre les structures existantes pour prendre en charge l'analyse des jeux;
Maintenir de grandes bases de données Apache Spark de plusieurs téraoctets qui incluent l'optimisation des performances et les processus de rétention et de purge des données;
Rechercher et régler les problèmes de qualité des données, fournir des corrections et proposer des solutions à court et à long terme;
Préparer la conception des systèmes de base de données et recommander des améliorations en matière de performance;
Maintenir et développer divers scripts et outils de base de données Python / Scala pour faciliter les processus d'automatisation;
Fournir un soutien lié à toutes les initiatives de suivi des données;
Évaluer la mise en place du suivi des données dans le jeu pour toutes les demandes de propositions et aider à améliorer la structure et le schéma des rapports pour optimiser la vitesse des requêtes;
Aider les spécialistes de la science des données à rassembler les données et à construire des tables de travail pour accélérer l'analyse;
Optimiser les requêtes SQL pour améliorer la vitesse de traitement des clusters Spark.

Build new and extend existing data structures to support game analytics;
Maintain large, multi-terabyte Apache Spark databases which includes performance tuning and data retention/purge processes;
Research and troubleshoot data quality issues, providing fixes and proposing both short- and long-term solutions;
Prepare designs for database systems and recommend improvements for performance;
Maintain and develop various Python / Scala database scripts and tools to facilitate automation processes;
Provide support related to all data tracking initiatives;
Evaluate the implementation of data tracking in the game all proposals requests and assist to improve the logs structure and schema to optimize for querying speed;
Assist data scientists to wrangle data and build working tables to speed analysis;
Optimize SQL queries to improve processing speeds on Spark clusters.
Qualifications:
Passion pour les jeux vidéo;
Minimum 3 ans d'expérience dans un rôle similaire dans le développement, la gestion, la maintenance et l'optimisation d'environnements de données de plusieurs téraoctets, y compris les pipelines de données et les processus ETL qui leur sont associés;
Très forte expérience avec Apache Spark ou une technologie similaire;
Excellentes compétences en SQL;
Solide expérience dans les langages de script et de programmation tels que Python, Scala, Linux Shell, C# scripting;
Expérience en modélisation de données pour les environnements transactionnels et d'entreposage de données, y compris la familiarité avec les normes de modélisation dimensionnelle de Kimball et 3NF;
Expérience de travail avec une variété de sources de données telles que MySQL, Oracle, SQL Server, PostgreSQL, S3, HDFS, et Dynamo DB;
Expérience avec les systèmes de contrôle des sources (Git, Perforce, SVN, etc.);
Solides compétences interpersonnelles et capacité de résolution de problèmes.

Passion for video games;
Minimum 3 years of experience in a similar role in developing, managing, maintaining and optimizing large, multi-terabyte data environments including the pipelines of data and ETL processes feeding into it;
Very strong experience with Apache Spark or a similar technology;
Expert level SQL skills;
Solid experience in scripting and programming languages such as Python, Scala, Linux Shell, C# scripting;
Data modeling experience for both transactional and data warehousing environments including familiarity with Kimball dimensional and 3NF modeling standards;
Experience working with a variety of data sources such as MySQL, Oracle, SQL Server, PostgreSQL, S3, HDFS, and Dynamo DB;
Experience using source control systems (Git, Perforce, SVN, etc.);
Strong interpersonal skills and problem-solving ability.
Preferred Skills:
Baccalauréat en informatique, en génie, ou en intelligence d'affaires avec une expérience supplémentaire appropriée;
Expérience dans l'industrie du jeu vidéo serait un grand plus;
Expérience de travail avec d'autres technologies de données AWS comme S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, et Kinesis;

BS degree in Computer Science, Engineering, or BI with appropriate additional experience;
Experience in the video game industry would be a big plus;
Experience working with other AWS data technologies such as S3, Redshift Spectrum, Athena, Data Pipeline, Glue, EMR, RDS, and Kinesis;
Experience working with big data solutions such as Apache Spark, PrestoDB, Impala or similar.
Applicant Privacy Notice:
Applicant Privacy Notice",ZeniMax Media Inc.,Montreal
414,Data Science Engineer,"About Us:
Designed for unlimited discovery and unmatched safety, Epic is the leading digital library for kids. With tens of thousands of high-quality books, audiobooks, and videos from the world's best publishers, every year millions of kids read, learn and explore on Epic.

To learn more about our vision to unlock the potential of every child, visit us at www.getepic.com .

About the job

We are looking for a Data Engineer to join our Data Engineering Team that delivers on key data initiatives. You will be working on developing data infrastructure and pipelines for a variety of heterogeneous data sources, including user content interaction, natural language content, impressions and click logs, for product features that use Artificial Intelligence (AI) and Machine Learning (ML) as well as for key business reports and analytics.

You will be part of the core engineering team whose contributions help create a better world through learning and unlock the potential of every child on the planet.

What you will be doing

Develop scalable real time streaming and batch infrastructure for various data streams and pipelines
Develop data observability systems to monitor data quality and data downtime
Develop data feeds for reporting and analytic needs
Develop automated AI and ML feature and model training pipelines for models developed by data scientists

What you should have

Experience in one of the following programming languages - Python, Java, or Scala
Experience working on distributed computing and stream processing involving technologies such as Kafka Streams, Spark streaming, Pub/Sub, and Google Cloud Dataflow
Experience with at least one relational database system such as PostgreSQL or MySQL
Bachelor's degree in CS, EE/ECE or a related field with at least 3 years relevant industry experience or M.S./ PhD degree in CS, EE/ECE or a related field with at least 1 years of relevant industry experience in data engineering
Curious, collaborative, and always willing to learn new things
Good communication skills
Passionate about data

Nice to have

Experience with a NoSQL database like Cassandra or MongoDB
Experience with Docker, Kubernetes, and Jenkins for CI/CD pipelines

Benefits

Full medical, dental and vision coverage
401(k) plan
Take as you need vacation
Home office stipend
Lifestyle allowance
In office perks (virtual for now)
Unlimited access to our product!

Job Type: Full-time",Epic,Victoria
415,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","Company Description


Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2020, Eurofins generated total revenues of EUR € 5.4 billion, and has been among the best performing stocks in Europe over the past 20 years.

Eurofins CDMO Alphora Inc. provides a fully integrated suite of services to support drug substance and drug product development from the IND enabling development stage, through to phase II & III supply, and commercial validation and manufacturing for niche APIs. In addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, Eurofins CDMO Alphora Inc. is committed to growing its state-of-the-art organization, with continued investments in its people, modern facilities, equipment, and instrumentation.



Job Description


We are currently sourcing for 3 upcoming roles:

Research Scientist
Senior Research Scientist
Group Leader

The successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients (APIs).

Responsibilities will include but are not limited to:

Research Scientist, Senior Research Scientist

Planning and execution of experiments in R&D laboratories
Data analysis, interpretation, and documentation in development reports
Development of inherently safe processes based on thermal hazard assessment
Maintaining a safe and well-organized laboratory work area
Technology transfer to both internal and external manufacturing facilities

Group Leader

In addition to above:

Leading API technology programs and Scientists associated
Provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project-related issues, generating interim and final reports, preparing executive summaries for Clients and executive management team


Qualifications


Experience and Education Requirements:

B.Sc. or M.Sc. in Chemistry with >10 years experience or Ph.D in Chemistry with >5 years experience in the pharmaceutical or biotechnology industry
The Group Leader position will require a Ph.D in Chemistry with >10 years experience in the pharmaceutical or biotechnology industry
Must have a strong knowledge of organic chemistry and hands-on experience in the synthesis of complex organic molecules
Experience in process scale-up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset
Must be highly motivated and have a proven record of success in multiple projects
Must be well organized and able to meet project timeline commitments
Must work well in a multi-disciplinary team environment and have excellent written and verbal communication skills.

Additional Information


What we offer:

Excellent full time benefits including comprehensive and medical coverage, dental, and vision options
Life and disability insurance
RRSP/DPSP eligibility with company match
Paid vacation and holidays
Employee Assistance Plan, Tuition Program and much more

WORKING CONDITIONS:

This position will be working in a laboratory/manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. Intermediate lifting requirements of no more than 50 lbs. Hazardous materials are handled using established safety procedures and appropriate PPE.
Shift work and overtime may be required, as well as working periodic weekends and/or evenings.

Eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply; if accommodations are required in the application or interview process, please contact us via www.eurofins.ca. Only shortlisted candidates will be contacted - no phonecalls or emails please. Selected candidates can expect to be contacted in 3-6 weeks.

NO AGENCIES, PHONECALLS OR EMAILS PLEASE",Eurofins Canada BioPharma,Mississauga
416,Data Engineer,"About Paytm Labs:
At Paytm Labs, we’re on a mission to provide useful technological solutions that enrich and empower millions of people in their daily lives. We apply big data, artificial intelligence and machine learning to bring the next generation of financial products and services to the Indian, Japanese and Canadian markets.

As a company, we’re committed to offering the most transparent, secure, and personalized consumer experience to over 500 million users and over 20 million merchants. Since our journey began 6 years ago, we’ve launched the Paytm Canada app (our bill management app), and PayPay (a QR-based payment app in Japan), all while powering the Paytm India app.

Job Description:
If working with billions of events, petabytes of data and optimizing for last millisecond is something that excites you then read on! We are looking for Data Engineers who have seen their fair share of messy data sets and have been able to structure them for building useful AI products.



You will be working on writing frameworks building for real time and batch pipelines to ingest and transform events(108 scale) from 100’s of applications every day. Our ML and Software engineers consume these for building data products like personalization and fraud detection. You will also help optimize the feature pipelines for fast execution and work with software engineers to build event driven microservices.



You will get to put cutting edge tech in production and freedom to experiment with new frameworks, try new ways to optimize and resources to build next big thing in fintech using data!
Responsibilities
Work directly with Machine Learning Engineers and Platform Engineering Team to create reusable experimental and production data pipelines.
Understand, tune, and master the processing engines (like Spark, Hive, Samza, etc) used day-to-day.
Keep the data whole, safe, and flowing with expertise on high volume data ingest and streaming platforms (like Spark Streaming, Kafka, etc).
Sheppard and shape the data by developing efficient structures and schema for the data in storage and transit.
Explore as many new technology options for data processing, storage, and share them with the team.
Develop tools and contribute to open source wherever possible.
Adopt problem solving as a way of life – always go to root cause
Qualifications:
Degree in Computer Science, Engineering or a related field
You have previously worked on building serious data pipelines ingesting and transforming > 10 ^6 events per minute and terabytes of data per day.
You are passionate about producing clean, maintainable and testable code part of real-time data pipeline.
You understand how microservices work and are familiar with concepts of data modelling.
You can connect different services and processes together even if you have not worked with them before and follow the flow of data through various pipelines to debug data issues.
You have worked with Spark and Kafka before and have experimented or heard about Flink/Druid/Ignite/Presto/Athena and understand when to use one over the other.
On a bad day maintaining zookeeper and bringing up cluster doesn’t bother you.
You may not be a networking expert but you understand issues with ingesting data from applications in multiple data centres across geographies, on-premise and cloud and will find a way to solve them.
Proficient in Java/Scala/Python/Spark
What we Offer!
Due to the pandemic, we have been and will continue to WFH until it is safe to open our office. Our company culture and values remain at the core of everything we do.
For the third year in a row, we are proud to announce that we have been certified as a Great Place to Work
We were also certified as one of the Best Workplaces for Mental Wellness in 2020
We are an open work environment that fosters collaboration, ownership, creativity, and urgency
We ensure flexible hours outside of our core working hours
Enrolment in the Group Health Benefits plan right from day 1, no waiting period
To keep things fun and stress-free during COVID-19 we started Virtual Daily, Virtual Weekly and Monthly team bonding activities including: Trivia, Games Nights, Movies Nights, Arts & Crafts (e.g. Origami), Lunch & Learns (e.g. Sign Language 101), Virtual Wellness Sessions (e.g. Meditation, Morning stretches), Virtual Team Ubereats Lunches, and so much more

When we are able to open our office, our in-office experience consists of:
Team building events (anything from axe throwing, go-karting, bike riding, etc.)
Fuel for the day: Weekly delivery of groceries, and all types of snacks
Catered lunches and desserts on a monthly basis
Flexibility with WFH
Daily fun in the office with our competitive games of Ping Pong, Pool, Smash Bros competitions, or FIFA
And of course, an unlimited amount of freshly made coffee! We’re pretty serious about our coffee beans
Notice for Job Applicants
Following the advice of Canadian health authorities, to mitigate the risk of the potential spread of COVID-19 and support social distancing, all recruiting activities including interviews and new hire onboarding will be conducted remotely. While we are doing our best to ensure reasonable response times, please expect potential delays during the recruiting process due to the current situation.

We are an equal opportunity employer and value diversity and uniqueness at our company. We thank all applicants, however, only those selected for an interview will be contacted.

Paytm Labs is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please let us know.

Don't have Paytm Canada App yet?
Check us out in the Google Play or App Store.","Paytm Labs
3.4",Midtown Toronto
417,Data Science II,"The OneDrive and SharePoint Data Science team's charter is to foster a data-driven culture to encourage and enable the entire organization to make more informed decisions through data. Our data and analytics team works closely with engineering, marketing, finance, and business leaders to identify opportunities for improving the customer experience and accelerate our business's growth in support of this mission. We analyze historical data to understand salient trends, deliver standardized views of business performance, develop models to predict performance, recommend actions to be taken, and run experiments to prove that desired outcomes are being achieved.

We are looking for a Data Scientist to join a new team focused on unlocking value for Microsoft customers by understanding product usage patterns across the entirety of Microsoft 365 (Viva Connections, Cortex, Syntex, OneDrive, Lists, SharePoint, and beyond). This is a unique opportunity to bring your knowledge of Consumer and Commercial offerings, as well as your deep understanding of data science methods and best practices, to help Microsoft deliver the best experience possible for our customers and partners. You will be joining a group of experts on the front lines of synthesizing vast customer purchase and engagement behavior data sets into targeted recommendations for addressing real-world business challenges at scale.

We arelooking for you to bring a fresh perspective andyour unique voice to our team.

About Our Culture
We are a modern product and services organization, one of the largest business & consumer services on the planet, and the second biggest workload in Office 365. Data scientists on this team will be part of the broader data science team, and specific product teams focused on tangible and immediate business impact. We have a tremendous responsibility to our customers to help transform their content needs with Microsoft 365. We use data to organize our business priorities. We empower our industry-leading data science, design, and user research teams to own our product's user experience. We take a direct role in framing our business value directly to our customers and vibrant community of fans.
Responsibilities
Work cross functionally to translate business problems into ones that can be solved and informed by data analysis
Have curiosity and apply analytical skills to dive deep into data to find key insights that impact the business.
Develop models of usage, user behavior & business behavior to make recommendations and influence the product road map.
Work with other teams across Microsoft to develop key metrics to achieve business outcomes.
Be a champion of AB testing. Design, execute and analyze experiments to prove product change attribution.
Utilize tools like Data Bricks, R, Python, SQL to execute analyses
Qualifications
One plus year exhibiting a strong passion & understanding for the need to deliver the right business impact by working with stakeholders to turn business problems into data analysis questions and unearthing deep insights from data.
Have a track record of innovative thinking and problem-solving skills using Big Data.
Be self-driven and show the ability to deliver on ambiguous projects with incomplete data.
Understanding of the practical uses of statistics (i.e. experimentation, sampling)
Professional experience with large-scale computing systems like Hadoop, MapReduce, and/or similar systems.
Strong skills in SQL, R, Python, Databricks, or related tools for large-scale analysis.
Excellent communications & interpersonal skills. Ability to convince other strong personalities of their ideas and communicate complex analysis & insights to a non-technical audience.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
418,Data Science II,"The OneDrive and SharePoint Data Science team's charter is to foster a data-driven culture to encourage and enable the entire organization to make more informed decisions through data. Our data and analytics team works closely with engineering, marketing, finance, and business leaders to identify opportunities for improving the customer experience and accelerate our business's growth in support of this mission. We analyze historical data to understand salient trends, deliver standardized views of business performance, develop models to predict performance, recommend actions to be taken, and run experiments to prove that desired outcomes are being achieved.

We are looking for a Data Scientist to join a new team focused on unlocking value for Microsoft customers by understanding product usage patterns across the entirety of Microsoft 365 (Viva Connections, Cortex, Syntex, OneDrive, Lists, SharePoint, and beyond). This is a unique opportunity to bring your knowledge of Consumer and Commercial offerings, as well as your deep understanding of data science methods and best practices, to help Microsoft deliver the best experience possible for our customers and partners. You will be joining a group of experts on the front lines of synthesizing vast customer purchase and engagement behavior data sets into targeted recommendations for addressing real-world business challenges at scale.

We arelooking for you to bring a fresh perspective andyour unique voice to our team.

About Our Culture
We are a modern product and services organization, one of the largest business & consumer services on the planet, and the second biggest workload in Office 365. Data scientists on this team will be part of the broader data science team, and specific product teams focused on tangible and immediate business impact. We have a tremendous responsibility to our customers to help transform their content needs with Microsoft 365. We use data to organize our business priorities. We empower our industry-leading data science, design, and user research teams to own our product's user experience. We take a direct role in framing our business value directly to our customers and vibrant community of fans.
Responsibilities
Work cross functionally to translate business problems into ones that can be solved and informed by data analysis
Have curiosity and apply analytical skills to dive deep into data to find key insights that impact the business.
Develop models of usage, user behavior & business behavior to make recommendations and influence the product road map.
Work with other teams across Microsoft to develop key metrics to achieve business outcomes.
Be a champion of AB testing. Design, execute and analyze experiments to prove product change attribution.
Utilize tools like Data Bricks, R, Python, SQL to execute analyses
Qualifications
One plus year exhibiting a strong passion & understanding for the need to deliver the right business impact by working with stakeholders to turn business problems into data analysis questions and unearthing deep insights from data.
Have a track record of innovative thinking and problem-solving skills using Big Data.
Be self-driven and show the ability to deliver on ambiguous projects with incomplete data.
Understanding of the practical uses of statistics (i.e. experimentation, sampling)
Professional experience with large-scale computing systems like Hadoop, MapReduce, and/or similar systems.
Strong skills in SQL, R, Python, Databricks, or related tools for large-scale analysis.
Excellent communications & interpersonal skills. Ability to convince other strong personalities of their ideas and communicate complex analysis & insights to a non-technical audience.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
419,Data Engineer,"StackAdapt is the no. 1 performing programmatic advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in performance by G2 Crowd for the fourth time, we're one of the fastest-growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add Data Engineers to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Engineering team, and CTO on building pipelines and ad optimization models. With databases that process millions of requests per second, there's no shortage of data and problems to tackle.

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
What you'll be doing:
Design modular and scalable data pipelines to handle huge datasets
Understand and implement custom ML algorithms
Work on a micro-service architecture that simultaneously implements and monitors thousands of ML models concurrently
We'll be reaching out to candidates that have:
A high GPA from a well-respected Computer Science program
Have confidence in algorithm design and concurrency
Preferably have at least 1 year of job experience (internships count)
Interest in designing distributed scalable systems
Implementation of probabilistic and machine learning algorithms
Algorithms design ability
StackAdapters enjoy:
Highly competitive salary with RRSP matching
3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off
Full benefits from League on day one of employment
Work from home reimbursements
Coverage and support of personal development initiatives (conferences, courses, etc)
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
A friendly, welcoming, and supportive culture
Our social and team events (virtually!)
About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by the most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory, and publisher partners. StackAdapt is a Top 100 Software Product on G2, being the only DSP on the Best Software Products and Highest Satisfaction lists.

We've been recognized for our high performing campaign conversion rates, award-winning customer service, and innovation by numerous industry publications including:

Great Place to Work® named StackAdapt as one of Canada’s Best Workplaces for Start-ups in 2021
A leader in the DSP, Video and Cross-Channel Advertising Categories on G2
A Top Growing Company in Canada based on the Globe and Mail's 2020 Business Report
Named 23rd in Deloitte Canada’s Technology Fast 50™ program
Named in Deloitte Technology's Fast 500 in North America

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.","StackAdapt
4.3",Midtown Toronto
420,Business Data Analyst (Investment banking),"Job Description

Trigyn is seeking Business Data Analyst for contract position with our direct financial services client in Montreal, QC.

Description:
The ideal candidate should have the skills listed below but in addition should be a self-driven, dedicated individual who works well in a team and thinks and acts strategically.
In addition, the candidate should respond well to change and quickly pick up new concepts in an ever moving regulatory landscape. When faced with a problem, the candidate should be able to ask questions and leverage the skill set of those around him/her.
The group is responsible for the prevention and investigation of abusive, manipulative or illegal trading practices by Financial Advisors and the monitoring overall client suitability. This group identifies patterns behavior across multiple asset classes that may be an indication of sales practice issues or suitability concerns before these can compromise the Firm's reputation or client's holdings.

RESPONSIBILITIES:

Maintain current state architecture, while being an active participant in discussions relating to data strategy across the organization
Collaborates with internal/external team members to architect solutions and implement enhancements to the platform
Responsible for data analysis, data profiling and data sourcing
Create and communicate an Analytics Strategy that sets the direction and describes the related activities necessary to create meaningful business and customer value
Support the global team of business analysts, data SME's, data providers and developers with data subject expertise, query building and optimization
Develop a thorough understanding of the data definitions, domain values, data relationships, business rules, sources and data integration
Translate business requirements into data models and ETL design specifications
Define data quality rules, identify data issues
Partner with data providers to ensure upstream data requirements are met
Coordinate and conduct impact analysis because of upstream data changes and/or issues
Write detailed data requirements and use cases
Ensure that data requirements are met by participating in testing and data reconciliation
Work with management to prioritize business and information needs
Identify and define new process improvement opportunities
Follow through with data sources on issues and resolution
Effectively troubleshoot data quality issues
Implement and refine data quality controls

QUALIFICATIONS:
The candidate should be capable of understanding and solving highly complex problems, have excellent communication skills and have financial services experience, preferably in the areas of investment banking and trading.

Proven working experience as a data analyst or business data analyst
Strong analytical skills with the ability to collect, organize, analyze, and disseminate large amounts of information with attention to detail and accuracy
Performs thorough root cause and impact analysis; Solid analytical, profiling and troubleshooting skills
Has strong understanding of data concepts (Modeling/Design, Warehousing, ETL Development)
Good knowledge of relational databases
Must possess sound knowledge in RDBMS, SQL Queries, Indexes, Keys and Tables considering platforms, such as Apache Hadoop, Oracle, MySQL, HiveQL, and Microsoft SQL.
Knowledge in programming languages, such as R, Python, Matlab and SAS. Advanced Analytics/Data Scientist experience a plus.
Experience in data integration, conversion and migration
Excellent verbal and written communication skills, ability to work with cross cultural teams located globally
Knowledge of Microsoft Office applications (Visio, PowerPoint, Excel, Word)
Experience with ETL tools (preferably Informatica) with the ability to develop ETL design specifications and understand from the code what existing ETLs do
Knowledge of domain specific data and enterprise data
Knowledge of Autosys, Unix commands and scripting
Knowledge of Data Quality controls & implementation of DQ rules/checks preferably using an Industry standard tool
Knowledge and experience in Agile development methodology preferred.
Extensive experience documenting processes, workflows and technical specifications.
Quick learner with excellent attention to detail.
Highly motivated, flexible, proactive, and adaptable to change.
Education Level: Bachelor's Degree

PLEASE RESPOND ONLY IF YOU ARE CURRENTLY ELIGIBLE TO WORK IN CANADA.

For Immediate Response call 732-876-7624, or send your resume to RecruiterLS@Trigyn.com

Trigyn-8181

TRIGYN TECHNOLOGIES, INC. is an EQUAL OPPORTUNITY EMPLOYER and has been in business for 30 years. TRIGYN is an ISO 9001:2015, ISO 27001:2013 (ISMS) and CMMI Level 5 certified company.","Trigyn
4.0",Montreal
421,Business Data Analyst (Investment banking),"Job Description

Trigyn is seeking Business Data Analyst for contract position with our direct financial services client in Montreal, QC.

Description:
The ideal candidate should have the skills listed below but in addition should be a self-driven, dedicated individual who works well in a team and thinks and acts strategically.
In addition, the candidate should respond well to change and quickly pick up new concepts in an ever moving regulatory landscape. When faced with a problem, the candidate should be able to ask questions and leverage the skill set of those around him/her.
The group is responsible for the prevention and investigation of abusive, manipulative or illegal trading practices by Financial Advisors and the monitoring overall client suitability. This group identifies patterns behavior across multiple asset classes that may be an indication of sales practice issues or suitability concerns before these can compromise the Firm's reputation or client's holdings.

RESPONSIBILITIES:

Maintain current state architecture, while being an active participant in discussions relating to data strategy across the organization
Collaborates with internal/external team members to architect solutions and implement enhancements to the platform
Responsible for data analysis, data profiling and data sourcing
Create and communicate an Analytics Strategy that sets the direction and describes the related activities necessary to create meaningful business and customer value
Support the global team of business analysts, data SME's, data providers and developers with data subject expertise, query building and optimization
Develop a thorough understanding of the data definitions, domain values, data relationships, business rules, sources and data integration
Translate business requirements into data models and ETL design specifications
Define data quality rules, identify data issues
Partner with data providers to ensure upstream data requirements are met
Coordinate and conduct impact analysis because of upstream data changes and/or issues
Write detailed data requirements and use cases
Ensure that data requirements are met by participating in testing and data reconciliation
Work with management to prioritize business and information needs
Identify and define new process improvement opportunities
Follow through with data sources on issues and resolution
Effectively troubleshoot data quality issues
Implement and refine data quality controls

QUALIFICATIONS:
The candidate should be capable of understanding and solving highly complex problems, have excellent communication skills and have financial services experience, preferably in the areas of investment banking and trading.

Proven working experience as a data analyst or business data analyst
Strong analytical skills with the ability to collect, organize, analyze, and disseminate large amounts of information with attention to detail and accuracy
Performs thorough root cause and impact analysis; Solid analytical, profiling and troubleshooting skills
Has strong understanding of data concepts (Modeling/Design, Warehousing, ETL Development)
Good knowledge of relational databases
Must possess sound knowledge in RDBMS, SQL Queries, Indexes, Keys and Tables considering platforms, such as Apache Hadoop, Oracle, MySQL, HiveQL, and Microsoft SQL.
Knowledge in programming languages, such as R, Python, Matlab and SAS. Advanced Analytics/Data Scientist experience a plus.
Experience in data integration, conversion and migration
Excellent verbal and written communication skills, ability to work with cross cultural teams located globally
Knowledge of Microsoft Office applications (Visio, PowerPoint, Excel, Word)
Experience with ETL tools (preferably Informatica) with the ability to develop ETL design specifications and understand from the code what existing ETLs do
Knowledge of domain specific data and enterprise data
Knowledge of Autosys, Unix commands and scripting
Knowledge of Data Quality controls & implementation of DQ rules/checks preferably using an Industry standard tool
Knowledge and experience in Agile development methodology preferred.
Extensive experience documenting processes, workflows and technical specifications.
Quick learner with excellent attention to detail.
Highly motivated, flexible, proactive, and adaptable to change.
Education Level: Bachelor's Degree

PLEASE RESPOND ONLY IF YOU ARE CURRENTLY ELIGIBLE TO WORK IN CANADA.

For Immediate Response call 732-876-7624, or send your resume to RecruiterLS@Trigyn.com

Trigyn-8181

TRIGYN TECHNOLOGIES, INC. is an EQUAL OPPORTUNITY EMPLOYER and has been in business for 30 years. TRIGYN is an ISO 9001:2015, ISO 27001:2013 (ISMS) and CMMI Level 5 certified company.","Trigyn
4.0",Montreal
422,Business Intelligence (BI) Developer/Data Analyst,"Company Description
At Jane, we’re working to find the best ways to help small businesses succeed, and we’re using the latest technology to build a better online marketplace. We have some pretty big goals and are always looking for talented people who want to be a part of something new. We not only work hard at our jobs but also to maintain a culture of authenticity and collaboration. Join us and enjoy the #janelife to its fullest.

Jane's Values
Lead with empathy
Pull together
Just say it
Make it count
Make your mark

About the Team:
The data team was recently formed under a single executive to combine resources throughout the organization to optimize and enhance the data-driven capabilities at Jane.
The main pillars of our data team are:
Analysis and Insights
BI Development
Data Engineering
Data Governance
Data Science
Performance Management
You will have the opportunity to work with others across our team collaborating to deliver services to enhance the execution of our business. While supporting all business functions at Jane, You will also have the chance to develop other data skills within the data team to apply to your development as a data professional.
What You'll Be Doing:
Reporting into our Manager of Data & Analytics, you will:
Build reports and dashboards on our BI platform (Looker) to support various stakeholders
Design and build data models on our BI platform to enable self-service BI and data exploration
Resolve ad hoc data requests and changes to our BI platform
Build complex SQL queries and explore data in support of business initiatives
Engage with business consumers of data, gather requirements, and deliver end-to-end data-driven insight and solutions
Maintain and update our data wiki and data dictionary as required
Provide training and guidance to end users of our BI platform and in the analysis and understanding of data
Prepare technical and non-technical documentation and presentations
Qualifications:
University or College degree with focus on either Computer Science, Business, Mathematics / Statistics preferred
At least 2+ years experience in similar data-related positions. For example, as a data analyst, data scientist, data engineer, BI developer. Compensation will be commensurate with experience
Solid understanding of data warehousing concepts, dimensional and relational database design
Strong experience and skills in SQL is a must
Experience with business intelligence platforms; l.e. Cognos, Tableau, Looker, and Power BI etc.
Ability to build interactive dashboards and reports
Strong written and verbal communication skills are a must
Ability to communicate and present to technical and non-technical audiences
Ability to write accurate, concise technical documentation
A self-starter who can work well independently with minimal direction
Ability to think outside the box and infuse creativity into problem solving","Jane.com
4.3",Vancouver
423,"Data Engineer, ClearAngel","ClearAngel is building YC for the 99% of founders. Those who traditionally don't have access to advice, capital or network -- we want to support that long tail.

Most founders don't live in Silicon Valley or have the pristine pedigree to get in front of the ""right"" people. For far too long, startups have played on a scarcity model.

This is limiting the potential of founders. We fundamentally believe that great founders and companies are everywhere. Where there are problems, opportunities exist. We want to empower those founders.

We are building ClearAngel to democratize access to advice, network and capital.

We do this by scaling access to the rest of the world:
Access to advice (knowledge, resources)
Access to network (intros, people, community)
Access to capital

The role of the Data Engineer is to collaborate on backend architecture and minimalistic data pipelines that enable features for the Clear Angels product and supporting processes. Your responsibilities will be a superset of a typical Data Engineer, as there are often experiments and uncertainty that require creative solutioning at the earliest stages.

Application Deadline: ongoing

What your day-to-day will look like:
You will own technical products end to end, from design and architecture to deployment and maintenance

Working closely with every member of the team, you will produce significant components of the ClearAngel code

Work closely with all functions of Clearbanc, ranging from core Engineering team to Data Science team to the marketing team

You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary

You will scope out business needs for ClearAngel, and action them with speed and accuracy and then execute on it yourself

You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs

When it comes to product and engineering on ClearAngel, buck stops with you. Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

You will thrive if you:
Have a desire to help founders. We take a strong founder first stance on this team

Are self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission

On this team, we maximize learning. You will fail if you're not learning fast enough

Are comfortable working in a high growth, constantly changing environment

You are heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support

Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!

Have a strong business sense, you can foresee potential issues and solve them quickly

Demonstrated ability to collaborate effectively across multiple teams

Strong interest in building businesses, ecommerce, fintech

Technical Requirements:
3+ years of experience working on a variety of different projects / stacks would be ideal

Experience working on remote teams

Able to architect and scale data integrations from third-party API docs independently without much support

Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes

Comfortable working in server and database environments that are changing constantly

Demonstrated experience with using third party solutions and external APIs to supercharge existing features

Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff

Comfortable with relational databases and schemas involving time-series

Skills and interest in Python, SQL, Snowflake, Kubernetes

Clearco is an equal opportunity employer. We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. At Clearco, we're committed to developing and upholding an inclusive, transparent, and comfortable environment for all. We create a space where every voice, perspective, and idea is heard and acknowledged. We embrace differences, and know that our diverse team is our strength and what drives our innovation.

Clearco is committed to developing a barrier-free recruitment process and work environment. If you require any accommodation, please let us know and we'll work with you to meet your accessibility needs.","Clearco
3.9",Ontario
424,Architecte de données / Data Architect - 312699,"Architecte de données

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Architecte de données pour une entreprise dans le domaine manufacturier. Notre client est situé à Montréal.





Description des tâches et responsabilités – Architecte de données

Les responsabilités du poste incluent :

Participer à l’établissement et au maintien du modèle de données global de l'entreprise, en collaboration étroite avec les lignes d'affaire, l'équipe de gouvernance des données et les ingénieurs de données de l'organisation;
Capturer les requis d'affaire afin d'établir les modèles de données de type relationnel, dimensionnel ou data vault afin de supporter différents cas d'utilisation de la donnée;
Revoir les modèles de données proposés par les ingénieurs de données, les analystes et les scientifiques afin de les optimiser, de les aligner avec le modèle global, et de les opérationnaliser, tout en assurant une adhésion aux standards de l'industrie et aux lois en lien avec GDPR et SOX;
Définir et mettre en place les éléments d'architecture qui assureront la disponibilité, la qualité, la sécurité et la mise à disposition des données;
Voir à la conformité de la plateforme BI, depuis la capture des données brutes jusqu'à la couche de présentation;
Être un/une leader dans la définition des meilleures pratiques et de la pensée créative.




Exigences du poste – Architecte de données

Maîtrise en informatique, intelligence d'affaire ou expérience équivalente;
Expérience solide et démontrée en différents types de modélisation de données :
Modèles relationnels;
Modèles dimensionnels;
Data Vault 2.0.
Travail en équipe, être ouvert d'esprit et toujours être prêt à discuter du modèle proposé ou de l'approche à prendre;
Très organisé, capable de bâtir un ""plan de match"", et de prioriser ses propres tâches avec des dates de livraison conflictuelles;
Propose sans cesse des idées d'amélioration créatives, et adore mettre les mains dans des technologies nouvelles;
Excellent communicateur oral et écrit, en français et en anglais, capable de préparer et de faire des présentations exécutives;
A déjà travaillé dans un modèle de livraison agile;
Une expérience avec SAP ECC et S4, Azure, Snowflake est un plus.




Type de poste
Contractuel 12 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH312699




____________ENGLISH VERSION___________

Data Architect

As a part of its agreements with its various clients, Procom is currently seeking a Data Architect for a company in the manufacturing sector. Our client is located in Montréal.





Job details – Data Architect

Key responsibilities for this position include:

Participate in the establishment and maintenance of the overall enterprise data model, working closely with business lines, the data governance team and the organization's data engineers;
Capture business requirements to establish relational, dimensional or data vault data models to support different data use cases;
Review data models proposed by data engineers, analysts and data scientists to optimize them, align them with the overall model, and operationalize them, while ensuring adherence to industry standards and laws related to GDPR and SOX;
Define and implement the architecture elements that will ensure data availability, quality, security and delivery;
Ensure compliance of the BI platform, from raw data capture to the presentation layer;
Be a leader in defining best practices and creative thinking.




Mandatory Skills – Data Architect

Master's degree in Computer Science, Business Intelligence or equivalent experience;
Strong and demonstrated experience in various types of data modeling:
Relational models;
Dimensional models;
Data Vault 2.0.
Team player, open minded and always willing to discuss the proposed model or approach to be taken;
Highly organized, able to build a ""game plan"", and prioritize own tasks with conflicting delivery dates;
Constantly comes up with creative ideas for improvement, and loves to get his hands into new technologies;
Excellent oral and written communication skills, in French and English, with the ability to prepare and deliver executive presentations;
Previously worked in an agile delivery model;
Experience with SAP ECC and S4, Azure, Snowflake is a plus.




Assignment Length
12-month contract – renewable

Start date
Immediately

Reference number
BH312699","Procom
4.3",Montreal
425,Data Engineer - TW 30,"The role is going to be Data Engineer with our client Thoughtworks.

Please find below the job description for the position. Please send the following documents to hr@smsoftconsulting.com if that interests you and matches your profile.

Without mandatory documents, we cannot submit a candidate.

1. Updated Resume in word format (Mandatory)
2. Expected hourly rate (Mandatory)

Duration: 6 months Contract with a possibility of extension.

Job Description:

You’ll spend time on the following:

You will use continuous delivery practices to deliver high-quality software as well as value to end customers as early as possible.
You will work in collaborative, value-driven teams to build innovative customer experiences for our clients
Create large-scale distributed systems out of microservices
You will apply the latest technology thinking from our tech radar to solve client problems
Efficiently utilize DevOps tools and practices to build and deploy software
You will lead or take part in the entire cycle of software consulting and delivery from ideation to deployment and everything in between
You will act as a mentor for less-experienced peers through both your technical knowledge and leadership skills

Here’s what we’re looking for:

You have at least 6 years of experience with two or more development languages such as Java, C#, or Ruby (Java and .net preferred)
You can skillfully write high-quality, well-tested code and you are comfortable with Object-Oriented programming
Presence in the external tech community: you proactively share your expertise with others via speaking engagements, contributions to open source, blogs and more
Comfortability with Agile methods, such as Extreme Programming (XP), Scrum and/or Kanban
You enjoy influencing others and always advocate for technical excellence while being open to change when needed
You’re willing and able to commit to travel to client sites in order to solve their business problems
You’re resilient in ambiguous situations and can approach challenges from multiple perspectives
Bonus points if you have working knowledge of cloud technology such as AWS, Azure, Kubernetes and Docker




4sIk1xxuV5","S M Software Solutions Inc
5.0",Midtown Toronto
426,CPXE-Data & AI Growth Analytics Analyst,"Who We Are

Cisco’s Customer Experience (CX) organization is one of Cisco’s fastest growing teams, and the Customer and Partner Experience Engineering (CPXE) group is redefining how Cisco delivers value to our customers & partners via our product portfolio.

The CXPE product growth team leads analytics and growth initiatives for the Cisco product po rtfolio . Our mission is to measure, understand and optimize the Cisco experience for customers (CX Cloud) and partners (PX Cloud) across enterprise, mid-market and growth segments .

We are a small data-driven team passionate about customer value acceleration, delivering delightful experiences and accelerating lifecycle growth through rapid experimentation. We spend our time determining the highest impact variables and l evers to unlock growth and optimize the path to product value.

We use data to drive product led growth.

What You’ll Do

As part of the product growth team, you will wo rk across a multi -functional team to identify, prioritiz e and execut e data-driven growth activities.

You will focus on using experimentation to drive growth and enhance the Cisco value experienc e for customers and partners.

You will build analytica l narratives t hat help solve business, marketing , and growth problems such as conversion and adoption optimization, LTV forecasting, churn analysis, causal inference, and more.

Who You’ll Work With

You will be part of a fun , loving, diverse team, with an inclusive culture. Duties collaboratively span strategy to execution across the CX organization to promote business growth and customer lifecycle acceleration . In addition to customers and partners , you’ll partner with Engineering, Product Management, IT, Digital Transformation, Data Scientists, UX Researchers & our executive team.

Specifically, y ou will:
Identify and investigate numerical and qualitative data sets , assemble disparate sources of data to provide insight into how customers using Cisco products.
Collaborate with product and engineering teams to establish hypothesis, set up experiments , and interpret results
Convert numerical results into concrete, meaningful recommendations for business or product improvement
S uccinctly communicate s olutions to cross-functional partners and leadership across engineering, data science, UX research, marketing and more.

Must have s :
BS in Computer Science, Engineering, Statistics or related work experience.
P roven track record of setting up and optimizing metrics tracking systems and A/B testing methodologies , multivariate testing , power analysis and regressions.
Proven experience working with extremely large datasets, ETL processing and Machine learning pipelines.
Proficiency with decision modeling techniques and software; SQL, Python, R

Nice to haves:
4+ years of experience in business data analysis. You can easily give us an example of a data project you’ve work on and what impact it had on driving business outcomes.
Knowledge of customer experience, product growth functions, understanding of customer lifecycles, familiarity with bookings and pipeline reporting.
Proficiency with decision modeling techniques and software; SQL, Python, R
Highly collaborative and communicative, with ability to effectively manage business expectations and regularly work with both business and technical stakeholders.

Why Cisco

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference. Here’s how we do it. We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (30 years strong!) and only about hardware, but we’re also a software company. And a security company. An AI/Machine Learning company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box! But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, we give our egos a break, and we give of ourselves (because giving back is built into our DNA.) We take accountability, we take bold steps, and we take difference to heart. Because without diversity of thought and a commitment to equality for all, there is no moving forward. So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool.

CPXE","Cisco Systems
4.3",Vancouver
427,Senior Data Scientist,"Parkland is an independent supplier and marketer of fuel and petroleum products and a leading convenience store operator. We power a growing family of locally known brands and our team members serve retail, commercial, and wholesale customers across Canada, the United States, the Caribbean region and the Americas. Our purpose as Parklanders is to energize people and businesses to get them where they want to go. We’re a passionate team of down-to-earth achievers, committed to getting our customers, colleagues and communities further, faster.

Job Title: Senior Data Scientist

Location: Calgary, AB (we are open to candidates in Vancouver, Calgary, Montreal, or Toronto)

Position Summary:

Parkland Corporation is deeply invested in building next-generation Enterprise Data, Digital & Analytics capability, with an aspiration to improve our value to customers, our customers‘ experiences, and drive profitable growth and industry leadership for Parkland.

Parkland is seeking a Senior Data Scientist to be part of our newly forming Enterprise Digital Team – consisting of skillsets spanning machine learning, AI, Statistics, Data Engineering and full stack development. You will work as part of a high caliber team that works on solutions across Parkland’s business areas including Supply, Pricing and Loyalty, Retail, Commercial, Trading and Refining to drive high value solutions. As Canada and Caribbean’s largest and one of America’s fastest growing independent suppliers of fuel and marketing products and a leading convenience store operator, Parkland’s operations provide a rich and varied set of analytics opportunities, including over 1 mm retail transactions per day.

Key Responsibilities:

Develop a close working relationship with a subset of business segments. Translate ambiguous business needs/questions into analytical approaches using available data (including Machine Learning and other approaches).
Able to assemble and guide small technical teams appropriate to the problem at hand. Provide strategic technical direction. Be able to take on accountability for business value.
Scope out and operationally deliver outcomes while making critical decisions regarding priorities, technologies and leadership guidance.
Oversee and guide the building, testing and deploy pipelines for Machine Learning (or other models) including, but not limited to, feature engineering, model train/test/validate, and repeatable analysis/measurement of results.
Be able to present internally and externally on technical matters and benchmark with peers in the technology space.
Keep the business and leadership abreast of next generation technology needs and help them develop and maintain a multi year roadmap consistent with Parkland’s growth.
Work with and support other team members, management, and partners.

Qualifications and Skills:

Advanced degree (MS/PhD) in a relevant technical field (e.g., Computer Science, Mathematics, Applied Mathematics, Statistics, Machine Learning, Data Science).
A minimum 10 years’ experience in data science, analytics, and model building roles in a business context.
Track record of working with, mentoring and leading technical teams towards measurable business output.
Fluency in statistical, machine learning (including neural network) methods from a mathematical and computational perspective.
Strong practical knowledge of applying analytical techniques and methodologies to business objectives, including: machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques.
Experience working with large complex data sets, real time/near real time analytics, and distributed big data platforms (Hadoop & MapReduce and/or Cassandra/Spark).
Strong knowledge of analysis tools such as Python, R, Spark, PySpark/R/Spark on Hadoop or Cassandra preferred.
Strong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc).
Proficiency in programming in Python, R, SQL, Javascript, Java/Scala/Ruby and shell scripting.
Natural curiosity and a strong passion for empirical research and problem solving.
Strong written and verbal communications skills; comfortable communicating with senior levels of both business and technology leadership.
The following are considered as asset:
Capability in data ingest and connector rools particularly Talend
Proficiency in workflow and CI/CD tools e.g., Airflow, CircleCI, Jenkins
Proficiency in consuming REST based API (with JSON payload)
Capability in big data platforms including Hadoop, MapReduce, Hive, Spark, PIG
Familiarity with Cloud based HaaS/PaaS solutions such as AWS EMR

We Offer:

Participation in Parkland Pledge, an employee-driven charitable giving program.
Our Performance-based Annual Incentive Plan, an annual bonus awarding your performance.
A share in our success through the Employee Share Purchase Plan and 100% company matching.
Flexible medical and dental packages, a Health Care Spending Account, along with a supportive Employee and Family Assistance Program.
In-house learning and development opportunities, leadership training, international opportunities.
An employee referral program – earn up to $2000 for your referral.
A focus on healthy living through wellness initiatives and an annual fitness reimbursement program.
Discount Programs and Educational Scholarship Programs for family members.

Candidates must be legally able to work in Canada or the United States at this time. Parkland regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.

We thank all candidates in advance for their interest, however only those being considered will be contacted.

Parkland Fuel Corporation is committed to the principles of Employment Equity.

We strive to provide accessibility in employment to ensure equal access to employment opportunities for candidates, including persons with disabilities. Parkland Fuel Corporation will endeavour to provide accommodation to persons with disabilities in the recruitment process upon request. If you are selected for an interview and you require accommodation due to a disability, please notify us upon scheduling your interview.","Parkland Corporation
3.3",Calgary
428,"Data Engineer, Omnia AI (Montreal)","Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.




You have a passion for analytics and advanced Data Management? You want to build solutions that will allow customers to go further with the best of the existing Data solutions (AI/ML/ETL/Data lakes…)? Are you ready to uncover the possibilities of AI in your career and set the foundation for success tomorrow?
Then we have an opportunity waiting for you!

What will your typical day look like?

As a Data Engineer within our Omnia AI practice, you will be a team player to a portfolio of Deloitte’s Omnia AI engagements (projects). You will have the opportunity to be involved in the full life-cycle over AI projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. You will be able to work on the largest and most advanced Analytics projects on the market : 2019, 2020, 2021 Gartner Data & Analytics Service Provider leader.

Specifically, you will:

Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer.
Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed).
About the team

Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. We work closely with the Omnia AI Strategy, AI Data Science and AI Factory (custom developed AI assets) teams to drive successful business outcomes. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. To support our continued growth, we are looking to add many team players with hands-on work experience ideally in the data, analytics and/or AI domains.

Enough about us, let’s talk about you

You are someone with:

Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications
2+ years of experience in Data Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes
An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms
Team player attitude
Superior communication skills, intellectual curiosity, and strong analytical skills
Undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous

Differentiators but not required:

Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects
Bilingual (English / French)

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.
The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?


Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Montreal
429,Data Engineer,"BE authentic . BE influential . BE the expert . Be all that and more at Colliers.

At Colliers, we help leaders succeed by helping them build amazing workplaces, businesses and communities around the world. We do this by thinking differently, sharing innovative ideas and offering a unique and collaborative workplace where you can succeed.

Who you are

You will work directly with Global Finance management and North America Accounting on strategic projects to support and enhance our systems. Various reporting and data analysis tools will be used to design solutions that best meet business needs, both current and long term. This role will work closely with other IT, finance, payroll and accounting teams around the world to effectively deliver projects.


What you bring

5+ years of relevant experience in a similar role.
3+ years of experience with Microsoft SQL Server tools (SSRS, SSAS, SSIS).
5+ years of overall progressive financial reports development and 2+ years’ experience with SQL Server programming.
3+ years of experience with design and development of ETL processes.
Experience with best practices of information visualization, user interface design, and iterative customer-driven design processes.
Experience with Financial and Reporting applications.
Experience with developing test plans, test cases and training materials.
Knowledge of oriented object programming (Java, C++, C#, X++).
A “customer service” orientation and demonstrate a “can do” attitude.
Ability to think critically and analytically.
Ability to multi-task in a fast paced environment.
An eye for automation and process improvements.


Bonus skills and experience

Experience in the following applications/systems would be considered an asset:
IBM Cognos TM1
IBM Cognos BI
Microsoft Dynamics AX
Azure DevOps
Office 365


What success looks like

You develop and maintain ETL (MS SSIS) processes between Third Party systems and the North America ERP and Global Finance data store
You successfully Develop and maintain Microsoft SQL databases including creating and maintaining databases, tables, views, stored procedures, and database triggers.
You successfully work with managers, technical staff, and users to implement new reporting and integration solutions . This includes involvement in requirement analysis, test plans, individual and group training, meetings and documentation as well as ensuring that proper processes are followed in the systems life cycle to maintain responsive, reliable, and functional systems.
You analyze, design, develop, test and maintain complex Business Intelligence reports and dashboard using various front-end tools (Excel, Cognos BI, SQL SSRS, Power BI).

#LI-ON1

BE who you are and what you want to be with Colliers. We’d love to meet you. Apply today to join our team.



Direct applicants only please, no agencies.



Colliers is an equal opportunity employer and values diversity in its workforce. Colliers encourages applications from all qualified individuals and will accommodate applicants' disability-related needs, up to the point of undue hardship, throughout all stages of the recruitment and selection process. If you require a disability-related accommodation in order to participate in the recruitment process, please contact the recruitment team by email at careers@colliers.com.","Colliers International
3.7",Vancouver
430,Architecte Solutions Infonuagiques - Data (Cloud Solution Architect- Data),"Microsoft a comme mission de permettre à chaque personne et à chaque organisation de la planète d’en accomplir davantage. Poussés vers le haut par notre culture, nous adoptons une mentalité de croissance, inspirons l’excellence et encourageons les équipes et les dirigeants à donner le meilleur d’eux-mêmes chaque jour. Ce faisant, nous créons des innovations qui changent les vies de milliards de personnes dans le monde entier. Vous pouvez nous aider à accomplir notre mission.

Microsoft souhaite aider ses clients à réaliser leur propre transformation numérique grâce à la puissance de ses solutions et services Microsoft Cloud. C’est dans cette optique que Microsoft investit dans une équipe consacrée à la réussite de ses clients, qui aidera ces derniers à atteindre leurs résultats commerciaux.

Azure est à l’heure actuelle la plateforme infonuagique la plus complète, la plus novatrice et la plus souple qui soit. Par conséquent, Microsoft embauche des professionnels qui favoriseront l’adoption du nuage par les clients au sein des entreprises les plus importantes du marché.

Nous ne cessons jamais d’apprendre. Nous sommes animés d’une insatiable curiosité. Nous faisons face à l’incertitude, prenons des risques et apprenons rapidement de nos erreurs. Nous nous développons grâce aux idées des autres, car nous sommes meilleurs tous ensemble. Nous sommes émerveillés par ce que l’humain peut accomplir, et cela nous motive à encourager les autres à en faire plus grâce à nos technologies et à nos innovations. Ensemble, nous changeons les choses.

Pour en savoir plus sur la mission de Microsoft, visitez le site : https://careers.microsoft.com/mission-culture

Découvrez tous nos produits au : http://www.microsoft.com/fr-ca

Nous recherchons un architecte de solutions infonuagiques pour plateforme de données spécialisé en analyses avancées et en intelligence artificielle. Cette personne, qui devra être fortement motivée et passionnée, sera amenée à conduire des initiatives clients hautement prioritaires sur la plateforme Microsoft Azure en collaboration avec les clients et les secteurs d’activité de nos comptes entreprise. Il s’agit d’un poste en lien direct avec les clients, ayant pour responsabilité d’assurer la relation technique globale entre les clients et la plateforme de données, d’analyses avancées et d’intelligence artificielle de Microsoft.

Vous serez chargé des engagements techniques liés à la plateforme de données et aux analyses avancées envers les clients, y compris des séances de conception architecturale, des projets de mise en œuvre particuliers et des PPPV. Le candidat idéal aura de l’expérience dans des fonctions en lien direct avec les clients et aura réussi à mener, avec son équipe dirigeante, les architectes d’entreprise, l’équipe de gestion des TI et les développeurs, des discussions axées sur une architecture technique approfondie dans le but de mettre en œuvre les solutions de plateforme de données et d’analyses avancées.

Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us to achieve our mission.
Microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of Microsoft Cloud solutions and support offerings. To this end, Microsoft invests in a dedicated Customer Success team that will help Microsoft customers successfully realize their business outcomes.

Azure is the most comprehensive, innovative and flexible cloud platform today and Microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market.

We are always learning. Insatiably curious. We lean into uncertainty, take risks, and learn quickly from our mistakes. We build on each other’s ideas because we are better together. We stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. Together we make a difference.

To learn more about Microsoft’s mission, please visit: https://careers.microsoft.com/mission-culture

Check out all of our products at: http://www.microsoft.com/en-us

We are looking for a highly motivated and passionate Data Platform & Advanced Analytics/Artificial Intelligence Cloud Solution Architect to drive high priority customer initiatives on the Microsoft Azure Platform in collaboration with customers and the Microsoft field in Enterprise accounts segment of our business. This is a customer facing role, owning overall technical relationship between customer and Microsoft Data, Advanced Analytics and Artificial Intelligence Platform.

You will own the Data Platform & Advanced Analytics technical customer engagements including architectural design sessions, specific implementation projects and/or MVPs. The ideal candidate will have experience in customer-facing roles and success leading deep technical architecture discussions with senior customer executives, Enterprise Architects, IT Management and Developers to drive Data Platform and Advanced Analytics solutions to productions.
Responsibilities

Parmi les principales responsabilités :

Comprendre l’ensemble des données des clients, leurs priorités informatiques et d’affaires et les mesures de réussite afin de concevoir des solutions et des architectures de mise en œuvre.
Appliquer des connaissances techniques pour élaborer l’architecture de solutions qui répond aux besoins commerciaux et informatiques, créer des feuilles de route pour la plateforme de données, les analyses et l’IA, et assurer la viabilité technique à long terme des nouveaux déploiements en intégrant des technologies d’analyses clés au besoin (p. ex., SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.).
S’assurer que les solutions présentent de hauts niveaux de performance, de sécurité, d’évolutivité et de maintenabilité, ainsi qu’une réutilisabilité et une fiabilité adéquates au moment du déploiement.
Établir des liens étroits avec les principaux décideurs des TI et d’entreprise pertinents (comme l’IA ou l’analyse), qui ont la capacité d’encourager l’adoption de l’infonuagique au sein de leur entreprise pour faire d’eux des défenseurs du nuage.
Être la voix du client pour partager des renseignements et des pratiques exemplaires et pour interagir avec l’équipe d’ingénierie dans le but de supprimer les obstacles principaux.
Évaluer les connaissances des clients de la plateforme Azure et de la préparation globale à l’infonuagique de manière à soutenir les clients au moyen d’un plan d’apprentissage structuré et à assurer sa mise en œuvre grâce aux partenaires.
Collaborer avec d’autres architectes de solutions infonuagiques et intervenants MS pour développer des solutions d’entreprise complexes de bout en bout sur les plateformes infonuagiques Microsoft.
Maintenir les connaissances et les compétences techniques, suivre les tendances du marché et recueillir des renseignements concurrentiels, et collaborer et partager ses découvertes avec la communauté technique tout en renseignant les clients sur la plateforme Azure.
Être un évangéliste de la plateforme Azure auprès des clients, des partenaires et des communautés externes.

Key responsibilities include:
Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.
Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.)
Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment
Develop deep relationships with key customer IT decision makers and relevant business decision makers (like AI or Analytics), who drive long-term cloud adoption within their company to enable them to be cloud advocates
Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.
Collaborate with other Cloud Solution Architects and MS stakeholders in developing complex end-to-end Enterprise solutions on Microsoft Cloud platforms.
Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform
Be an Azure Platform evangelist with customers, partners and external communities.
Qualifications

Expérience requise en matière de formation, d’expériences clés, de connaissances et de compétences : expérience professionnelle. Au moins 5 ans de succès dans le domaine des ventes techniques consultatives ou complexes et du déploiement de projets de plateforme de données et d’analyses, ainsi que d’expérience en architecture, conception, mise en œuvre ou soutien d’applications distribuées à grande échelle obligatoire.

Développement de relations. Expérience reconnue en ce qui concerne l’établissement de relations techniques approfondies avec des dirigeants des TI de clients importants ou hautement stratégiques. Expérience de gestion des relations avec divers intervenants afin d’obtenir un consensus au sujet d’une solution ou de projets obligatoire.
Bon sens des affaires pour comprendre rapidement le secteur et les affaires du client de manière à avoir des discussions pertinentes avec les décideurs commerciaux.
Résolution de problèmes. Aptitude à résoudre les problèmes des clients au moyen de technologies infonuagiques
Collaboration et communication. Reconnaissance pour son expertise en matière de prise de décisions collaborative, de résolution de conflits et de suivi des mesures et décisions prises, en plus de compétences exceptionnelles en matière de communication verbale et écrite Aptitude à organiser et à mener avec influence des équipes virtuelles pour assurer le succès de la mise en œuvre des projets clients. Compétences de présentation avec très grande aisance face à des publics vastes ou plus restreints (dirigeants, équipe de gestion des TI, administrateurs de bases de données et scientifiques des données) obligatoires.


Profil technique

Expérience technique en milieu d’entreprise avec conceptions architecturales infonuagiques et hybrides de données et d’analyses, migrations de base de données et gestion de la technologie obligatoire
Expérience et aptitude technique à apprendre de nouvelles technologies et à comprendre les tendances infonuagiques pertinentes, en particulier dans les plateformes de données et l’analyse
Concurrence : connaissance des plateformes de développement infonuagique
Partenaires : compréhension des écosystèmes des partenaires et capacité à mettre à profit les solutions partenaires pour répondre aux besoins des clients souhaitables

Vastes connaissances et expérience technique avec expertise approfondie en la matière dans au moins deux des solutions de plateforme infonuagique pour les analyses de données et l’IA obligatoires

SQL, y compris les logiciels à code source libre (Postgres, MySQL, etc.), Azure SQL
Bases de données NoSQL, y compris les logiciels à code source libre (Maria, Mongo, etc.), Cosmos DB
Données massives, y compris SQL DW, Snowflake, Big Query, Redshift
Analyses avancées, y compris Azure Data Bricks, outils de visualisation comme PowerBI, Tableau
Gouvernance des données
Ingénierie des données
Science des données
Apprentissage automatique, y compris Azure ML, ML Server
Intelligence artificielle, y compris BOT framework, Cognitive Services, Cognitive Search
Expertise dans les charges de travail de l’environnement de données comme HDInsight, Hadoop, Cloudera, Spark, Python

Formation

Baccalauréat en informatique, en technologies de l’information, en ingénierie ou dans un domaine connexe souhaitable
Certification souhaitable dans au moins une des technologies suivantes : infonuagique, mobile, base de données, données massives, veille stratégique, science des données, apprentissage automatique, intelligence artificielle

Expérience

Expérience de travail dans un poste de consultation ou d’architecture au sein d’une entreprise de logiciels ou de services comme Amazon, VMware, Google, IBM ou Oracle souhaitable
Expérience antérieure de livraison de solutions chez des fournisseurs spécialisées en analyse et en IA


Microsoft souscrit au principe de l’égalité d’accès à l’emploi. Tous les candidats admissibles seront considérés pour le poste, peu importe l’âge, l’ascendance, la couleur, la nécessité d’un congé familial ou d’un congé de maladie, l’identité ou l’expression sexuelle, l’information génétique, l’état civil, l’état de santé, l’origine nationale, le handicap physique ou mental, l’allégeance politique, le statut d’ancien combattant, la race, la religion, le genre, l’état de grossesse, l’orientation sexuelle ou toute autre caractéristique protégée par les lois applicables, les réglementations ou les ordonnances.


Les avantages énumérés ci-dessous peuvent varier en fonction de la nature de votre emploi chez Microsoft et du pays où vous travaillez.


Knowledge and Skills: Professional Experience

5+ years of success in consultative/complex technical sales and deployment Data Platform and Analytics projects, architecture, design, implementation, and/or support of highly distributed applications required
Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. Required
Good business acumen to quickly understand the customer’s industry and business to have relevant discussions with business decision makers.
Problem Solving. Ability to solve customer problems through cloud technologies Required
Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) Required
Technical
Enterprise-scale technical experience with cloud and hybrid Data and Analytics architecture designs, database migrations, and technology management. required
The technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in Data Platforms and Analytics
Competitive Landscape: Knowledge of cloud development platforms
Partners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred
Breadth of technical experience and knowledge, with depth / Subject Matter Expertise in two or more of the following Data Analytics and AI Platform Cloud solutions required
SQL including OSS (postgres, MySQL etc), Azure SQL
NoSQL Databases including OSS (Maria, Mongo etc), Cosmos DB
Big Data including SQL DW, Snowflake, Big Query, Redshift
Advanced Analytics including Azure Data Bricks, visualization tools as PowerBI, Tableau
Data Governance
Data Engineering
Data Science
Machine Learning including Azure ML, ML Server
Artificial Intelligence including BOT framework, Cognitive Services, Cognitive Search
Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python
Education
Bachelor's degree in Computer Science, Information Technology, Engineer, or related field preferred
Certification in one or more of the following technologies preferred: Cloud, mobile, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence
Experience
Prior work experience in a Consulting/Architecture position within a software and/or services company such as Amazon, VMware, Google, IBM, Oracle desired
Prior solution delivery experience in Analytic and AI specialized solution providers

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Montreal
431,Senior Data Engineer | Ingénieur de Données Senior,"With thousands of beautiful spaces built for travel and living, Sonder is transforming the future of hospitality. Each Sonder is purposefully selected, designed and maintained - customized to reflect the vibe of its neighborhood. Whether your stay is two days, two months or two years, in a studio or a six-bedroom, Sonder ensures a unique, yet consistent experience. And with 24/7 contactless service, professional cleanings that exceed PHAC recommendations, and over 200 other quality standards, we're taking stay further for guests all around the world.

Sonder started in 2014, and now has thousands of spaces in cities across the globe.

The Data Engineering team is mainly focused on building and operating our data infrastructure, data warehouse, data and ETL pipelines, ML platform, and performing data modeling for analytics purposes. The team also partners with product engineering and data science teams to deliver data products to the business.

AT SONDER YOU WILL:
Build and operate our data infrastructure by building and maintaining the data platform, data pipelines, and the tools that ingest, process, transform and serve data
Build software libraries that standardize the acquisition, ingestion and integration of external data sources critical for real-time competitive intelligence and pricing
Use your expert SQL and data modeling skills to build the data warehouse base layer data models that will power Sonder's reporting dashboards
Establish and maintain the company's data lake/data warehousing strategy, define the appropriate data architecture, implement the best technical solution, and continue to meet the growing needs of the business;
Work with product and business analytics teams to ensure availability and accessibility of relevant business data and business metrics for product analytics and business performance reporting.
Understand Sonder's business intimately and model data that will be the source of truth for Sonder's business KPIs and metrics
Design and develop scalable platforms and processes for feature extraction, model training, and simulation
Own tools, processes and controls to help the team grow at scale.

WHAT WE LOOK FOR:
5+ years of experience working as a Data Engineer at a progressive company
Expert Python coding skills
Expert SQL and data modeling skills
Knowledge of data warehouse principles and methodologies
Experience in writing ETL jobs, performance tuning and query optimization
Strong communication skills and ability to gather requirements and translate them to specs and design
Experience with AWS cloud services and data warehouse stores like Redshift or Snowflake
Background in real estate or hotel industry is desirable
Self-driven, highly motivated and able to learn quickly

We offer great benefits to make your life easier so you can focus on what you're best at:

Competitive salary
Generous stock option plan
Medical, dental and vision insurance
Discretionary vacation/ Paid vacation and sick time
Annual free credits and discounts to stay in Sonders
Monthly culture budget: join your fellow colleagues for a monthly get together
A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Avec des milliers de beaux espaces construits pour le voyage et la vie, Sonder transforme l'avenir de l'hospitalité. Chaque Sonder est sélectionné, conçu et entretenu de manière ciblée, et personnalisé pour refléter l'ambiance de son quartier. Que votre séjour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, Sonder vous garantit une expérience unique, mais cohérente. Et grâce à un service sans contact 24 heures sur 24, 7 jours sur 7, à des nettoyages professionnels qui dépassent les recommandations de l'ASPC et à plus de 200 autres normes de qualité, nous allons encore plus loin pour nos clients du monde entier.

Sonder a débuté en 2014, et compte aujourd'hui des milliers de chambres dans des villes du monde entier.

L'équipe d'ingénierie des données se concentre principalement sur la construction et l'exploitation de notre infrastructure de données, de notre entrepôt de données, de nos pipelines de données et d'ETL, de notre plateforme ML et sur la modélisation des données à des fins d'analyse. L'équipe s'associe également à des équipes d'ingénierie de produits et de science des données pour fournir des produits de données à l'entreprise.

À SONDER VOUS LE FEREZ :
Construire et exploiter notre infrastructure de données en construisant et en entretenant la plate-forme de données, les pipelines de données et les outils qui ingèrent, traitent, transforment et servent les données

Créer des bibliothèques de logiciels qui normalisent l'acquisition, l'ingestion et l'intégration de sources de données externes essentielles pour la veille concurrentielle et la tarification en temps réel

Utilisez vos compétences en matière de SQL et de modélisation des données pour construire les modèles de données de la couche de base de l'entrepôt de données qui alimenteront les tableaux de bord de Sonder

Établir et maintenir la stratégie de l'entreprise en matière de lac de données/entreposage de données, définir l'architecture de données appropriée, mettre en œuvre la meilleure solution technique et continuer à répondre aux besoins croissants de l'entreprise ;

Travailler avec les équipes d'analyse des produits et des activités pour garantir la disponibilité et l'accessibilité des données commerciales pertinentes et des mesures commerciales pour l'analyse des produits et les rapports sur les performances commerciales.

Comprendre intimement l'activité de Sonder et modéliser les données qui seront la source de vérité pour les KPI et les métriques de l'activité de Sonder

Concevoir et développer des plates-formes et des processus évolutifs pour l'extraction de caractéristiques, la formation de modèles et la simulation

Des outils, des processus et des contrôles propres pour aider l'équipe à se développer à l'échelle.

CE QUE NOUS RECHERCHONS :
5+ ans d'expérience en tant qu'ingénieur de données dans une entreprise progressiste

Compétences d'expert en codage Python

Compétences d'expert en SQL et en modélisation de données

Connaissance des principes et des méthodologies de l'entrepôt de données

Expérience dans la rédaction de travaux ETL, l'optimisation des performances et des requêtes

Solides compétences en matière de communication et capacité à rassembler les exigences et à les traduire en spécifications et en conception

Expérience avec les services de cloud computing AWS et les entrepôts de données comme Redshift ou Snowflake

Une formation dans l'immobilier ou l'hôtellerie est souhaitable

Autonome, très motivé et capable d'apprendre rapidement

Nous vous offrons de grands avantages pour vous faciliter la vie afin que vous puissiez vous concentrer sur ce que vous faites de mieux :

Un salaire compétitif

Un plan d'options d'achat d'actions généreux

Assurance médicale, dentaire et visuelle

Vacances discrétionnaires/ Vacances payées et congés de maladie

Crédits annuels gratuits et réductions pour séjourner à Sonders

Budget mensuel de la culture : rejoignez vos collègues pour une réunion mensuelle

Une entreprise qui a une grande vision, un environnement de travail dynamique et une équipe de collègues intelligents, ambitieux et agréables à travailler!

Nous sommes un employeur souscrivant au principe de l'égalité des chances et valorisons la diversité au sein de notre entreprise. Nous ne faisons aucune discrimination fondée sur la race, la religion, la couleur, l'origine nationale, le sexe, l'orientation sexuelle, l'âge, l'état civil, le statut d'ancien combattant ou le handicap.","Sonder
3.2",Montreal
432,Lead Data Scientist,"We’re building a brand-new team to deliver the next-generation new product suites. This is a golden opportunity to join the team on the ground floor and you’ll have opportunity to not only to define and execute on the architecture, but also to build and shape the culture of the team.

Who We Are

To succeed in the modern world you must exploit digital resources and empower human capital. Often companies struggle to identify underlying opportunities and miss exploiting exponential technologies. IntegrityCo helps companies make the right investment with the best result. We help them beat the competition and reach their fullest potential. We make legendary products. This role is dedicated to help a client located in Washington; a Human Performance company, existing at the intersection of well-being and performance. Together we are unlocking human potential in the workplace by providing expert coaching, interactive content, meaningful incentives, and personalized insights in a fun, inspiring way. This helps to ignite cultures, create inclusivity, and build social connections that promote growth and flourishing of people in life and work.

Responsibilities
Position Description & Responsibilities
The role responsibilities include but are not limited to:

Design, prototype, and implement new machine learning system architectures and predictive models with a focus on classification and inference from time-series data.
Use statistical methods and machine learning techniques to create scalable prediction systems.
Conduct exploratory analysis - go deep into the data to develop hypotheses and to answer complex metric driven questions.
Make recommendations for new metrics, techniques, and strategies to improve methods to prioritize the performance of the platform.
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation.
Play the role of tech lead on the data science team, mentor fellow or junior data scientists.

Qualifications:

PhD or MSc in mathematics, statistics, computer science, physics, machine learning, micro-economics or other quantitative field or equivalent years of experience
5+ years working as a Data Scientist, Applied Researcher, or Machine Learning Scientist
5+ years of professional experience with a scripting language with fluency in Python and SQL.
Knowledgeable in two or more of the following: machine learning, information retrieval, statistical inference, and time-series analysis.
Solid understanding of statistical analysis and experimentation, and capacity to drive conclusions from the analysis in a scientific way.
Experience working with large scale data platforms such as Spark, Hadoop and cloud-based computing (preferably AWS).
Linux skills is a plus.
Exemplary communication skills, both verbal and written, ability to work with large cross functional teams of technical and non-technical members.
Ability to work across disparate data sources to obtain sensible results
Ability to draw conclusions from data and provide recommendations
Experience leading and managing a technical team
A strong passion for data, charts, analysis, trends, and evangelizing data usage with experience in data visualization software such as Tableau, and Power BI.
Proven track in leading, mentoring and growing teams of data scientists
Experience with defining organizational research and development practices in an industry setting
Experience in managing stakeholders and distilling complex requirements into analytical solutions

Community 
We are avid Zoom collaborators until we can be together again in our office space. Our community fosters collaboration, so be ready to converse and let ideas percolate! We believe diversity is a necessary element to our success as a business. We are committed to building a community that represents and celebrates a variety of backgrounds, perspectives and skills; we want you to bring your verve!

Location
We are currently fully remote.

Job Types: Full-time, Permanent

Salary: $140,000.00-$200,000.00 per year

Benefits:

Casual dress
Dental care
Extended health care
Life insurance
Vision care

Schedule:

Monday to Friday

Education:

Master's Degree (required)

Experience:

Python: 4 years (required)
statistical analysis: 2 years (required)
Machine Learning: 4 years (required)",integrityCo Solutions Inc.,Vancouver
433,Senior Data Engineer // Ingénieur·e des données,"Mistplay is the first Loyalty Program for mobile gamers. Players use our platform to play games, connect with friends, and earn awesome rewards; such as Amazon gift cards and prepaid Visas.

We leverage a wealth of in-game data and Machine Learning to recommend the best games to our users and coach developers of all sizes to help them build games. We use our marketing expertise and platforms to make sure our studio partners' games reach millions of players around the world.

With a growth of over 10 million users in under 3 years, Mistplay is one of the fastest-growing companies in North America. Join us as we continue to level up!



Mistplay is seeking a Data engineer to join our Engineering & Infrastructure team. We are a fast-growing start-up, which means you can jump into action and make significant contributions right away! Join our skilled, diverse and multidisciplinary team to build the data, analytics, and machine learning platform that we depend on. You'll have a unique opportunity to wear different hats so don't be afraid to roll up your sleeves and think of creative solutions to develop and improve our existing AI, database and pipeline solutions.

We're looking for self-starters who are focused on detail and quality while being passionate about making meaningful impacts within the company. Technical skills are important, but so is being a positive addition to our culture. A can-do attitude will take you a long way with Mistplay!

********************************************************************************************************************************

Mistplay recherche un·e ingénieur·e des données pour rejoindre notre équipe d'ingénieurie et d'infrastructure. Nous sommes une start-up à croissance rapide, ce qui signifie que vous pourrez passer à l'action et apporter des contributions significatives immédiatement ! Rejoignez notre équipe d'experts, diversifiée et multidisciplinaire, pour développer les données, l'analyse et la plateforme d'apprentissage automatique dont nous dépendons. Vous aurez l'occasion unique de prendre différentes casquettes, alors n'ayez pas peur de retrousser vos manches et de réfléchir à des solutions créatives pour développer et améliorer nos solutions d'IA, de base de données et de pipeline de données actuelles.

Nous recherchons des personnes capables de prendre des initiatives, qui ont le souci du détail et de la qualité, et qui ont à cœur d'avoir un impact significatif sur l'entreprise. Les compétences techniques sont importantes, mais il est tout aussi important de contribuer de manière positive à notre culture. Une attitude positive vous mènera loin chez Mistplay !


What You'll Be Doing:
Write and test code that is performant, scalable, maintainable and meets functional requirements
Build scalable data warehouses and ETL processes for consumption by various machine learning and analytics products in collaboration with the analysts and data scientists
Develop and maintain our current data architectures (Hive, Spark, Flink)
Develop tools to automate and handle data lifecycle and metadata management
Collaborate with other departments (Sales, Marketing and Product) to improve the quality and reliability of data
Vos responsabilités seront les suivantes:
Écrire et tester du code performant, évolutif, facile à maintenir et qui réponde aux exigences fonctionnelles.
Créer des data warehouses et des processus ETL évolutifs qui seront utilisés par divers produits d'apprentissage automatique et d'analyse en collaboration avec les analystes et scientifiques des données.
Développer et maintenir nos solutions d'architecture de données actuelles (Hive, Spark, Flink)
Développer des outils pour l'automatisation et la gestion du cycle de vie des données, ainsi que la gestion des métadonnées.
Collaborer avec les autres services (Ventes, Marketing et Produit) pour améliorer la qualité et la fiabilité des données.


What We're Looking For:
Bachelors degree in Computer Science or equivalent
Strong experience working with Python
3-5 years experience in working with big data tools (Hadoop, Spark & related technologies)
3-5 years with AWS or equivalent cloud provider
Knowledge of data persistence paradigms (relational, columnar, key-value etc.)
Curiosity and a willingness to learn
Ce que nous recherchons:
Baccalauréat (Bachelor's degree) en informatique ou équivalent.
Solide expérience professionnelle avec Python
3 à 5 ans d'expérience dans l'utilisation d'outils Big Data (Hadoop, Spark et technologies connexes).
3 à 5 ans d'expérience avec AWS ou un fournisseur de cloud computing équivalent.
Connaissance des paradigmes de persistance des données (relationnel, en colonnes, clé-valeur, etc.).
Curiosité et envie d'apprendre.
We work hard to make our work atmosphere as inviting and fun as possible! Working at Mistplay is coupled with a whole array of perks that we've adopted virtually and in-person: Team Lunches, game nights, company-wide events, and so much more.



Our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. We utilize data to constantly learn, improve, and adapt. We foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life.



Think you have what it takes? We'd love to meet you!","Mistplay
4.7",Montreal
434,"Data Analyst, Embedded Systems","Who we are:

Geotab is a global leader in IoT and connected transportation and certified “Great Place to Work.” We are a company of diverse and talented individuals who work together to help businesses grow and succeed, and increase the safety and sustainability of our communities.

Geotab is advancing security, connecting commercial vehicles to the internet and providing web-based analytics to help customers better manage their fleets. Geotab’s open platform and Marketplace, offering hundreds of third-party solution options, allows both small and large businesses to automate operations by integrating vehicle data with their other data assets. Processing billions of data points a day, Geotab leverages data analytics and machine learning to improve productivity, optimize fleets through the reduction of fuel consumption, enhance driver safety and achieve strong compliance to regulatory changes.

Our team is growing and we’re looking for people who follow their passion, think differently and want to make an impact. Ours is a fast paced, ever changing environment. Geotabbers accept that challenge and are willing to take on new tasks and activities - ones that may not always be described in the initial job description. Join us for a fulfilling career with opportunities to innovate, great benefits, and our fun and inclusive work culture. Reach your full potential with Geotab. To see what it’s like to be a Geotabber, check out our blog and follow us @InsideGeotab on Instagram, Twitter or Facebook.

Who you are:

We are always looking for amazing talent who can contribute to our growth and deliver results! Geotab is seeking a Data Analyst, Embedded Systems who will join our Automotive Engineering Department, and will work with data analysts and firmware engineers to drive insights and values from massive amounts of vehicle data. If you love technology, and are keen to join an industry leader — we would love to hear from you!

What you’ll do:

You will be interacting with our data, including clean data, analyze data, visualize data, and provide insights and reports on a daily basis. This role will work closely with the firmware team and gain domain-specific knowledge of GO telematics system and firmware development. The ultimate goal for this role will be helping firmware engineers to monitor various product related issues, detect anomalies, send notifications, and keep improving the quality of the firmware in the long run. Also, you will partner with other departments such as Data and Analytics, Support and Solution Engineering to achieve these objectives. To be successful in this role you will be a self-starter with strong written and verbal communication skills, and have the ability to quickly understand complex, technical concepts. Geotab Data Scientists and Analysts share the common passion for utilizing big data to find simple solutions for complex problems and to drive business decisions. We leverage the Google Cloud Platform (GCP) as our big-data environment, and most of our development work happens in Python and SQL.


How you’ll make an impact:
Interact with Geotab’s BigData Infrastructure on Google BigQuery using SQL and develop Jupyter notebooks using Python.
Work with our firmware engineers and other stakeholders to identify the firmware issues and implement visualizations and reports using the data in various formats.
Process, clean and verify the integrity of the data that was collected by our product, and set up necessary monitors and alerts.
Leverage big data tools and assist firmware engineers with troubleshooting and providing meaningful insights.
Mine messy data from vehicles and build accurate and useful datasets in BigQuery to meet different requirements.
Develop SQL queries to detect anomaly behaviours from our GO devices and vehicles.
Make recommendations for new metrics, techniques, and strategies to improve the reliability and quality of Geotab device and firmware.
What you’ll bring to this role:
Post-Secondary Degree specialization in Computer Science, Math, Engineering, Science or any other related field.
Solid technical background with understanding and/or hands-on experience in large data environments and data analytics.
Familiar with and have experience in data warehousing and data ETL processes.
2+ years’ experience using Jupyter Notebook, Python and data analytics packages, such as Pandas, Numpy, Matplotlib etc.
2+ years’ experience using SQL and being able to manipulate large amounts of data in DBMS or data warehouse (experience with Google BigQuery preferred).
2+ years’ experience with data visualization in python and being able to draw some insights by given unknown data.
Experience with developing containerized app using docker, and writing bash script on Linux systems is a plus.
Experience working with cloud products such as Google Cloud Platform is nice to have.
Familiar with Version Control System such as git and Agile Project Management platform such as Jira.
Being inquisitive, results-oriented, problem-solving, and paying attention to details is crucial.
Highly organized and able to manage multiple tasks and projects simultaneously.
A keen interest to learn new technologies and utilize them into our Big Data Environment.
A strong team-player with the ability to engage with people within the department or outside the department.
Entrepreneurial mindset and comfortable in a flat organization.
Why job seekers choose Geotab:

Work from home and flex work arrangements
Baby bonus
Home office reimbursement program
Online learning and networking opportunities
Electric vehicle purchase incentive program
Competitive medical and dental benefits (full-time employees only)
Retirement savings program (full-time employees only)

How we work:

At Geotab, we understand that the world is always changing and that we need to change with it. Geotab has adopted a hybrid model for working, including a flexible work from home program, with the opportunity to work in our safe, clean offices. When working from home, you are required to have a reliable internet connection with at least 50mb DL/10mb UL. Virtual work is supported with cloud-based applications, collaboration tools and asynchronous working. The health and safety of employees are a top priority. We encourage work-life balance and keep the Geotab culture going strong with online social events, chat rooms and gatherings. Join us and help reshape the future of technology!

We believe that ensuring diversity is fundamental to our future growth and progress and is an integral part of our business. We believe that success happens where new ideas can flourish – in an environment that is rich in diversity and a place where people from various backgrounds can work together. Geotab encourages applications from all qualified individuals. We are committed to accommodating people with disabilities during the recruitment and assessment processes and when people are hired. We will ensure the accessibility needs of employees with disabilities are taken into account as part of performance management, career development, training and redeployment processes. If you require accommodation at any stage of the application process or want more information about our diversity and inclusion as well as accommodation policies and practices, please contact us at careers@geotab.com. Click here to learn more about what happens with your personal data.","Geotab
4.2",Oakville
435,Python Data Engineer,"Python Data Engineer



ID #; 7GB0204PDE

Location: Ottawa, Ontario Canada

Term: Full time


We are looking for a Data Engineer, with Python fluency and dedication to code quality. As for Python, we are after proficiency in object-oriented and test-driven development, as well as hands-on experience with scientific computing packages in Python (such as Pandas and NumPy).


Bachelor’s degree in computer science or equivalent
3+ years of experience in building large-scale, high performance, high availability software systems in a distributed Linux environment
Strong computer science fundamentals such as algorithms, data structures, etc.
Fluency and facility with one or more of the following programming languages: Python, Scala, R, Julia, Go
Experience with big data technologies, particularly Apache Spark, Elasticsearch, Cassandra, Kafka, and Hadoop ecosystem
Working experience with microservices, container and streaming technologies
Comfort manipulating and analyzing complex, high-volume, high dimensionality data from varying sources
Excellent written and oral communication skills, able to communicate with all levels of internal technology teams and business teams
Is dedicated to Quality - we're seeking someone who achieves a high standard of SW quality


Desired Skills:

Experience solving analytical problems using quantitative approaches, operations research and optimization algorithms
Exposure to machine learning, deep learning and neural networks
Passion for answering hard questions with data


Note 1: You MUST be legally entitled to work in Canada (i.e., possess Canadian Citizenship, Permanent Residency or Valid Work Permit)

Note 2: High Tech Genesis Inc. is an Equal Opportunity Employer.

Note 3: Accommodations are available upon request for all aspects of the hiring process.

Note 4: Please submit a MS Word version of your resume when applying for this position.","High Tech Genesis
5.0",Ottawa
436,"Sr. Data Scientist, Architectural Services / Scientifique de données sénior, Services d'architecture","The opportunity

The Architectural Services group provides Unity's developers with crucial opportunities for technical collaboration across the company that meaningfully improves how we build our products. This is accomplished by integrating with, storing, and analyzing large data sets that are enablers to make value-based business decisions that directly influence the way that we work as a company. As a Sr. Data Engineer working with the VP of Architectural Services, you will make an impact by navigating globally distributed data, provide insight on significant correlation and causality events, and improve our overall understanding of a given problem space. We do this in service to support the creation of sophisticated and engaging digital content.
What you'll be doing

Data integration, maintenance, and analysis using your problem-solving skills to reach data-informed conclusions

Develop, optimize, data models to improve our technology and development practices

Identify, define, and lead data engineering projects end-to-end

Research and collaborate on solutions that achieve specific measurable goals

Collaborate on your analysis, code, and approach with leadership to align with Unity's overall direction and needs

What we're looking for

Applied experience identifying, integrating, extracting, shaping data (Data warehousing & ETL) from various sources in production via on-prem or Cloud environments (e.g. MySQL, Postgres, GCP Big Table, AWS Aurora, or others)

Applied experience publishing and communicating data in a production environment by setting up dashboards, websites, and building presentations

Extensive experience developing applications with various programming/scripting languages utilizing light-weight front-end frameworks and microservices (e.g. Node/JS, Python, Go, Scala, R, or others)

Professional experience leading data-centric projects from problem identification to production with excellent analysis and interpersonal skills.

A Bachelor's degree in one of the following areas or equivalent experience: Computer Science, Mathematics, Data Analysis, or Data Engineering

You might also have

Prior experience with the Unity engine

Worked on large projects in a globally distributed, collaborative, and diverse environment

Life at Unity

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com .

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

L'opportunité

Le groupe Architectural Services offre aux développeurs de Unity des possibilités cruciales de collaboration technique à l'échelle de l'entreprise, qui améliorent de manière significative la façon dont nous concevons nos produits. Pour ce faire, nous intégrons, stockons et analysons de grands ensembles de données qui permettent de prendre des décisions commerciales basées sur la valeur qui influencent directement la façon dont nous travaillons en tant qu'entreprise. En tant que développeur de données principal travaillant avec le vice-président des Architectural Services, vous apporterez votre contribution en parcourant les données distribuées à l'échelle mondiale, en fournissant des informations sur les événements de corrélation et de causalité significatifs et en améliorant notre compréhension globale d'un espace-problème donné. Nous agissons ainsi pour soutenir la création d'un contenu numérique sophistiqué et attrayant.

Ce que vous allez faire :
Tirer parti de vos compétences en résolution de problèmes pour l'intégration, la maintenance et l'analyse des données afin de parvenir à des conclusions fondées sur les données

Développer et optimiser les modèles de données pour améliorer notre technologie et nos pratiques en matière de développement

Identifier, définir et diriger des projets de développement des données de bout en bout

Rechercher et collaborer à la mise en place de solutions qui permettent de réaliser des objectifs spécifiques et mesurables

Collaborer sur votre analyse, votre code et votre approche avec la direction pour s'aligner sur la direction générale et les besoins de Unity

Ce que nous recherchons :
Expérience appliquée d'identification, d'intégration, d'extraction et de mise en forme de données (entreposage de données et ETC) à partir de diverses sources en production au moyen d'environnements sur site ou infonuagiques (p. ex., MySQL, Postgres, GCP Big Table, AWS Aurora, ou autres)

Expérience appliquée de publication et de communication de données dans un environnement de production par la configuration de tableaux de bord, de sites Web et la création de présentations

Grande expérience de développement d'applications avec divers langages de programmation/script utilisant des environnements de développement frontaux légers et des micro-services (p. ex., Node/JS, Python, Go, Scala, R ou autres)

Expérience professionnelle dans la direction de projets liés aux données, de l'identification des problèmes à la production, avec d'excellentes compétences d'analyse et interpersonnelles

Baccalauréat dans l'un des domaines suivants ou expérience équivalente : informatique, mathématiques, analyse des données ou développement des données

Vous avez peut-être également

Expérience avec le moteur Unity

Expérience de travail sur de grands projets dans un environnement mondialement distribué, collaboratif et diversifié

La vie chez Unity

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com .

Unity est un employeur axé sur l'égalité qui s'engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d'emploi qui ne tiennent pas compte de l'âge, de l'ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l'identité sexuelle ou d'un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n'hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n'acceptons pas d'être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-LL2 #SEN","Unity Technologies
4.6",Montreal
437,Principal Data Scientist - AWS Professional Services,"A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
10+ years of industry experience in predictive modeling, science and analysis
Previous experience in a ML or scientist role and a track record of building ML or DL models
Experience using and/or R
Knowledge of SparkML
Excited by using massive amounts of to Machine Learning (ML) and Deep Learning (DL) models? Help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI). Are you eager to learn from many different enterprise use cases of AWS ML and DL? Come be a key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?

At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

You enjoy diving deep into , doing analysis, discovering root causes, and designing long-term solutions. You like to have fun, love to learn, and want to innovate in the world of AI.

You will:

Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating , exploring , building & validating predictive models, and deploying completed models to deliver business impact to the organization.
Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
Work with our Professional Services Big consultants to analyze, extract, normalize, and label relevant .
Work with our Professional Services DevOps consultants to help our customers operationalize models after they are .
Assist customers with identifying model drift and retraining models.
Research and novel ML and DL approaches, including using FPGA.
Be able to write production level code, which is well-written and explainable
Have experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Have experience working with GPUs to models
Have experience handling terabyte size datasets
Be able to track record of diving into data to discover hidden patterns
Have familiarity with using data visualization tools
Have knowledge and experience of writing and tuning SQL
Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
This role is for Toronto/Vancouver/Calgary/Montreal.

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a value on work-live balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member and enable them to take on more complex tasks in the future.


PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
12+ years of industry experience in predictive modeling and analysis
Good skills with programming languages, such as or C/C++
Ability to experimental and analytic plans for modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentation in recognized Machine Learning, Deep Learning and Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Pipeline, & EMR
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contacted for an employment opportunity, advise Human Resources if you require accommodation, including in order to apply for a position.","Amazon Web Services Canada, In
3.8",Canada
438,Research Scientist – Protein Engineering & Lead Optimization,"AbCellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated scientist with experience engineering antibody sequences. Our ideal candidate is a self-directed scientist, a team-player who thrives in a fast-paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. This is an exciting opportunity to join one of Canada's fastest growing biotechs and to contribute to our cutting-edge research on next-generation antibody-derived therapies.

How you might spend your days:
Engineering antibody sequences, including bispecifics and single-chain antibodies to improve therapeutically relevant molecular properties

Performing data analysis of biophysical datasets from UPLC and SPR-based methods.

Implementation and evaluation of novel protein engineering techniques

Developing and iterating workflows to streamline common protein engineering tasks

Collaborating with teams across the company to understand protein engineering challenges and propose solutions

Organizing, supporting, and collaborating with team members to meet project deliverables and timelines

We'd love to hear from you if:
You are a creative problem solver and fast learner who believes in team work to tackle the most challenging scientific problems

You are self-motivated and have the initiative and drive to meet goals under tight project timelines

You think critically, and are passionate about the integration of computational and experimental protein engineering methods

Required qualifications and experience:
A PhD in Biochemistry (or related) or Computational Biology or MSc with 5+ years in an academic or industry lab environment

Great interpersonal skills with the ability to work collaboratively as a member of cross-functional team

Strong data analysis skills and the ability to interpret, communicate, and document large data sets. Familiarity with Python data analysis (Pandas, Numpy) is preferred.

Experience with common antibody engineering tasks, including humanization, reformatting, and bispecific antibody generation

Excellent verbal and written communication skills, including public presentation of complex data

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter

An attractive compensation package, including health and lifestyle benefits

A minimum of 3 weeks' vacation

Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please submit your application through our website and refer to Job ID 21154 in your cover letter. We apologize in advance, but we receive a large volume of applications and are only able to contact those who are selected for an interview.","AbCellera
4.8",Vancouver
439,Data Engineer,"Mogo Finance Technology Inc. (Mogo) (TSX: MOGO; NASDAQ: MOGO) — a financial technology company — offers a finance app that empowers consumers with simple solutions to help them get in control of their financial health and be more mindful of the impact they have on society and the planet. We all know it’s time to do things differently. It’s time for a new way to manage our money, one that’s inclusive and sustainable. One that takes into account our financial health, the planet’s health and the health of our society. At Mogo, users can sign up for a free account in only three minutes and begin to learn the 4 habits of financial health and get convenient access to products that can help them achieve their financial goals and have a positive impact on the planet including a digital spending account with Mogo Visa* Platinum Prepaid Card featuring automatic carbon offsetting, free monthly credit score monitoring, ID fraud protection and personal loans. The Mogo platform has been purpose-built to deliver a best-in-class digital experience, with best-in-class products all through one account. With more than one million members and a marketing partnership with Canada's largest news media company, Mogo continues to execute on its vision of becoming the go-to financial app for the next generation of Canadians. To learn more, please visit mogo.ca or download the mobile app (iOS or Android).

Mogo is looking for a Data Engineer to be a key member of Mogo’s team. Based in Vancouver, this role will be responsible for the architecture, integration and analysis of both traditional and non-traditional data sources used for model building. Check out the list of qualifications below and if this sounds like you, send us your resume - we want to hear from you!

What you'll do:

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

What you'll need:

3-5 years experience in a similar role with an emphasis on translating quantitative data into meaningful insights.
Experience working in the Financial services industry and/or with digital products.
Degree in Computer Science, Statistics, Mathematics or other related discipline
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Proficient with the the following software/tools:
Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and MongoDB.
AWS cloud services: EC2, EMR, RDS, Redshift
Object-oriented/object function scripting languages: Python, Javascript.

Salary range for this role is $80,000-$90,000 per annum based on experience.

Interested applicants can submit an application online or through email at hr@mogo.ca




klWw6Hss46","Mogo Finance Technology Inc.
3.7",Vancouver
440,SENIOR DATA SCIENTIST,"We are looking for a Senior Data Scientist who is enthusiastically driven to generate actionable insights and create new growth opportunities. You must have proven leadership skills to grow and foster a highly effective team capable of rapid learning and application. You will lead a team conducting research experiments, advanced statistical modelling and develop data-driven products across several domains including infrastructure optimization, logistics efficiency, and data visualization. This is a unique opportunity to apply your leadership skills in a growing company and lead our next generation products.

REQUIREMENTS
M.Sc. or Ph.D. in a quantitative field (e.g., Computer Science, Statistics, Financial Economics, Applied Mathematics, Computer Engineering, or other related discipline).
Significant experience solving problems with the required the use of advanced statistical modelling techniques.
Proven programming skills including experience conducting modelling and statistical analysis (e.g., R, Matlab), object-oriented software development (e.g., Python, Scala), and massive parallel processing (e.g., Spark, Apache Hadoop).
Excellent communication skills and ability to describe and present complex technical concepts in clear language.
Ability to lead teams and create an environment of continuous learning and open communication.
Ability to structure and lead a project from idea to experimentation to prototype to delivery.
WHAT WE EXPECT?
Self-starter that is focused and driven with amazing follow-through.
Enthusiastically tackling problems with a love for teaching and celebrating the successes of others.
Ability to synthesize information, evoke good conversation and consider problems from new perspectives.
Desire to share information with others and contribute to our top-notch learning environment.
Driven to delivery quality solutions.",Temetrix,Ottawa
441,Ingénieur de données - Data & Analytic / Data engineer - Data & Analytic - 313669,"Ingénieur de données - Data & Analytic

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Ingénieur de données - Data & Analytic pour une entreprise dans le domaine du transport. Notre client est situé à Montréal.





Description des tâches et responsabilités – Ingénieur de données - Data & Analytic

Les responsabilités du poste incluent :

Construire et concevoir des applications à grande échelle;
Architecture de base de données et entreposage de données;
Modélisation et extraction de données;
Modélisation statistique et analyse de régression;
Calcul distribué et algorithmes de fractionnement pour une précision prédictive.




Exigences du poste – Ingénieur de données - Data & Analytic

Développement Spark / Python;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks et / ou Snowflake;
Expérience ETL / Data;
Compréhension et expérience de travail avec le processus et le pipeline DevOps (nous utilisons Azure DevOps).




Type de poste
Contractuel 5 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH313669




____________ENGLISH VERSION___________

Data engineer - Data & Analytic
As a part of its agreements with its various clients, Procom is currently seeking a Data engineer - Data & Analytic for a company in the transport sector. Our client is located in Montréal.





Job details – Data engineer - Data & Analytic

Key responsibilities for this position include:

Building and designing large-scale applications;
Database architecture and data warehousing;
Data modeling and mining;
Statistical modeling and regression analysis;
Distributed computing and splitting algorithms to yield predictive accuracy.




Mandatory Skills – Data engineer - Data & Analytic

Spark / Python development;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks and/or Snowflake;
ETL / Data experience;
Understands and experience working with DevOps process & pipeline (we use Azure DevOps).




Assignment Length
5-month contract – renewable

Start date
Immediately

Reference number
BH313669","Procom
4.3",Montreal
442,Ingénieur de données - Data & Analytic / Data engineer - Data & Analytic - 313669,"Ingénieur de données - Data & Analytic

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Ingénieur de données - Data & Analytic pour une entreprise dans le domaine du transport. Notre client est situé à Montréal.





Description des tâches et responsabilités – Ingénieur de données - Data & Analytic

Les responsabilités du poste incluent :

Construire et concevoir des applications à grande échelle;
Architecture de base de données et entreposage de données;
Modélisation et extraction de données;
Modélisation statistique et analyse de régression;
Calcul distribué et algorithmes de fractionnement pour une précision prédictive.




Exigences du poste – Ingénieur de données - Data & Analytic

Développement Spark / Python;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks et / ou Snowflake;
Expérience ETL / Data;
Compréhension et expérience de travail avec le processus et le pipeline DevOps (nous utilisons Azure DevOps).




Type de poste
Contractuel 5 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH313669




____________ENGLISH VERSION___________

Data engineer - Data & Analytic
As a part of its agreements with its various clients, Procom is currently seeking a Data engineer - Data & Analytic for a company in the transport sector. Our client is located in Montréal.





Job details – Data engineer - Data & Analytic

Key responsibilities for this position include:

Building and designing large-scale applications;
Database architecture and data warehousing;
Data modeling and mining;
Statistical modeling and regression analysis;
Distributed computing and splitting algorithms to yield predictive accuracy.




Mandatory Skills – Data engineer - Data & Analytic

Spark / Python development;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks and/or Snowflake;
ETL / Data experience;
Understands and experience working with DevOps process & pipeline (we use Azure DevOps).




Assignment Length
5-month contract – renewable

Start date
Immediately

Reference number
BH313669","Procom
4.3",Montreal
443,"Specialist, Information Management (Open Data)","Who are we?

Credit Valley Conservation is one of Ontario’s 36 conservation authorities dedicated to protecting, restoring and enhancing our local natural environment. We care for the Credit River, its streams and tributaries from the headwaters in Orangeville to the shores of Lake Ontario in Mississauga. We are scientists, engineers, researchers, educators, environmentalists, stewards, planners, foresters, recreation experts and much more. We create connections between people and nature, knowledge and action. We inspire appreciation for the role of nature in keeping people connected, healthy and happy. We’re leaders and explorers. We are professional and we’re inspired. We know our stuff, and we work every day to make a difference.

Who are you?

You want to be part of an organization with an environmental goal. You get up every day and go to work with purpose. You accept that you may not change the world, but you’ll try to make an impact in your corner. You like to partner with skilled people across many professions. It’s as natural for you think about the outdoors as it is to think out of the box. You’re passionate, responsible and approachable. You do what’s right, not just what’s easy. You care, and it shows.

Why work for us?

We offer competitive public sector pay. We have a good employee benefits program. We’re members of the Ontario Municipal Employees Retirement System (OMERS) pension fund. We have flexible work hours for many positions. We find time to have fun and celebrate successes. You’ll have free access to our parks and discounts on recreational equipment rentals. You’ll know your co-workers by name and will make fast friends. You’ll like being at work.

Summary of Functions

Reporting to the Manager, Information Management at Credit Valley Conservation (CVC), this position will be responsible for CVC’s open data policy creation, working with stakeholders to ensure data quality and currency, deployment of open data platform and assist the Information Management team with various other ArcGIS online related projects, GIS analysis and data management. This is a 12-month contract position.

The primary role will be to focus on CVC’s status on various datasets, research and create open data policy with as per guidelines set out by the Information Management (IM) framework and in consultation with various stakeholders, deployment of the open data platforms and related ArcGIS online projects. The position also will support with meta data and data quality projects. The position will support the IM team for various GIS projects while assisting team members with an occasional database related work, particularly around integration with various systems.

This position will work closely with Records and Information Management System (RIMS) team, GIS team, mobile application/solutions team, and database team members on various tasks. Work will be performed according to guidelines, standards and recommendations provided by CVC. The specialist will work with developers to develop or enhance the front-end applications, primarily related to data, data management and visualization. The other role of the position involves integration or interlinking of various data and databases, including GIS and other information management systems.

Eligibility Requirements

Education

University degree or advanced diploma in geography, environmental science or studies, GIS, computer science.

Required Experience

3 years of relevant progressive experience with GIS, data management, databases, mapping, access databases, data quality review, analytics, databases, GIS, and visualization.
Very solid proven background and experience with various open data policies, platforms, implementation paths.
Strong expertise in GIS, ESRI based suites, particularly a background in publishing and coordinating with ArcGIS online related projects.
Experience or a strong understanding of various geohubs, open data solutions, story maps.
Understanding of a high-level integration of SQL server and GIS systems.
Experience with analytical and modeling software related to GIS.
Hands-on experience in process automation, best practice approach, technology efficiency, and effectiveness.
Experience in various database-related tasks.
Experience in troubleshooting and coming up with solutions.

Desirable Skills

Certification or accreditation in GIS or SQL server an asset.
Experience query building using Access and an understanding of SQL server system an asset.
Experience with project conception to implementation.
Knowledge of various databases, including geodatabase (enterprise, personal) to Access.
Experience with SQL Query Development as it relates to spatial and non-spatial databases an asset.

Knowledge, Skills, and Ability

Pro-active with “service-first” attitude, positive attitude with a great customer services as it requires interacting with clients for business requirement gathering.
Knowledge of, or experience with ESRI based Enterprise GIS systems.
Demonstrated advanced problem-solving abilities.
Excels at the highest technical level of all phases of applications systems analysis and programming activities.
Ability to exercise considerable independent judgment, tact, and sensitivity in dealing with internal and external contacts.
Able to present ideas and clearly articulate the concepts to management.
Excellent problem solving/analytical skills and knowledge of analytical tools.
Display and execute logical and complex troubleshooting methods.
Report writing and presentation skills as needed.
Excellent time management skills and the ability to prioritize and complete projects with conflicting deadlines and urgency.
Ability to work in a team environment as well as independently.
Proven ability to be innovative and flexible, doing what is needed to get the job done.
Ability to work independently and self-manage tasks to completion.
Ability to provide outstanding customer service, be a good listener and work well with others.
Outstanding attention to detail with superior time and project management skills.
Ability to learn new concepts and skills quickly.
A valid driver’s license and/or access to a vehicle an asset.

Summary of Major Tasks

GIS, Open Data, ArcGIS Online related projects

Open data related research, summary creation, policy drafting and coordinate platform deployment.
Review CVC’s current data holding, data licensing, intellectual properties on data, to prepare them for the public release.
Assist IM team in the existing data sharing processes and help streamline the process.
GIS, data management, and project implementation as a part of ArcGIS online or Enterprise GIS systems.
Utilize all available tools in GIS, with a particular focus on ArcMap, ArcGIS Pro, ArcGIS online, mobile solutions to help meet users' requirements.
Come up with various ways to deploy various spatial and non-spatial data to public.
Maintain documentation such as systems design and build documents.
Recommend data, data quality, and related software products to the IM manager as needed.
Gather user needs requirements; create scoping, provide relevant solutions to the users.
Research and stay up to date with innovative solutions and plan for a smooth transition from legacy tools and platforms.
Use a data-driven philosophy to help bring an objective, measurable and smart decision to CVC.
As a member of the IM team, work on all open data related projects to address CVC’s needs.
Test, configure, debug, and manage GIS-related solutions as assigned.
Stay current to technological changes and evaluate various platforms to implement at CVC.
Other duties as assigned.

Operational Tasks

Coordinate open data related projects and products.
Assist with various data, metadata, data sharing and other requests.
Work on ArcGIS online related project such as story maps as needed.
Work on GIS-related ongoing projects on a day to day basis that includes mapping, analyzing, QA/QC of various datasets.
Work on data and mapping maintenance such as conservation action plan studies that are ongoing.
Assist CVC’s staff on ArcGIS base solutions.
Track, coordinate, and inventory CVC’s spatial data and maintain a guideline, and quality and currency of the data.
Stay current to technological changes and evaluate new data management, mobile data collection platforms, and help to implement them to meet user needs.
Transfer knowledge to staff via lunch and learns, newsletter, etc. as needed.
Assists the department with other day-to-day tasks as needed.
Other duties as assigned.

Anticipated Start Dates: As soon as possible (35 hours/week)

Annual Salary Starting At: $68,196

Forward resume and cover letter by June 28th, 2021:

Please quote “21.2-Information Management Specialist (Open Data)” on resume/letter.

Resumes/letters submitted electronically must be submitted in Word or Pdf. format as one document.

We thank all applicants for their interest. However only those selected for an interview will be contacted. No phone calls please.

CVC is an Equal Opportunity Employer. In accordance with AODA (Accessibility for Ontarians with Disabilities Act, 2005), CVC will provide accommodations throughout the recruitment, selection and/or assessment process to applicants with disabilities. If you require disability – related accommodations, please inform the Human Resources (HR) staff. All personal information is collected under the authority of the municipal Freedom of Information and Protection of Privacy Act.

Reference ID: 21.2

Contract length: 12 months

Application deadline: 2021-06-28

Job Types: Full-time, Contract

Salary: From $68,196.00 per year","Credit Valley Conservation
4.1",Mississauga
444,"Specialist, Information Management (Open Data)","Who are we?

Credit Valley Conservation is one of Ontario’s 36 conservation authorities dedicated to protecting, restoring and enhancing our local natural environment. We care for the Credit River, its streams and tributaries from the headwaters in Orangeville to the shores of Lake Ontario in Mississauga. We are scientists, engineers, researchers, educators, environmentalists, stewards, planners, foresters, recreation experts and much more. We create connections between people and nature, knowledge and action. We inspire appreciation for the role of nature in keeping people connected, healthy and happy. We’re leaders and explorers. We are professional and we’re inspired. We know our stuff, and we work every day to make a difference.

Who are you?

You want to be part of an organization with an environmental goal. You get up every day and go to work with purpose. You accept that you may not change the world, but you’ll try to make an impact in your corner. You like to partner with skilled people across many professions. It’s as natural for you think about the outdoors as it is to think out of the box. You’re passionate, responsible and approachable. You do what’s right, not just what’s easy. You care, and it shows.

Why work for us?

We offer competitive public sector pay. We have a good employee benefits program. We’re members of the Ontario Municipal Employees Retirement System (OMERS) pension fund. We have flexible work hours for many positions. We find time to have fun and celebrate successes. You’ll have free access to our parks and discounts on recreational equipment rentals. You’ll know your co-workers by name and will make fast friends. You’ll like being at work.

Summary of Functions

Reporting to the Manager, Information Management at Credit Valley Conservation (CVC), this position will be responsible for CVC’s open data policy creation, working with stakeholders to ensure data quality and currency, deployment of open data platform and assist the Information Management team with various other ArcGIS online related projects, GIS analysis and data management. This is a 12-month contract position.

The primary role will be to focus on CVC’s status on various datasets, research and create open data policy with as per guidelines set out by the Information Management (IM) framework and in consultation with various stakeholders, deployment of the open data platforms and related ArcGIS online projects. The position also will support with meta data and data quality projects. The position will support the IM team for various GIS projects while assisting team members with an occasional database related work, particularly around integration with various systems.

This position will work closely with Records and Information Management System (RIMS) team, GIS team, mobile application/solutions team, and database team members on various tasks. Work will be performed according to guidelines, standards and recommendations provided by CVC. The specialist will work with developers to develop or enhance the front-end applications, primarily related to data, data management and visualization. The other role of the position involves integration or interlinking of various data and databases, including GIS and other information management systems.

Eligibility Requirements

Education

University degree or advanced diploma in geography, environmental science or studies, GIS, computer science.

Required Experience

3 years of relevant progressive experience with GIS, data management, databases, mapping, access databases, data quality review, analytics, databases, GIS, and visualization.
Very solid proven background and experience with various open data policies, platforms, implementation paths.
Strong expertise in GIS, ESRI based suites, particularly a background in publishing and coordinating with ArcGIS online related projects.
Experience or a strong understanding of various geohubs, open data solutions, story maps.
Understanding of a high-level integration of SQL server and GIS systems.
Experience with analytical and modeling software related to GIS.
Hands-on experience in process automation, best practice approach, technology efficiency, and effectiveness.
Experience in various database-related tasks.
Experience in troubleshooting and coming up with solutions.

Desirable Skills

Certification or accreditation in GIS or SQL server an asset.
Experience query building using Access and an understanding of SQL server system an asset.
Experience with project conception to implementation.
Knowledge of various databases, including geodatabase (enterprise, personal) to Access.
Experience with SQL Query Development as it relates to spatial and non-spatial databases an asset.

Knowledge, Skills, and Ability

Pro-active with “service-first” attitude, positive attitude with a great customer services as it requires interacting with clients for business requirement gathering.
Knowledge of, or experience with ESRI based Enterprise GIS systems.
Demonstrated advanced problem-solving abilities.
Excels at the highest technical level of all phases of applications systems analysis and programming activities.
Ability to exercise considerable independent judgment, tact, and sensitivity in dealing with internal and external contacts.
Able to present ideas and clearly articulate the concepts to management.
Excellent problem solving/analytical skills and knowledge of analytical tools.
Display and execute logical and complex troubleshooting methods.
Report writing and presentation skills as needed.
Excellent time management skills and the ability to prioritize and complete projects with conflicting deadlines and urgency.
Ability to work in a team environment as well as independently.
Proven ability to be innovative and flexible, doing what is needed to get the job done.
Ability to work independently and self-manage tasks to completion.
Ability to provide outstanding customer service, be a good listener and work well with others.
Outstanding attention to detail with superior time and project management skills.
Ability to learn new concepts and skills quickly.
A valid driver’s license and/or access to a vehicle an asset.

Summary of Major Tasks

GIS, Open Data, ArcGIS Online related projects

Open data related research, summary creation, policy drafting and coordinate platform deployment.
Review CVC’s current data holding, data licensing, intellectual properties on data, to prepare them for the public release.
Assist IM team in the existing data sharing processes and help streamline the process.
GIS, data management, and project implementation as a part of ArcGIS online or Enterprise GIS systems.
Utilize all available tools in GIS, with a particular focus on ArcMap, ArcGIS Pro, ArcGIS online, mobile solutions to help meet users' requirements.
Come up with various ways to deploy various spatial and non-spatial data to public.
Maintain documentation such as systems design and build documents.
Recommend data, data quality, and related software products to the IM manager as needed.
Gather user needs requirements; create scoping, provide relevant solutions to the users.
Research and stay up to date with innovative solutions and plan for a smooth transition from legacy tools and platforms.
Use a data-driven philosophy to help bring an objective, measurable and smart decision to CVC.
As a member of the IM team, work on all open data related projects to address CVC’s needs.
Test, configure, debug, and manage GIS-related solutions as assigned.
Stay current to technological changes and evaluate various platforms to implement at CVC.
Other duties as assigned.

Operational Tasks

Coordinate open data related projects and products.
Assist with various data, metadata, data sharing and other requests.
Work on ArcGIS online related project such as story maps as needed.
Work on GIS-related ongoing projects on a day to day basis that includes mapping, analyzing, QA/QC of various datasets.
Work on data and mapping maintenance such as conservation action plan studies that are ongoing.
Assist CVC’s staff on ArcGIS base solutions.
Track, coordinate, and inventory CVC’s spatial data and maintain a guideline, and quality and currency of the data.
Stay current to technological changes and evaluate new data management, mobile data collection platforms, and help to implement them to meet user needs.
Transfer knowledge to staff via lunch and learns, newsletter, etc. as needed.
Assists the department with other day-to-day tasks as needed.
Other duties as assigned.

Anticipated Start Dates: As soon as possible (35 hours/week)

Annual Salary Starting At: $68,196

Forward resume and cover letter by June 28th, 2021:

Please quote “21.2-Information Management Specialist (Open Data)” on resume/letter.

Resumes/letters submitted electronically must be submitted in Word or Pdf. format as one document.

We thank all applicants for their interest. However only those selected for an interview will be contacted. No phone calls please.

CVC is an Equal Opportunity Employer. In accordance with AODA (Accessibility for Ontarians with Disabilities Act, 2005), CVC will provide accommodations throughout the recruitment, selection and/or assessment process to applicants with disabilities. If you require disability – related accommodations, please inform the Human Resources (HR) staff. All personal information is collected under the authority of the municipal Freedom of Information and Protection of Privacy Act.

Reference ID: 21.2

Contract length: 12 months

Application deadline: 2021-06-28

Job Types: Full-time, Contract

Salary: From $68,196.00 per year","Credit Valley Conservation
4.1",Mississauga
445,"Applied Scientist, Alexa AI","PhD or equivalent Master's Degree plus 4+ years of experience in CS, CE, ML or related field
2+ years of experience of building machine learning models for business application
Experience programming in Java, C++, Python or related language
Are you excited about developing state-of-the-art Machine Learning, Computer Vision, Deep Learning and Natural Language Processing algorithms, and designs using large data sets to solve real world problems? Do you have proven analytical capabilities and can multi-task and thrive in a fast-paced environment?

As an Applied Scientist with the Alexa AI team, you will bring statistical modeling and machine learning advancements to data analytics for customer-facing solutions in complex industrial settings. You will be working in a fast-paced, cross-disciplinary team of researchers who are leaders in the field. You will take on challenging problems, distill real requirements, and then deliver solutions that either leverage existing academic and industrial research, or utilize your own out-of-the-box pragmatic thinking. In addition to coming up with novel solutions and prototypes, you may even need to deliver these to production in customer facing products


Expertise on a broad set of ML approaches and techniques, ranging from supervised to unsupervised learning including SVM, RDF & DNN.
A track record of thoughtful leadership and contributions that have advanced the field (Published in top tier conferences in the field of Machine Learning, Computer Vision, Multimodal, NLP)
Expertise in Deep Learning Framework (MXNet, Tensor Flow, etc.).
Experience in deploying deep learning algorithms on edge devices.
Experience working effectively with science, data processing, and software engineering teams.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, disability, age, or other legally protected status. If you would like to request an accommodation, please notify your Recruiter.","Amazon Dev Centre Canada ULC
3.8",Vancouver
446,Data Engineer,"Function: Data Science/Data Engineering
Reports to: Interim to SVP, Analytics and Optimization
Location: Toronto
Type: Full Time, Permanent**

Role Description
The Data Engineer is responsible for the deployment and maintenance of Machine Learning
systems and supporting data streaming pipelines in production. The role reports to the
Director, Data Science & Machine Learning.
As Data Engineer, you'll work closely with Data Scientists deploying and managing machine
learning solutions and build data streaming pipelines that support these solutions. You will
work with internal product and technology project teams involving large-scale data sets,
building Machine Learning pipelines for Machine Learning model training, and serving up the
personalized offers that power Exchange Solutions products.
This role is a unique opportunity to join a dynamic team of analytical professionals that
partners up with Business and Technology to design innovative, value-adding customer
engagement solutions for our clients. The role is a great fit for motivated individuals seeking
to further develop their expertise in the area of Machine Learning in the area of e-commerce
and customer loyalty personalized offers.

Primary Responsibilities
Be a part of a cross-functional organization that includes business product management,
technical product management, technical solution architects, data scientists, data
management, data analysts, software and Machine Learning engineers, etc.
Work closely with Product Managers, Architects, and Data Scientists to design, build,
maintain and optimize our data streams and machine learning applications.
Work with data scientists and engineers to deploy machine learning models in production.
Build and manage kinesis streams, feature stores used in Machine Learning model
training, and real-time prediction
Implement and automate continuous integration (CI), continuous delivery (CD), and
continuous training (CT) for machine learning (ML) systems.
Apply DevOps best practices and automated deployments, model and data versioning,
model validation, data validation, and monitoring Machine Learning production systems

Closely collaborate with Data Scientists and Machine Learning Engineers on the
implementation, scaling, and maintenance of data science solutions within personalized
offers products
Ensuring all relevant operational data sources ingest appropriately into standardized data
warehouse (Snowflake) schemas, working collaboratively with the Data Management
team
Implement and maintain model management and A/B testing framework for evaluating
test and trial of model and rule optimizations.
Participate in ESI Innovation labs as needed to support rapid product prototyping and
product development
Contribute to the overall operations and culture of the company, fostering our values and
policies.

Capability Requirements – education, skills & experience
Post-secondary education with a graduate degree in Computer Science, Machine
Learning, or related fields
Minimum 3-5 years’ experience with 1-2 years of data streaming experience
Proficiency with SQL and Python
Proficiency with SQL and NoSQL database technologies
Proven experience in implementation and maintenance of Machine Learning solutions
using AWS tooling such as kinesis streams, feature stores, Sagemaker, Lambdas
Understanding of open source streaming processing systems (Apache Kafka, Storm,
Spark streaming, Kinesis Analytics or Flink) will be a plus
Exposure to automated testing and CI/CD in the Machine Learning context
Understanding of fundamental Machine Learning concepts
Critical thinking, attention to detail and accuracy, high aptitude for problem-solving.
Excellent communication skills, both verbal and written.
Driven self-starter looking to learn, teach and contribute significantly to the energy of a
high-performing team.

Job Types: Full-time, Permanent","Exchange Solutions
4.0",Midtown Toronto
447,Senior Data Scientist - AWS Professional Services,"A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
10+ years of industry experience in predictive modeling, science and analysis
Previous experience in a ML or scientist role and a track record of building ML or DL models
Experience using and/or R
Knowledge of SparkML
Excited by using massive amounts of to Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? You will be eager to learn from many different enterprise’s use cases of AWS ML and DL. You are thrilled to be a key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?

At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

You enjoy diving deep into , doing analysis, discovering root causes, and designing long-term solutions. You like to have fun, love to learn, and want to innovate in the world of AI.

You will:

Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating , exploring , building & validating predictive models, and deploying completed models to deliver business impact to the organization.
Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
Work with our Professional Services Big consultants to analyze, extract, normalize, and label relevant .
Work with our Professional Services DevOps consultants to help our customers operationalize models after they are .
Assist customers with identifying model drift and retraining models.
Research and novel ML and DL approaches, including using FPGA.
Be able to write production level code, which is well-written and explainable
Have experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Have experience working with GPUs to models
Have experience handling terabyte size datasets
Be able to track record of diving into data to discover hidden patterns
Have familiarity with using data visualization tools
Have knowledge and experience of writing and tuning SQL
Past and current experience writing and speaking about complex technical concepts to broad audiences in a simplified format
This role is for Toronto/Vancouver/Calgary/Montreal.

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a value on work-live balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member and enable them to take on more complex tasks in the future.


PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
12+ years of industry experience in predictive modeling and analysis
Good skills with programming languages, such as or C/C++
Ability to experimental and analytic plans for modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentation in recognized Machine Learning, Deep Learning and Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Pipeline, & EMR
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contacted for an employment opportunity, advise Human Resources if you require accommodation, including in order to apply for a position.","Amazon Web Services Canada, In
3.8",Vancouver
448,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","Mississauga, ON, Canada
Full-time


Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2020, Eurofins generated total revenues of EUR € 5.4 billion, and has been among the best performing stocks in Europe over the past 20 years.

Eurofins CDMO Alphora Inc. provides a fully integrated suite of services to support drug substance and drug product development from the IND enabling development stage, through to phase II & III supply, and commercial validation and manufacturing for niche APIs. In addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, Eurofins CDMO Alphora Inc. is committed to growing its state-of-the-art organization, with continued investments in its people, modern facilities, equipment, and instrumentation.

Job Description

We are currently sourcing for 3 upcoming roles:

Research Scientist
Senior Research Scientist
Group Leader

The successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients (APIs).

Responsibilities will include but are not limited to:

Research Scientist, Senior Research Scientist

Planning and execution of experiments in R&D laboratories
Data analysis, interpretation, and documentation in development reports
Development of inherently safe processes based on thermal hazard assessment
Maintaining a safe and well-organized laboratory work area
Technology transfer to both internal and external manufacturing facilities

Group Leader

In addition to above:

Leading API technology programs and Scientists associated
Provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project-related issues, generating interim and final reports, preparing executive summaries for Clients and executive management team
Qualifications

Experience and Education Requirements:

B.Sc. or M.Sc. in Chemistry with >10 years experience or Ph.D in Chemistry with >5 years experience in the pharmaceutical or biotechnology industry
The Group Leader position will require a Ph.D in Chemistry with >10 years experience in the pharmaceutical or biotechnology industry
Must have a strong knowledge of organic chemistry and hands-on experience in the synthesis of complex organic molecules
Experience in process scale-up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset
Must be highly motivated and have a proven record of success in multiple projects
Must be well organized and able to meet project timeline commitments
Must work well in a multi-disciplinary team environment and have excellent written and verbal communication skills.
Additional Information

What we offer:

Excellent full time benefits including comprehensive and medical coverage, dental, and vision options
Life and disability insurance
RRSP/DPSP eligibility with company match
Paid vacation and holidays
Employee Assistance Plan, Tuition Program and much more

WORKING CONDITIONS:

This position will be working in a laboratory/manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. Intermediate lifting requirements of no more than 50 lbs. Hazardous materials are handled using established safety procedures and appropriate PPE.
Shift work and overtime may be required, as well as working periodic weekends and/or evenings.

Eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply; if accommodations are required in the application or interview process, please contact us via www.eurofins.ca. Only shortlisted candidates will be contacted - no phonecalls or emails please. Selected candidates can expect to be contacted in 3-6 weeks.

NO AGENCIES, PHONECALLS OR EMAILS PLEASE","Eurofins Central Laboratory
3.4",Mississauga
449,Data Engineer,"Summary:

The Data Engineer will be responsible for supporting, defining, and executing plans to create reporting solutions for our business and support teams. Primarily, the Data Engineer will be accountable for the movement of data from our enterprise systems (SAP BW, SQL) and landing it into a structured dataset for reporting solutions to utilize. These solutions include, but are not limited to, Business Intelligence and Data Visualization tools (SQL Server Analysis Service / Azure Analysis Services, Power BI Desktop). This position will work with business leads and IT to gather the reporting requirements and will help develop the solution. SAP BW, SAP Business Object, Power BI, Excel, SQL, SSIS, Azure Data Factory, and other tools will be used as necessary to provide the best solution possible. This position will create and/or support data models of varying complexity from concept to completion including documenting the solution. This position will be a part of the global business intelligence team and must be able to work in a team environment and share knowledge.

Essential Job Duties:

Data Engineering responsibilities include, but are not limited to (90%):

Create and build robust data structures to support end user's analysis and decision making across multiple business verticals. This includes both end-to-end architecting and business solutioning.
Collaborate with end users and peers to understand requirements, formulate use cases, and then translate into an effective technical solution.
Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products.
Effectively communicate and interact with business and technical personnel in solving complex data related business and technical problems.
Monitor data warehouse eco-system and identify opportunities to make enhancements.
Ensure data processes run and complete on a timely basis to ensure business continuity.
Adhere to timelines and excel in a fast-paced, high-energy environment.
Coach and develop other data professionals.
Drive data best practices and contribute to development of overall data strategy and roadmap.

Stay informed of latest engineering methodologies and industry direction (10%):

Stay informed of the latest Data Engineering industry news and direction.
Other duties as assigned


Reporting Relationships:

Data Engineering works under general supervision and may take direction from BI Engineering and the Data & Analytics Management
Reports to Data & Analytics Manager


Credentials:

Required:

Associate’s Degree or two years relevant experience
Strong understanding of relational and dimensional data modeling (Kimball Dimensional Modeling Methodology). Advanced experience working with data warehouses and ETL applications with expert-level knowledge of relational data.
Clear communication skills; the ability to explain complex technical concepts to non- technical internal clients.
Expertise in SQL (e.g. MS SQL, T-SQL, PostgreSQL, SPARQL)
Advanced experience leveraging various strategies for ingesting, modelling, processing, and persisting data as well as excellent analytical and problem-solving skills.
Experience with cloud data warehousing and management solutions.
Familiarity with Power BI and other visualization solutions (e.g. Tableau, Looker, Qlik, etc.).
Be a self-starter, with the ability to learn new technologies and work independently - an ideal candidate is curious and always willing to implement the latest and greatest technologies.
Demonstrated experience with Azure Data Factory, Azure SQL Managed Instance, and Azure DevOps, SQL Server Integration Services and other industry grade ETL tools.

Preferred:

Bachelor’s Degree or four years relevant experience as a Data Engineer or related specialty with demonstrable track record in developing data solutions that are correct, stable, and high performing; provide business value; and use resources efficiently (e.g. system hardware, data storage, query optimization, cloud infrastructure, etc.).
Coding proficiency in one or more languages (e.g. Python, Scala, Ruby, Java), expertise
SAP Experience
Expertise with Power BI, SSAS/AAS, and SSIS/Azure Data Factory
Cloud Experience preferred (e.g. AWS, Azure, Google Cloud Platform, etc.).
Proficiency in foreign language (Spanish, Portuguese, French, German)

Physical Requirements:

Ability to sit at a computer terminal for long periods of time.
Ability to be physically in attendance at workstation at designated company office location during normal business hours designated for the position.
Ability to handle considerable stress at times.


ScanSource, Inc. is an Equal Opportunity Employer

EOE/M/F","ScanSource Canada Inc.
5.0",Mississauga
450,"Sr. Data Scientist, Wish Local","Company Description


Wish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.



Job Description


We are looking for a Data Scientist who will work cross-functionally with technical and non-technical teams to take on a variety of tasks including but not limited to mining data, building models, building dashboards, and conducting detailed analysis. The ideal candidate should be passionate about Wish and e-commerce, has a strong analytical and consultative mindset, deep understanding of databases, visualization, and modeling techniques, and the ability to thrive in a dynamic, fast-paced environment delivering against tight deadlines. This role is looking for a data scientist that will drive high impact to the company through its newest function: Wish Local. The data scientist will help shape the data strategy of this program from the ground up.

What you'll be doing:

Design, development and evaluation of highly innovative models
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Work closely with software engineering teams to drive real-time model implementations and new feature creations
Analyze internal behavior tracking data and forecast Wish demand
Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate
Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process
Create & own dashboards and analytical reports to track progress & share learnings

#LI-MB1
#LI-REMOTE



Qualifications

Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar)
3+ years of hands-on experience in predictive modeling and analysis
3+ years experience writing complex SQL queries in a business environment
2+ years in Python
A/B test experience
Experience collaborating with business & eng teams

Preferred Qualifications:

Analytical mindset and ability to see the big picture and influence others
Detail-oriented and must have an aptitude for solving unstructured problems
Ability to work effectively in a multi-task, high volume environment
Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations
Experience operating in a Unix/Linux environment
Strong presentation skills

Additional Information


Wish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.","Wish
3.3",Midtown Toronto
451,Data Science Instructor,"About the Position

Exciting things are happening at Juno College! We’re in the midst of building out our Data Science Career Pathway and are seeking a full-time Instructor to join our Data Science team in May. We’re looking for someone who is collaborative, empathetic, and passionate about teaching, with a strong background in Data Science. This is a flexible role that’ll allow you to inspire and lead others, mould new pedagogies, research and test innovative ways of delivering content, and support the growth of our Data Science program offerings, while also still having the chance to practice your craft by taking on data science projects for Juno, exploring our various data sets, and delivering insights that can change the trajectory of our business.


We are currently offering all of our courses Live Online, and will only move back to in person learning when it's safe to do so. We anticipate having most, if not all, courses Live Online for all of 2021 and so this role is remote-friendly.


About Us

Founded in 2012, Juno College of Technology (formerly HackerYou College of Technology) is a well-loved provider of hands-on, project-based training for people who want to launch new careers in tech! From our 12,000 square foot office in downtown Toronto (pre- and post-COVID-19) to our Live Online classrooms, we run Bootcamps and continuing education courses year-round. With thousands of alumni and 1000+ students a year, there’s a large community of people ready to welcome you to Juno!


Responsibilities:

Work with a team of instructors and mentors to lead Data Analytics and Data Science courses, helping students learn through lessons, code-alongs and interactive exercises
Work directly with our students in the classroom and give project support
Help resolve issues, and coach through debugging and technical problem-solving
Provide a thoughtful, stimulating, and positive classroom experience
Participate in supporting student events
Create, update and refine curriculum using student feedback and new developments in the Data Science field according to our Curriculum Roadmap
Collaborate with the team to create and review program improvements and innovations
Contribute expertise to in-house data science projects using Juno’s data sets
Other tasks as required



About You

As a private career college, all of our instructors are required to have at least 2 years of practical, real-world experience as Data Analysts, Data Scientists or similar. Candidates who do not have the required experience will not be considered for this position. It would be great if you also have any experience as a teacher, instructor, or mentor, in any discipline.


Your Qualifications

Hold a degree, diploma, or certification from an Ontario college, university, private career college, or equivalent, and
Have 24 months occupational Data Science experience

Or

Have 36 months of teaching Data Science experience, and
Have 24 months occupational Data Science experience

Or

Have 48 months of occupational Data Science experience



You could be a great fit if you:

are an excellent public speaker and written communicator
are passionate about teaching data science and data fluency skills
have demonstrable hands-on industry experience in data science
are collaborative, energetic, and empathetic, and a great technical problem solver
have expertise in using Python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization
have practical knowledge of working with big data, performing customer segmentation, and using cloud services
are comfortable using Git, GitHub, Google Docs, Sheets, and Drive
have a positive attitude and a desire to help others.



Salary, Perks and Benefits

Position type: Full-Time, Permanent
Starting salary: $70,000 - $85,000
Clear growth paths
Three weeks paid vacation plus extra time off in December
Seven paid personal days each year
Health spending account refreshed annually
& more



Visit our Careers page at junocollege.com/careers for a full list of perks & benefits.


How to Apply

Please apply through the link below and answer the provided questions. We’d love to see your resume, and anything else you’d like to provide us! All applications are appreciated, but we will only contact successful applicants to move on to the next stage.","Juno College
2.8",Midtown Toronto
452,GCP Data Engineer,"ProCogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.




At ProCogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.




We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.




The Position




ProCogia are looking to add a Data Engineer with GCP Big Query experience to our Engineering team based in Vancouver.

The Data Engineer is a key member of the Data Engineering team. Your position will be based around building Enterprise Data Warehouse and Data Lake.


Main Responsibilities



Work in building and architecting multiple Data pipelines, end to end ETL and ELT process for Data ingestion and transformation in Google Cloud Platform (GCP)
Coordinating tasks amongst the team
Build, maintain, and monitor batch, micro-batch and real-time ETL pipelines in a Google Cloud Platform architecture (BigQuery, Dataproc, Cloud Composer, Cloud DataFlow, Google Cloud functions, etc.)
Work closely with the Data Science and Analytics teams to develop a clear understanding of data and data infrastructure needs; assist with data-related technical issue
Research and evaluate various approaches to data architecture and applications, including big data technologies; review existing artifacts and recommend solutions and technologies to implement
Analyze corporate data, design and develop Business Intelligence and other data management solutions
Perform data validation and quality assurance.
Document requirements and business rules into appropriate technical specifications
Participate in work planning and estimation
Present technical solutions to various stakeholders
Provide day-to-day support of the EDW and DL environments, with excellent customer service to internal clients, monitor new deployments and services, escalating issues where appropriate
Create Tableau data sources and dashboards for various Business stakeholders



Requirements



5+ years experience working in a directly comparable role responsible for data warehouse and/or data lake development
2+ years experience with Google Cloud Platform (BigQuery, GCS, Cloud Functions, Cloud Dataflow, Pub/Sub, Cloud Shell, GSUTIL, BQ command line utilities, DataProc, Cloud Operations)
2+ years experience with other cloud data technologies such as AWS (S3, Glue, Lambda, Lake Formation, CloudFormation, Athena, Redshift)
5 years working directly with relational databases with strong SQL programming skills; significant experience with SQL Server (DBMS, SSAS Tabular Model, SSRS), including MDX and DAX
3 years experience designing, building, and optimizing ‘big data’ pipelines, architectures, and data sets
3 years experience with modern programming languages (Python, PySpark, Java, etc.)
2 years experience working with NoSQL databases/repositories
2 years experience with big data solutions (Kafka, Hadoop, Spark, etc.), including data stream processing
Experience designing a new data solution or new subject area
Understanding of dimensional modeling, star schemas, and associated Kimball methodology
Excellent verbal and written skills in English
Exceptional attention to detail
Experience working on an Agile development team
Strong analytical, troubleshooting, and problem-solving skills
A proven ability to effectively prioritize and execute tasks in a high-pressure environment
A strong work ethic without sacrificing your sense of humor or your ability to have fun on the job.","ProCogia
4.7",Vancouver
453,Data Engineer,"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:

Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done

Here's what you'll be doing:

Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery

Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI

Why Join Us?

Bond is proudly recognized as a Great Place to Work and a Best Managed Company for the third year in a row.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

At Bond, we are proud to be a diverse organization and we are committed to building and fostering an environment where our employees feel included, valued, and heard. Our belief is that a strong commitment to diversity and inclusion enables us to truly create equal opportunity and positive employment experiences for everyone. We encourage applications from Indigenous peoples, racialized people, people with disabilities, people from gender and sexually diverse communities and people with intersectional identities.","Bond Brand Loyalty Inc
3.5",Mississauga
454,Chercheur scientifique - Principal - Research Scientist,"***English will Follow***

Résumé :

En tant que chercheur principal au sein du groupe de recherche ASR, le candidat effectuera des recherches algorithmiques sur des ensembles de données à l'échelle de production dans le but d'optimiser la précision, la vitesse et l'évolutivité, principalement pour les systèmes ASR de bout en bout qui équipent les produits Nuance. Ces recherches porteront notamment sur les architectures de réseaux neuronaux, les algorithmes d'entraînement et d'adaptation ([non/semi-]supervisés), ainsi que sur le traitement et l'augmentation des données.

Principales tâches et responsabilités -

Fournir une analyse expérimentale et théorique des problèmes de reconnaissance de la parole.
Formuler et mettre en œuvre de nouveaux algorithmes et concevoir/réaliser des expériences pour les vérifier.
Explorer de nouvelles architectures de modélisation de séquence à séquence pour améliorer la précision de la reconnaissance.
Optimiser la précision des systèmes de reconnaissance vocale de bout en bout sur des données réelles difficiles.
Suivre les développements externes en matière d'algorithmes de reconnaissance vocale afin de maintenir nos recherches à la pointe du progrès.
Discuter et présenter les idées et les résultats, en rendant compte régulièrement des progrès réalisés.
Rédiger des rapports techniques internes et des articles pour une publication externe.

Connaissances, compétences et qualifications -

Formation : Doctorat en informatique ou équivalent

Nombre minimum d'années d'expérience professionnelle : 3


Compétences requises :

Expérience et connaissances approfondies des algorithmes d'apprentissage automatique, y compris l'apprentissage profond.
Compréhension approfondie des algorithmes de reconnaissance vocale.
Capacité démontrée à mener des recherches inédites sur les algorithmes de reconnaissance vocale.
Expérience avec les boîtes à outils open source d'apprentissage profond (en particulier TensorFlow ou PyTorch).
Python et script shell dans un environnement UNIX.
Bonnes compétences en communication écrite et orale.
Capacité à prendre des initiatives, mais aussi à suivre un plan et à bien travailler au sein d'une équipe.

Compétences préféré :

Bonnes capacités d'analyse et de diagnostic.
Expérience de l'exécution d'expériences à grande échelle dans un environnement de calcul GPU en grille ou en nuage.
Expérience des techniques de modélisation de séquence à séquence.

-

Summary –

As a Principal Research Scientist in the ASR Research group, the candidate will perform algorithmic research on production-scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end-to-end ASR systems powering Nuance products. This will include research into neural network architectures, ([un/semi-]supervised) training / adaptation algorithms, and data processing / augmentation.


Principal duties and responsibilities-

Provide experimental and theoretical analysis of speech recognition problems.
Formulate and implement new algorithms and design/conduct experiments to verify them.
Explore new sequence-to-sequence modeling architectures for improving recognition accuracy
Optimize the accuracy of end-to-end speech recognition systems on challenging real-world data.
Follow external developments in speech recognition algorithms to keep our research state-of-the-art.
Discuss and present ideas and results, reporting progress on a regular basis.
Write internal technical reports and papers for external publication.


Knowledge, skills and qualifications –

Education: PhD in CS or equivalent

Minimum years of work experience: 3 years

Required skills:

· Strong background and knowledge of machine learning algorithms including deep learning.

· In-depth understanding of speech recognition algorithms

· Demonstrated ability to conduct novel research in speech recognition algorithms.
Experience with open source deep learning toolkits (especially TensorFlow or PyTorch)

· Python and shell scripting in a UNIX environment.

· Good written and oral communications skills.

· Ability to take initiative, but also follow a plan and work well as part of a team.

·

Preferred skills:

· Good analytical and diagnostic skills.

· Experience of running large scale experiments in a grid / cloud GPU computing environment.

· Experience with sequence to sequence modeling techniques.

What we offer!

Unique environment for collaborative teamwork on cutting-edge technology:

Location is in the heart of downtown Montreal

Flexible hours

Transit reimbursement and parking

Working with international teams to push the boundaries of technology

Contributing to and collaborating with international teams that drive innovation

Competitive benefit package

4 weeks’ vacation

10 paid sick days

Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan

Award-winning Top Employer:

Canada's Top 100 Employers – 7 consecutive years

Montreal’s Top Employers – 6 consecutive years

Canada's Top Employers for Young People - 3 consecutive years","Nuance
3.8",Montreal
455,Chercheur scientifique - Principal - Research Scientist,"***English will Follow***

Résumé :

En tant que chercheur principal au sein du groupe de recherche ASR, le candidat effectuera des recherches algorithmiques sur des ensembles de données à l'échelle de production dans le but d'optimiser la précision, la vitesse et l'évolutivité, principalement pour les systèmes ASR de bout en bout qui équipent les produits Nuance. Ces recherches porteront notamment sur les architectures de réseaux neuronaux, les algorithmes d'entraînement et d'adaptation ([non/semi-]supervisés), ainsi que sur le traitement et l'augmentation des données.

Principales tâches et responsabilités -

Fournir une analyse expérimentale et théorique des problèmes de reconnaissance de la parole.
Formuler et mettre en œuvre de nouveaux algorithmes et concevoir/réaliser des expériences pour les vérifier.
Explorer de nouvelles architectures de modélisation de séquence à séquence pour améliorer la précision de la reconnaissance.
Optimiser la précision des systèmes de reconnaissance vocale de bout en bout sur des données réelles difficiles.
Suivre les développements externes en matière d'algorithmes de reconnaissance vocale afin de maintenir nos recherches à la pointe du progrès.
Discuter et présenter les idées et les résultats, en rendant compte régulièrement des progrès réalisés.
Rédiger des rapports techniques internes et des articles pour une publication externe.

Connaissances, compétences et qualifications -

Formation : Doctorat en informatique ou équivalent

Nombre minimum d'années d'expérience professionnelle : 3


Compétences requises :

Expérience et connaissances approfondies des algorithmes d'apprentissage automatique, y compris l'apprentissage profond.
Compréhension approfondie des algorithmes de reconnaissance vocale.
Capacité démontrée à mener des recherches inédites sur les algorithmes de reconnaissance vocale.
Expérience avec les boîtes à outils open source d'apprentissage profond (en particulier TensorFlow ou PyTorch).
Python et script shell dans un environnement UNIX.
Bonnes compétences en communication écrite et orale.
Capacité à prendre des initiatives, mais aussi à suivre un plan et à bien travailler au sein d'une équipe.

Compétences préféré :

Bonnes capacités d'analyse et de diagnostic.
Expérience de l'exécution d'expériences à grande échelle dans un environnement de calcul GPU en grille ou en nuage.
Expérience des techniques de modélisation de séquence à séquence.

-

Summary –

As a Principal Research Scientist in the ASR Research group, the candidate will perform algorithmic research on production-scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end-to-end ASR systems powering Nuance products. This will include research into neural network architectures, ([un/semi-]supervised) training / adaptation algorithms, and data processing / augmentation.


Principal duties and responsibilities-

Provide experimental and theoretical analysis of speech recognition problems.
Formulate and implement new algorithms and design/conduct experiments to verify them.
Explore new sequence-to-sequence modeling architectures for improving recognition accuracy
Optimize the accuracy of end-to-end speech recognition systems on challenging real-world data.
Follow external developments in speech recognition algorithms to keep our research state-of-the-art.
Discuss and present ideas and results, reporting progress on a regular basis.
Write internal technical reports and papers for external publication.


Knowledge, skills and qualifications –

Education: PhD in CS or equivalent

Minimum years of work experience: 3 years

Required skills:

· Strong background and knowledge of machine learning algorithms including deep learning.

· In-depth understanding of speech recognition algorithms

· Demonstrated ability to conduct novel research in speech recognition algorithms.
Experience with open source deep learning toolkits (especially TensorFlow or PyTorch)

· Python and shell scripting in a UNIX environment.

· Good written and oral communications skills.

· Ability to take initiative, but also follow a plan and work well as part of a team.

·

Preferred skills:

· Good analytical and diagnostic skills.

· Experience of running large scale experiments in a grid / cloud GPU computing environment.

· Experience with sequence to sequence modeling techniques.

What we offer!

Unique environment for collaborative teamwork on cutting-edge technology:

Location is in the heart of downtown Montreal

Flexible hours

Transit reimbursement and parking

Working with international teams to push the boundaries of technology

Contributing to and collaborating with international teams that drive innovation

Competitive benefit package

4 weeks’ vacation

10 paid sick days

Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan

Award-winning Top Employer:

Canada's Top 100 Employers – 7 consecutive years

Montreal’s Top Employers – 6 consecutive years

Canada's Top Employers for Young People - 3 consecutive years","Nuance
3.8",Montreal
456,"Compliance Manager, Data Protection & Cybersecurity","Do you want to join a rocket ship that is passionate about data protection and
building a compliant product the right way?
Do you want to leverage your GDPR, HIPAA or SOC 2 compliance expertise to help us
cure COVID and cancer?
Do you want to work with a gender-balanced team of highly recognized experts in the
field of Cybersecurity, AI and Genomics?
My Intelligent Machines (MIMs) is looking for a talented Compliance Manager, Data Protection & Cybersecurity to help build a world class augmented intelligence R&D platform for life scientists working in BioPharma and agriculture companies. MIMs is a fast-growing software company, with recurring revenues, that embraces Agile and Privacy by Design methodologies. Reporting directly to the COO, you will be working closely with our Cybersecurity Analysts, DevOps Engineers, System Administrators, bioinformaticians, life scientists, data scientists, AI and software developers to establish best practices for the AI revolution in genomics.
Main Responsibilities
Collaborate with our open-minded teams to maintain compliance with these guidelines and standards:
European General Data Protection Regulation (GDPR)
US Health Insurance Portability and Accountability Act of 1996 (HIPAA)
SOC 2
Cybersecurity Framework of the US Nat Inst. of Stand. and Tech. (NIST)
Canada Personal Information Protection and Electronic Documents Act
(PIPEDA)
California Consumer Privacy Act (CCPA)
ISO 27001
Hébergeur de Données de Santé (HDS)
Translate legislation and regulations into policy and procedures in order to embed them smoothly in day-to-day activities
Be the company expert and champion on new regulatory developments (e.g. consultation papers, communication from regulators), industry trends, and how they apply to MIMs
Assessment and review of Company’s service level agreements with outsourced companies and regularly review compliance of outsourced companies with these agreements
Provide advice, assistance and support to the business on compliance related matters
Assuring the design, implementation and execution of compliance framework in line with all policies
Setting up compliance by design especially in customer journeys or digital initiatives and while setting up playbooks for a further explanation of specific topics
Promoting a strong compliance culture and contributing to training and awareness on the topic of data protection and cybersecurity
Plan & support Internal and External Audits
Regularly monitors and reviews risks as part of the compliance risk management process
Advise on further mitigation or on specific control testing
Provide guidance and feedback to the security team and compliance teams in implementing the various initiatives launched by MIMS
Guides on incident learning reports, investigates (whistleblowing) incidents. Takes the lead in person oriented investigations
Carry out due diligence checks on new clients and suppliers or consultants
Qualifications
Minimum of 5 years of experience in a similar role
A relevant certification from this list or the desire to achieve one, fully paid by
MIMs:
Certified Ethical Hacker (CEH)
Certified Information Systems Security Professional (CISSP)
Certified Compliance Professional (CAMS)
CompTIA Security+
GIAC Information Security fundamentals (GISF)
ISACA CSX
Microsoft Technology Associate (MTA) Security Fundamentals
System Security Certified Practitioner (SSCP)
Experience with identifying and resolving IS (security) technology related problems in an industrial and international company is a plus
High-level of professionalism, even in the midst of multiple engagements
Experience in working on multiple projects concurrently using Agile methodologies
Experience with programming and/or scripting languages is a plus
High level of proficiency in English
High level of proficiency in French is a plus
A confident approach and an ability to communicate with a wide range of people including regulators, legal advisors, outsourced partners and senior management
Relevant University Degree
Who you are
A flexible attitude to job roles as well as a willingness to contribute wherever needed
The ideal candidate will take full ownership of their core responsibilities, and will be comfortable with those responsibilities evolving with the changing needs of the company
The ideal candidate is exceptionally detail-oriented and derives joy from bringing rigor, structure, and organization to complex systems
Ability to contribute in a multidisciplinary team as a strong team player, focused on delivering results against multiple deadlines in a fast-paced growing environment
Submission
Please submit your resume or any questions you may have to hr@mims.ai. We would like to hear from you even if you are not sure you have all the qualifications.
By applying to this position, you are confirming you possess either a Canadian citizenship,
permanent resident status or work permit.
We thank all those who apply but only those selected for further consideration will be contacted.
About MIMs
My Intelligent Machines (MIMs), based in Montreal, is a leader in artificial intelligence applied to life sciences. We provide Biopharma and Agtech companies with augmented intelligence systems enabling life scientists working in this space to model patients, cells, tissues or farm animals to develop more efficient and personalized treatments and agro-products. The company is growing at a fast pace and has a strong and active research and development team.
MIMs is a dynamic tech company with an exceptional culture which embraces diversity and gender equity. New team members consistently rate our onboarding and integration process as one of the best they have seen in their career. We are currently one of the few tech companies reaching gender balance, as half of the team is composed of women. We received the 2020 Red Herring’s Top 100 North America Award, one of the most prestigious prizes granted each year to the 100 most promising private tech companies.
For more information, please visit https://www.mims.ai",My Intelligent Machines,Montreal
457,Chercheur Scientifique Senior - Senior Research Scientist,"***English Will Follow***

Résumé :

En tant que chercheur senior au sein du groupe de recherche ASR, le candidat effectuera des recherches algorithmiques sur des ensembles de données à l'échelle de production dans le but d'optimiser la précision, la vitesse et l'évolutivité, principalement pour les systèmes ASR de bout en bout qui équipent les produits Nuance. Ces recherches porteront notamment sur les architectures de réseaux neuronaux, les algorithmes d'entraînement et d'adaptation ([non/semi-]supervisés), ainsi que sur le traitement et l'augmentation des données.





Principales tâches et responsabilités

Fournir une analyse expérimentale et théorique des problèmes de reconnaissance de la parole.
Formuler et mettre en œuvre de nouveaux algorithmes et concevoir/réaliser des expériences pour les vérifier.
Explorer de nouvelles architectures de modélisation de séquence à séquence pour améliorer la précision de la reconnaissance.
Optimiser la précision des systèmes de reconnaissance vocale de bout en bout sur des données réelles difficiles.
Suivre les développements externes en matière d'algorithmes de reconnaissance vocale afin de maintenir nos recherches à la pointe du progrès.
Discuter et présenter les idées et les résultats, en rendant compte régulièrement des progrès réalisés.
Rédiger des rapports techniques internes et des articles pour une publication externe.

Connaissances, compétences et qualifications -

Formation : Doctorat en informatique ou équivalent

Nombre minimum d'années d'expérience professionnelle : 3

Compétences requises :

Expérience et connaissances approfondies des algorithmes d'apprentissage automatique, y compris l'apprentissage profond.
Compréhension approfondie des algorithmes de reconnaissance vocale.
Capacité démontrée à mener des recherches inédites sur les algorithmes de reconnaissance vocale.
Expérience avec les boîtes à outils open source d'apprentissage profond (en particulier TensorFlow ou PyTorch).
Python et script shell dans un environnement UNIX.
Bonnes compétences en communication écrite et orale.
Capacité à prendre des initiatives, mais aussi à suivre un plan et à bien travailler au sein d'une équipe.

Compétences souhaitées :

Bonnes capacités d'analyse et de diagnostic.
Expérience de l'exécution d'expériences à grande échelle dans un environnement de calcul GPU en grille ou en nuage.
Expérience des techniques de modélisation de séquence à séquence.

-

Position summary:

As a Senior Research Scientist in the ASR Research group, the candidate will perform algorithmic research on production-scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end-to-end ASR systems powering Nuance products. This will include research into neural network architectures, ([un/semi-]supervised) training / adaptation algorithms, and data processing / augmentation.


Principal duties and responsibilities –

Provide experimental and theoretical analysis of speech recognition problems.
Formulate and implement new algorithms and design/conduct experiments to verify them.
Explore new sequence-to-sequence modeling architectures for improving recognition accuracy
Optimize the accuracy of end-to-end speech recognition systems on challenging real-world data.
Follow external developments in speech recognition algorithms to keep our research state-of-the-art.
Discuss and present ideas and results, reporting progress on a regular basis.
Write internal technical reports and papers for external publication.



Knowledge, skills and qualifications –

Education: PhD in CS or equivalent

Minimum years of work experience: 3

Required skills:



Strong background and knowledge of machine learning algorithms including deep learning.
In-depth understanding of speech recognition algorithms
Demonstrated ability to conduct novel research in speech recognition algorithms.
Experience with open source deep learning toolkits (especially TensorFlow or PyTorch)
Python and shell scripting in a UNIX environment.
Good written and oral communications skills.
Ability to take initiative, but also follow a plan and work well as part of a team.

Preferred skills:

Good analytical and diagnostic skills.
Experience of running large scale experiments in a grid / cloud GPU computing environment.
Experience with sequence to sequence modeling techniques.

What we offer!

Unique environment for collaborative teamwork on cutting-edge technology:

Location is in the heart of downtown Montreal

Flexible hours

Transit reimbursement and parking

Working with international teams to push the boundaries of technology

Contributing to and collaborating with international teams that drive innovation

Competitive benefit package

4 weeks’ vacation

10 paid sick days

Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan

Award-winning Top Employer:

Canada's Top 100 Employers – 7 consecutive years

Montreal’s Top Employers – 6 consecutive years

Canada's Top Employers for Young People - 3 consecutive years","Nuance
3.8",Montreal
458,Senior Data Scientist - 311451,"Senior Data Engineer

On behalf of our Client, PROCOM is searching for a Senior Data Scientist. The candidate should have excellent foundations of a seasoned data scientist. This professional is a dedicated Senior Data Scientist with excellent knowledge of Phyton, SQL and data science toolkits. This professional will be responsible for maintaining fast growing datasets, developing custom data models, and extracting actionable insights to make our client’s products more enjoyable and intuitive for their customers. This position works in close collaboration with cross functional teams to influence product innovation. If you want to learn the right approach to delivering the best health care experiences to our customers and are passioned about the health and wellness industry, this career path is for you. Additionally, this professional must enjoy working in a fast-paced environment, using cutting-edge technology, and working with big data. You want to be a part of something bigger them yourself and strive to change lives for better, through digital health solutions for end users. Being passioned about user experience and work well in a collaborative, knowledge-sharing environment will your give the edge you need to apply for this role.

Job Details
As the Senior Data Scientist in this team, you will:

Build and expand machine learning models using NLP, classification, Neural Networks, etc.
Work with Engineers to integrate data from multiple sources and develop predictive algorithms.
Extract actionable insights from complex data sets and report insights via internal dashboards and visualization to Product teams for roadmap and feature decisions.
Review latest research papers and trends in the field of Artificial Intelligence and update team with new technologies.
Communicate findings and new trends with company leadership.
Conduct exploratory analysis and develop statistical models to answer key product usage and engagement questions.
Help Product and Marketing teams use experimentation and cohorting to test assumptions and launch new marketing campaigns, features and product releases.
Partner with Product teams to define and benchmark metrics for new features launches and initiatives and help create a culture of measurement.

Mandatory Skills
As the Senior Data Scientist in this team, you will:

Master’s degree or higher in computer science, statistics, electrical engineering, or other related fields.
5+ years’ experience as Data Scientist.
Proficiency in using Python and SQL.
Proficiency in using data science toolkits such as Keras, Tensorflow, PyTorch, etc.
Practical experience in time series analysis and sequential modeling.
Prior experience developing machine learning approaches for modeling and predicting user behaviors.
Prior experience building NLP pipelines for chatbots in a limited training data environment.
Prior experience building REST APIs and interfacing applications with other 3rd party APIs.
Ability to work independently and with moderate supervision.
Exceptional organizational skills and problem-solving ability.
Good communication skills, both verbal and written.



Soft Skills

Stable employment history
Passion for helping people
Collaborative nature

If you think you could add value to a group of passionate and dedicated health and wellness professionals; and be a part of a learning environment that values your contributions, let us know, please. We look forward to seeing your application!","Procom
4.3",Vancouver
459,"Data Engineer, Trust and Safety Operations","Dapper Labs is at an inflection point in our journey and it might be the perfect time for you to join us. Less than 6 months ago we launched NBA Top Shot on the new Flow blockchain and it is already on track to be the fastest-growing marketplace in history. Over $200 million in sales in the past 30 days and counting – we need to scale our systems to handle the demand!

We're looking for product-minded data engineers to build out our fraud protection team. You'll join a small team that's scaling rapidly and build sustainable foundations for the future.



Our data pipeline currently include Segment and Tableau. Most of our backend systems are in Go, frontends in React. We use vanilla postgres as well as Kafka event-driven architecture in NBA Top Shot. This is an opportunity to help define the company's data strategy, while laser focused on enabling the organization to make data-driven decisions by unlocking the distribution, collection, and tooling of data.

We believe in an open digital future: one where people own the assets they pay for and have full transparency into the software they're using. We believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they're helping create. Crypto, or blockchain, is the technology that enables this future. Blockchains are public computers that anyone can access, everyone can trust, and no-one can block or take down. Currencies and collectibles are only scratching the surface of what's possible.



Titles or years of experience don't matter to us – impact, authenticity, and values alignment do. We are now a remote-first team and open to hiring anywhere in the world.



About the role:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity
Work with Google Cloud Platform, BigQuery, Cloud Composer, etc, and drive adoption of other key technologies
Cleaning, processing, transposing data from our data lake to endpoints like Tableau
Create predictive models to understand user-level fraud risk
Consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality
Research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities
Innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the Dapper product team and our finance department
Bonus points if you have the following:
You have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made
You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply
You have a bachelor's degree in a highly quantitate field (Computer Science, Machine Learning, Statistics, Mathematics), and a master's degree preferred
You have 5+ years working experience in data science and or machine learning. Strong knowledge of SQL and python programming and graph databases
You are naturally curious and passionate about fraud prevention: if something seems off, you want to investigate what's going on and solve the true problem
You are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions

More about Dapper Labs:

Dapper Labs is the world's first blockchain entertainment company. We are the creators of industry-leading experiences including CryptoKitties and NBA Top Shot, as well as Dapper Wallet, the simplest way to manage your assets and use the blockchain. We are also the original developers behind Flow, a new decentralized blockchain designed from the ground up for scalability and ease of use.

Our mission at Dapper Labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. We have raised over $350M from leading VCs including Fred Wilson (USV) and Chris Dixon as well as Venrock, Samsung, Google Ventures, Coatue, NBA players, and global artists, among others. Dapper Labs partners include the NBA and NBPA, the NFL-PA, Ubisoft, Warner Music, Turner, Dr. Seuss, Genies, and the UFC, as well as 100+ others.

Visit our website to learn even more about Dapper Labs, including information about benefits and perks.","Axiom Zen
4.3",Vancouver
460,"Data Engineer / Power BI Developer, Omnia AI","Job Type: Permanent
Primary Location: Vancouver, British Columbia, Canada
All Available Locations: Vancouver; Calgary; Edmonton

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the officev


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Data Engineer / Power BI Developer within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in technical data solutions including ETL, data integration, data warehousing, dimensional models, in-memory architectures, master data/reference management, business visualization and business analytics. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Engineer and architect ETL and BI/DW solutions to enable business analytics and drive insights

Translate business rules and requirements into data objects, visualizations, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly

Plan/schedule tasks, lead small development teams, and mentor junior colleagues

Facilitate technical meetings with client staff and advise client with technical option analyses based on leading practices

About the team


Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge BI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

The Integration Modernization Practice helps clients manage the complexity inherent in today’s diverse business landscape while supporting them in consolidating or customizing multiple technologies. You will be part of a multi-disciplinary team focused on delivering a breadth of solutions to solve our clients most challenging business problems, with a focus on Integration Platforms, API design, and Micro and Web Services. We help our customers to reduce costs and risks by simplifying integration with existing systems and supporting them in all aspects of creating customized and innovative digital solutions.

Enough about us, let’s talk about you


You are someone with:

Bachelor’s Degree in Computer Science, Mathematics or Statics; Master’s Degree desirable

5 or more years of BI – Data Engineering related experience with high proficiency in PL/SQL coding, Power BI, Python, Cloud-based data platforms (AWS and Azure preferred), database management, and ETL from job creation to performance testing and tuning

Ability to tackle tight deadlines and work under pressure

Experience working in fast-paced Agile environments an asset

Competent decision-making capabilities with ability to respond and react to emergency situations effectively and communicate to stakeholders, client leadership, and individuals at several organization levels

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Vancouver
461,Data Engineer,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21275

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease.

We are seeking an ambitious and experienced Data Engineer to join our Data Management team and contribute towards building a dynamic and scalable architecture in support of our rapidly advancing data pipeline. The ideal candidate will have experience working with ambiguity and be a creative thinker as our data landscape continues to evolve in scale, complexity, and demand. We are a fast-moving and innovative company that lives on the frontier of discovery, both scientifically and technically. As such, the successful candidate will spend their days focused on the design and implementation of a sophisticated data architecture that maximizes data quality, value, and velocity based on the needs of a talented team of scientists and developers.

How you might spend your days:

Identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Working with our team of developers to help improve the flow of data across the technology stack.
Building the infrastructure required for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources using SQL and AWS big data technologies.
Working with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Designing and publishing data models with supporting architecture that reflect on the prevailing needs of the organization; ensuring proposed solutions are scalable and dynamic.
Leveraging experience with multiple AWS services (S3, Redshift, Kinesis and RDS., etc.) or equivalent to design solutions in response to the data needs of key stakeholders and teams.
Together with the software development teams, optimizing and ensuring data security through integration and management of identity management tools within proposed data architecture.
Working with the Data Governance Office to ensure proposed solutions adhere to and align with the published data recommendations, practices, and policies.
Sharing your knowledge in data engineering with team members and colleagues, helping to elevate the core understanding for big data architecture and its impact on improving business processes.

We'd love to hear from you if you have:

5+ years of work experience with ETL, Data Modeling, and Data Architecture.
4+ years of work experience in writing advanced SQL
Bachelor’s Degree in quantitative areas such as Computer Science, Information Systems, Big Data & Analytics, or related fields.
Experience with Relational SQL and NoSQL databases: Postgres, MS SQL Server, and Cassandra, etc.
Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirement
Experience building and optimizing big data data pipelines, architectures and data sets.
Experience with data lakes, data warehousing, and the associated tools and applications for managing the flow of data across these environments.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong project management and organizational skills.
Experience with Agile development methods in data-oriented projects
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in tracking data lineage, ensuring data quality, and improving discoverability of data.

Preferred Qualifications:

Experience with native AWS technologies for data and analytics such as Redshift Spectrum, Athena, S3, Lambda, Glue, EMR, Kinesis, SNS, CloudWatch, etc. or equivalent relevant technologies (e.g. Snowflake, Alteryx, Matillion, Boomi , etc.)
Expertise in one or more programming languages, preferably Scala, PySpark, Python and/or Java.
Experience with big data tools (e.g. Hadoop, Spark, Kafka, etc.).

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please send us your application through our website and refer to Job ID 21275 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera Biologics
4.8",Vancouver
462,Cloud Data Engineer- GCP/BigQuery,"Job Description:
Applied Systems, Inc., a worldwide leader in insurance technology, is currently searching for a knowledgeable and talented Cloud Data Engineer-GCP/BigQuery to join our Data Engineering Team. This team works to build data solutions and implement tools to help improve data accuracy and reliability so our customers can make data-driven decisions with confidence. As the Cloud Data Engineer, you will be responsible for the design and implementation of our data lake ensuring reliable data infrastructure and creating data solutions for business partners.

RESPONSIBILITIES
Drive innovation within Data Engineering by playing a lead role in technology decisions for the future of our data science, analysis, and reporting needs
Work with business partners and software engineers to gather, understand, and bridge definitions and requirements
Lead the design and development for highly complex and critical data projects with strict timelines
Drive efficiency gains through improved reliability and stakeholder adoption of self-serve tools
Leverage research and previous experience to ensure we’re up to date and continuously exploring
Identify gaps and weaknesses in our data stack and continues to drive learning advancements for the team
Provide technical expertise, leadership, and mentor the Data Engineering team in all phases of work including analysis, design, and development of architecture
Design, build and work with dispersed engineering teams and business users to implement data pipelines into our centralized data platform
Developing in Python leveraging a wide range of technologies, notably: GCP, BigQuery, Google Pub/Sub, Google DataFlow, Kubernetes, and Docker
Develop cloud data pipelines to transform and process data between systems
Maintaining, improving existing continuous integration/delivery (CI/CD) pipelines
QUALIFICATIONS FOR THIS JOB
3+ years of development experience building large scale data solutions
Experience with GCP BigQuery, GCP DataFlow, GCP Pub/Sub, Apache Airflow and Python preferred
Experience with GitOps in an Infrastructure as Code culture.
Experienced with Git and common development workflows in Github/Gitlab/Bitbucket
Experienced with CI/CD declarative pipelines
Experience with Docker for containerizing applications and workloads
Experience with Terraform (or related technology) for infrastructure provisioning
Experience with reporting schema designs including data modeling, denormalization, data warehousing, and data lakes
Experience with data quality monitoring and alerting on dynamic data sources, including anomaly detection
Experience with metadata management, data governance, data catalogs, and data discovery
Proven ability to work closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality
Ability to communicate technical hurdles and challenges clearly and succinctly
Take problems from inception to completion - own the building, automated testing, deployment, and maintenance of the code that you work on

WHO WE ARE
LEADING GLOBAL PROVIDER OF CLOUD-BASED INSURANCE SOFTWARE- Applied Systems develops the top two Insurance Agency/Broker Management software products in the world. In addition, we also provide innovative mobile apps, Data Analytics, Customer Self-Service, Insurer Connectivity & Rating, eServicing, Benefits Design, and CRM software products. By automating the insurance lifecycle, Applied’s people and products enable millions of people around the world to safeguard and protect what matters most.
CLOUD SOLUTIONS & PROFESSIONAL SERVICES- We offer cloud solutions, 24x7 technical support, consulting, implementation, and education services.
AWARD WINNING TECHNOLOGY- We have been voted
2020 Company of the Year (Stevie Award)
2020 New Product or Service of the Year- 2 awards (Stevie Award)
2019 Best Cloud-Based Software Solutions Provider in the insurance industry (2019 Corporate Excellence Awards)
2019 Digital Service Provider of the Year (Business Excellence Awards)
2019 Best Broker Software Management House (Insurance Times)
GOOGLE’S INVESTMENT IN APPLIED- Google/CapitalG made a minority investment in Applied that will spur AI, machine learning, and digital marketing innovation in the global insurance industry.
CLIENTS- We provide technology to over 160k users within insurance agencies, brokerages, and carriers throughout the US, Canada, the UK, and Ireland.
EMPLOYEES- Applied currently has 1,800+ employees across the US, Canada, the UK, and Ireland.

COMPANY CULTURE & PERKS
JOIN A GREAT TEAM- We believe that success comes from a dynamic working environment that offers professionals an opportunity to grow and succeed alongside extraordinary people. We encourage idea sharing, problem solving, and teamwork in our environment.
DIVERSITY MATTERS- We strive to create a positive workplace culture for those of different thinking, backgrounds, experiences, expertise, and individual qualities across our organization. We want the best and the brightest to be a part of a growing culture that embraces a sense of belonging.
RELAXED DRESS CODE- Applied allows for a relaxed dress code where jeans are permitted; we call this “Dress for your Day”.
FUN PARTIES & PERKS- Fun perks are a staple at Applied, including holiday parties with games and contests, summer celebrations employee appreciation events, art contests, employee discount programs, and more!
OPPORTUNITIES FOR ADVANCEMENT- We are a growing company that offers career opportunities, and not just “another job”. Applied believes in growing our employees and promoting from within, offering many opportunities for professional advancement along the way!
CAREER STABILITY & LONGEVITY- Our average employee tenure is 9 years.
CULTURE OF RECOGNITION- Applied provides a culture of employee recognition with our Circle of Excellence program, and our internal social network recognition program.
APPLIED CARES- We have a culture that embraces and promotes volunteerism. Applied encourages our employees to help local charities and communities through the ‘Applied Cares’ program

BENEFITS & REWARDS
BENEFITS FROM DAY ONE- Applied offers Medical, Rx, Dental, Vision, Virtual Doctors’ Appointments, Health Savings Account, Flexible Spending Accounts, Critical Illness, Group Accident, and Wellness Incentives to ensure employees are covered from day one.
FINANCIAL PEACE OF MIND- In addition to wellness benefits, Applied offers traditional and Roth 401k options, with employer match. Accidental Death & Dismemberment, Short and Long Term Disability, and Business Travel Accident insurance are also offered.
WORKLIFE BALANCE- There is more to life than work: that is why Applied offers benefits to help balance your work and home life. We offer competitive paid vacation time, personal/sick time, paid holidays, summer hours, paid parental leave, volunteer time off, and a free day off for your birthday!

TO LEARN MORE
Please visit AppliedSystems.com

Applied Systems is an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Applied, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.


#LI-Remote","Applied Systems, Inc.
4.2",Remote
463,"Data Engineer, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Vancouver; Montreal; Ottawa; Toronto

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the office.


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Data Engineer on our Data & Analytics Modernization team within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in technical data solutions including ETL, data integration, data warehousing, dimensional models, in-memory architectures, master data/reference management, and business analytics. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Engineer and architect ETL and BI/DW solutions to enable business analytics and drive insights
Translate business rules and requirements into data objects, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly
Plan/schedule tasks, lead small development teams, and mentor junior colleagues
Facilitate technical meetings with client staff, and advise client with technical option analyses based on leading practices
About the team


Omnia AI, Deloitte’s Artificial Intelligence (AI) practice is comprised of a collaborative team of experts who use their hands-on experience with cutting-edge information assets to facilitate successful AI transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

Enough about us, let’s talk about you


You are someone with:

3+ years experience with analysis, design, development, testing and deployment of ETL services in relational data warehouse environments on DB2, Oracle, SQL Server and/or SAP/HANA using technologies such as Informatica PowerCenter, IBM DataStage, Microsoft SSIS and/or Talend for batch and/or real-time data processing
3+ years implementation experience with data warehouse architectures, data vaults, dimensional models, and/or star schema designs implemented on MPP, in-memory/columnar databases, cloud-based and/or RDBMS platforms
Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirements
Experience with Agile development methods in data-oriented projects
Completed Bachelor’s Degree (or higher) in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or related field is desired

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.","Deloitte
3.9",Midtown Toronto
464,Data Engineer,"Open up to the Possibilities!
At Purolator, you’ll be proud knowing you’re working for a Canadian company that truly values its employees. And it’s community. This is an exciting and evolving industry and we’re leading the change as we strive to deliver the future. Here you will be empowered to help move the business forward. Each and every day. Are you open to the possibilities?


Job Description


Successful candidates will demonstrate excellent skill and maturity, be self-motivated as well as team-oriented, and have the ability to support the development and implementation of solutions to meet the needs of our customers. Your strong experience and skills in Business Intelligence and Data Architecture will help Purolator leverage its data for a variety of analytic use cases to support strategic decision making, in a way that is governed, sustainable, and scalable.

You are passionate about data, and not only do you understand the mechanics of how to access, move and manipulate data, you also understand how data can be leveraged to empower reporting and analytics. While you are strong technically, you are also adept at consulting with non-technical business users to understand the root of their requirements, to develop BI solutions that truly meet their needs.


Responsibilities

Serve as a subject matter expert in Data Engineering technology and related processes.
Understand business issues and decompose them into measurable data or data modelling requirements.
Curate data for governed reporting and self-service data discovery and analytics
Contribute to consultations workshops with various business stakeholders to understand the root business needs for new reporting and analytics use cases
Build experimental data processes and BI assets for rapid prototyping of reports and dashboards from new data sources
Help administer the Business Intelligence platforms to ensure the environment is secure, up to date, and accessible

Skills:

A seasoned Business Intelligence professional with hands-on experience developing and administering front-end BI tools such as PowerBI, Qliksense
A savvy data architect with strong understanding of datawarehouse principles and methodologies
Great communication skills, you can effectively convey highly technical concepts to a non-technical audience
Excellent problem-solving skills, able to systematically analyze, hypothesize, and solution problems and issues
Hands-on experience with datawarehouse technologies, preferably with cloud-based platforms such as AWS Redshift and Azure Synapse
Experience developing and building ETL/ELT pipelines using GUI based tools such as Glue, Pyspark and ability to code custom data workflows via Java and Python a strong asset
Energized by working on a small team with the ability to make an immediate impact on the business
Experience working in an Agile environment (developing stories, prioritizing tasks, grooming)

Qualifications:

Bachelor or Master degree in a technology/analytical field such as Computer Science, Management of Information Systems, Mathematics, Statistics, Machine Learning/AI, Engineering, or other relevant technical fields.
Experience in an Agile environment
Excellent programming knowledge in any of the languages (Phyton, R, Hadoop, Kafka, Spark/Scala).
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with relational SQL and NoSQL databases.


POSTING DETAILS
Location: 530 - Corporate
Working Conditions: Office Environment

Reports to: Manager Reporting and Data Delivery
-

Purolator is an equal opportunity employer committed to diversity and inclusion. We consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Indigenous status or any other factors considered discriminatory. If you require an accommodation during the recruitment process, we will work with you to meet your needs.


We recognize that our employees and their families are key stakeholders. We will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. We hire for attitude and train for skills. To learn more about us and our values, go to www.purolator.com.


At Purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.","Purolator
3.9",Mississauga
465,Senior Scientist – Assay Development,"Deepcell is an early-stage Stanford spin-off company that has developed a unique platform for use in research, diagnostic testing, and therapeutics. We combine microfluidics, imaging, deep learning, and genomics to identify, isolate and analyze live, single cells. Our technology addresses diverse applications in the life sciences.
Come join Deepcell and make a difference! We're a small team of passionate innovators in biomedical engineering, artificial intelligence, molecular biology, and genomics. Our technology has won multiple prestigious awards and is backed by top-tier venture capitalists in Silicon Valley.
The senior scientist -assay development at Deepcell will report to principal scientist and be responsible on developing and optimizing methods and protocols for NGS-based molecular assays.
Responsibilities:
Work closely with cross-functional R&D team to design and execute experiments for cell isolation and bulk and single cell analysis
Design and optimize assays for molecular analysis of samples with small quantities of DNA and RNA.
Develop and optimize NGS-based single cell analysis workflow
Perform sample prep, instrument operation, assay design, optimization and validation
Develop new SOPs to improve consistency and accuracy
Contribute to product development milestones and company goal planning process
Key Qualifications:
PhD in Molecular biology, biochemistry, chemistry or similar fields
Broad background and knowledge of NGS technologies and data analysis
2+ years industrial experience in NGS assay development, preferably on single cells or low input samples
Demonstrated record in product development and verification/validation
Excellent experimental design, data analysis and trouble-shooting skills. Sound scientific judgement.
Strong written and oral communication skills
Strong interpersonal skills with the ability to interact with individuals from a variety of levels and functions
Self-organizer, meticulous hands-on habits, keen attention to detail
Ability to understand and execute on the company’s mission and values
Maintain a high degree of ethical standard and trustworthiness
Ability to think and adapt to a rapidly changing startup environment",Deepcell,Mountain View
466,Data Engineer,"Data engineering at EQ means you're working in the hottest areas of today's technology landscape: machine learning, big data, and geolocation data sets. You will be coming up with solutions to derive actionable insights about behavior, demographics, and personality out of our multi-terabyte dataset of location data. Examples of the type of analysis we do include:
Understanding what university students do during the summer holidays.
Predicting if someone is about to buy a house based on their visiting locations
Understanding someone at the airport is a business or leisure traveler.
And more.
Your role will involve working very closely with our CTO, data scientists, and the extended product team. With EQ leading the pack for location ad analytics in Canada and a top North American player - this role would let you define and shape the standards in this very vibrant and evolving industry.
Understand our current data sets and models and help us discover new ways to enrich the data
Creatively extracting real-world behavior and trends out of the location data
Monitor and build processes for cleaning up inbound data
Dream up a solution, perform the R&D, and deploy to production within our fluid work environment
Requirements
Ability to work with large amounts of data
Experience with map-reduce frameworks - Hive, Hadoop, and Spark (Elastic Map Reduce would be a plus)
Firm grasp of statistics, data modeling, and designing algorithms
Benefits
Cloud service credits (AWS, Google Cloud, Azure, Digital Ocean, etc.)
Public Transit allowance
Mobile data allowance
Home internet allowance
Flex days","EQ Works
3.4",Remote
467,"Data Analyst, Marketing Acquisition","FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an elite online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity – Data Analyst, Marketing Acquisition

The Analyst will enable FreshBooks reporting and help to derive insights from website, event, campaign and customer web and product interaction data to improve the volume and quality of acquired trailers, determine growth opportunities, understand the customer journey and major drop-offs.

The right person for the job will love to solve a problem and have a knack for translating data into insight and presenting that information to stakeholders. You will be collaborating with managers and a team that includes other analysts, data scientists, marketers, financial analysts, and developers all working together to drive growth at FreshBooks.

What you'll do:
Complete regular ad-hoc / deep-dive analyses by translating raw data into useable information and insights
Build dashboards for core performance metrics/monitor KPI's
Channel level reporting on trends in acquisition performance
Support with A/B testing for campaign treatments
Content / Webpage reviews and analyses
Work independently & with engineering to ensure the integrity of data flows / transfers
Monitor changes in usage behaviours (organically and due to marketing)
Performance evaluations of various customer segments
Assist with GTM tagging, maintenance and general organization
Consult with internal clients to gather requirements, scope & execute
Complex, long-term analyses on visitor trends and performance impacts
Communicate results and recommended analyses/approaches to stakeholders

What you bring:
Intermediate to advanced knowledge of SQL is required
Minimum 2-3 years in data analytics/business intelligence
Knowledge of Google Analytics data, and/or similar web analytics tools
Strong knowledge of one or more visualization tools such as Looker, Tableau etc.
Quantitative background with strong analytical skills
Experience working with relational databases
Familiarity with the marketing campaign and/or web data is preferred
Python knowledge is an asset
Google Tag Manager experience is an asset

Why Join Us

We're a motivated bunch, with our eyes laser-focused on shipping extraordinary experiences to businesses. You will be surrounded by hardworking team members who share a common vision for what an amazing software company could be, and have the opportunity to help build an elite one, right here in downtown Toronto.

Apply Now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer. We do not discriminate based on gender, religion, race, mental disability, sexual orientation, age, or any other status. All applicants are considered based on their qualifications and merits. At FreshBooks, we inspire an environment of mutual respect and we believe diversity and inclusion are crucial to our success.

FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com.","FreshBooks
4.0",British Columbia
468,Machine Learning Scientist (Can be Remote Within Canada),"At BluWave-ai our mission is to deliver innovative AI solutions to accelerate the transformation towards renewable energy. We apply AI software to increase the use of clean energy in smart grids and microgrids with distributed energy resources and demand response. We are also driving the transition to electrification of transportation as the grid becomes the local gas station.

We are looking for talented people with entrepreneurial drive to seize on the ground floor opportunities, grow their careers, and make a positive impact for the environment.

1. Who you are

A machine learning engineer, with professional experience or equivalent applied research, strongly motivated by building impactful and dependable products based on pragmatic and rigorous application of ML techniques.
You have the drive to learn, evaluate, and apply a range of data science and ML techniques. The applications are real-time smart grid control and optimization solutions in the context of best scalability, availability, and security principles.
You are a pragmatic innovator who thrives in a fast-paced, disciplined, and team-oriented environment where we strive individually while supporting, learning from, and building on each other's ideas and efforts to succeed as a team. You have strong verbal and written communication skills with the ability to distill complex technical concepts to the level that non-specialists can comprehend. You are effective at teamwork, and you enjoy mentoring.
2. What you are Responsible for

Analysis, design, and implementation of ML solutions to prediction and optimization tasks.
Develop statistical and machine learning solutions for analysis, data mining, and modeling of IOT data.
Develop resilient testing strategies to monitor model performance.
Prepare documents and presentations to inform and demonstrate.
3. Your Knowledge, Experience, and Skills

Required:

Experience as a ML scientist within a commercial environment, or equivalent academic research experience with pragmatic experimentation or industry collaborative projects.
Experience with cleaning, reshaping, exploring, and visualizing data in various formats.
Strong programming knowledge and skills in Python.
Familiarity with machine learning tools and platforms such as TensorFlow, Keras, etc.
Considered an asset:

Experience in developing ML techniques for time-series prediction: e.g. regression, support vector machines, and neural networks.
Familiarity with control and optimization of modern power and energy systems.
Educational Requirements:

MSc or PhD in Mathematics, Statistics, Computer Science, or related data-intensive fields. Exceptional Candidates with a Bachelor's degree with strong relevant solution delivery experience are encouraged to apply.
4. What You Will Gain

Motivation to serve to the greater cause of climate change mitigation.
Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains on the intersection of electrical engineering, machine learning, optimization, and software development.
Startup experience and ground floor opportunities for growth in an inter-disciplinary team that includes PhD Smart Grid and Machine Learning Scientists, recent grads, and seasoned business professionals.
Competitive compensation.
High quality of life and career in Canada's National Capital Region or remote work.
Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events.
5. General Information

Level: All experience ranges are encouraged to apply
Position Type: Full-time
Location: Ottawa, ON (can be remote for exceptional candidates)
Department: Applied Science
Position Reports to: Vice President of Technology

Diversity makes us stronger. BluWave-ai provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, gender, national origin, disability, or any other characteristic protected by applicable laws, regulations, or ordinances.

Authorization to work in Canada is required for this position.","BluWave-ai
5.0",Ottawa
469,Intermediate Data Engineer,"BlueDot continues to grow, and as a result we are looking for an Intermediate Data Engineer to join our Data Systems team!


As an Intermediate Data Engineer, you will create, expand, and optimize data pipelines to build upon our data platform. You thrive on writing complex queries, working with big data, and enjoy automating data pipelines and workflows. With us, you will solve problems with data integration and be working with data that has an impact on global connectivity as well as local areas of analysis. You will be working with both structured and unstructured datasets that are both spatial and non-spatial in nature.




Who we are:

BlueDot protects people around the world from infectious diseases using human and artificial intelligence. Our software-as-a-service solution combines medical and public health expertise with advanced data analytics to track, contextualize, and mitigate infectious disease risks. Our global early warning system combines more than 100 datasets with proprietary algorithms to deliver critical insights on the spread of infectious diseases. In December 2019, we flagged an undiagnosed respiratory syndrome in Wuhan, China. In January 2020, we published the world's first scientific paper on COVID-19, accurately predicting its global spread. Our team understands the complexity of the challenge in front of us – and that the urgency to solve the problem has never been greater.

Our Culture:
We are a Certified B Corp, have a Glassdoor rating of 4.7, are Diversio certified, a 2020 LinkedIn Top Start-Up and have been recognized as a Top 50 Best Place to Work in Canada, Best Place to Work for Women, Best in Technology, Best for Youth, and Best Start-Up!

Driven by a Purpose Bigger than Ourselves
United in a common purpose to create a healthier, safer, and more secure world, free from the impacts of dangerous infectious diseases, we understand the complexity of the challenge in front of us, and that it is so much bigger than any one of us. Together, we are motivated to positively impact lives around the world, to do no harm, and to elevate each other through respect and encouragement. Building careers through collaborative discovery and learning, our people tackle complex challenges with diverse expertise not assembled elsewhere. We promote personal fulfillment in the workplace by removing barriers, politics and exclusion, believing in the philosophy that by creating a positive environment we all have the opportunity do the most meaningful work of our lives.

Our values:
Our values are not just words on a wall. They are our compass and they guide us in our work, in the decisions we make and in how we treat each other:



Be the Change (our heart) - Making a meaningful difference through our work - for each other, for our customers, and for the world. Taking initiative, ownership, and action.
Think Without Borders (our mind) - Freeing our minds from conventional thinking, discovering without fear of failure, and learning from our customers - we make impossible challenges possible.
Lift Others Up (our soul) - Creating space for all those inspired by our purpose, elevating each other and fostering mutual growth. Our unique perspectives valued, respected and included.



What you will do in more detail:

Create and maintain optimal data pipeline architecture
Build and manage microservices on AWS
Design, develop, maintain cross-platform ETL processes
Use python to automate data processes and analyses to maximize efficiency
Help design, develop, test, document, and data pipeline related applications, programs and systems
Perform spatial analyses and create information products utilizing GIS and related software
Help design and implement data quality control procedures and policies
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Oversee and execute data migration from existing data stores
Assist with operationalizing data science models



What you have done to get here:

Degree in Computer Science, Engineering, related quantitative fields, or equivalent experience
Knowledge and experience with Python
Knowledge and experience with SQL
Experience with enterprise databases (MS SQL, MySQL or PostgreSQL)
Experience with source code control frameworks (Git).
Knowledge and experience with ETL software such as FME Desktop and FME Server
Knowledge and experience using NoSQL databases such as MongoDB or DynamoDB
Experience with GIS Products (QGIS, ArcGIS Enterprise, ArcGIS Pro) - nice to have
Collaborative attitude, with ability to excel in a team environment
Ability to quickly learn new tasks and systems, flexible in skills and attitude
Commitment to internal/external customer satisfaction through delivered excellence
Excellent written and verbal communication and interpersonal skills
Goal orientation with a drive to exceed expectations
Superior attention to detail and ability to produce professional deliverables & documentation on time.
Ability to manage personal time and priorities effectively



Ideally, you also have:

A basic understanding of modern techniques and tools for Data Science, Modeling and Analytics
An understanding of API architecture and integration
Experience with infrastructure as code (terraform, cloudformation)
Experience in the health sector



What we offer our team:

Meaningful work that truly has purpose
As a smaller, agile team, we offer roles with impact
Your contributions are integral, your voice will be heard
A competitive comprehensive compensation package
Outstanding health, vision and dental benefits
Employee and Family Assistance Plan
A health and wellness spending account
Generous vacation and other PTO
A home office setup allowance



We are working fully remotely due to COVID-19 until at least January 2022 – post pandemic we will continue with our remote first culture with the opportunity for a hybrid/flexible office space in downtown Toronto accessible to our team but without the requirement to work from the office.




Together let’s create a healthier, safer, and more prosperous world.




For more information, visit us at: http://bluedot.global.




BlueDot recognizes that challenges remain in achieving the full participation of equity-seeking groups (including women, Indigenous Peoples, persons with disabilities, members of visible minority/racialized groups, and members of LGBTQ2+) in tech careers and is committed to identifying and eliminating barriers that may exist within its own hiring process, programs, and practices.

BlueDot is committed to fair and accessible employment practices. If you are contacted for a job opportunity, please let us know how we can best meet your needs and advise us of any accommodations required to ensure fair and equitable access throughout the recruitment and selection process.

We thank and appreciate all applicants for their interest. Only those selected for an interview will be contacted. Please no agency calls.","BlueDot Inc.
4.7",Midtown Toronto
470,Data Engineer - 96042,"What you do at AMD changes everything


At AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies – building blocks for gaming, immersive platforms, and the data center.


Developing great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the “extra mile” to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.




The world's most successful companies heavily leverage data to design products and services that delight their customers. At AMD, we have a culture of being customer-centric, and deliver high performance devices that are a joy to use. In this Data Engineer position, you will be part of a select team that works on the cloud-based big data analytic process and tools that will help build the analytic and data processing pipeline and to contribute to the analytic thought process that impacts AMD company-wide. You will be working on one of the fastest growing areas, with updated skill sets and hands-on access to big data.




Preferred Experience:

Proficiency in one or more of the following: Python, R, SQL, Java, Scala
Good understanding of quantitative analysis and statistical reasoning
Ability to learn new big data and analytic tools and technologies
Full stack web development, particular data dashboards
Machine learning and model creation and predictions
Examples of projects connecting data analysis with engineering or business improvements
Having worked on cloud-based technologies (any AWS services, Apache Spark, Databricks, Hortworks/Cloudera Data Platform, etc)

Academic Credentials:




Minimum of B.Sc. in Electrical/Computer Engineering or Computer Science

Location:

Canada, Ontario, Markham

#LI-CC2



Requisition Number: 96042
Country: Canada Province: Ontario City: Markham
Job Function:Design




AMD is an inclusive employer dedicated to building a diverse workforce. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective provincial human rights codes throughout all stages of the recruitment and selection process. Any applicant who requires accommodation should contact AskHR@amd.com.

AMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services.","Advanced Micro Devices, Inc.
4.1",Markham
471,"Mentor (Development, Data Science, or Cyber Security)","Since 2013, Lighthouse Labs has been helping curious and creative people break into the tech industry with our accelerated, personalized, and outcomes-obsessed education. Our mission is to train the next generation of tech talent in coding, cyber security, and data science by looking at the unique needs of each student and helping them map out and achieve their career goals. A major part of this approach is our robust mentorship program, where students are guided through their learning journey by professionals who work in the industry themselves.


To keep serving the ever-expanding needs of our students and communities, we’re growing our team of amazing mentors that are so key to student success. We’re looking for intermediate to senior level full-stack developers, cyber security professionals, and data scientists to join our team. Are you passionate about mentoring, are creative and critical, and excited about problem-solving? We’d love to hear from you!


Mentoring with Lighthouse Labs:


As a mentor, your mission is to support our students through their academic journey, and prepare them for their transition into an exciting new career in tech. You’ll work directly with students to coach them through any roadblocks they might be experiencing, give them tips on solving problems, and generally provide them with support and advice.


Based on your personal experiences, field of knowledge, and availability, you can be matched to mentor in any of the following groups:

Web Development Bootcamp Cohorts
Introductory Program Cohorts
Junior Developers
Junior Data Scientists
Cyber Security



We’re flexible in how we work with mentors, and your schedule is structured according to how many hours you’re available for. Mentors are paid an hourly rate, and are able to work from any time zone.


What we need from you:




Mentors aren’t required to have formal training in their area of expertise. However, a true passion and curiosity for coding, cyber, or data, as well as learning and education in general, is a must.


The following qualifications are all important assets for aspiring mentors:

Minimum 2 years of professional experience in Software Development, Cyber Security, or Data Science.
Experience in a range of popular technologies in Web Development, Cyber Security and/or Data Science.
HTML, CSS, Javascript, Ruby/Rails, Python, Java, Scala, Golang, Elixir, Java, Scala,jQuery, Rails, React, NodeJS + (Express or Koa), Django, , MeteorJS, Elixir + Phoenix, Scala, AngularJS, Ember, R, Jupyter Notebooks, Tableau, Excel, AWS, MySQL, jira, Flutter, Firebase, TypeScript, Apollo, GraphQL, PostgreSQL, MongoDB
A strong understanding of open source development workflows using tools such as Github
Any experience in teaching, mentoring, or tutoring is an asset.



Lighthouse Labs is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. All positions at this time are remote, and we welcome all applicants.","Lighthouse Labs
3.9",British Columbia
472,AI-Driven Drug Discovery Scientist (Psychedelics),"About MagicMed Industries

MagicMed is a biotechnology company focused on the discovery and commercial development of novel pharmaceuticals based on known psychedelic compounds. MagicMed’s expanding collection of psychedelic derivatives (the Psybrary™) is expected to yield the next generation of precision medicines for brain and mental health.

About The Opportunity
There is a revolution happening in mental health treating addictions and alleviating pain. Would you like to join an innovative and growing company whose goal is to make a positive impact on human health? Are you interested in participating in artificial intelligence and machine learning applications for cutting edge R&D?

MagicMed is seeking a full-time scientist to apply machine learning techniques to the problems of drug screening and discovery. You’ll be working with our Research & Development team as they evaluate new compounds, and with our technical partners who will provide direction on the AI elements of the screening pipeline. This is an opportunity to be involved in every aspect of our computational pipeline, to contribute your ideas, and have an impact in the development of novel psychedelic compounds.

Ideally this position will be based at our office in Calgary, Alberta; however, alternative options may be considered for the right candidate.
About The Candidate
Our ideal candidate is enthusiastic and has experience in the application of state-of-the-art cheminformatics and AI (machine learning, deep learning) tools to drug discovery projects. The candidate can work independently and is comfortable writing software, using libraries, and scripting data flows.

Key Responsibilities:

· Filter chemical databases by using virtual-screening approaches

· Apply existing models and techniques to assess drug candidates

· Collaborate effectively with the experimentalist team to improve biological properties (pharmacodynamics/pharmacokinetics) of drug candidates based on feedback from assay results

· Investigate, adapt, and train new models to improve the pipeline

· Provide regular reports and progress updates as required

Education:

· BSc in relevant field (Computation Chemistry, Computational Drug Discovery, Computer Science or related computational field)

· Master Degree or PhD preferred

Experience:

· Experience with computational chemistry tool sets such as Schrödinger, ACD/Labs, MOE, or similar.

· Previous experience with Artificial Intelligence and Machine Learning or Deep Learning frameworks (such as TensorFlow, PyTorch)

Core Competencies:

· An understanding of the fundamentals of drug discovery, from docking to ADMET.

· Strong analytical, trouble shooting and problem-solving skills, with the ability to exercise independent judgment

· Able to work collaboratively in cross functional multidisciplinary teams

· Excellent verbal and written communication skills

· Strong organization, prioritization and time management skills, with high attention to detail

· Motivated and self-directed with a demonstrated ability to work with minimum supervision in a fast-paced, dynamic environment

· Proficient in the use of the Microsoft Office suite

The successful candidate will have a strong interest and willingness to learn about psychedelics and the application of AI to drug discovery.
To Apply
MagicMed offers a competitive compensation and benefits package, a dynamic work environment and a great team! Please visit our web site at www.MagicMedIndustries.com for more information about our company.

To apply for this position, please send your resume and cover letter (detailing AI/machine learning and related experience).

MagicMed is equal opportunity employer, committed to an inclusive, diverse and accessible workplace. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact Human Resources.

We thank all applicants for their interest in MagicMed Industries; however, only candidates selected for interviews will be contacted.

Expected start date: 2021-06-28

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

COVID-19 considerations:
COVID-19 safety precautions and temporary remote work.

Work remotely:

Temporarily due to COVID-19",MagicMed Industries Inc.,Calgary
473,Data Engineer (Data Factory Experience),"1 year + Contract
French Strongly Preferred but will consider English Only Profiles
Need a Data Engineer with Data Factory Experience
Remote Across Canada

Context and mandate

The client intends in the coming years through its BI Modernisation program to migrate various business units from existing BI environments to its next-generation Enterprise Data Platform in the Cloud.

In that context, the Client is looking for a knowledgeable, experienced, and motivated Data Integration Developer. You will play a pivotal role in operationalizing the most urgent data and analytics initiatives for the Client's BI, Data and Analytics strategy.

The bulk of the work would be in the building, managing, and optimizing data pipelines and then moving these data pipelines effectively into production for key BI, data, and analytics consumers.

You will need to guarantee compliance with data governance and data management requirements while creating, improving, and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse, and vastly improved time-to-solution for the Client's BI, data, and analytics initiatives.

Duration: June 15th until March 31st, 2022

Possibility de renew: Yes
Possibility de convert to a permanent position: To be determined

Responsibilities / Accountabilities

Build data pipelines and ETLs.
Provide data structure definition, validation, ingestion, processing, and visualization.
Collaborate with business units, architects, data modelers, data scientists, and project/product team.
Work with the information security team to define and implement data access.
Drive automation through effective data management lifecycle from governance to quality to cataloging to lineage, to ensure data compliance.

Requirements

Professional Experience

3+ years of experience in Data Integration with the required technology.
Experience in data profiling and data quality analysis.
Experience in identifying, analyzing, and interpreting trends or patterns in data sets.
Experience with MS Data integration stack, e.g. Azure Data Factory, SSIS, etc.
Experience with SQL for RDBMSs such as Azure SQL, MS SQL Server, and MySQL.
Experience working with PowerBI for semantic-layer-based data discovery.
Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management.
Knowledge of Azure Migration stack, e.g. Azure Migrate, Azure database migration service, etc.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional data integration technologies such as ETL/ELT, data replication/CDC, message-oriented data movement, event processing, API design, and access.
Experience in agile methodologies and capable of applying DataOps principles to data pipeline build engineering to improve integration, reuse, and automation of data.

Educational Experience

University degree or higher in computer science, business administration, business intelligence, statistics, mathematics, or equivalent.

Soft Skills

Ability to linearize and bridge business needs into technical requirements.
Strong communication, documentation, storytelling, creativity, and presentation skills.
Strong interpersonal, teamwork, coordination, and consensus-building skills.
Strong organizational skills, ability to perform under pressure, and manage multiple priorities with competing demands.

Language

Good verbal and written communication skills in French and English.

Other

The mandate will be carried out remotely until the return to the offices

Once back at the office, the position will be carried out according to a hybrid model (face-to-face/telework) to be confirmed.

Contract length: 12 months

Part-time hours: 40 per week

Job Types: Full-time, Part-time, Contract

Pay: $65.00-$85.00 per hour

Language:

French (preferred)

Work remotely:

Yes",Sky Systems Inc,Montreal
474,"Certified Azure Data Engineer (DP-200 & Dp-201, DP-203) 12+ yrs Exp","Azure Data Engineer

Location- Brampton, ON

Salary: 95k Full time

On contract Rate CAD $65/hr on Inc

Client- Tech M

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Databricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on NoSql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Temporary, Permanent

Salary: $79,138.00-$95,000.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Vision care
Work from home

Schedule:

8 hour shift

Work remotely:

Yes","Compest solutions Inc.
4.6",Brampton
475,"Data Engineer, Data Lake","Job Category:

Software

Opportunity Awaits at Altus Group!

The next stage in PropTech solutions: Unlocking the value of data and predictive analytics

Altus Group is embarking on the next evolution of data, software and technology leading cloud products and services. As pioneers in the Proptech and real estate analytics spaces, we are growing our offerings to enable our global clients to unlock the value of data and leverage predictive analytics for better decision-making.

This journey represents an expansion of our data and analytical solutions to other Altus business units, including ARGUS Software, the industry standard for valuation and asset management software. We’re adding world class talent to our technical team; people who are interested in building the data infrastructure that will support the wide variety of global opportunities aligned to our client’s needs. As we take our new and existing cloud products to the next level, this initiative is one that our leadership believes is critical to accelerating the continued and future success of Altus Group and our clients.

The opportunity

Building on established market leading software and incorporating new technologies, we are creating an unrivalled platform to serve the real estate investment industry. As part of the new team spearheaded by the Director, Application Service Delivery, Data Solutions, we are adding two Data Engineers in Toronto. You will collaborate with internal teams on both technical aspects of data migration and storage as well as in a consultative manner to understand unique data parameters, contributing to the design and build of a data lake. You will aggregate, organize and ingest data from various sources to ensure that the data can be accessed efficiently by our internal and external users and applications.

Who you are

You are a Data Engineer with a few years of experience storing, pipelining, and transforming data using a range of technologies. You want to balance your technical deliverables with internal client interaction to gain an in-depth understanding of how our platform will work and how we can meet the data needs and drive key decisions for everyone. You want to be part of building something new with great visibility across the organisation and endless possibilities ahead as we continue to grow and scale. You want to play a critical role in seeing our collaborative vision implemented.

What’s in it for you?

Unparalleled exposure and impact. You will work alongside development, architecture, and product teams who are at the top of their game, solving problems that have never been looked at before. As part of a platform team specifically assembled to collaborate on new work, you will have the freedom to create from the ground up, and work unrestricted by existing tools or legacy technology. This is an opportunity to make your mark and truly accomplish something exciting as we focus on defining and driving our data and SaaS strategy.

The latest technology, in leading-edge ways. Data is at the heart of everything we do. We are actively pursuing the latest iterations of modern technologies. Our stack encompasses Docker, Microservices, Snowflake, Glue, Spark, Python, Tableau, JavaScript, Angular, Node/JS, REST APIs, Swagger WSo2, and the AWS ecosystem. You will be part of the team working with - and continuously evolving - this tech stack and our approach to data.

Growth and career development. Altus fosters a culture of professional development and promotion from within. With retention rates double the tech industry average, and dozens of promotions within and across teams, this is a place to truly expand your skills and grow your exposure. The Data Solutions team offers individuals the chance to lead the scrums on a rotating basis and push the limits of what they do with dedicated time to further their individual areas of technical interest. As we move from building to scaling; from platform to product; and from storage to application, the opportunities to grow your skills, gain exposure, try new things, and make an impact will grow too.

Our new Data Engineer, Data Lake will:

Learn. Working in close collaboration with the Senior Data Engineer, you will be given the support you need and the information you require to come up to speed and make a valuable contribution to the team.

Elicit, understand, and translate. You will work across business lines and newly acquired businesses to understand individualized technical and practical data storage.

Design. You will create and support an ETL solution using AWS Glue to extract and import data into the new data lake. You will determine how to connect to the various data sources, bring data into our new data lake, and the appropriate method of storing the data.

Analyse. You will create data pipelines, reports, visualisations and extracts to support product and research needs. You will work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.

Advise. You will research data governance and security to ensure our data storage methodology adheres to any constraints and follows best practices.

Try new things. You will take the initiative to research, test, and solve complex data engineering problems and big data storage.

Our new Data Engineer, Data Lake will have:

An eagerness and ability to learn quickly. You have a devotion to evaluating and appropriately applying emerging and alternative technologies, languages, frameworks, and platforms.

A commitment to collaboration. You thrive working across inter-disciplinary groups, including architects, developers, product, and management, to build great products. You have a way of speaking, writing, and relaying information that engages people and expresses appreciation for diverse opinions and approaches.

Hands-on experience. You have worked with a broad range of data management, analysis, and visualisation tools, including ETL/data format conversion, SQL, and NoSQL/ non-traditional database technologies, including newer tools such as Glue and Snowflake. You have worked with AWS/Cloud computing infrastructure.

Come realize your potential at Altus Group!

Altus Group is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs. If you are a person with a disability and require assistance during the application process, please contact us at accessibility@altusgroup.com or 416-641-9500.","Altus Group
3.9",Midtown Toronto
476,Data Engineer - Mississauga,"Our client, located in Mississauga Ontario is looking for Data Engineers to join them on a permanent basis.

Join a creative organization with design, implementation, maintenance of data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services.

Advantages
We are looking for a problem solver, someone that works collaboratively and is passionate as well as a self starter.

Responsibilities
You will be responsible for all design, implementation, system performance. Automation of manual processes and process improvements.

Qualifications

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI


Summary
If you have the skills above, please apply today as we certainly would like to speak with you!","Randstad
4.2",Mississauga
477,Data Engineer Senior Consultant (Azure) / Ingénieur(e) de données (Azure),"*English will follow*


Slalom est une société de conseil moderne axée sur la transformation de la stratégie, de la technologie et des activités. Dans 40 marchés aux États-Unis, au Royaume-Uni, au Japon, en Australie et au Canada, nos équipes ont l’autonomie nécessaire pour agir rapidement et faire ce qui est juste, toujours. Ils sont soutenus par des centres d’innovation régionaux, une culture globale d’innovation et des partenariats avec les plus grands fournisseurs de technologie au monde.

Chez Slalom, la connexion personnelle rencontre l’échelle mondiale. Nous établissons des relations étroites avec les clients au sein de nos marchés et à l’échelle mondiale, en faisant circuler nos connaissances dans tous les marchés afin que chaque engagement puisse bénéficier de toute l’étendue de l’expertise de Slalom. Nos sept centres régionaux Build agissent comme points centraux de l’innovation pour attirer des talents de haut niveau qui collaboreront rapidement à la création des produits technologiques de demain. Nous entretenons également de solides partenariats avec plus de 200 fournisseurs technologiques de premier plan, notamment Amazon Web Services, Google Cloud, Microsoft et Salesforce.

Avec notre mentalité axée sur les objectifs, nous travaillons en collaboration avec des entreprises pour repousser ensemble les limites de ce qui est possible. Chez Slalom, chaque jour, nous sommes motivés par les valeurs fondamentales et la vision de notre entreprise. Nos valeurs fondamentales sont au cœur de toutes nos activités et orientent notre façon de travailler avec nos clients, nos équipes et nos communautés. Chacune de nos valeurs fondamentales nous rappelle de rester fidèles à nous-mêmes tout en produisant des résultats incroyables pour nos clients. Notre principe directeur est « Aimez votre avenir », ce qui inspire notre culture, notre travail et nos relations. Et, plus important encore, c’est ce qui nous permet d’avoir le plus grand impact possible!

Fondée en 2001, Slalom a établi son siège social à Seattle et, selon un mode de développement par croissance interne, compte maintenant plus de 9 000 employés. Nous figurons sur la liste des 100 meilleurs employeurs de 2021 établie par le magazine Fortune pour la sixième année consécutive, et nous sommes régulièrement reconnus par nos employés comme offrant l’un des meilleurs environnements de travail. En savoir plus : https://www.slalom.com/fr-ca/?lp=1.

Au Canada depuis 2015, Slalom compte maintenant plus de 600 employés répartis dans trois marchés : Vancouver, Toronto et Montréal.

Titre du poste :

Ingénieur(e) de données (Azure)

L’équipe Slalom de Montréal recherche un(e) ingénieur(e) de données (Azure) pour notre pratique d’analytiques des données. À titre d’ingénieur(e) infonuagique de données de notre équipe, vous analyserez, concevrez et architecturez des solutions infonuagiques pour répondre aux besoins de nos clients en matière d’infrastructure sous forme de service, de plateforme sous forme de service et de logiciel sous forme de service. Ce poste vous fera utiliser des outils d’architecture modernes, y compris l’infonuagique (Azure), Hadoop, Spark, Kafka et d’autres technologies liées aux mégadonnées. En plus de bâtir la prochaine génération de plateformes de données, vous travaillerez avec certaines des organisations les plus innovatrices en analytiques des données. Nous sommes à la recherche de personnes vives d’esprit, disciplinées et motivées, qui sont passionnées par l’emploi de solutions infonuagiques pour résoudre des problèmes d’entreprise réels.


Alors, quel sera mon travail?

Travailler au sein d’une équipe sur la conception et le développement de solutions infonuagiques de données
Établir les exigences techniques, évaluer les capacités des clients et analyser les résultats afin de fournir des recommandations appropriées en matière de solutions infonuagiques et de stratégies d’adoption
Définir les stratégies infonuagiques de données, y compris la conception de feuilles de route de mise en œuvre à plusieurs phases
Diriger l’analyse, la construction, la conception et le développement d’entrepôts de données et de solutions d’intelligence d’affaires
En savoir beaucoup sur les solutions infonuagiques, l’architecture et les technologies Azure, ainsi que leurs interdépendances
Expérience démontrée avec des outils ETL (Azure Data Factory, Databricks), d’entrepôt de données (SQL Database, Synapse/Snowflake), d’intégration de données (DataLake, Blob storage), de profilage de données et de visualisation de données (PowerBI)
Connaissance de l’orchestration avec Azure Logic Apps
Connaissance de la diffusion en continu des données Azure avec Azure Event Hub
Connaissance approfondie de SQL et de débogage de problèmes complexes
Rechercher, analyser, recommander et sélectionner des approches techniques pour résoudre des problèmes de développement et d’intégration difficiles et stimulants
Découvrir et adopter de nouveaux outils et de nouvelles techniques afin d’accroître la performance, l’automatisation et l’évolutivité
Aider les équipes de développement des affaires à exécuter les activités de prévente et les demandes de proposition
Comprendre les objectifs et déclencheurs d’affaires, et les traduire en une solution technique appropriée

Et qu’offrirai-je à l’organisation?

Plus de trois ans de construction et de mise en œuvre d’infrastructures Azure
Comprendre la mise en œuvre de conceptions fondées sur l’architecture Lambda
Expérience de configuration et d’ajustement de nuages virtuels privés
Expérience concrète d’évaluation des besoins en matériel et en stockage
Solides capacités analytiques de résolution de problèmes
Personne autonome ayant la capacité de travailler de façon indépendante ou au sein d’une équipe de projet
B. Sc. en sciences informatiques, en un domaine connexe ou une expérience professionnelle équivalente
Connaissance de Python et d’Azure DevOps, un atout
Connaissance du codage en Python et .Net, un atout
Compréhension des écosystèmes infonuagiques et des technologies infonuagiques émergentes et dernier cri
Bilinguisme (anglais et français)

Qu’est-ce qui nous motive?


La culture! Notre vision est de créer un monde dans lequel tout le monde aime son travail et sa vie. Nous croyons en l’importance d’une communauté d’employés Slalom diversifiée et inclusive, et nous les encourageons tous à être fidèles à eux-mêmes au quotidien. Nous croyons qu’il nous faut rester humbles et curieux, tout en inspirant passion et aventure!
Ce n’est pas parce que nous travaillons d’arrache-pied que nous ne nous amusons pas! Slalom s’efforce de consolider ses équipes et s’assure qu’elles ont autant de plaisir qu’elles sont productives. L’entreprise adore rassembler ses employés en organisant plusieurs activités comme des événements trimestriels, des célébrations pour les fêtes, des événements de bienfaisance et, de façon plus décontractée, des événements sur place ou virtuels comme des dîners-conférences, des jeux-questionnaires, des soirées cinéma, des marathons de programmation et bien d’autres!

Slalom est un employeur inclusif valorisant l’égalité des chances et engagé à la création d’une main-d’œuvre diversifiée. Nous accueillons à bras ouverts les candidatures de toutes les personnes qualifiées et travaillerons à accommoder raisonnablement les candidats tout au long du processus de recrutement et de sélection. Veuillez communiquer avec l’équipe d’attraction de talents si vous nécessitez des accommodements lors du processus d’entrevue.


Veuillez noter que si vous êtes embauché(e) chez Slalom, vous devrez remplir une vérification des antécédents.


Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 40 markets across the US, UK, Japan, Australia, and Canada, our teams have the autonomy to move fast and do what’s right, always. They are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world’s top technology providers.

At Slalom, personal connection meets global scale. We build deep relationships with our clients within our markets and across the globe, while sharing insights across markets to bring the full breadth of Slalom's expertise to every engagement. Our seven regional Build Centers are hubs for innovation, attracting top talent to rapidly co-create the technology products of tomorrow. We also nurture strong partnerships with over 200 leading technology providers, including Amazon Web Services, Google Cloud, Microsoft, and Salesforce.

With our purpose-driven mindset, we partner with companies to push the boundaries of what’s possible—together. Here at Slalom, we are motivated every day by our company’s core values and vision. Our core values are at the heart of everything we do and guide how we work with our clients, our teams, and our communities. Each core value reminds us to stay true to ourselves while driving amazing outcomes for our clients. Our guiding principle is to “Love your Future” which inspires our culture, work, and relationships, and most importantly it is how we make our biggest impact!

Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 9,000 employees. We were named one of Fortune's 100 Best Companies to Work For in 2021 for the 6th year in a row and are regularly recognized by our employees as a best place to work. Learn more at slalom.com.

Slalom in Canada began in 2015 and has grown to over 600 employees across 3 markets – Vancouver, Toronto, and Montréal.

Job Title:

Data Engineering Senior Consultant (Azure)


So, what will I do?

Work as part of a team, to design and develop cloud data solutions
Gather technical requirements, assess client capabilities and analyze findings to provide appropriate cloud solution recommendations and adoption strategy
Define Cloud Data strategies, including designing multi-phased implementation roadmaps
Lead analysis, architecture, design, and development of data warehouse and business intelligence solutions
Be versed in Azure cloud solutions, architecture, related technologies, and their inter-dependencies
Proven experience with ETL (Azure Data Factory, Databricks), data warehousing (SQL Database, Synapse/Snowflake), data ingestion (Data Lake, Blob storage), data profiling and data visualization (PowerBI) tools
Knowledge of orchestration with Azure Logic Apps
Knowledge of Azure data streaming with Azure Event Hub
Proficient in SQL and debugging complex queries
Research, analyze, recommend, and select technical approaches for solving difficult and challenging development and integration problems
Learn and adopt new tools and techniques to increase performance, automation, and scalability
Assist business development teams with pre-sales activities and RFPs
Understand business goals and drivers and translate those into an appropriate technical solution

And, what will I bring?

3+ years architecting and implementing Azure infrastructure
Understanding implementing Lambda architecture-based data designs
Experience configuring and tuning virtual private clouds
Practical experience sizing hardware and storage needs
Strong analytical problem-solving ability
Self-starter with the ability to work independently or as part of a project team
B.S. in Computer Science, related fields or commensurate work experience
Python, Azure DevOps experience is a plus
Experience coding in Python and .Net is a plus
Understanding of cloud ecosystem and leading-edge cloud emerging technologies
Bilingualism (English & French)

What keeps us here?

Culture! Our vision is to enable a world in which everyone loves their work and life. We believe in having a diverse and inclusive community of Slalomers, encouraging everyone to bring their authentic selves to work, every day. We believe in staying humble and curious, while still inspiring passion and adventure!
Just because we work hard doesn’t mean we don’t have fun! Slalom strives to bring our teams together and ensure we have just as much fun as we do work. Slalom loves to bring their employees together by hosting many events such as quarterly events, holiday parties, charity events and more casually, in-office/virtual events like lunch & learns, trivia and movie nights, hackathons and many more!


Slalom is an inclusive, equal opportunity employer dedicated to building a diverse workforce. We encourage applications from all qualified candidates and will work to reasonably accommodate applicants’ needs throughout all stages of the recruitment and selection process. Please advise the talent acquisition team if you require accommodations during the interview process.


Please note if you are hired at Slalom you will be required to complete a background check.


#LI-LD1","Slalom Consulting
4.3",Montreal
478,Data Management Specialist – Pharmaceutical,"At ProCogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.

We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.

ProCogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.




Position Details



We are seeking a Data Management Specialist for our Pharmaceutical clients’ Development Sciences department.
The Data Management Specialist will be performing data management and curation tasks to support biomarker discovery and companion diagnostic development efforts. In the process of performing this work, the candidate will communicate extensively with scientists, research associates, operations managers, clinical data managers, analysts, and vendor representatives.
Responsibilities

Working with biomarker operations managers and biometrics colleagues to draft data transfer specifications and statements of work.
Acquiring and QC’ing digital pathology image data and associated metadata files from internal groups and external vendors. Capturing data in internal file systems and databases.
Monitoring data processing requests and submitting data files to analysis pipelines
Merging different data types with clinical data to generate analysis-ready data sets
Curating and cataloguing data sets, maintaining listings of available data, and distributing to collaborators
Maintaining and curating content of internal knowledge sharing repositories
Maintaining and developing data conformance checking scripts and requirements


Required Skills



Familiarity working in a Linux computing environment
Proficiency in scripting languages such as R or Python; Database skills
Familiarity with modern informatics systems, relational and non-relational databases, scripting languages, and data visualization tools.
Demonstrated experience with informatics best practices and developing well-documented, production code in non-academic environments.
Working knowledge of scientific research application development cycles and data management principles.
Working knowledge of anatomical pathology workflow and digital pathology data lifecycles
Experience managing and curating biological or clinical data
Careful, detail-oriented working style
Outstanding communication, collaboration, and problem-solving skills
Able to work independently and in a team setting.


Nice to have but not required



Relational databases and SQL
Statistical software packages such as R or SAS
Clinical trial data management
Working with medical images data
Setting up and maintaining online content management systems or wikis


Education



Bachelors or Master's degree in Life Science, Computer Sciences or Biomedical Engineering with at least >3 years work related experience.","ProCogia
4.7",Midtown Toronto
479,Data Engineer,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client's employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the ""Glocal"" team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.

A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.

Key responsibilities:
Key member of the product team building Business Intelligence and Analytics SaaS solutions.

Collaborate with business stakeholders to gather and define data and reporting requirements.

End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analytics

Develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.

Drive Web Scraping alternate data implementation and automation.

Build, test, and maintain scalable and robust data and analytics stack.

What we value:
You hold a bachelor's in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.

You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.

You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.

You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).

You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.

You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etc.

What we Offer :
Opportunity to work in a fast-growing organization with the ability to make a quick impact.

Allow your inspirational ideas to come to life in a highly creative and executional environment.

Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.

The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.

This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.

Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",Elements,Midtown Toronto
480,"Data Engineer, Data Lake","Job Category:

Software

Opportunity Awaits at Altus Group!

The next stage in PropTech solutions: Unlocking the value of data and predictive analytics

Altus Group is embarking on the next evolution of data, software and technology leading cloud products and services. As pioneers in the Proptech and real estate analytics spaces, we are growing our offerings to enable our global clients to unlock the value of data and leverage predictive analytics for better decision-making.

This journey represents an expansion of our data and analytical solutions to other Altus business units, including ARGUS Software, the industry standard for valuation and asset management software. We’re adding world class talent to our technical team; people who are interested in building the data infrastructure that will support the wide variety of global opportunities aligned to our client’s needs. As we take our new and existing cloud products to the next level, this initiative is one that our leadership believes is critical to accelerating the continued and future success of Altus Group and our clients.

The opportunity

Building on established market leading software and incorporating new technologies, we are creating an unrivalled platform to serve the real estate investment industry. As part of the new team spearheaded by the Director, Application Service Delivery, Data Solutions, we are adding two Data Engineers in Toronto. You will collaborate with internal teams on both technical aspects of data migration and storage as well as in a consultative manner to understand unique data parameters, contributing to the design and build of a data lake. You will aggregate, organize and ingest data from various sources to ensure that the data can be accessed efficiently by our internal and external users and applications.

Who you are

You are a Data Engineer with a few years of experience storing, pipelining, and transforming data using a range of technologies. You want to balance your technical deliverables with internal client interaction to gain an in-depth understanding of how our platform will work and how we can meet the data needs and drive key decisions for everyone. You want to be part of building something new with great visibility across the organisation and endless possibilities ahead as we continue to grow and scale. You want to play a critical role in seeing our collaborative vision implemented.

What’s in it for you?

Unparalleled exposure and impact. You will work alongside development, architecture, and product teams who are at the top of their game, solving problems that have never been looked at before. As part of a platform team specifically assembled to collaborate on new work, you will have the freedom to create from the ground up, and work unrestricted by existing tools or legacy technology. This is an opportunity to make your mark and truly accomplish something exciting as we focus on defining and driving our data and SaaS strategy.

The latest technology, in leading-edge ways. Data is at the heart of everything we do. We are actively pursuing the latest iterations of modern technologies. Our stack encompasses Docker, Microservices, Snowflake, Glue, Spark, Python, Tableau, JavaScript, Angular, Node/JS, REST APIs, Swagger WSo2, and the AWS ecosystem. You will be part of the team working with - and continuously evolving - this tech stack and our approach to data.

Growth and career development. Altus fosters a culture of professional development and promotion from within. With retention rates double the tech industry average, and dozens of promotions within and across teams, this is a place to truly expand your skills and grow your exposure. The Data Solutions team offers individuals the chance to lead the scrums on a rotating basis and push the limits of what they do with dedicated time to further their individual areas of technical interest. As we move from building to scaling; from platform to product; and from storage to application, the opportunities to grow your skills, gain exposure, try new things, and make an impact will grow too.

Our new Data Engineer, Data Lake will:

Learn. Working in close collaboration with the Senior Data Engineer, you will be given the support you need and the information you require to come up to speed and make a valuable contribution to the team.

Elicit, understand, and translate. You will work across business lines and newly acquired businesses to understand individualized technical and practical data storage.

Design. You will create and support an ETL solution using AWS Glue to extract and import data into the new data lake. You will determine how to connect to the various data sources, bring data into our new data lake, and the appropriate method of storing the data.

Analyse. You will create data pipelines, reports, visualisations and extracts to support product and research needs. You will work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.

Advise. You will research data governance and security to ensure our data storage methodology adheres to any constraints and follows best practices.

Try new things. You will take the initiative to research, test, and solve complex data engineering problems and big data storage.

Our new Data Engineer, Data Lake will have:

An eagerness and ability to learn quickly. You have a devotion to evaluating and appropriately applying emerging and alternative technologies, languages, frameworks, and platforms.

A commitment to collaboration. You thrive working across inter-disciplinary groups, including architects, developers, product, and management, to build great products. You have a way of speaking, writing, and relaying information that engages people and expresses appreciation for diverse opinions and approaches.

Hands-on experience. You have worked with a broad range of data management, analysis, and visualisation tools, including ETL/data format conversion, SQL, and NoSQL/ non-traditional database technologies, including newer tools such as Glue and Snowflake. You have worked with AWS/Cloud computing infrastructure.

Come realize your potential at Altus Group!

Altus Group is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs. If you are a person with a disability and require assistance during the application process, please contact us at accessibility@altusgroup.com or 416-641-9500.","Altus Group
3.9",Midtown Toronto
481,Data Engineer (Data Factory Experience),"1 year + Contract
French Strongly Preferred but will consider English Only Profiles
Need a Data Engineer with Data Factory Experience
Remote Across Canada

Context and mandate

The client intends in the coming years through its BI Modernisation program to migrate various business units from existing BI environments to its next-generation Enterprise Data Platform in the Cloud.

In that context, the Client is looking for a knowledgeable, experienced, and motivated Data Integration Developer. You will play a pivotal role in operationalizing the most urgent data and analytics initiatives for the Client's BI, Data and Analytics strategy.

The bulk of the work would be in the building, managing, and optimizing data pipelines and then moving these data pipelines effectively into production for key BI, data, and analytics consumers.

You will need to guarantee compliance with data governance and data management requirements while creating, improving, and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse, and vastly improved time-to-solution for the Client's BI, data, and analytics initiatives.

Duration: June 15th until March 31st, 2022

Possibility de renew: Yes
Possibility de convert to a permanent position: To be determined

Responsibilities / Accountabilities

Build data pipelines and ETLs.
Provide data structure definition, validation, ingestion, processing, and visualization.
Collaborate with business units, architects, data modelers, data scientists, and project/product team.
Work with the information security team to define and implement data access.
Drive automation through effective data management lifecycle from governance to quality to cataloging to lineage, to ensure data compliance.

Requirements

Professional Experience

3+ years of experience in Data Integration with the required technology.
Experience in data profiling and data quality analysis.
Experience in identifying, analyzing, and interpreting trends or patterns in data sets.
Experience with MS Data integration stack, e.g. Azure Data Factory, SSIS, etc.
Experience with SQL for RDBMSs such as Azure SQL, MS SQL Server, and MySQL.
Experience working with PowerBI for semantic-layer-based data discovery.
Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management.
Knowledge of Azure Migration stack, e.g. Azure Migrate, Azure database migration service, etc.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional data integration technologies such as ETL/ELT, data replication/CDC, message-oriented data movement, event processing, API design, and access.
Experience in agile methodologies and capable of applying DataOps principles to data pipeline build engineering to improve integration, reuse, and automation of data.

Educational Experience

University degree or higher in computer science, business administration, business intelligence, statistics, mathematics, or equivalent.

Soft Skills

Ability to linearize and bridge business needs into technical requirements.
Strong communication, documentation, storytelling, creativity, and presentation skills.
Strong interpersonal, teamwork, coordination, and consensus-building skills.
Strong organizational skills, ability to perform under pressure, and manage multiple priorities with competing demands.

Language

Good verbal and written communication skills in French and English.

Other

The mandate will be carried out remotely until the return to the offices

Once back at the office, the position will be carried out according to a hybrid model (face-to-face/telework) to be confirmed.

Contract length: 12 months

Part-time hours: 40 per week

Job Types: Full-time, Part-time, Contract

Pay: $65.00-$85.00 per hour

Language:

French (preferred)

Work remotely:

Yes",Sky Systems Inc,Montreal
482,Data Engineer,"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:

Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done

Here's what you'll be doing:

Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery

Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI

Why Join Us?

Bond is proudly recognized as a Great Place to Work and a Best Managed Company for the third year in a row.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

At Bond, we are proud to be a diverse organization and we are committed to building and fostering an environment where our employees feel included, valued, and heard. Our belief is that a strong commitment to diversity and inclusion enables us to truly create equal opportunity and positive employment experiences for everyone. We encourage applications from Indigenous peoples, racialized people, people with disabilities, people from gender and sexually diverse communities and people with intersectional identities.","Bond Brand Loyalty Inc
3.5",Mississauga
483,Data Engineer,"Open up to the Possibilities!
At Purolator, you’ll be proud knowing you’re working for a Canadian company that truly values its employees. And it’s community. This is an exciting and evolving industry and we’re leading the change as we strive to deliver the future. Here you will be empowered to help move the business forward. Each and every day. Are you open to the possibilities?


Job Description


Successful candidates will demonstrate excellent skill and maturity, be self-motivated as well as team-oriented, and have the ability to support the development and implementation of solutions to meet the needs of our customers. Your strong experience and skills in Business Intelligence and Data Architecture will help Purolator leverage its data for a variety of analytic use cases to support strategic decision making, in a way that is governed, sustainable, and scalable.

You are passionate about data, and not only do you understand the mechanics of how to access, move and manipulate data, you also understand how data can be leveraged to empower reporting and analytics. While you are strong technically, you are also adept at consulting with non-technical business users to understand the root of their requirements, to develop BI solutions that truly meet their needs.


Responsibilities

Serve as a subject matter expert in Data Engineering technology and related processes.
Understand business issues and decompose them into measurable data or data modelling requirements.
Curate data for governed reporting and self-service data discovery and analytics
Contribute to consultations workshops with various business stakeholders to understand the root business needs for new reporting and analytics use cases
Build experimental data processes and BI assets for rapid prototyping of reports and dashboards from new data sources
Help administer the Business Intelligence platforms to ensure the environment is secure, up to date, and accessible

Skills:

A seasoned Business Intelligence professional with hands-on experience developing and administering front-end BI tools such as PowerBI, Qliksense
A savvy data architect with strong understanding of datawarehouse principles and methodologies
Great communication skills, you can effectively convey highly technical concepts to a non-technical audience
Excellent problem-solving skills, able to systematically analyze, hypothesize, and solution problems and issues
Hands-on experience with datawarehouse technologies, preferably with cloud-based platforms such as AWS Redshift and Azure Synapse
Experience developing and building ETL/ELT pipelines using GUI based tools such as Glue, Pyspark and ability to code custom data workflows via Java and Python a strong asset
Energized by working on a small team with the ability to make an immediate impact on the business
Experience working in an Agile environment (developing stories, prioritizing tasks, grooming)

Qualifications:

Bachelor or Master degree in a technology/analytical field such as Computer Science, Management of Information Systems, Mathematics, Statistics, Machine Learning/AI, Engineering, or other relevant technical fields.
Experience in an Agile environment
Excellent programming knowledge in any of the languages (Phyton, R, Hadoop, Kafka, Spark/Scala).
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with relational SQL and NoSQL databases.


POSTING DETAILS
Location: 530 - Corporate
Working Conditions: Office Environment

Reports to: Manager Reporting and Data Delivery
-

Purolator is an equal opportunity employer committed to diversity and inclusion. We consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Indigenous status or any other factors considered discriminatory. If you require an accommodation during the recruitment process, we will work with you to meet your needs.


We recognize that our employees and their families are key stakeholders. We will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. We hire for attitude and train for skills. To learn more about us and our values, go to www.purolator.com.


At Purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.","Purolator
3.9",Mississauga
484,Data Engineer,"Open up to the Possibilities!
At Purolator, you’ll be proud knowing you’re working for a Canadian company that truly values its employees. And it’s community. This is an exciting and evolving industry and we’re leading the change as we strive to deliver the future. Here you will be empowered to help move the business forward. Each and every day. Are you open to the possibilities?


Job Description


Successful candidates will demonstrate excellent skill and maturity, be self-motivated as well as team-oriented, and have the ability to support the development and implementation of solutions to meet the needs of our customers. Your strong experience and skills in Business Intelligence and Data Architecture will help Purolator leverage its data for a variety of analytic use cases to support strategic decision making, in a way that is governed, sustainable, and scalable.

You are passionate about data, and not only do you understand the mechanics of how to access, move and manipulate data, you also understand how data can be leveraged to empower reporting and analytics. While you are strong technically, you are also adept at consulting with non-technical business users to understand the root of their requirements, to develop BI solutions that truly meet their needs.


Responsibilities

Serve as a subject matter expert in Data Engineering technology and related processes.
Understand business issues and decompose them into measurable data or data modelling requirements.
Curate data for governed reporting and self-service data discovery and analytics
Contribute to consultations workshops with various business stakeholders to understand the root business needs for new reporting and analytics use cases
Build experimental data processes and BI assets for rapid prototyping of reports and dashboards from new data sources
Help administer the Business Intelligence platforms to ensure the environment is secure, up to date, and accessible

Skills:

A seasoned Business Intelligence professional with hands-on experience developing and administering front-end BI tools such as PowerBI, Qliksense
A savvy data architect with strong understanding of datawarehouse principles and methodologies
Great communication skills, you can effectively convey highly technical concepts to a non-technical audience
Excellent problem-solving skills, able to systematically analyze, hypothesize, and solution problems and issues
Hands-on experience with datawarehouse technologies, preferably with cloud-based platforms such as AWS Redshift and Azure Synapse
Experience developing and building ETL/ELT pipelines using GUI based tools such as Glue, Pyspark and ability to code custom data workflows via Java and Python a strong asset
Energized by working on a small team with the ability to make an immediate impact on the business
Experience working in an Agile environment (developing stories, prioritizing tasks, grooming)

Qualifications:

Bachelor or Master degree in a technology/analytical field such as Computer Science, Management of Information Systems, Mathematics, Statistics, Machine Learning/AI, Engineering, or other relevant technical fields.
Experience in an Agile environment
Excellent programming knowledge in any of the languages (Phyton, R, Hadoop, Kafka, Spark/Scala).
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with relational SQL and NoSQL databases.


POSTING DETAILS
Location: 530 - Corporate
Working Conditions: Office Environment

Reports to: Manager Reporting and Data Delivery
-

Purolator is an equal opportunity employer committed to diversity and inclusion. We consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Indigenous status or any other factors considered discriminatory. If you require an accommodation during the recruitment process, we will work with you to meet your needs.


We recognize that our employees and their families are key stakeholders. We will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. We hire for attitude and train for skills. To learn more about us and our values, go to www.purolator.com.


At Purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.","Purolator
3.9",Mississauga
485,"Data Analyst, Marketing Acquisition","FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an elite online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity – Data Analyst, Marketing Acquisition

The Analyst will enable FreshBooks reporting and help to derive insights from website, event, campaign and customer web and product interaction data to improve the volume and quality of acquired trailers, determine growth opportunities, understand the customer journey and major drop-offs.

The right person for the job will love to solve a problem and have a knack for translating data into insight and presenting that information to stakeholders. You will be collaborating with managers and a team that includes other analysts, data scientists, marketers, financial analysts, and developers all working together to drive growth at FreshBooks.

What you'll do:
Complete regular ad-hoc / deep-dive analyses by translating raw data into useable information and insights
Build dashboards for core performance metrics/monitor KPI's
Channel level reporting on trends in acquisition performance
Support with A/B testing for campaign treatments
Content / Webpage reviews and analyses
Work independently & with engineering to ensure the integrity of data flows / transfers
Monitor changes in usage behaviours (organically and due to marketing)
Performance evaluations of various customer segments
Assist with GTM tagging, maintenance and general organization
Consult with internal clients to gather requirements, scope & execute
Complex, long-term analyses on visitor trends and performance impacts
Communicate results and recommended analyses/approaches to stakeholders

What you bring:
Intermediate to advanced knowledge of SQL is required
Minimum 2-3 years in data analytics/business intelligence
Knowledge of Google Analytics data, and/or similar web analytics tools
Strong knowledge of one or more visualization tools such as Looker, Tableau etc.
Quantitative background with strong analytical skills
Experience working with relational databases
Familiarity with the marketing campaign and/or web data is preferred
Python knowledge is an asset
Google Tag Manager experience is an asset

Why Join Us

We're a motivated bunch, with our eyes laser-focused on shipping extraordinary experiences to businesses. You will be surrounded by hardworking team members who share a common vision for what an amazing software company could be, and have the opportunity to help build an elite one, right here in downtown Toronto.

Apply Now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer. We do not discriminate based on gender, religion, race, mental disability, sexual orientation, age, or any other status. All applicants are considered based on their qualifications and merits. At FreshBooks, we inspire an environment of mutual respect and we believe diversity and inclusion are crucial to our success.

FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com.","FreshBooks
4.0",British Columbia
486,Data Engineer - Mississauga,"Our client, located in Mississauga Ontario is looking for Data Engineers to join them on a permanent basis.

Join a creative organization with design, implementation, maintenance of data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services.

Advantages
We are looking for a problem solver, someone that works collaboratively and is passionate as well as a self starter.

Responsibilities
You will be responsible for all design, implementation, system performance. Automation of manual processes and process improvements.

Qualifications

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI


Summary
If you have the skills above, please apply today as we certainly would like to speak with you!","Randstad
4.2",Mississauga
487,Data Management Specialist – Pharmaceutical,"At ProCogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.

We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.

ProCogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.




Position Details



We are seeking a Data Management Specialist for our Pharmaceutical clients’ Development Sciences department.
The Data Management Specialist will be performing data management and curation tasks to support biomarker discovery and companion diagnostic development efforts. In the process of performing this work, the candidate will communicate extensively with scientists, research associates, operations managers, clinical data managers, analysts, and vendor representatives.
Responsibilities

Working with biomarker operations managers and biometrics colleagues to draft data transfer specifications and statements of work.
Acquiring and QC’ing digital pathology image data and associated metadata files from internal groups and external vendors. Capturing data in internal file systems and databases.
Monitoring data processing requests and submitting data files to analysis pipelines
Merging different data types with clinical data to generate analysis-ready data sets
Curating and cataloguing data sets, maintaining listings of available data, and distributing to collaborators
Maintaining and curating content of internal knowledge sharing repositories
Maintaining and developing data conformance checking scripts and requirements


Required Skills



Familiarity working in a Linux computing environment
Proficiency in scripting languages such as R or Python; Database skills
Familiarity with modern informatics systems, relational and non-relational databases, scripting languages, and data visualization tools.
Demonstrated experience with informatics best practices and developing well-documented, production code in non-academic environments.
Working knowledge of scientific research application development cycles and data management principles.
Working knowledge of anatomical pathology workflow and digital pathology data lifecycles
Experience managing and curating biological or clinical data
Careful, detail-oriented working style
Outstanding communication, collaboration, and problem-solving skills
Able to work independently and in a team setting.


Nice to have but not required



Relational databases and SQL
Statistical software packages such as R or SAS
Clinical trial data management
Working with medical images data
Setting up and maintaining online content management systems or wikis


Education



Bachelors or Master's degree in Life Science, Computer Sciences or Biomedical Engineering with at least >3 years work related experience.","ProCogia
4.7",Midtown Toronto
488,Data Engineer,"Data Engineer
Information Technology
Remote Position – Canadian based candidates
Competitive Salary

Our client is looking for a passionate Data Engineer to join their growing team for the development and deployment of ETL processes, Data management, Data Warehousing. This role will be responsible for the development and deployment of ETL processes, Data management, Data Warehousing to improve, optimize and lead further development of their data aggregation processes. You’ll bring a deep understanding of big data and will help to build and enable big data analytics solutions. The ideal candidate is innovative, collaborative, determined and takes great pride in their work.

The Role:
Code, test, and document new or modified data systems to create robust and scalable applications for data analytics
Work with stakeholders including Analytics, Product, and Design teams to assist with data related technical issues and support their data infrastructure needs.
Engineer solutions for large data storage, management, and curation of training data models.
Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities.
Act as an internal expert in each of the data sources so that you can own overall data quality.
Design, build and deploy new data models, ETL pipelines into production and data warehouse.
Define and manage overall schedule and availability of all data sets.
Process, cleanse, verify and work with data from multiple sources
Work with the data science team to access and understand internal and external data sources
Develop algorithms and build models to solve business problems.
Collaborate with solution engineers to integrate pipelines into our proprietary applications
Bring your great ideas for new products and features to the team

The ideal Candidate:
Masters or BS degree in Computer Science or related technical field, or equivalent practical experience.
3+ Years experience with Data gathering, Data pipelining, Data Standardization, Data Cleansing, Stitching aspects
Some experience with cloud: AWS, Azure, or GCP
Proficiency in a major programming language (e.g. Java/C) and/or a scripting language (scala/php/python)
Highly analytical and detail oriented with a dedication to analyzing data to identify deliverables, anomalies, and gaps and propose solutions to address these findings
Strong analytic skills related to working with unstructured datasets
Solid understanding and working knowledge of relational or non-relational databases
Excellent communication (both written and verbal), organizational, and trouble-shooting skills.
A preference for candidates located in Calgary, Winnipeg, GTA, Hamilton but open to Canada wide applications","TalentSphere Staffing Solutions
5.0",Midtown Toronto
489,Data Engineer,"The Green Organic Dutchman is a global leader in cultivating premium, certified organically grown cannabis.


At The Green Organic Dutchman (TGOD), we are proud be to cultivating a great workplace from the ground up. Every day we are challenging, defining, and shaping this new industry. We are growing strong with a team that is proudly committed to creating the world’s best certified-organic cannabis.


The Data Engineer is a critical role for TGOD as our business hits unprecedented scale. You will provide and grow in-house expertise on ELT/ETL formulations and API interactions. Our data is a critical business asset – how we handle and manage that data must enable our agile business and be compliant with laws/regulations to preserve its confidentiality, availability and integrity. This role forms part of TGOD’s data science functions and will support the Director of Data Science in leading and managing all data-related activities including business intelligence.


This role is fully remote, within Canada.


Key Responsibilities

Support and develop data pipelines for all core systems and 3rd party integrations into the data lake and analytics database.
Leverage API endpoints for operational use of centralized data assets
Develop broad domain and technical knowledge in AWS solutions.
Demonstrate strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.


Basic Qualifications

Bachelor's degree in Computer Science, Information Systems Management, IT Security, Finance, Technology or related field; or 3 years relevant work experience in a data-related field
2+ years Python, SQL (Redshift, Postgres) is a must. Strong ELT/ETL background
1+ years using APIs for data extract and load (Postman, Lambda)
1+ years with linux shell/bash for automation and server administration
Experience with Apache Airflow and Docker is preferred
Experience with web scraping is preferred
Experience in the BI/Analytics/Data Warehousing space is preferred
Experience with Amazon Web Services ecosystem (Redshift, S3, Fargate, EC2, EFS, Lambda, Cloudformation, Cloudwatch, VPC, Codecommit, SES, SNS) and general cloud architecture
Demonstrate critical inquiry with attention to detail
Ability to effectively articulate recommendations/conclusions verbally and in writing


Preferred Qualifications

Tableau server(Ubuntu) and Tableau desktop
SAP HANA cloud data model, data extraction and API use cases
Version control best practices
Highly independent, organized and efficient.
Snowflake data warehouse
Data presentation skills to both business and technical teams.


The Green Organic Dutchman is an Equal Opportunity Employer and we welcome diversity in the workplace. We encourage applications from all qualified individuals, including visible minorities, Aboriginal People, and persons with disabilities. Please contact Human Resources to request any accommodations you may require to participate in the recruitment process (including alternate formats of materials or accessible meeting rooms).",The Green Organic Dutchman Holdings Ltd,Mississauga
490,"Certified Azure Data Engineer (DP-200 & Dp-201, DP-203) 12+ yrs Exp","Azure Data Engineer

Location- Brampton, ON

Salary: 95k Full time

On contract Rate CAD $65/hr on Inc

Client- Tech M

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Databricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on NoSql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Temporary, Permanent

Salary: $79,138.00-$95,000.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Vision care
Work from home

Schedule:

8 hour shift

Work remotely:

Yes","Compest solutions Inc.
4.6",Brampton
491,Data Science Senior Manager,"We Are

The people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in AI/ML. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Accenture Applied Intelligence.

You Are

An expert at solving real-world challenges with data, analytics, AI/ML and creativity. Yes, creativity! You know the theory and you have hands-on expertise from studies, experience and/or self-taught projects. As a senior manager working at Accenture you will work on a team with diverse clients and industries delivering analytics solutions and help clients turn data into actionable insights that drive tangible outcomes, improve performance and help clients lead the market.

What You’ll Do

Collaborate with prospective clients to solve large & complex business problems with data, analytics and AI/ML
Develop innovative cloud solutions for clients across functions & industries
Educate account teams about data, analytics AI/ML and applicability to their industry/clients
Lead multiple teams and engagements to engineer & deliver value for clients
Play an active role building a practice including capability development and recruitment
Stay abreast of technologies, academic researches & hands-on techniques on cloud, data, analytics and AI/ML




What We’re Looking For

Extensive experience engaging with client senior leadership on complex business problems
Expertise developing solution offerings and communicating findings to executive audiences
Well versed with managing data science teams and engagements, and providing technical leadership
Extensive experience embracing challenges with cloud, data, analytics and AI/ML lifecycle in enterprise setting
8+ years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation

Bonus Point If

Graduate degree in data science or related disciplines: e.g. Mathematics, Statistics, Computer Science, Economics, Engineering and Physics
Ability to build, manage and foster a team-oriented environment, working creatively and analytically in a problem-solving environment
A blend of data science capability, industry and consulting expertise
High initiative and a desire/ability to persist through obstacles/ambiguity
Excellent written and oral communication skills with ability to clearly communicate findings, concepts and ideas","Accenture
4.1",Montreal
492,Data Science Senior Manager,"We Are

The people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in AI/ML. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Accenture Applied Intelligence.

You Are

An expert at solving real-world challenges with data, analytics, AI/ML and creativity. Yes, creativity! You know the theory and you have hands-on expertise from studies, experience and/or self-taught projects. As a senior manager working at Accenture you will work on a team with diverse clients and industries delivering analytics solutions and help clients turn data into actionable insights that drive tangible outcomes, improve performance and help clients lead the market.

What You’ll Do

Collaborate with prospective clients to solve large & complex business problems with data, analytics and AI/ML
Develop innovative cloud solutions for clients across functions & industries
Educate account teams about data, analytics AI/ML and applicability to their industry/clients
Lead multiple teams and engagements to engineer & deliver value for clients
Play an active role building a practice including capability development and recruitment
Stay abreast of technologies, academic researches & hands-on techniques on cloud, data, analytics and AI/ML




What We’re Looking For

Extensive experience engaging with client senior leadership on complex business problems
Expertise developing solution offerings and communicating findings to executive audiences
Well versed with managing data science teams and engagements, and providing technical leadership
Extensive experience embracing challenges with cloud, data, analytics and AI/ML lifecycle in enterprise setting
8+ years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation

Bonus Point If

Graduate degree in data science or related disciplines: e.g. Mathematics, Statistics, Computer Science, Economics, Engineering and Physics
Ability to build, manage and foster a team-oriented environment, working creatively and analytically in a problem-solving environment
A blend of data science capability, industry and consulting expertise
High initiative and a desire/ability to persist through obstacles/ambiguity
Excellent written and oral communication skills with ability to clearly communicate findings, concepts and ideas","Accenture
4.1",Montreal
493,Data Engineer,"Cyient is a global engineering and technology solutions company. As a Design, Build, and Maintain partner for leading organizations worldwide, we take solution ownership across the value chain to help clients focus on their core, innovate, and stay ahead of the curve. We leverage digital technologies, advanced analytics capabilities, and our domain knowledge and technical expertise, to solve complex business problems.

With over 15,000 employees globally, we partner with clients to operate as part of their extended team in ways that best suit their organization’s culture and requirements. Our industry focus includes aerospace and defence, healthcare, telecommunications, rail transportation, semiconductor, geospatial, industrial, and energy.

Job Description

The Data Engineer will work closely with a multidisciplinary agile team to build high quality data pipelines driving analytic solutions. These solutions will generate insights from the organization’s connected data, enabling Pratt & Whitney Canada to advance the data-driven decision-making capabilities of our enterprise. This role requires deep understanding of data architecture, data engineering, data analysis, reporting, and a basic understanding of data science techniques and workflows in additional to basic understanding on business processes supported by the data pipeline. The ideal candidate is a skilled data / software engineer with experience creating data products supporting analytic solutions with experience in the assigned area. Finally, they are an agile learner, possessing strong problem-solving skills, working as part of a technical, cross functional analytics team, and desiring to solve complex data problems and deliver the insights to enable analytics strategy.

Bachelor’s degree required; Computer Science, MIS, or Engineering preferred
5+ years of experience working in data engineering or architecture role, 7+ preferred (3 years with 5 preferred for Jr. role)
Expertise in ELT and data analysis and experience with SQL and at least one programming language (Python/R preferred)
Experience developing and maintaining data warehouses in big data solutions e.g. Snowflake
Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space
Database development experience using Hadoop, SPARK or BigQuery and experience with a variety of relational, NoSQL, and cloud database technologies
Worked with BI tools such as Alteryx, Tableau, Power BI, Looker
Conceptual knowledge of data and analytics, such as dimensional modeling, ELT, reporting tools, data governance, data warehousing, structured and unstructured data.
Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)
Familiarity with the Linux operating system
Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics
Strong understanding of agile methodologies
Experience as a Data Engineer on a cross-functional agile team preferred
Strong communication skills with ability to communicate complex technical concepts and align organization on decisions
Sound problem-solving skills with the ability to quickly process complex information and present it clearly and simply
Utilizes team collaboration to create innovative solutions efficiently
Passionate about technology and excited about the impact of emerging / disruptive technologies
Proven learning agility on both the technical and business process realms
Wants to unleash inner self-starter and work in an environment that fosters entrepreneurial minds
Believes in culture of brutal transparency and trust and open to learning new ideas outside scope or knowledge

Skills & Experience

Apache Spark, Hadoop Ecosystem, IBM Cloud, Microsoft Azure, Microsoft Azure Databricks, Microsoft Azure SQL Database, Scala, Spark SQL, SQL

Cyient is an Equal Opportunity Employer.


Cyient recruits, employs, trains, compensates, and promotes regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, veteran status, and other protected status as required by applicable law. We are proud to be a diverse and inclusive company where our people can focus their whole self on solving problems that matter.","Cyient
3.3",Montreal
494,Data Science Associate - Montreal,"Company presentation


World leader in gases, technologies and services for Industry and Health, Air Liquide is present in 80 countries with approximately 65,000 employees and serves more than 3 million customers and patients. Oxygen, nitrogen and hydrogen have been at the core of the company’s activities since its creation in 1902. Air Liquide’s ambition is to be the leader in its industry, delivering long-term performance and acting responsibly.


Entity and activity description


Founded in 1911, Air Liquide Canada has over 2,200 employees and serves over 80,000 customers in Canada’s aeronautics, automobile, agri-food, chemical, defence, electronics, energy, metallurgy, metal fabrication, mining and healthcare industries from our sites located in key industrial regions from coast to coast.


Missions and Responsibilities


The R&D Data Science group at Air Liquide has an opening for a Data Scientist. The researcher will have the opportunity to work on challenging problems focusing on customers, patients and operations.The researcher will also interact with multi-disciplinary teams composed of Business, IT and Digital resources that define operating models, and build digital solutions.

Duties and Responsibilities

Collaborate with the business to define needs and challenges, translate them into functional specifications, and develop solutions to address them.
Work with IT and external organizations to obtain online/offline data. Clean, and analyze the data.
Develop solutions relying on machine learning methods such as clustering, regression, classification, time series and deep learning.
Test and verify the performance of solutions with prototypes developed in R, Python, or similar development environments.
Support the development of industrial tools and their deployment in the business units.
Train team members and the business, thus ensuring sustainability of the solutions for Air Liquide.
Publish research in internal reports, at conferences and peer-reviewed journals

Competencies and Profile

Master in Computer Science or related field
3 years of relevant experience is preferred
A strong background and experience in statistics and machine learning
Strong programming skills in Python or R
Ability to write production level, modular code
Demonstrates strong process and operational safety behavior at all times
Excellent communication and interpersonal skills (written and oral)
Ability to work in a multi-disciplinary and international team

Preferred

Experience in AWS, Azure, and SQL

Additional information


Thank you for your interest. Please note that only applicants selected for an interview will be contacted For more information on our company, visit us online at www.airliquide.ca


Job Reference: CA04024","Air Liquide
3.8",Quebec
495,Data Engineer - Machine Learning,"Who we are
Creating a planet fueled by reliable, clean energy isn’t what keeps us up at night; it’s what gets us out of bed. At Opus One Solutions, our software platform GridOS® helps us pursue solutions that will change how countries access, optimize and distribute electrical energy. From microgrids that keep things running in the event of an outage, to helping electric utilities optimize their operations and allowing homeowners to feed energy into a power grid, we're powering a more sustainable future.

The Opportunity
As the shift to reliable, clean energy becomes an imperative, Opus One Solutions is at the forefront of this transition. Our software reduces the complexity of systems coordination and establishes the financial base for resource deployment, allowing countries to accelerate carbon reduction, and system operators to facilitate the distribution of carbon neutral energy.

The Opus One Solutions GridOS software platform brings intelligence to every level of the electrical grid, from smart meters that can minimize the impact of power outages to the most challenging electrical utility marketplaces that can coordinate market actors to enhance system operations. Our software enables optimization of energy systems from planning to operations, leveraging the data at not only the utility, but also the various entities connected to its infrastructure.
We have assembled a diverse group of power systems experts and distributed software system professionals who are working to tackle these challenges together and are looking to expand the team to accelerate our shared journey to a more sustainable future.
You will be working as part of the Opus One Solutions data science team focusing primarily on building and deploying high velocity machine learning models targeted at electrical distribution utility customers.
Our end users require the integration of highly accurate energy demand and generation forecasts combined with production level outcomes delivered into operational systems resulting in a need for a balanced approach of model development and deployment.
Energy demand and generation both depend on climate, weather, seasonality, and long-term trends. The data sources may be clear and well understood or sparse and require investigation by the data science team. You will be an integral part of this process.
You will work with the data science team to ensure the outcomes are repeatable, scalable, traceable, and defensible

What you will work on?
Design, build and maintain the data processing pipelines required for the Opus One Solutions machine learning based time series forecasting models and production deployments.
Create the ETL/ELT workflows to ingest measurement data timeseries forecasting engine
Support the integration with third-party data sources including Advanced Metering Infrastructure (AMI), electrical grid distribution and feeder models, meteorological services, solar and generation forecast data along (short term forecasts) with additional socio-economic information as required (long-term forecasts).
Analyze foundational data tables and metrics supporting the power flow optimization and data science teams with clear definitions, data lineage, loading patterns, test coverage and transformations to ensure that data is reliable, intelligible, and maintainable
Build and extend time series forecasting engine APIs for product and project services.
Implement systems to track data quality and consistency explaining issues/problems with data.
Communicate high-quality software engineering practices for building data infrastructure and pipelines at scale including the documentation of ETL/ELT flows and systems architecture.
Support testing processes, troubleshoot and resolve issues.
Work in an Agile/SCRUM team setting including cross-functional structures and varying levels of management.
Requirements
Who are you?
We're looking for a data engineer to help us accelerate the adoption of distributed energy resources such as wind and solar into the day-to-day operations of the electrical utilities. You will have a proven track record of shipping performant data processing systems in production environments and are comfortable developing and automating complex pipelines and workflows that underpin AI/ML powered products.
You are a data engineer with experience working in a machine learning or big data production environment.
Experience in the application of best practices for software engineering in the AI/ML and data spaces, with an emphasis on time-series data
Experience standing up services and building scalable production data workflows.
You may also have experience working within the electrical utility marketplace or an adjacent industry where experience in forecasting can be used.

Here’s what you bring:
Education
Bachelor's degree in Computer Science, Math, Statistics, Engineering, or a related quantitative field, or equivalent experience
Technical
3+ years of industry experience in software engineering or data engineering
Proficiency working with structured and unstructured data including experience with relational data stores such PostgreSQL, SQL, and ETL/ELT frameworks
Experience with implementing chronological, time series processes
Experience with Service-Oriented Architecture including designing and developing RESTful APIs
A demonstrated ability to build and maintain ETL/ELT processes including staging, cleansing, mapping, and loading
Work experience developing in Python, Java, or other programming languages
Experience building high-quality end-to-end data solutions in an agile environment from requirements to production.
Some exposure to the workflow management engines (Airflow) along with Hadoop or similar ecosystems including Hive, Spark, Pig, or others is desired.
Collaboration
Solve problems in robust and creative ways demonstrating solid verbal, interpersonal and written communication skills.
Effective in working across team boundaries to establish overarching data architecture, and provide guidance to individual teams
Collaborate across multiple development, project delivery teams along with technical and non-technical stakeholders.
Benefits
Why join Opus One Solutions?
Opus One is growing! After spending first four years under the radar focused on research and pilot projects we’re ready to shine as one of Canada’s top 10 game-changers named by CIX Cleantech, Fast Company’s 2017 World Changing Idea in Energy and one of top 100 Global Cleantech companies! We are deploying exciting microgrid projects in North America and have partnerships with leading energy players such as National Grid.
Our leadership has assembled carefully selected teams with some of the best strategic visionaries - and executors - in technology and the clean energy space. We are all driven by one common goal: to accelerate the integration of clean and sustainable energy in North America and the world.
At Opus One Solutions we understand that not everyone develops their talent and hones their skills in a traditional way. Different paths and experiences are part of the diversity we know we need to succeed. If you feel you meet all or most of the qualifications we are seeking, take a chance and express your interest here.
Opus One Solutions welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Opus One Solutions
3.3",Midtown Toronto
496,Sr. Medical Scientist (Cell Therapy) / Scientifique Médical (Thérapie cellulaire),"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.




For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.

Job Description

Kite, a Gilead Company, is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors.

The Role:

The Medical Scientist (MS) is a field-based medical-scientific expert in the assigned therapeutic area. The MS assumes responsibility for all Medical activities within the assigned territory and executes the field medical strategy. This involves gathering insights, medical education and communication, supporting clinical research, and managing projects of various scope including educational events and regional advisory boards. The role requires close national and international collaboration with colleagues from Medical Affairs and other departments.

Implements defined goals and objectives aligned with the Medical Affairs Plan of Action and other strategic initiatives within the Cell Therapy therapeutic area

Responds to clinical inquiries regarding marketed or developmental Gilead/Kite products.

Develops and presents complex scientific and clinical data related to Gilead/Kite products.

Identifies and develops regional and national opinion leaders to support Gilead/Kite products through personal contacts and on-site visits

Establishes strong relationships with opinion leaders, clinical investigators and healthcare professionals at academic and non-academic settings

Works on phase 3/phase 4 programs that include collaboration with investigators and internal personnel

Provides input into site selection for both phase 4 and other clinical trials

Anticipates obstacles and difficulties that may arise in the field and resolves them in a collaborative manner

The candidate works collaboratively with Gilead/Kite personnel in Commercial, Marketing, Market Access, Clinical Research, Global Safety and Global Medical Affairs

Utilizes scientific resources to deliver impactful presentations in a variety of settings.

The incumbent travels to appointments, meetings and conferences on a frequent and regular basis, occasionally with short notice

Must have the ability to work as a member of several teams that may overlap such as national MS team, regional team, national accounts, and others

Well-developed experience in preparing and delivering presentations is required.

Experience in the management or investigation of clinical trials is preferred

Exhibits Gilead/Kite core values: integrity, inclusion, teamwork, accountability, and excellence

Knowledge, Experience and Skills:

Advanced health sciences degree (M.D., Pharm. D., PhD are preferred) with a minimum of 3 years of experience in healthcare or pharmaceutical industry

Two to four years of experience in Oncology (specifically Hematologic Malignancy) in a clinical/research or medical affairs capacity is preferred

Excellent oral and written communication skills and interpersonal skills (including ability to network)

Bilingualism (French and English) is required

Excellent project management ability and organizational skills, including the management of multiple priorities and resources

Excellent judgment and personal initiative are required

Advanced knowledge of Microsoft Office suite (Word, PowerPoint, Excel, Access, Outlook) is required

Must have knowledge of and be willing to comply with all regulatory/compliance policies

Candidate must be based in Quebec

Ability to travel 70% of the time; domestic and international travel is required, including potential attendance at conferences which may include occasional weekend travel





Kite, une société de Gilead, se consacre à la mise au point d’immunothérapies novatrices contre le cancer dans le but d’offrir une réponse rapide, durable et à long terme et d’éliminer le fardeau que représentent les soins de longue durée. L’entreprise concentre ses énergies sur des thérapies cellulaires, à savoir les cellules T à récepteur antigénique chimérique (CAR-T) et les récepteurs de l’antigène des lymphocytes T (TCR). Ces traitements visent à renforcer la capacité du système immunitaire à détecter les tumeurs et à les éliminer.

Rôle

Le scientifique médical (SM) est un expert scientifique du domaine médical qui travaille sur le terrain, dans le domaine thérapeutique qui lui a été attribué. Le SM assume la responsabilité de toutes les activités médicales dans le territoire attribué et exécute la stratégie médicale sur le terrain. Il doit par exemple recueillir des idées, soutenir la formation et les communications médicales, appuyer la recherche clinique et gérer des projets d’importances diverses, y compris des événements éducatifs et des conseils consultatifs régionaux. Le titulaire de ce poste doit entretenir une étroite collaboration nationale et internationale avec des collègues des Affaires médicales et d’autres services.

Mettre en œuvre des objectifs définis qui cadrent avec le Plan d’action des Affaires médicales et avec les autres initiatives stratégiques du domaine thérapeutique de la thérapie cellulaire.

Répondre aux questions cliniques portant sur les produits de Gilead/Kite actuellement sur le marché ou en cours de développement.

Développer et présenter des données scientifiques et cliniques complexes liées aux produits Gilead/Kite.

Repérer des leaders d’opinion régionaux et nationaux, et les amener à appuyer les produits de Gilead/Kite par l’intermédiaire de contacts personnels et de visites sur place.

Établir de solides relations avec des leaders d’opinion, des investigateurs cliniques et des professionnels de la santé en milieu universitaire et non universitaire.

Travailler aux programmes de phase III et IV notamment en collaborant avec les investigateurs et le personnel interne.

Contribuer à la sélection des centres où seront réalisées des études cliniques de phase IV et d’autres études cliniques.

Prévoir les obstacles et les difficultés pouvant survenir sur le terrain, puis les résoudre de manière collaborative.

Travailler avec le personnel de Gilead/Kite des secteurs Affaires commerciales, Marketing, Accès au marché, Recherche clinique, Innocuité mondiale et Affaires médicales mondiales.

Employer des ressources scientifiques pour donner des présentations convaincantes dans divers milieux.

Se rendre régulièrement et fréquemment à des rendez-vous, à des réunions et à des conférences, parfois avec un court préavis.

Pouvoir travailler en tant que membre de plusieurs équipes dont les activités pourraient se chevaucher, notamment dans l’équipe nationale des scientifiques médicaux, l’équipe régionale et l’équipe des comptes nationaux.

Posséder une grande expérience en élaboration et en animation de présentations, obligatoire.

Posséder une expérience en gestion ou en investigation d’études cliniques, un atout.

Incarner les valeurs de Gilead/Kite, soit l’intégrité, l’inclusion, le travail d’équipe, la responsabilité et l’excellence.

Connaissances, expériences et compétences

Diplôme de haut niveau en sciences de la santé (préférablement M.D., Pharm D. et Ph. D) et au moins trois ans d’expérience dans le secteur pharmaceutique ou des soins de santé.

De deux à quatre ans d’expérience en oncologie (plus précisément en hémopathies malignes) dans un poste du domaine clinique, de la recherche ou des affaires médicales, un atout.

Excellentes aptitudes en communications écrites et orales, et de solides compétences en relations interpersonnelles (y compris en réseautage).

Bilinguisme, anglais et français, obligatoire.

Remarquables compétences organisationnelles et en gestion de projets, y compris la capacité de gérer plusieurs ressources et priorités.

Jugement et esprit d’initiative hors pair, obligatoire.

Connaissance avancée de la suite Microsoft Office (Word, PowerPoint, Excel, Access, Outlook), obligatoire.

Connaissance des politiques réglementaires et de conformité , et volonté de les respecter, obligatoires.

Domicile au Québec, obligatoire.

Capacité à voyager 70 % du temps, autant à l’intérieur qu’à l’extérieur du pays, ce qui inclut d’éventuelles participations à des conférences pouvant nécessiter des déplacements les fins de semaine.



Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com . Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma .



For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.","Gilead Sciences
3.8",Quebec
497,Big Data Engineer,"Company description

VirtueTech Inc. is an Amazon Partner Network (APN) Consulting Partner, focusing exclusively on Amazon Web Services (AWS). With a strong foot in AWS, Cloud Infrastructure and Data Analytics, we are a global technology solutions provider with a reputation for stringent quality standards.

We are a very fast growing company and a trusted analytics partner for multiple Fortune 500 companies. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. Working with us offers you an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility

Job description

Job Description-

Focus on scalability, performance, service robustness, and cost trade-offs
Continuous drive to explore, improve, enhance, automate, and optimize systems and tools to best meet evolving business and market needs
Attention to detail, coupled with ability to think abstractly
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Create prototypes and proof-of-concepts for iterative development
Keen to learn new technologies and apply the knowledge in production systems
Take complete ownership of projects and their development cycle

Contract length: 6-8 months

Application deadline: 2021-04-24

Expected start date: 2021-04-26

Job Types: Full-time, Temporary, Contract

Salary: $62,173.00-$130,000.00 per year

Additional pay:

Overtime pay

Schedule:

8 hour shift
Monday to Friday

COVID-19 considerations:
Remote job. Working from home

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process",Virtue Tech Inc.,Midtown Toronto
498,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
499,Big Data Engineer (Remote Optional),"WHO WE ARE

Centro delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands.

Our comprehensive ad tech platform, Basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place.

We are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. We invest in our culture and support our employees so they can do their best work.

Centro is headquartered in Chicago, with beautiful offices also in Toronto, Dallas, Denver, and New York to name a few. Post-COVID, many of us will be returning to one of our offices (by choice, not requirement - we believe results matter more than where they are produced). All of our employees have the flexibility to work in one of our office locations, completely remote, or a hybrid of the two. Please note, we are hiring on a remote working basis only in the U.S. and Canada.



ABOUT THE TEAM

Technology is at the core of what we do. Centro’s innovative Engineering team designs and develops new features and integrations for Basis, our industry-leading, comprehensive software solution. Our platform processes over 300 billion events per day and uses AI and machine learning to automate and simplify the entire digital campaign process.

WAYS YOU'LL CONTRIBUTE

This team is all about data—and in order to create value from the massive amount of data we collect, engineering leverages their dynamic Data Engineering, Data Science, and Business Intelligence teams to create insights that benefit the industry as a whole. You will contribute by:
Implementing scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment.
Developing platform services to operate the big data applications at scale.
Gathering and processing raw data at scale from diversified sources into Hadoop.
Building enterprise business analytics and reporting applications on Hadoop.
WHAT YOU BRING TO THE TABLE
Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie
Strong understanding of computer science fundamentals
Proficiency with relational databases and SQL queries (MySQL, Oracle or similar)
Understanding of how to handle high velocity, high volume data events.
Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning.
Experience implementing data pipelines moving large volumes of data a day.
Experience in implementing application in Scala on SPARK.
Experience coding in Python
BONUS POINTS
Skills in real-time streaming applications.
Knowledge of Scala.
A development workflow using Docker containers.
Compulsion for automating your day-to-day processes.
OUR TECH STACK
Ruby, Java, Python, and React.js
Hadoop, Scala, Spark, Hive
Kubernetes, Docker, Kafka
PostgreSQL, NoSQL
AWS

ANYTHING ELSE?

Don't think you have all the skills required for this role? That's okay, we recognize that experience can be built in many ways. If you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn’t match our exact requirements.

LIFE WITH CENTRO

We take care of our people and believe that Centro’s success depends on the growth and well-being of each one of our team members.

We provide a thoughtful perks and benefits package including competitive 401k/RRSP matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a work from home stipend for employees in closed offices, and more.

We are proud to be an equal opportunity employer are committed to building teams of Centrons that are diverse in thought, perspective, and culture. We celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age. Our employee-led communities enrich our culture of uniqueness, inclusivity, and empowerment.","Centro
4.1",Ontario
500,Data Engineer,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client's employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the ""Glocal"" team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.

A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.

Key responsibilities:
Key member of the product team building Business Intelligence and Analytics SaaS solutions.

Collaborate with business stakeholders to gather and define data and reporting requirements.

End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analytics

Develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.

Drive Web Scraping alternate data implementation and automation.

Build, test, and maintain scalable and robust data and analytics stack.

What we value:
You hold a bachelor's in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.

You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.

You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.

You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).

You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.

You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etc.

What we Offer :
Opportunity to work in a fast-growing organization with the ability to make a quick impact.

Allow your inspirational ideas to come to life in a highly creative and executional environment.

Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.

The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.

This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.

Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",Elements,Midtown Toronto
501,Data Governance Analyst,"Title: Data Governance Analyst

FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an extraordinary online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity - Data Governance Analyst

FreshBooks is seeking a Data Governance Analyst to join our team. As part of the Data and Analytics Team, you will contribute to the creation of, and help implement, our data governance strategy across the enterprise. If you're committed to great work and are constantly looking for ways to improve the systems you're responsible for, we'd love to chat with you!

What you'll do:
Collaborate with data engineers, data scientists, and data analysts to design and develop data glossaries and standards and keep the metadata repositories up to date.

Work with business stakeholders to identify and map business critical and sensitive data elements.

Collaborate closely with colleagues from business and technology teams to ensure metadata requirements are well understood.

Focus on data management functional areas of data quality, data lineage, data cataloging and data privacy.

Manage, maintain and continuously update the metadata repositories/tools.

Interface with vendors to make sure the data governance tools are running and working as expected.

Be the champion for promoting data literacy within the organization.

Provide expertise around the data governance policy reviews, metrics, and reporting wherever needed by business and technical teams.

What you bring:
2-4 year's experience in a field related to information management or metadata management.

Experience applying metadata management and data governance principles.

Experience with metadata management tools is an asset (e.g. Informatica Axon, Enterprise Data Catalog, Collibra, Alation)

The ability to write accurate SQL queries.

Familiarity with data and analytics platforms and concepts (e.g. Google Cloud Platform, BI tools, SQL server, data warehouse, data lake)

Ability to create a variety of business documents (including standards) that will be positioned as enterprise artifacts.

What you might bring:
Experience implementing data solutions or rolling out new data tools/products.

Experience with industry ETL & BI tools (Informatica, Datastage, Looker, Tableau, PowerBI etc.)

Understanding of data warehouse modeling fundamentals (e.g. dimensional modeling, 3NF, star schema) and application relational database concepts (e.g. normalization, referential integrity)

Subject matter data expertise in SaaS industry.

Why Join Us

We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. You'll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world-class one, right here in downtown Toronto.

Apply now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer that embraces the differences in all our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position.

Here at FreshBooks, we welcome and encourage applications from people with disabilities. Should you require any accommodations during the recruitment process, please advise your recruiter on how we can meet your needs to ensure a fair and equitable selection process in a confidential manner.

Job Type: Full-time","FreshBooks
4.0",Midtown Toronto
502,Data Science Instructor,"About the role::
Journey is looking for an experienced, energetic, data scientist with an interest in teaching. As a data science instructor you will be responsible for leading lectures on various topics, assigning course work, grading, and mentoring students on a 1-1 basis. You will work closely with other instructors and members of our education team, and follow along with our pre-built curriculum and teacher guide. You will work as an instructor for our Concordia Bootcamps program (a partnership between us and Concordia University) and have a direct impact on changing peoples lives through education.

This is a full-time contractual position which will last 14-weeks. Hours will be from 9:30am to 5:30pm (EST) Monday through Friday. This course will be taught remotely.

You can review the program and upcoming course dates here: https://concordiabootcamps.ca/courses/data-science-remote/ (https://concordiabootcamps.ca/courses/data-science-remote/)

Responsibilities::

Teach a class of beginners (in collaboration with 1-2 other instructors) with the goal of ensuring they graduate ready for junior level roles in Data Science
Act as coach/mentor to students as they work their way through the course
Care profoundly about every student's success
Present lectures on Math, Stats, Python, Pandas, SQL, Data Visualization, and more
Work with the Director of Education to learn and adjust to the pre-established curriculum and course content
Follow each student independently and ensure that they develop a mastery of the subject matter
Qualifications::

You have experience teaching (as a TA), coaching, managing or supporting junior staff or managing projects
You have a minimum of 2 years of professional experience in the field of Data Science
You are an outstanding presenter. You're easy to follow when you explain difficult concepts because of your ability to dissect and disseminate them into bite-sized, understandable ideas
You're energetic and have a strong ability to motivate others
Who you are::

You love the idea of helping people lead better lives through education
You're a lifelong learner, constantly learning new things in your field
You love to share your learnings and experiences with others
You don't let a bad minute ruin a good day
You're an active listener
You're empathetic
Salary and benefits::

This is a 14-week contractual position (40 hours per week)
Salary range from $10,000-$15,000 CAD for the duration of the contract - dependant on experience
Fully remote work
Work with an amazing and fun team
Possibility to extend your contract and teach more courses
About Journey Education:
Journey provides digital skills training with courses, workshops, and events all offered online. Our product lineup currently includes courses in Web Development and Data Science, with new products on the way. Founded in 2014 and headquartered in Montreal, Canada, Journey works with highly experienced instructors to develop cutting-edge, real-world training and meaningful educational products that help people unlock their potential.

At Journey, we are building an environment where our employees feel included and heard. Diversity and inclusion are important to us and we strongly encourage applications from minorities, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities.",Journey Education,Canada
503,"Azure Data Engineer (Certified DP-200 & Dp-201, DP-203)","Title- Azure Data Engineer

Location- Brampton, ON

Rate- $60/hr or $90K

Tech Mahindra

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Data bricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on nosql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Contract, Permanent

Salary: $80,078.00-$90,207.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Work from home

Schedule:

8 hour shift","Compest solutions Inc.
4.6",Brampton
504,FULLSTACK DEVELOPPER & DATA ENGINEER (bank of candidates),"Position Description:

We are looking for a savvy Data Engineer to join our growing Data Analytics and Business Intelligence local practice team.
In the role of Fullstack Developer, the ideal candidate will assume Front-End and/or Back-End analysis, design and development on all types of programming languages required by the client mandates to which he or she will be assigned.
The Date Engineer will be responsible for expanding and optimizing our client’s data and data pipeline architecture, as well as optimizing data flow and collection from a variety of sources for cross-functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
They ensure that data is ready for use in digital products, data science, reporting, and analytics. They will design and maintain data warehouses and data marts, and structure volumes of data.

They must be self-directed and comfortable supporting the data needs of multiple teams and systems

#WeareCGI

Your future duties and responsibilities:
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep data separated and secure across national boundaries through multiple data centers and cloud providers regions..
Improve data availability, acting as a liaison between source systems and Data Science and BI teams
Collect, blend, and transform data using ETL tools, database management systems, and code including SQL and Python
Perform aggregation on data across various warehousing models, such as OLAP cubes and star schemas for BI purposes
Provide training or coaching for junior members
Managing a team as a Lead Developer/ScrumMaster
Ensure the analysis, design, estimation, planning and Front-End and/or Backend development of cloud computing, Web, Ecommerce or Big Data applications (Java, Microservices, Angular, PHP, NodeJS, VueJS, React, .Net, C#, Androïd, Hybris Java, Python, HTML, CSS, Kafka, Azure, AWS, GCP etc.).
Required qualifications to be successful in this role:
2-5 years of experience in a Data Engineer role
5-6 years experience in a backend and/or front-end developer role
Computer Science, Statistics, Informatics, Information Systems degree or equivalent education and experience.
Advanced working SQL knowledge and experience working with relational databases.
Experience building and optimizing ‘big data’ data pipelines.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytics skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong proficiency in Python (especially data science packages like pandas, numpy etc) and SQL for analytics, database development, and data modelling
Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Should also have experience using the following software/tools:
o Experience with big data tools: Python, Hadoop, Spark, Kafka, etc.
o Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
o Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
o Experience with AWS, MS Azure, Google cloud services, DataBricks
o Experience with stream-processing systems: Storm, Spark-Streaming, etc.
o Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Fluency in French and English, oral and written
Strong understanding of Agile methodologies and experience on an agile team
Keen collaborator and clear communicator, responsive to service needs and operational demands
Passionate about the impact of emerging technologies and learning new skills and ideas

Optional:

Experience with ERP and CRM environments and data: SAP, SalesForce, PeopleSoft, MS Dynamics, etc.
What you can expect from us:

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer.","CGI Inc
3.8",Shawinigan
505,Data Analyst (Research),"ABOUT HRI

Homewood Research Institute (HRI) invites applicants for the position of Data Analyst (Permanent, Full-time).

HRI is an ambitious and growing national charity dedicated to research that transforms mental health and addiction services in Canada and around the world. Through strategic partnerships with Homewood Health and a vital growing network including some of the world’s most influential scientists, clinicians and researchers, we are uniquely positioned to innovate, test new discoveries, and accelerate the process that brings research into solutions for the real world. For more information, visit hriresearch.com.

POSITION OVERVIEW

The HRI Data Analyst works closely with Research Associates, Research Scientists, and Investigators to ensure accurate collection, organization, documentation, analysis and sharing of data. The Data Analyst is responsible for the statistical analysis required for knowledge translation and exchange activities and for peer-reviewed publications. The Data Analyst is an integral member of the research and evaluation team.

KEY RESPONSIBILITIES

1. Data Analysis and Planning

Plans and conducts relevant analyses for internal/external collaborators involving a range of statistical methods, including multivariate analyses, structural equation modeling with cross-sectional and longitudinal data using data from a rolling cohort
Applies methods of handling missing data, such as multiple imputations
Uses external data from a variety of sources (e.g. Statistics Canada, Resident Assessment Instrument-Mental Health), in combination with internal project data
Prioritizes and responds to ad hoc and routine data inquiries

2. Development and Maintenance of Datasets

Leads the development and maintenance of datasets including the creation of standard operating procedures for creating, organizing, storing, documenting, extracting/exporting, converting, merging and manipulating large and small data files
Ensures that data are accurate, consistent, properly maintained, and shared in compliance with relevant privacy protection, confidentiality, and other ethical principles
Uses SAS or R to process and prepare datasets for HRI investigators including merging multiple data sets (different sources), deriving project-specific variables in consultation with HRI investigators, and applying appropriate de-identification techniques tailored to each unique data request
Writes documentation reports to accompany the release of datasets, including relevant procedural notes and data codebooks

3. Knowledge Translation and Communication

Contributes to the writing of peer-reviewed scientific publications and technical reports
Provides data outputs and creates reports for stakeholders including visually intuitive graphs and depictions on complex study results
Presents findings at scientific meetings when appropriate
Communicates clearly with research team members, external stakeholders, and funders

4. Consultation and Training

Provides data analysis and data management consultation/ support to researchers, graduate students, post-doctoral fellows and to affiliated scientists as needed

POSITION REQUIREMENTS

Education

Master’s degree in quantitative research (i.e., biostatistics, health sciences, psychology)

Skills and Experience

Demonstrated ability to interact effectively and build rapport with a wide range of individuals
Strong organizational skills and initiative; work well independently
Proficiency in statistical analysis software such as SAS, R, Mplus, STATA, and/or SPSS; Advanced proficiency in Microsoft Excel
Ability to perform data management and formatting for standard statistical software
Strong verbal and written communication skills with statisticians and non-statisticians including technical report writing and writing for peer-reviewed scientific publications
Ability to work on multiple analytical projects concurrently with attention to detail
Initiative to acquire new skills and remain current with new developments as required
Commitment to HRI values of Anti-Oppression Equity and Inclusion and supports related organizational goals and research activities
Knowledge of mental health and addictions research would be an asset
English/French bilingual capacity would be considered an asset

Anti-Oppression, Diversity and Inclusion Focus

At HRI, we strive to foster Anti-Oppression, Equity, and Inclusion (AOEI), because we believe living these values is the most powerful platform for social change. We believe that people and organizations thrive when we embrace the richness of the human experience and invite all voices to contribute to a shared goal.

We are passionate about our vision: “No life held back or cut short by mental illness or addiction.” This vision encompasses everyone, including (but not limited to) First Nations, Métis, and Inuit, people with disabilities, people of all cultural, religious, racial, and ethnic backgrounds, people of all income and education levels, people of all ages, non-binary and gender-nonconforming people, women, and two-spirit, lesbian, gay, bisexual, trans, queer, questioning, intersex, and asexual (2SLGBTQQIA) people.

As a research organization, we are working continuously to move AOEI values into action through our organizational culture, policies, and research activities.

JOB LOCATION

This position offers remote work arrangements due to the ongoing pandemic, however regular in-person meetings and events will be required when work returns to normal.

HOW TO APPLY

Please submit a resume and cover letter and inform us if you require accommodations during the interview process. We thank all applicants for their interest, however, only those selected to interview will be contacted.

Reference ID: HRI - 2021-03

Application deadline: 2021-06-25

Job Types: Full-time, Permanent

Pay: $29.88-$38.15 per hour

Benefits:

Dental care
Disability insurance
Employee assistance program
Extended health care
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Education:

Master's Degree (preferred)

Work remotely:

Temporarily due to COVID-19",Homewood Research Institute,Guelph
506,Data Engineer (Ingestion),"Data Engineer - Ingestion


Location: Toronto


Are you ready to step up and take your technology expertise to the next level?


There is never a typical day at Accenture, but that’s why we love it here! This is an extraordinary chance to begin a rewarding career at Accenture Technology. Immersed in a digitally-compassionate and innovation-led environment, here is where you can help top clients shift to the NEW using leading-edge technologies on the most ground-breaking projects imaginable. Immerse yourself in a supportive ecosystem that values your individuality and encourages you to innovate, ideate and disrupt. We recognize that it's the diversity of our people that makes us stronger, smarter and more effective as a team.


We are Accenture Cloud First


Accenture is a leader in cloud transformations working with AWS, Azure, Google, and private clouds. The formation of Accenture Cloud First, with a $3 billion investment over three years, demonstrates our commitment to deliver greater value to our clients when they need it most. Our Cloud First multi-service group of more than 70,000 cloud professionals delivers a full stack of integrated cloud capabilities across data, edge, integrated infrastructure and applications, deep ecosystem skills, culture of change along with a deep industry expertise to shape, move, build and operate our clients’ businesses in the cloud. To accelerate our clients’ transformation leveraging cloud, we combine world-class learning and talent development expertise; deep experience in cloud change management; and cloud-ready operating models with a commitment to responsible business by design — with security, data privacy, responsible use of artificial intelligence, sustainability and ethics and compliance built into the fundamental changes Accenture helps companies achieve. Our services cover the full spectrum of client needs, from strategy to service management, device-to-cloud networks, workplace solutions, and more.

Today, more than ever, companies need to operate and compete at an unprecedented speed and scale as industries are reshaping beneath them. This means innovating faster, creating new revenue streams, deriving more insights from data - and from the edge - and interacting differently with their customers, partners, and employees. Choose Accenture and make delivering this kind of innovative work part of your extraordinary career.


The Work


Accenture’s Cloud First Infrastructure Engineering professionals’ partner with our clients to advise, create, and deploy end-to-end infrastructure transformation solutions, enabling business innovation. These solutions are the backbone of driving IT-enabled differentiation. IE professionals are grounded in New-IT with an expertise in one or more of our core practice areas: Digital Workplace, Network Technology, Service Management, Hybrid Cloud, Public Cloud, and traditional Data Center.


Key Responsibilities:


Application Design, Development and Support for Azure Data and AI Data analytics Platform
Involved in designing and developing new solutions
Lead the effort to design, build and configure applications, acting as the primary point of contact.
Lead team for Azure Databricks, Azure Data Lake, ADB, PySpark and Synapse
Responsible for Application Support and lead the role with offshore & on-shore teams
Co-ordinate with the client resolving issues, implementing enhancement, and troubleshooting issues to come up with recommendations for the client



Who are we looking for?

3 year of experience in the following:

Azure Data Factory
PySpark
Azure SQL
Azure Data Lake

Preferred Skills:

Certification: Azure Data Certification

Python","Accenture
4.1",Mississauga
507,Senior Data Engineer,"Senior Data Engineer
My client, the largest e-commerce investor, was founded by founders for founders. They invested $2B+ in over 4k business. Looking for a Data Engineer talent to join their smart team to build the data-driven app for early-stage founders.

Contact me for details about this exciting opp!!!

100% Remote if you want; but NO NO NO outside-the-country applicants, thank you.
Responsibilities:
You will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development
Working closely with every member of the team, vendors and external partners, you will produce significant components of the code
Collaborate with all functions, ranging from core Engineering team to Data Science team to the marketing team
You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary
You will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself.
You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs
Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

What we look for:
Great communication skills, with a desire or experience to lead a small team of other devs in the near future
Desire to help founders. We take a strong founder first stance on this team
Be self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission
On this team, we maximize learning. You will fail if you're not learning fast enough
Comfort working in a high growth, constantly changing environment
Heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support
Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!
Have a strong business sense, you can foresee potential issues and solve them quickly
Demonstrated ability to collaborate effectively across multiple teams
Strong interest in building businesses, ecommerce and fintech

Technical Requirements:
Ideally, you have worked on 3 or more different stacks in your career in a professional setting. Bonus points for systems managing time-series
Able to architect and scale data integrations (shopify, paypal, plaid, etc.) from third-party API docs independently, extracting the right business value for the vision and roadmap
Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes
Comfortable working in server and database environments that are changing constantly
Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff
Comfortable with relational databases and schemas involving time-series
Skills and interest in Python, SQL, Snowflake, Kubernetes and pipeline management/orchestration tools (Eg. Airflow)
TOR123","Vaco
3.7",Midtown Toronto
508,Ingénieur·e de données /Data Engineer,"Qui sommes-nous :

BusPatrouille est une entreprise spécialisée dans la technologie de sécurité. À titre de principal fournisseur international de dispositifs visant à faire respecter le bras d’arrêt des autobus scolaires, notre mission principale est d’améliorer la vie des élèves où qu’ils se trouvent.

La technologie de BusPatrouille a été déployée sur un plus grand nombre d’autobus et a été utilisée pour délivrer un plus grand nombre de contraventions relatives au bras d’arrêt des autobus scolaires que toute autre technologie des autres entreprises existantes à l’échelle mondiale. Notre technologie exclusive transforme les autobus scolaires en autobus intelligents équipés de caméras vidéo, de GPS, de télémétrie, de traitement de données et d’archivage. De cette manière, nous permettons aux comtés et aux districts scolaires d’améliorer la sécurité des enfants.

BusPatrouille est en pleine croissance. Nous sommes donc à la recherche d’un.e ingénieur.e de données d’expérience pour intégrer notre équipe de veille stratégique (BI). Si vous aimez travailler dans un environnement dynamique avec des collègues talentueux, ce poste est pour vous.

Responsabilités :

Le rôle de l’ingénieur.e de données est essentiel pour construire des données évolutives et des modèles analytiques, ainsi qu’une architecture allant de la formation à l’ingestion d’événements, puis à la production de rapports, en partant du début. Vous évaluerez et soutiendrez la mise en œuvre de systèmes robustes utilisés par chaque équipe et client de BusPatrouille. La personne idéale possède de solides connaissances en gestion des données, en développement ETL (extraire, transformer, charger), en codage et en infonuagique. Elle aime travailler avec une diversité d’outils, de langages, de systèmes et d’architectures tout en s’assurant que les systèmes de données et la stratégie respectent les meilleures pratiques en matière d’évolutivité.

Rédiger des tâches ETL (extraire, transformer, charger) et ELT (extraire, charger, transformer) à l’aide de divers outils et langages de programmation.
Créer des pipelines de données dans des environnements AWS avec AWS glue.
Écrire des requêtes SQL complexes et optimiser leur vitesse et leur précision.
Concevoir, développer, tester, corriger et déployer des pipelines de données en soutien aux produits de base, aux déploiements auprès des clients et aux rapports de performance.
Écrire des scripts pour planifier l’ingestion et la synchronisation des données.
Développer des minientrepôt de données (data marts) à partir des besoins de l’entreprise pour permettre aux parties prenantes de l’entreprise d’être autonomes.
Créer et tenir à jour une documentation claire.
Travailler avec des collègues ingénieur.e.s, des chefs de projet et des utilisateurs.
Suivre les processus et les procédures de l’entreprise, en particulier les pratiques relatives à la sécurité de l’information.

Connaissances et compétences requises :

Un baccalauréat ou un diplôme supérieur en technologie, dans un domaine quantitatif ou dans un autre domaine connexe (par exemple, informatique, statistiques, génie électrique).
Plus de cinq ans d’expérience en ingénierie des données, ingénierie des bases de données ou analyse commerciale.
Plus de cinq ans d’expérience avec SQL (MySQL, PostgreSQL, Redshift).
Plus de quatre ans d’expérience avec les principaux langages de script tels que Python.
Plus de trois ans d’expérience dans la conception de schémas, la modélisation de données dimensionnelles, la conception d’API et le développement de services Web RESTful.
Une expérience de la visualisation de données (par exemple avec Tableau) est un atout.
Une curiosité intellectuelle, une volonté constante d’apprendre, un esprit d’initiative.
De solides compétences en communication écrite et verbale.
Un esprit d’équipe.

Rémunération et avantages :

Un salaire concurrentiel.
Des avantages sociaux complets, notamment une assurance soins médicaux, soins dentaires et soins de la vue.
Un poste indispensable au sein d’une entreprise qui se développe rapidement et qui est investie d’une mission.
L’occasion de travailler avec une équipe très performante.
L’occasion de contribuer à la création d’une entreprise vouée à la sécurité des enfants.

Nous sommes à la recherche de membres essentiels de l’équipe de BusPatrouille qui nous aideront dans notre quête pour accroître la sécurité des enfants. Ce poste joue un rôle important dans notre entreprise et constitue une formidable opportunité pour les personnes qui seront retenues. Nous offrons un milieu de travail inclusif, diversifié, enthousiaste, intègre et profondément engagé. Venez nous aider à assurer la sécurité des enfants.

=========================================================================

Who We Are:

Our mission is to create a culture of responsibility and awareness on the road. We are devoted to making the journey to and from school safer. We develop partnerships, deploy safety tech and manage the entire program. We have equipped thousands of busses across North America with our innovative technology and we continue to educate tens of thousands of drivers a month on safety. BusPatrol America cares about student safety. We educate motorists every day by helping enforce the law and work with school officials to improve safety.

The Role:

The Data Engineer at BusPatrol will build scalable data and analytics models and architecture from event formation to ingestion to reporting, from scratch. You will evaluate and lead the implementation of robust systems used by every team within BusPatrol. You will shape the vision and architecture of end-to-end pipeline while following industry best practices. The right candidate will have strong data architecture, ETL, SQL, and a proven track record working with enterprise metrics to build automated data pipelines. The candidate will also have strong operational skills to drive efficiency and speed, expertise in building repeatable data engineering processes, strong project management skills, and a vision for how to deliver data products.

Responsibilities:

Create data pipelines in state-of-the-art AWS environment EC2, S3, Lambda, etc. with AWS Glue.
Manage all aspects of the data and analytics system from stream configuration to ETL to aggregate tables and cubes for reporting needs.
Identify, design, and implement internal data pipeline jobs / processes improvements using machine learning (and other modern techniques): automating manual processes, optimizing data delivery, re-designing infrastructure for scalability, etc.
Write scripts to schedule data ingestion and syncing. Evaluate, lead and form backend logic to create data marts from requirements for the purposes of self-serving stakeholders.
Assist data architects to build the working framework for data search and retrieval.
Troubleshoot data jobs / processes in production to fix data quality bugs or pipeline performance issues.
Build and assemble large, complex data sets with multi-dimensional relationships that meet both functional and non-functional requirements from business stakeholders.
Build Appropriate ML data models and data schemas for business use cases.

Requirements:

Bachelor's degree or higher in a quantitative/technical field (e.g., Computer Science, Statistics, Engineering)
5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics
5+ years of SQL knowledge for various reporting and transformation needs (MySQL, PostgreSQL, Redshift)
4+ years of experience in core languages such as Python
3+ years of experience with schema design and dimensional data modeling
Experience with Data Lake architectures, and with combining structured and unstructured data into unified representations.
Experience with API design and development of RESTful web services
Hands on experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.
Analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions.
Data visualization experience with tools like Tableau a plus
Must be an intellectually curious self-starter and motivated to continually learn.

What we will offer you

The opportunity to join a mission-driven company, dedicated to developing and deploying safety technology in support of children’s safety
The opportunity to build an IT infrastructure group in support of our mission
Dedicated, accessible and committed colleagues and leadership team
The chance to join an innovative and dedicated team, focused on leading edge technology
Competitive salary and benefits package

We’re looking for critical members of the BusPatrol team to assist us in our quest to improve children’s safety. This is an important role for us and a great opportunity for the right candidates. Our environment is inclusive, diverse, ignited, built on integrity and deeply committed. Come and help us keep our children safe.

Type d'emploi : Temps Plein","BusPatrol
3.8",Montreal
509,Data Engineer (contract),"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:

Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done

Here's what you'll be doing:

Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery

Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI

Why Join Us?

You can see the code getting to production faster than you used to; you will try your Big Data skills, where precise and robust code really matters; you will work with the 3.5 Billion-record tables; you will learn how difference between European and Australian privacy laws can affect your design decisions.

Bond Brand Loyalty is proud to be recognized as one of Canada’s Best Managed Companies.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

Bond Brand Loyalty welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Bond Brand Loyalty Inc
3.5",Mississauga
510,"Senior Actuarial Analyst, Actuarial Consultant or Data Scientist (level 2-3)","From coast-to-coast, our inspiring colleagues are at the heart of what we do best: helping people, businesses and society prosper in good times and be resilient in bad times. With our team, you’ll bring this purpose to life every day by living our Values, being open to change, and pursuing your goals.

At Intact, we’ll give you countless opportunities to learn and grow, alongside a diverse and passionate community of experts – the best the industry has to offer. You’ll be empowered to be your best self, do your best work, and make a meaningful impact. Here, you can: shape the future of insurance, win as a team, and grow with us.







About the role






Attention to all analytical superstars who are ready to take on a new challenge! We are looking for several actuaries or data scientists to join our brand new team within the Data Lab. Its mandate is to support the profitability and growth objectives of a whole new market for IFC: the United Kingdom.

We need you and your expertise to find solutions to complex problems that only critical minds can solve. We do everything we can to create an inspiring work environment that offers great opportunities to develop your skills, pursue a rewarding career and bring your innovative ideas to life.

Hiring manager: Catherine Tremblay

Your mission:

From Canada, you will work closely with our UK personal lines pricing team. You'll be called upon to:

Play a key role in the collaboration between the two countries and the knowledge transfer between the Canadian and English markets.
Support the various pricing teams already in place in the UK in their ongoing initiatives to improve pricing sophistication.
Identify opportunities for involvement in order to implement the best pricing strategy in a changing market environment.
Integrate a new team with high visibility and which will offer a range of varied and stimulating challenges.

What does the collaboration with the United Kingdom consist of?

Since June 1, 2021, ICF has an insurance product distribution network outside of North America. With the largest market being the UK, it is with the aim of creating a close relationship with Canada that we are setting up the UK&I team within the Data Lab. The team has a broad mandate and you will be involved in contributing and supporting a variety of UK personal lines pricing projects. In this role, team members should have an openness to travel to the UK if the need arises.

The market context is currently in a period of change with a major legislative reform that will change the face of insurance in the country starting January 2022. Canadian knowledge and experience will be a great asset to help put in place the best strategy for this new reality.






Qualifications






Your qualities:

You are autonomous and resourceful.
You understand the needs and are able to translate a business problem into a concrete solution within a set time frame.
You have great communication skills and you know how to adapt to many different audiences.
You are a driver of change and you strive for excellence.
You are comfortable working in complex and constantly changing environments.
You are always ready to help your colleagues and put team success at the forefront.
You demonstrate leadership, have influence capabilities and networking skills.

Your qualifications:

Bachelor's degree in actuarial science or post-secondary training in data science (or related field).
At least 2 years of experience as an actuary or data scientist.
Knowledge of pricing and portfolio optimization concepts and related practical experience.
Ability to focus on loosely defined issues requiring a creative and effective approach.
Understanding of machine learning and artificial intelligence (an asset).
Knowledge of Earnix, Emblem and Radar software (an asset).
FCAS (an asset).
Personal lines insurance experience in a regulated environment (an asset).

Here are a few reasons why others have joined our team:

An award-winning, inspiring workplace that supports its people and recognizes great work
Stimulating, challenging projects and development opportunities to help you grow your skills and career
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A $350 annual wellness account that promotes an active lifestyle





Closing Statement






We are an Equal Opportunity Employer

At Intact, our value of Respect is founded on seeing diversity as a strength, being inclusive and fostering collaboration. We value diversity and strive to create an inclusive, accessible workplace where all individuals feel valued, respected and heard.

If we can provide a specific adjustment to make the recruitment process more accessible for you, please advise the Talent Acquisition partner who reaches out about the job opportunity and they will work with you to meet your needs.

Background Checks

As an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. We want Intact to be a great place to work! This means that internal and external candidates will be asked to consent to background checks so we can learn more about you. Please note that for positions with access to financial data or funds, your credit must be in good standing.

Internal Candidates

For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility to Work in Canada

It’s important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.






LinkedIn Sponsored






#LI-QuebecIT","Intact
4.4",Montreal
511,Intermediate Project Scientist / Intermediate Project Technician,"Intermediate Project Scientist / Intermediate Project Technician

Why join us?

This position is based out of our Environment & Geoscience (E&G) office in Fort St. and reports to a Project Manager. You will be responsible for supporting our local environment team on a variety of projects in the site assessment and remediation and environmental monitoring sectors. As a result of growth and internal opportunities, SNC-Lavalin is seeking an experienced and career oriented Intermediate Project Scientist / Intermediate Project Technician with technical and project management capabilities.

E&G offers consulting services in the following areas: land reclamation, environmental studies, environmental impact assessments and social impact assessments, habitat assessments and compensation, aquatic life assessments, air quality assessments and greenhouse gas emissions, carbon credits, sustainability, environmental management and planning, geographic information systems, contaminated sites, waste management, mining, water distribution and treatment, pollution control and rural development.

Our offices are located in attractive regions of BC, with quick access to arts & culture and a variety of outdoor activities including mountain biking, skiing, hiking, hunting, and water sports. SNC-Lavalin offers a flexible work schedule and a relaxed office environment.

How will you contribute to the team?

Setting and maintaining project schedules, health and safety plans and program budgets; making decisions with respect to overall technical execution of the project; liaising with technical specialists, field personnel or other project managers to ensure the technical integrity of the project.
Provide management and technical expertise for contaminated site investigation and remediation programs.
Interpret findings and preparation and/or review of technical reports.
Supervision or mentorship of junior professional staff involved in carrying out field programs, ensuring project requirements are communicated and health and safety protocols are adhered to.
Responsible for conducting or participating in yearly performance evaluations of assigned staff.
Actively promote Health and Safety programs and culture.
Active in business development activities and maintaining client relationships.
Participate in the preparation of proposals and cost estimates.
Work as a team in all areas of the Environment and in other regions as opportunities arise.
Reviewing and ensuring billing memos/invoices are accurate and issued monthly
Participate in short and long range planning within assigned clients group or offices.

What will you contribute?

Diploma, bachelor’s or advanced degree in Engineering, Sciences or Environmental with eligibility for professional designation (e.g., P.Eng., P.Geol., P. Ag, etc.).
Intermediate Positions: Minimum of 8 years of progressive experience encompassing project coordination and/or management, staff training and supervision, and contractor supervision with emphasis in the areas of contaminated site investigation and remediation.
Experience should include preparation and review of Phase I ESAs, Phase II ESAs including design and execution of soil, groundwater and vapour phase investigation programs, interpretation of hydrogeological and geochemical data, monitoring studies, Phase III remedial plan design and implementation and execution, report writing and review, and interpretation of provincial and federal environmental regulations.
Experience should demonstrate leadership and managerial experience as well as a commitment to excellent health & safety practices.
Demonstrate excellent verbal and written communication skills, proven technical report writing skills, and an ability to multi-task as well as being organized and detail oriented.
Valid Class 5 BC driver's license.","SNC-Lavalin
3.6",Fort St. John
512,Data Engineer - Big Data - $70.00 p/h REMOTE Contract,"Role: Data Engineer - Big Data Projects
Structure: Contract - 6+ months
Location: Toronto, ON (remote during COVID)
Pay: $70.00 p/h inc.
Hours: Monday - Friday (business hours)

We currently have an opportunity for a Data Engineer working on Big Data projects contract working in Banking environments.

The required skills for this role will be:

6 years in Data Engineering or Analysis
Good experience with SQL and NoSQL databases
General ETL experience
Previous experience with 1 project on Public Cloud either Azure or AWS or GCP
Good communication skills

-

Please apply with an updated resume and ensure the required skills you are able to speak to for this position are included.

For more roles like this please go to www.corgta.com/find-a-job/

Job Types: Full-time, Permanent

Salary: $65.00-$70.00 per hour

Schedule:

8 hour shift

Work remotely:

Temporarily due to COVID-19","CorGTA Inc.
5.0",Midtown Toronto
513,Data Science II,"The OneDrive and SharePoint Data Science team's charter is to foster a data-driven culture to encourage and enable the entire organization to make more informed decisions through data. Our data and analytics team works closely with engineering, marketing, finance, and business leaders to identify opportunities for improving the customer experience and accelerate our business's growth in support of this mission. We analyze historical data to understand salient trends, deliver standardized views of business performance, develop models to predict performance, recommend actions to be taken, and run experiments to prove that desired outcomes are being achieved.

We are looking for a Data Scientist to join a new team focused on unlocking value for Microsoft customers by understanding product usage patterns across the entirety of Microsoft 365 (Viva Connections, Cortex, Syntex, OneDrive, Lists, SharePoint, and beyond). This is a unique opportunity to bring your knowledge of Consumer and Commercial offerings, as well as your deep understanding of data science methods and best practices, to help Microsoft deliver the best experience possible for our customers and partners. You will be joining a group of experts on the front lines of synthesizing vast customer purchase and engagement behavior data sets into targeted recommendations for addressing real-world business challenges at scale.

We arelooking for you to bring a fresh perspective andyour unique voice to our team.

About Our Culture
We are a modern product and services organization, one of the largest business & consumer services on the planet, and the second biggest workload in Office 365. Data scientists on this team will be part of the broader data science team, and specific product teams focused on tangible and immediate business impact. We have a tremendous responsibility to our customers to help transform their content needs with Microsoft 365. We use data to organize our business priorities. We empower our industry-leading data science, design, and user research teams to own our product's user experience. We take a direct role in framing our business value directly to our customers and vibrant community of fans.
Responsibilities
Work cross functionally to translate business problems into ones that can be solved and informed by data analysis
Have curiosity and apply analytical skills to dive deep into data to find key insights that impact the business.
Develop models of usage, user behavior & business behavior to make recommendations and influence the product road map.
Work with other teams across Microsoft to develop key metrics to achieve business outcomes.
Be a champion of AB testing. Design, execute and analyze experiments to prove product change attribution.
Utilize tools like Data Bricks, R, Python, SQL to execute analyses
Qualifications
One plus year exhibiting a strong passion & understanding for the need to deliver the right business impact by working with stakeholders to turn business problems into data analysis questions and unearthing deep insights from data.
Have a track record of innovative thinking and problem-solving skills using Big Data.
Be self-driven and show the ability to deliver on ambiguous projects with incomplete data.
Understanding of the practical uses of statistics (i.e. experimentation, sampling)
Professional experience with large-scale computing systems like Hadoop, MapReduce, and/or similar systems.
Strong skills in SQL, R, Python, Databricks, or related tools for large-scale analysis.
Excellent communications & interpersonal skills. Ability to convince other strong personalities of their ideas and communicate complex analysis & insights to a non-technical audience.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
514,Data Engineer,"StackAdapt is the no. 1 performing programmatic advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in performance by G2 Crowd for the fourth time, we're one of the fastest-growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add Data Engineers to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Engineering team, and CTO on building pipelines and ad optimization models. With databases that process millions of requests per second, there's no shortage of data and problems to tackle.

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
What you'll be doing:
Design modular and scalable data pipelines to handle huge datasets
Understand and implement custom ML algorithms
Work on a micro-service architecture that simultaneously implements and monitors thousands of ML models concurrently
We'll be reaching out to candidates that have:
A high GPA from a well-respected Computer Science program
Have confidence in algorithm design and concurrency
Preferably have at least 1 year of job experience (internships count)
Interest in designing distributed scalable systems
Implementation of probabilistic and machine learning algorithms
Algorithms design ability
StackAdapters enjoy:
Highly competitive salary with RRSP matching
3 weeks vacation + 3 personal care days + 1 volunteer day + birthdays off
Full benefits from League on day one of employment
Work from home reimbursements
Coverage and support of personal development initiatives (conferences, courses, etc)
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
A friendly, welcoming, and supportive culture
Our social and team events (virtually!)
About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by the most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory, and publisher partners. StackAdapt is a Top 100 Software Product on G2, being the only DSP on the Best Software Products and Highest Satisfaction lists.

We've been recognized for our high performing campaign conversion rates, award-winning customer service, and innovation by numerous industry publications including:

Great Place to Work® named StackAdapt as one of Canada’s Best Workplaces for Start-ups in 2021
A leader in the DSP, Video and Cross-Channel Advertising Categories on G2
A Top Growing Company in Canada based on the Globe and Mail's 2020 Business Report
Named 23rd in Deloitte Canada’s Technology Fast 50™ program
Named in Deloitte Technology's Fast 500 in North America

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.","StackAdapt
4.3",Midtown Toronto
515,Senior Data System Analyst - Big Data,"At CN, we work together to move our company—and North America—forward. Be part of our Information & Technology (I&T) team, a critical piece of the engine that keeps us in motion. From enterprise architecture to operational technology, our teams use the agile methodology to automate and digitize our railroad ensuring our operations run optimally and safely and our employees can focus on value-added tasks. You will be able to develop your skills and career in our close-knit, safety-focused culture working together as ONE TEAM. The careers we offer are meaningful because the work we do matters. Join us!

Job Summary

The role of the data designer is to work with leading-edge technologies such as sensors and control electronics, sophisticated planning and decision support systems, big data infrastructures, advanced analytics, deep learning. This role is responsible for delivering of data services in support data goverance, engineering and machine learning practices. The role requires a deep understanding of the data analysis techniques and data model design. The data designer brings technical expertise to ensure the quality and accuracy of that data, then process, design and present it in ways to help people, businesses, and organizations make better decisions. The role ensures data integrity and normalization, and provides designs to support the development of data pipelines. The roles requires an individual that is able to develop a specification to support the data pipelines for both batch and real time data streaming.

Main Responsibilities

Definition & Delivery of data assets

Design, develop data assets to be consumable from a data lake, and data warehouse, to support operational reporting, data science and self serve analytics
Data design must be ensure the integrity of all data accuracy
Participate in (and eventually proposing) simplification initiatives to allow for more effective data management to change the conversation from tactical to strategic which is insight and action orientated focused
Obtains the requirements from the business using user stories, for the data pipelines design that will enable faster, better, data-informed decision-making within the business
Leads innovation through exploration, benchmarking, making recommendations, and implementing data technologies and data design models
Analyzing proposed application/system changes and making recommendations for approval
Identify sources systems, develops knowledge of business context, becomes SME of data source, works with data engineers/scientists to provide expertize on the data sources being analyzed
Performs ad-hoc analyses of data stored in the business’s databases/data warehouse and writes SQL scripts, to analyze data
Troubleshoots data issues within the business and across the business and presents solutions to these issues
Must be able to test and apply test processes for data management practice.

Illustrate and Support a Variety of Optimized Analytics Delivery Capabilities

Working Conditions

This role may require occasional business travel in accordance with CN policy for meetings

Requirements

General Experience

Minimum 7-10 years overall work experience
Between 5 and 7 years of experience in support the development of data warehouse, and data lakes
Must have experience in building data models, for data warehouse and data lake storage
Ideal if the person has design experience in supporting real time streaming, modeling for non sql database
Has developed requirements into user stories, worked with developers for grooming the requirements
Has provided conceptual, logical and physical data models
Has capture business transformation rules
Must be able to do data wrangling, cleans the data, develop insights from data assets\
Expert ability to identify data requirements, gaps and assess end-to-end data requirements
Excellent Communication skills to build alliances and gain consensus with key stakeholders to promote Test Data Management best practices

Education/Certification/Designation

Bachelor’s degree specializing in Mathematics and Statistics / Computer Science / Business Analytics / or other quantitative field, related degree or equivalent experience

Technical Skills/Knowledge

Has worked in a Data Warehouse or Data lake organization
Experience in Data Design, Data Analytics or Data Science
Exposure to Data modeling experience, and data architecture best practices
Experience with relational database modeling techniques
Experience with dimensional modeling techniquesExperience with coding, using Data Bricks, spark streaming, Python, Data Factory, SnowFlake
Expert in SQL development further providing support to the database design, data flow and analysis activities
Advising staff and users on database design practices
Nice to have experience with unstructured data, withe background with using data from of social media, video feeds or audio.
Excellent verbal and written communication skills and the ability to interact professionally with a diverse group
Experience in doing design for real time data streaming and loading
Data profiling, data extraction and breaking down data to a domain driven model
Strong test strategies, using advance SQL skills to support the performance tuning of the extraction process,
Ability to create strategies for loading, purging and retaining data

Assets

Tools used ideally Kafka, spark, mulesoft, postgress, graphql, Snowflake, Databricks and spark
Experience working across both business and technology (5+ yrs.)
Written presentation experience; presenting insights in plain language and images (5+ yrs.)
Experience in understanding complex businesses questions and framing the right analytical question to solve a business problem (5+ yrs.)
Excellent verbal and written communication skills and the ability to interact professionally with a diverse group
The ability to learn quickly, problem solve/troubleshoot, work independently and in a team
Exposure to principles of change management, and scrum agile
Experience in leading and participating in business workshops
Ability to promote business intelligence, analytics, and reporting vision
Exposure to delivering commercially beneficial insights and analytics strategies
Exposure to hands-on support to orientate analytics around delivering value back to the business
Willingness to work on multiple projects at one time
Exposure to building analytical and quantitative analysis models (5+ yrs.)

About CN

As a leading North American transportation and logistics company, CN is a true backbone of the economy. With a team of approximately 25,000 railroaders, our focus is on moving both our company and the economy forward. We transport US$200 billion worth of goods annually for a wide range of business sectors from resource to manufactured products to consumer goods, across a 20,000-mile network spanning Canada and mid-America. CN is the only Canadian company listed in the Transportation and Transportation Infrastructure sector of the Dow Jones Sustainability World Index (DJSI). Launched in 1999, the DJSI World represents the gold standard for corporate sustainability. At CN, we work as ONE TEAM, focused on safety, sustainability and our customers, providing operational and supply chain excellence to deliver results.


CN is an employment equity employer and we encourage all qualified candidates to apply. We thank all applicants for their interest, however, only candidates under consideration will be contacted. Please monitor your email on a regular basis, as communication is primarily made through email.","Canadian National Railway
3.3",Edmonton
516,Bio informaticien/Bioinformatics scientist,"Avant le SRAS-CoV-2, un vaccin qui était développé rapidement prenait environ 4 ans. En comparaison, les vaccins contre le SRAS-CoV-2 ont été développés en moins de 12 mois. Imaginez un monde où chaque vaccin serait développé à la vitesse des vaccins contre le SRAS-CoV-2... Aidez GenAIz à faire de ce rêve une réalité. Rejoignez-nous maintenant !




GenAIz, une division d'Uni3T, est une entreprise jeune et dynamique de développement de logiciels, active dans l'industrie pharmaceutique et des sciences de la vie. Notre mission est d'accroître le bien-être collectif en accélérant la création de meilleurs produits, processus et traitements grâce à un assistant à l'innovateur à la pointe de la technologie.


Nous recherchons actuellement un bio informaticien qui apportera automatisation et innovation aux processus bio-informatiques pour les clients. Il s'agira de mettre en œuvre des techniques analytiques standard (par exemple, l'analyse des voies) et d'améliorer les techniques existantes. En tant que bio informaticien de GENAIZ, vous devez aimer documenter votre travail et vos recherches, partager ces connaissances et écrire un excellent code, tout en suivant les processus de développement agiles typiques.


Le générique masculin est utilisé sans discrimination et uniquement dans le but d'alléger le texte.


Responsabilités :



Traduire les besoins bio-informatiques des clients en solutions innovantes et robustes prêtes pour la production, avec l'aide d'une équipe.
Créer des connaissances et des technologies en s'appropriant des projets bio-informatiques.
Agir de manière indépendante, en effectuant votre travail sans supervision importante.
Communiquer et documenter les solutions bio-informatiques pour des publics techniques et non techniques.
Communiquer et documenter la recherche pour des publics techniques et non techniques.
Rapporter et présenter des solutions (par exemple, recherche, bio-informatique) de manière claire et efficace à ses collègues et à la direction.
Être un joueur d'équipe en participant à la révision par les collègues, en partageant des idées et en aidant tout le monde à réussir.



Qualifications :



Une maîtrise ou un doctorat en bio-informatique, en informatique médicale, en informatique ou dans un domaine lié.
5+ ans d'expérience dans l'industrie sur des projets bio-informatiques multidisciplinaires.
Expérience dans la réalisation de recherches, l'analyse et la communication des résultats.
Quelque expérience en matière d'exigences opérationnelles.
Efficacité prouvée à travailler avec des données biomédicales (biologie moléculaire).
Capable d'écrire du code propre, réutilisable et prêt pour la production sur Python, R et Bioconductor.
Connaissance des statistiques et des structures de données computationnelles telles que les graphes.
Excellente communication écrite, verbale et interpersonnelle.
Une expertise dans l'analyse des réseaux et des voies de communication et dans des analyses similaires.
Connaissance des données STRING, REACTOME, KEGG et similaires.



Qualifications préférées :



Expérience avec MongoDB, git, GCP, Docker, AWS, K8s et les micro-services.
Expérience en protéomique et génomiques computationnelles.



Avantages :



Poste permanent à temps plein
Salaire de base compétitif + prime
Couverture d'assurance complète
Culture d'entreprise dynamique avec des possibilités de développement de carrière
Horaires de travail flexibles
Situé entre Griffintown et le Vieux-Montréal, dans le quartier de la Cité du Multimédia, qui fait maintenant partie du pôle holistique de Montréal pour l'innovation, l'éducation et l'entrepreneuriat : le Quartier de l'Innovation.



GenAIz est un employeur offrant l'égalité des chances. Tous les candidats seront considérés pour un emploi sans égard à l'âge, à la couleur, aux congés pour soins familiaux ou médicaux, à l'identité ou à l'expression sexuelle, à l'état civil, à la condition médicale, à l'origine nationale, à un handicap physique ou mental, à l'affiliation politique, à la race, à la religion, au sexe (y compris la grossesse), à l'orientation sexuelle ou à toute autre caractéristique protégée par les lois, règlements et ordinogrammes applicables.


Nous vous remercions de votre intérêt. Seuls les candidats qualifiés seront contactés.


-


Until SARS-CoV-2, the fastest vaccine ever developed took about 4 years. SARS-CoV-2 vaccines were developed in less than 12 months. Imagine a world where every vaccine was developed at the speed of SARS-CoV-2 vaccines. Help GenAIz make this a reality. Join us!


GenAIz, a division of Uni3T, is a young and dynamic software development company that is active in the life science and pharmaceutical industry. Our mission is to increase collective well-being by accelerating the creation of better products, processes and treatments, through a state-of-the-art innovator’s assistant.


We are currently looking for a bioinformatics scientist that will bring automation and innovation to bioinformatics processes for clients. This will involve implementing standard analytic techniques (e.g., pathway analysis) and improving on existing techniques. As a GENAIZ bioinformatics scientist, you must enjoy documenting your work and research, sharing this knowledge and writing excellent code, while following typical agile development processes.




Responsibilities:



Translate client bioinformatics needs into innovative robust production ready solutions, with the help of a team.
Create knowledge and technology by owning bioinformatics projects
Act independently, completing your work without significant supervision
Communicate and document bioinformatics solutions for technical and non-technical audiences.
Communicate and document research for technical and non-technical audiences.
Report and present solutions (e.g., research, bioinformatics) clearly and effectively to peers and management
Be a team player by participating in peer review, sharing ideas and helping everyone succeed



Qualifications:



A master's or PhD degree in Bioinformatics, Medical Informatics, Computer Science or related field
5+ years of industry experience on multidisciplinary bioinformatics projects
Experience completing research, analyzing and communicating results
Some working knowledge of business requirements
Experience working with biomedical data (molecular biology)
Able to write clean, re-usable, and production-ready code on Python, R and Bioconductor
Knowledge of statistics and computational data structures such as graphs

Proven capabilities of network and pathway analysis and similar analyses
Experience with STRING, REACTOME, KEGG and similar data
Excellent written, verbal and interpersonal communication



Preferred Qualifications:



Experience with MongoDB, git, GCP, Docker, AWS, K8s and micro-services
Experience with computational proteomics & genomics



Benefits:



Permanent Full-time position
Competitive base salary + bonus
Comprehensive insurance coverage
Dynamic company culture with career development opportunities
Flexible working hours
Located between Griffintown and the Old Montreal, in the Cité du Multimédia neighborhood, now part of Montreal’s holistic hub for innovation, education, and entrepreneurship: the Quartier de l’Innovation


GenAIz Group is an equal opportunity employer. All applicants will receive consideration for employment without regard to age, color, family or medical care leave, gender identity or expression, marital status, medical condition, national origin, physical or mental disability, political affiliation, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.


We thank you for your interest, only qualifying candidates will be contacted.","GenAIz
5.0",Montreal
517,Azure Data Engineer with ADF,"Hello,

Please go through below job description and let me know your interest.

Role : Azure Data Engineer with ADF

Location : Boca Raton, FL / Milwaukee, WI / Remote

Duration : 12+ Month

Job Details:

Must Have Skills (Top 3 technical skills only) *
1. ADF
2. Data Bricks

3. Hive

Detailed Job Description:

Has to work on pipeline, data Ingestion framework and data transformation framework.
Experience in Azure platform, Big Data, Cloud technologies
Developing and maintaining solutions to integrate data from various data sources
Testing the code using testing document as per the testing methods.
Deploying the code using deployment group
Possess knowledge on Data Lake, and reporting tools
Support UAT Testing during Business Hours, help users on the data extract needed for dashboard validation
Respond users on the query, issue and clarification.
Interact with clients for plans, specifications and effort estimates for development and support work.

Thanks

Sumit Talekar | Sr. Technical Recruiter | USA & Canada

SILVERLINK TECHNOLOGIES LLC

Job Types: Full-time, Permanent, Seasonal

Pay: $60.00-$65.00 per hour

Schedule:

8 hour shift

Experience:

Azure ADF: 4 years (preferred)
Data Engineer: 7 years (preferred)
Azure Data Bricks: 5 years (preferred)

Work remotely:

Temporarily due to COVID-19","SILVERLINK TECHNOLOGIES LLC
4.4",Midtown Toronto
518,Research Scientist - Primary Cell Culture,"AbCellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking an experienced scientist with a strong background in primary cell culture and media development to join our Discovery team. This role offers the exciting opportunity to contribute to the development of technologies for therapeutic antibody discovery from natural immune repertoires, while working in one of Canada's top biotech companies. We are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. If you're highly motivated, self-directed, and a team-player who thrives in a fast-paced and focused environment, we'd love to hear from you. The candidate should have exceptional organizational and collaborative skills, be able to multitask, problem-solve, think critically, and demonstrate scientific rigor.

How you might spend your days:
Developing and optimizing culture and media conditions for diverse species and tissues for therapeutic antibody discovery

Innovating and refining the tools and approaches for measuring successful implementation of new media and cell culture protocols

Working with project leads and specialized teams to support, optimize and troubleshoot the development of protocols for high-throughput antibody discovery

Coordination and support of a multidisciplinary R&D group focused on multiple parallel goals, including tracking progress of individual projects and managing group priorities

Performing literature reviews and reviewing project data to identify areas of improvement or innovation that will ultimately improve antibody discovery and other parallel technologies

Liaising and coordinating joint projects and technologies with other R&D groups including enrichment, immunization, assay development, immune repertoire sequencing, and data sciences

Hands-on execution of experiments, including training and supporting developing talent

Creating and maintaining systems for tracking reagent inventories and resources

Solving problems at a high level

Training, mentoring and supervising members of a dynamic team

We'd love to hear from you if:
You are experienced in the development and assessment of primary cell culture strategies for culture and in vitro differentiation

You think outside the box and excel at identifying and prioritizing key activities

You have strong leadership skills and you enjoy mentoring and bringing out the best in your teammates

You have exceptional organizational skills; you enjoy planning and managing multiple lab-based projects

You are proficient in the analysis and interpretation of data

You thrive in a collaborative environment

You take pride in being a self-motivated person, fast learner, team player, and creative problem solver

Required qualifications and experience:
PhD in relevant field or MSc plus at least 5 years work experience in primary cell culture or the development of culture protocols and media/associated reagents

Demonstrated experience and broad expertise across areas of cell biology, cell purification or enrichment, microscopy, molecular biology and data analysis

Hands-on cell culture experience is a requirement

Excellent documentation and organizational skills

Proven interpersonal skills with the ability to work collaboratively

Strong leadership skills, including demonstrated mentorship & training

Experience in immunology is highly desired, but not required

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter

An attractive compensation package, including health and lifestyle benefits

A minimum of 3 weeks' vacation

Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please send us your application through our website and refer to Job ID 21123 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera
4.8",Vancouver
519,Research Scientist - Cell Biology & Assay Development,"AbCellera is a vibrant, rapidly growing company nestled in the heart of Vancouver. We are seeking an experienced scientist with a strong background in mammalian cell biology and assay development to join our dynamic Cell Screening team. This role offers the exciting opportunity to contribute to therapeutic antibody discovery from natural immune repertoires using cutting-edge technologies, while working in one of Canada's top biotech companies. We are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. If you're highly motivated, self-directed, and a team-player who thrives in a fast-paced and focused environment, we'd love to hear from you.

How you might spend your days:
Working with our highly motivated team on projects related to the identification of high-quality antibodies. The scope of the work may include the development of in vitro assays that include various mammalian cell lines and primary cells, design of in vivo experiments, development of media conditions and/or enrichment strategies for primary cells, and design of complex functional assays

Optimizing and troubleshooting the development of screening assays for high-throughput antibody discovery and antibody validation

Developing assays and cutting-edge technologies for antibody discovery against challenging targets

Designing, planning, and executing experiments, either independently or in collaboration with your teammates

Analyzing and presenting data to colleagues and partners

Solving problems at a high level

Liaising with partners and communicating project updates and deliverables

Training, mentoring and supervising members of a dynamic team

Maintaining and implementing standard operating procedures while recognizing opportunities for improvements and innovation

Organizing, supporting and collaborating with other team members to meet project deliverables and timelines

We'd love to hear from you if:
You thrive in a collaborative environment

You enjoy mentoring and bringing out the best in your teammates

You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities

You take pride in being a self-motivated person, fast learner, team player, and creative problem solver

Required qualifications and experience:
Post-doc or PhD in relevant field, or MSc plus at least 5 years work experience in relevant field

Demonstrated experience in cell biology and data analysis

Experience with mammalian cell culture and cell-based assay development

Excellent communication and presentation skills

Excellent documentation and organizational skills

Impeccable attention to detail

Proven interpersonal skills with the ability to work collaboratively

Strong leadership skills

Experience in immunology, infectious disease, development of antibody-based assays, flow cytometry or microscopy (optional, but desired)

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter

An attractive compensation package, including health and lifestyle benefits

A minimum of 3 weeks' vacation

Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please submit your application through our website and refer to Job ID 2015 in your cover letter. Only applicants selected for an interview will be contacted.","AbCellera
4.8",Vancouver
520,Research Scientist - Cell Enrichment & Flow Cytometry,"AbCellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking an experienced scientist with a strong background in mammalian cell biology, immunology and cell enrichment strategies to join our dynamic Discovery team. This role offers the exciting opportunity to contribute to therapeutic antibody discovery from natural immune repertoires using cutting-edge technologies, while working in one of Canada's top biotech companies. We are a multidisciplinary team that believes that through teamwork, innovation, and mutual support, together we can solve the biggest challenges in drug discovery. If you're highly motivated, self-directed, and a team-player who thrives in a fast-paced and focused environment, we'd love to hear from you.

How you might spend your days:
Working with our dynamic team on developing and optimizing innovative cell enrichment strategies using flow cytometry, cell sorting or other cell separation technologies
Contributing to our antibody discovery campaigns by advising on the design of enrichment strategies and helping hands-on in their implementation
Designing, planning, and executing experiments, either independently or as a member of various cross-functional teams spanning a wide expertise range (e.g. immunization, antigen design, antibody discovery, cell and molecular biology, engineering)
Developing cutting-edge molecular, cellular and functional assays to assess enrichment strategies
Analyzing and presenting data to key stakeholders
Maintaining and implementing standard operating procedures while recognizing and addressing opportunities for improvements and innovation
Training, mentoring and supervising members of a dynamic team
Organizing, supporting and collaborating with other team members to meet project deliverables and timelines

We'd love to hear from you if:
You thrive in a collaborative environment

You enjoy mentoring and bringing out the best in your teammates

You enjoy working in a fast-paced work environment and coordinating with your team to juggle multiple competing priorities

You take pride in being a self-motivated person, fast learner, team player, and creative problem solver

Required qualifications and experience:
MSc or PhD in relevant field with at least 5 years work experience in cell biology, immunology and cell enrichment strategies
Strong experience in multicolor flow cytometry (including complex panel design and marker selection), cell sorting, or other cell separation technologies
Demonstrated experience in developing innovative cell enrichment strategies
Experience with mammalian tissue isolation and processing, cell culture and cell-based assay development
Strong troubleshooting and decision-making skills in a fast-paced environment
Excellent data analysis and interpretation skills
Excellent communication and presentation skills
Excellent documentation and organizational skills
Impeccable attention to detail
Proven interpersonal skills with the ability to work collaboratively
Strong leadership skills
(Optional, but desired) Background in B cell immunology, experience in imaging, microscopy and development of antibody-based assays.

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks' vacation
Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please send us your application through our website and refer to Job ID 21118 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera
4.8",Vancouver
521,Business Data Analyst (Investment banking),"Job Description

Trigyn is seeking Business Data Analyst for contract position with our direct financial services client in Montreal, QC.

Description:
The ideal candidate should have the skills listed below but in addition should be a self-driven, dedicated individual who works well in a team and thinks and acts strategically.
In addition, the candidate should respond well to change and quickly pick up new concepts in an ever moving regulatory landscape. When faced with a problem, the candidate should be able to ask questions and leverage the skill set of those around him/her.
The group is responsible for the prevention and investigation of abusive, manipulative or illegal trading practices by Financial Advisors and the monitoring overall client suitability. This group identifies patterns behavior across multiple asset classes that may be an indication of sales practice issues or suitability concerns before these can compromise the Firm's reputation or client's holdings.

RESPONSIBILITIES:

Maintain current state architecture, while being an active participant in discussions relating to data strategy across the organization
Collaborates with internal/external team members to architect solutions and implement enhancements to the platform
Responsible for data analysis, data profiling and data sourcing
Create and communicate an Analytics Strategy that sets the direction and describes the related activities necessary to create meaningful business and customer value
Support the global team of business analysts, data SME's, data providers and developers with data subject expertise, query building and optimization
Develop a thorough understanding of the data definitions, domain values, data relationships, business rules, sources and data integration
Translate business requirements into data models and ETL design specifications
Define data quality rules, identify data issues
Partner with data providers to ensure upstream data requirements are met
Coordinate and conduct impact analysis because of upstream data changes and/or issues
Write detailed data requirements and use cases
Ensure that data requirements are met by participating in testing and data reconciliation
Work with management to prioritize business and information needs
Identify and define new process improvement opportunities
Follow through with data sources on issues and resolution
Effectively troubleshoot data quality issues
Implement and refine data quality controls

QUALIFICATIONS:
The candidate should be capable of understanding and solving highly complex problems, have excellent communication skills and have financial services experience, preferably in the areas of investment banking and trading.

Proven working experience as a data analyst or business data analyst
Strong analytical skills with the ability to collect, organize, analyze, and disseminate large amounts of information with attention to detail and accuracy
Performs thorough root cause and impact analysis; Solid analytical, profiling and troubleshooting skills
Has strong understanding of data concepts (Modeling/Design, Warehousing, ETL Development)
Good knowledge of relational databases
Must possess sound knowledge in RDBMS, SQL Queries, Indexes, Keys and Tables considering platforms, such as Apache Hadoop, Oracle, MySQL, HiveQL, and Microsoft SQL.
Knowledge in programming languages, such as R, Python, Matlab and SAS. Advanced Analytics/Data Scientist experience a plus.
Experience in data integration, conversion and migration
Excellent verbal and written communication skills, ability to work with cross cultural teams located globally
Knowledge of Microsoft Office applications (Visio, PowerPoint, Excel, Word)
Experience with ETL tools (preferably Informatica) with the ability to develop ETL design specifications and understand from the code what existing ETLs do
Knowledge of domain specific data and enterprise data
Knowledge of Autosys, Unix commands and scripting
Knowledge of Data Quality controls & implementation of DQ rules/checks preferably using an Industry standard tool
Knowledge and experience in Agile development methodology preferred.
Extensive experience documenting processes, workflows and technical specifications.
Quick learner with excellent attention to detail.
Highly motivated, flexible, proactive, and adaptable to change.
Education Level: Bachelor's Degree

PLEASE RESPOND ONLY IF YOU ARE CURRENTLY ELIGIBLE TO WORK IN CANADA.

For Immediate Response call 732-876-7624, or send your resume to RecruiterLS@Trigyn.com

Trigyn-8181

TRIGYN TECHNOLOGIES, INC. is an EQUAL OPPORTUNITY EMPLOYER and has been in business for 30 years. TRIGYN is an ISO 9001:2015, ISO 27001:2013 (ISMS) and CMMI Level 5 certified company.","Trigyn
4.0",Montreal
522,"Manager, Customer Data Platform","This role requires a broad understanding of marketing technologies, CRM and integrations of Customer Data Platforms (CDP) to consumer facing applications such as customer interactions hubs, emails, chat bots, web personalization, call centers, and analytics tools.

This position is the subject matter expert for the CDP. You will be responsible for creating and owning a vision that aligns to business priorities and delivering that vision through providing overall direction, planning, coordination, execution, monitoring, and control of our customer data.

This role requires strong partnership and interactions with senior executive management, business stakeholders (marketing, sales, product marketing), data scientists, engineering, and IT organizations.

The person must be able to work at a detail level, when needed, to identify issues, risks, root causes, develop mitigation strategies and solutions, and identify and track actions to closure. The candidate must be articulate, be able to effectively and openly communicate with management, raise issues and risks quickly, and help develop solutions.

ESSENTIAL JOB DUTIES AND RESPONSIBILITIES

Drive Customer data platform vendor assessment workshops

Obtain requirements from different and global business stakeholders and create a product roadmap for the CDP

Implement best in class CDP system

Work with various marketing teams in order to create ideal customer profiles based on CDP data

Responsibility for assisting marketing campaigns with segmentations derived from CDP

Ad-hoc reporting and data analysis

ESSENTIAL JOB QUALIFICATIONS

2+ years experiences in CDP, analytics, data driven marketing, and digital transformation

Experience in data architecture and data modeling

Experience working with various marketing technologies (marketing automation, advertisement, webinars etc), SFDC, paid media, social, and offline data

Proven success through partnership and collaboration with a cross-functional team

Proven ability to set strategic direction and drive high quality execution

Strong track record of managing large technology initiatives and delivering capabilities that drive business growth

Solid understanding of segmentation for marketing purposes

Excellent team player with the ability to influence and negotiate

Highly adaptable to changing environment

Disclaimer

The above statements are intended to describe the general nature and levels of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

Quadient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.","Quadient
3.6",Markham
523,Data Engineer,"Type: Full-time, permanent

Career Level: Experienced

Category: Information Technology

About Company

Marine Thinking is a young, agile, dynamic team in the artificial intelligence (AI) and Robotic technologies industry. We partner with businesses across Atlantic Canada and West Coast marine industries, advancing and improving processing factories’ workflow, work efficiency and driving higher production efficiency. Our technology at Marine Thinking aims to protect the environment and strengthen the sustainable development of the marine industry.

We are looking for motivated, energetic and talented Data Engineer to join us to support AI team to design, build and maintain our big data platform, help to implement and scale machine learning models to solve real world problems.

Duties & Responsibilities

Design, care, and feeding of our Big Data environments built upon technologies in the Hadoop Ecosystem
Discover and solve real-world problems by analyzing large amounts of ocean and sensor data
Collaborate with the development team to design simulations and experiments and create models
Investigate and characterize non-trivial issues in various environ, identify problems and provide solutions on marine-related projects
Work on data modelling, discovering insights, and identifying opportunities through the use of statistical, algorithmic, data mining, and visualization techniques
Customize and manage integration tools, databases, and analytical systems
Manage and structure data, including performance optimization, database optimization and stream processing
Day-to-day troubleshooting of problems and performance issues in our clusters
Validate system configurations from hardware layer to Hadoop Application layer
Prepare technical documents in clear, concise writing
Perform project delivery activities such as undertaking and organizing data collection and survey fieldwork, data and literature review
Willingness to mentor and teach people around you

Qualifications

Bachelor's degree in Computer Science or a closely related computer technical field and 3+ years of Hadoop Administration experience or comparable work experience
Intimate and extensive knowledge of Linux Administration and Operational practices
Must have experience with monitoring tools used in the Hadoop ecosystem such as Nagios and Ambari
Experience in designing, implementing and administering large (100 nodes - 1000 nodes), highly available Hadoop clusters
Experience with modern data pipelines, data streaming, and real time analytics using tools such as Apache Kafka, Spark Streaming, or similar tools; Experience with containerization (Kubernetes) is a plus
In-depth knowledge of capacity planning, management, and troubleshooting for HDFS, YARN/MapReduce, HBase
Understanding cluster capacity and bottlenecks, basics of memory, CPU, OS, storage, and networks
Experience in data management, analysis and model modification
Proficiency in a scientific computing language (Python, MATLAB, R)
Must demonstrate practical experience of data management, data analysis, mapping and data standards and associated software
Ability to handle time pressures, managing own time to accomplish required results within deadlines
Strong technical writing abilities
Ability to communicate effectively, orally and in writing
Ability to understand and set priorities among multiple work tasks
Ability to work independently as well as, work well with others
Exceptional communication skills, both written and verbal
Attention to detail

Job Types: Full-time, Permanent

Benefits:

Dental care
Extended health care
Vision care

Schedule:

Monday to Friday","Marine Thinking Inc.
3.0",Halifax
524,IT Expert - Backend/Java/Data,"Position: IT Expert - (Java & Backend/Data)
Duration: Permanent full time
Location: Mississauga office

IT Expert (Java/Backend/Data) who will innovate healthcare

We are the IT centre for Roche - a company in top 10 biggest R&D spenders worldwide.

We do #Code4life to create innovative software that helps doctors, patients and scientists around the world.

We are looking for IT Expert (Java/Backend/Data) who has:

Bachelor’s or Master degree (Computer Sciences, Software Engineering, Mathematical, Information Systems or other) or equivalent work experience;
Minimum 6 years of work experience related to custom software development in enterprise projects;
Expert knowledge in Java technologies (min. 5 years of experience); knowledge of other JVM based programming languages and frameworks like Java SDK, Spring, REST, Data Persistence
Excellent knowledge of database technologies like SQL, NoSQL and (nice-to-have) graph databases
Knowledge and hands-on experience with warehousing solutions, ETL processing and data pipelines
(Nice-to-have) Knowledge and hands-on experience with Apache Spark, Hadoop, or equivalent Big Data processing technologies and tools
Fluency in the usage of cloud computing models (IaaS, PaaS, SaaS), good knowledge of modern architectures (e.g. microservices), tools (e.g. containers) and practices (CI/CD), all connected with DevOps mindset
Excellent knowledge of modern development tools like IntelliJ, GIT, JIRA, etc.
Experience in driving cross organizational initiatives related to custom software development model implementation and rising maturity in this area
Ability to design solutions and independently solve complex problems within the framework of own duties and assisting others in this respect
Knowledge of and ability to put standards and good practices in scope of designing architecture of IT solutions into effect.

Leadership skills:

Strategic thinking, management level communication and influencing skills within peers, partners and upwards
Motivation to learn and develop new skills, fast learner
Responsible and reliable, goal and task oriented.

This position is not eligible for relocation support.

All employment is conditional upon the completing and obtaining a satisfactory background check, including educational, employment, references and criminal records (for which a pardon has not been granted) checks.

AGENCY NOTICE: Please note that Roche Canada does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Services Agreement with agency/recruiter, Roche Canada will not consider or agree to payment of any referral compensation or recruiter fee. In the event a recruiter or agency submits a resume or candidate without a previously signed agreement, Roche Canada explicitly reserves the right to pursue and hire those candidate(s) without any financial obligation to the recruiter or agency.","Roche
4.3",Mississauga
525,Scientifique Principal - Immunologie / Principal Scientist - Immunology,"Sommaire

Le scientifique principal chez CellCarta, au sein de l’unité d’affaire ImmuneCarta, est le lead scientifique pour les études en immune monitoring en support aux essais cliniques et aux études pré-cliniques. Le scientifique principal participe au design, au développement et à la validation des essais in vitro. De plus, il est le premier point de contact avec les Sponsors, leurs fournissant un sommaire des données, des présentations et des rapports. Il participe aussi au troubleshooting. Finalement, le scientifique principal est en charge des aspects scientifiques et réglementaires des études en immune monitoring.

Principales Responsabilités

Supervise la planification et l'avancement des études et des projets sous sa responsabilité;
Réalise et prépare des plans de travail spécifiques aux études et prépare les documents justificatifs pour les essais et les protocoles de suivi de la réponse immunitaire; discute avec la direction et obtient les approbations nécessaire, le cas échéant;
Participe à l'élaboration de nouveaux tests in vitro selon les besoins des clients, y compris la phase qualification et validation des essais;
Travaille en étroite collaboration avec le personnel du laboratoire (ex. assistants de recherche et techniciens) affectés à ses projets;
Veille à ce que les projets soient réalisés selon les délais établis; à ce que les retards soient communiqués de manière proactive aux clients avec un plan d'action pour réduire les retards au minimum;
Identifie les contraintes de ressources et travaille avec la direction pour les résoudre et améliorer la productivité;
Participe à la préparation des présentations et des publications en collaboration avec les clients lorsque cela est possible;
Interagit régulièrement avec les clients, les sites cliniques et la direction de CellCarta pour résoudre sans délai tout problème lié au projet à la satisfaction du client. Documente les interactions et les communications liées aux études;
Participe activement à la préparation et la conduite des audits pour les clients ou les organismes réglementaires.

Formation Requise

Ph.D. ou formation équivalente en sciences de la vie, de préférence en immunologie, virologie, microbiologie ou biologie moléculaire.

Expérience et Connaissances Exigées

Un minimum de 5 ans d'expérience dans un poste équivalent en industrie;
Connaissance en immunologie moderne et être à jour concernant la littérature actuelle, les méthodologies de suivi de la réponse immunitaire et de la conception et de la réglementation des essais cliniques;
Connaissance et expérience avec les techniques de cytométrie en flux et les applications génériques dans le domaine du suivi de la réponse immunitaire;
Connaissance de la conception de tests, ainsi que la manipulation de données complexes d’essais de cytométrie multiparamétriques;
Connaissance des analyses en milieu cellulaire pour suivre l’évolution des réponses immunitaires acquises et naturelles;
Expérience de travail avec les logiciels d’analyse de données en cytométrie en flux et d’analyse statistiques;
Connaissance et compréhension suffisantes des normes GLP et d'autres directives réglementaires pour effectuer des études GLP;
Excellentes aptitudes de communication avec des collaborateurs internes et les clients;
Expérience en gestion de projets et faire preuve de solides aptitude en planification et organisation;
Parle couramment le français et l'anglais (écrit et parlé).
Approche de travail méthodique et systématique;
Capable d’établir des priorités;
Démontre et applique un niveau avancé de compréhension et de compétences analytiques pour interpréter les données et en tirer des conclusions dans les objectifs du projet;
Démontre un esprit critique et créatif;
Communique clairement et avec confiance et possède d'excellentes compétences interpersonnelles;
Capacité à travailler sur plusieurs tâches en même temps dans un environnement dynamique.

Conditions de travail

Doit être disposé à exercer des fonctions ou à superviser des activités dans des installations de niveau de sécurité biologique (NSB) 1 ou 2 où les échantillons biologiques peuvent être soit naturellement ou expérimentalement infectés par des virus potentiellement dangereux tels que le VIH, le VHC ou le CMV.

Summary

The Principal Scientist is responsible for the overall conduct of studies in different immune-therapeutic area, overseeing experimental testing design, as well as formulating conclusions and recommendations for next steps. The incumbent has the ability to present CellCarta capabilities to clients in a compelling way demonstrating value and differentiation as support function to Business Development activities as well as presentation of results to Sponsor and scientific meetings. The incumbent is ensuring that the timelines and milestones of a study are met by proactively assessing foreseeing challenges, assessing impact of deviations and overall quality of the study conduct.

Main Responsibilities

Oversees the planning and progress of studies and projects under her/his responsibility;
Designs and prepares detailed study-specific work plans and support documentation for protocols and assays; discusses with management and obtains approval as appropriate;
Participates in the development of new in vitro assays as per client needs, including the assay qualification and validation phase;
Instructs laboratory personnel (e.g. research assistants and technicians) assigned to her/his projects;
Ensures that projects are conducted as per established timelines and delays are communicated in a proactive manner to clients with action plan to minimize the delays;
Identifies resource constraints and inefficiencies and works with management to resolve;
Prepares preliminary and final reports;
Ensures that all study-related data is appropriately maintained and archived;
Participates in the preparation of presentations and publications in collaboration with clients when possible;
Interacts regularly with clients, clinical sites and CellCarta management to address project issues in a timely manner and to the satisfaction of the client. Documents study-related interactions and communications properly;
Actively participates in the preparation and conduct of audits for clients or regulatory bodies.


Education

Ph.D. or equivalent training in life sciences, preferably in immunology, virology, microbiology or molecular biology.

Experience and Skills Required

A minimum of 2 years experience in an equivalent position in the industry or in an academic environment;
Knowledge and experience with multi-parametric flow cytometry techniques and its generic applications in the field of IM including testing design as well as handling complex data set of multi-color panels;
Knowledge of modern immunology and kept abreast with current literature, IM methodologies and clinical trial design and regulations;
Knowledge of cell-based assays to monitor adaptive and innate immune responses;
Experience working with FlowJo, Pestle, Spice, Prism and Excel
Knowledge and understanding of GLP regulations and other regulatory guidelines sufficient to carry out GLP studies;
Experience in project management;
Experience with client management;
Strong communication ability;
Approaches work methodically and systematically;
Establishes priorities from among a number of demands;
Demonstrates and applies advanced level of understanding and analytical skills to interpret data and draw conclusions within the project goals;
Critical and creative thinker;
Communicates clearly and confidently and has excellent interpersonal skills;
Skilled at working in a fast-paced and multi-tasking environment.




eAviGgh2bF",CellCarta,Montreal
526,Data Engineer,"Role Details

Reporting to the Director of Machine Learning & Artificial Intelligence, the Data Engineer will be responsible for the development and deployment of ETL processes, Data management, Data Warehousing and more in the Automotive Digital Advertising industry. LotLinx is looking for a candidate that has talent with data to improve, optimize and lead further development of our data aggregation processes.

Required Skills:

BS degree in Computer Science or related technical field, or equivalent practical experience.
Strong analytic skills related to working with unstructured datasets.
Solid understanding and working knowledge of relational or non-relational databases.
Proficiency in a major programming language (e.g. Java/C) and/or a scripting language (scala/php/python).
3+ years experience with Data gathering, Data pipelining, Data Standardization, Data Cleansing, Stitching aspects.
Innately curious and organized with the drive to analyze data to identify deliverables, anomalies, and gaps and propose solutions to address these findings.

Responsibilities:

Work with stakeholders including Analytics, Product, and Design teams to assist with data related technical issues and support their data infrastructure needs.
Engineer solutions for large data storage, management, and curation of training data models.
Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities.
Act as an internal expert in each of the data sources so that you can own overall data quality.
Design, build and deploy new data models, ETL pipelines into production and data warehouse.
Define and manage overall schedule and availability of all data sets.


About LotLinx

LotLinx is a leading automotive SaaS Data company, utilizing AI-powered technology to provide our clients with an end-to-end Vehicle Management and Marketing System. We are experiencing tremendous growth and have an exciting opportunity for an Intermediate to Senior developer located in Canada. Our offices are currently in Winnipeg, MB, and Hamilton, ON but given current circumstances are open to any remote location in Canada. LotLinx provides employees with a dynamic work environment that is challenging, team-oriented, and full of passionate people. We offer great incentives to our employees, such as competitive compensation and benefits, flex time off, and excellent career development opportunities.","LotLinx, Inc.
3.2",Winnipeg
527,Data engineer,"About Q4
At Q4, we hustle, we grind and we grow. As the team members that make up #Q4orce, we care, we compete and we support each other every day. We’re on a mission to deliver a best-in-class client experience driven by technology, data, and of course, our people.

As the leading provider of website, analytics and virtual events solutions to investor relations and the capital markets, Q4 is a trusted partner to over 2,400 of the world’s most successful public companies and institutions – and we are growing at an incredible pace. We’re on our way to becoming the largest capital markets platform company in the world. That’s where you come in.

We hire smart, curious, and talented people to push boundaries, reimagine what’s possible and turn challenges into opportunities, all while keeping the needs of our clients at the heart of everything we do.

This is your opportunity to be a part of something special. Join us!

The gig.
The data engineer will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Key Responsibilities:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Keep our data separated and secure through multiple data centers and AWS regions.
Create data tools for analytics and different team members that assist them in building and optimizing our product into an innovative industry leader.
Requirements
Bachelor's Degree in Computer Engineering or a related field required, or equivalent education
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing system
Analytical mind, critical thinker, problem-solver
Understanding of the financial services industry and global capital markets




Why Q4?
We are motivated by solving complex problems in unorthodox ways. Emphasis on your well-being means you experience your true potential. We offer a variety of benefits to ensure you can always work hard and have fun:

Health, wellness and lifestyle benefits to balance your heart, mind, and body.
Pension matching and Employee Equity Incentives to support your financial health.
Unlimited paid time off so you can be really recharge and enjoy life. Enough said.
Flexible working environment. Choose your home, one of our trendy offices or mix it up.
Virtual team building and socials. Keeping people connected is important.
And an amazing culture to top it all off!
Join #Q4orce
A career at Q4 means joining a team that thrives in a fast paced, high growth environment; one that is focused on providing growth opportunities, encouraging diversity & inclusion and working to inspire an entrepreneurial spirit. We’re thrilled to be able say that the Q4 team and culture have even won some awards along the way including being recognized as one of Canada's Best Workplaces for Women and Technology.



Q4 values diversity and people of all backgrounds and abilities. Should you require any accommodations prior to or during the interview process, please contact talent@q4inc.com.","Q4
3.9",Midtown Toronto
528,"Data Engineer, ClearAngel","ClearAngel is building YC for the 99% of founders. Those who traditionally don't have access to advice, capital or network -- we want to support that long tail.

Most founders don't live in Silicon Valley or have the pristine pedigree to get in front of the ""right"" people. For far too long, startups have played on a scarcity model.

This is limiting the potential of founders. We fundamentally believe that great founders and companies are everywhere. Where there are problems, opportunities exist. We want to empower those founders.

We are building ClearAngel to democratize access to advice, network and capital.

We do this by scaling access to the rest of the world:
Access to advice (knowledge, resources)
Access to network (intros, people, community)
Access to capital

The role of the Data Engineer is to collaborate on backend architecture and minimalistic data pipelines that enable features for the Clear Angels product and supporting processes. Your responsibilities will be a superset of a typical Data Engineer, as there are often experiments and uncertainty that require creative solutioning at the earliest stages.

Application Deadline: ongoing

What your day-to-day will look like:
You will own technical products end to end, from design and architecture to deployment and maintenance

Working closely with every member of the team, you will produce significant components of the ClearAngel code

Work closely with all functions of Clearbanc, ranging from core Engineering team to Data Science team to the marketing team

You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary

You will scope out business needs for ClearAngel, and action them with speed and accuracy and then execute on it yourself

You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs

When it comes to product and engineering on ClearAngel, buck stops with you. Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

You will thrive if you:
Have a desire to help founders. We take a strong founder first stance on this team

Are self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission

On this team, we maximize learning. You will fail if you're not learning fast enough

Are comfortable working in a high growth, constantly changing environment

You are heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support

Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!

Have a strong business sense, you can foresee potential issues and solve them quickly

Demonstrated ability to collaborate effectively across multiple teams

Strong interest in building businesses, ecommerce, fintech

Technical Requirements:
3+ years of experience working on a variety of different projects / stacks would be ideal

Experience working on remote teams

Able to architect and scale data integrations from third-party API docs independently without much support

Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes

Comfortable working in server and database environments that are changing constantly

Demonstrated experience with using third party solutions and external APIs to supercharge existing features

Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff

Comfortable with relational databases and schemas involving time-series

Skills and interest in Python, SQL, Snowflake, Kubernetes

Clearco is an equal opportunity employer. We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives to apply. At Clearco, we're committed to developing and upholding an inclusive, transparent, and comfortable environment for all. We create a space where every voice, perspective, and idea is heard and acknowledged. We embrace differences, and know that our diverse team is our strength and what drives our innovation.

Clearco is committed to developing a barrier-free recruitment process and work environment. If you require any accommodation, please let us know and we'll work with you to meet your accessibility needs.","Clearco
3.9",Ontario
529,Business Intelligence (BI) Developer/Data Analyst,"Company Description
At Jane, we’re working to find the best ways to help small businesses succeed, and we’re using the latest technology to build a better online marketplace. We have some pretty big goals and are always looking for talented people who want to be a part of something new. We not only work hard at our jobs but also to maintain a culture of authenticity and collaboration. Join us and enjoy the #janelife to its fullest.

Jane's Values
Lead with empathy
Pull together
Just say it
Make it count
Make your mark

About the Team:
The data team was recently formed under a single executive to combine resources throughout the organization to optimize and enhance the data-driven capabilities at Jane.
The main pillars of our data team are:
Analysis and Insights
BI Development
Data Engineering
Data Governance
Data Science
Performance Management
You will have the opportunity to work with others across our team collaborating to deliver services to enhance the execution of our business. While supporting all business functions at Jane, You will also have the chance to develop other data skills within the data team to apply to your development as a data professional.
What You'll Be Doing:
Reporting into our Manager of Data & Analytics, you will:
Build reports and dashboards on our BI platform (Looker) to support various stakeholders
Design and build data models on our BI platform to enable self-service BI and data exploration
Resolve ad hoc data requests and changes to our BI platform
Build complex SQL queries and explore data in support of business initiatives
Engage with business consumers of data, gather requirements, and deliver end-to-end data-driven insight and solutions
Maintain and update our data wiki and data dictionary as required
Provide training and guidance to end users of our BI platform and in the analysis and understanding of data
Prepare technical and non-technical documentation and presentations
Qualifications:
University or College degree with focus on either Computer Science, Business, Mathematics / Statistics preferred
At least 2+ years experience in similar data-related positions. For example, as a data analyst, data scientist, data engineer, BI developer. Compensation will be commensurate with experience
Solid understanding of data warehousing concepts, dimensional and relational database design
Strong experience and skills in SQL is a must
Experience with business intelligence platforms; l.e. Cognos, Tableau, Looker, and Power BI etc.
Ability to build interactive dashboards and reports
Strong written and verbal communication skills are a must
Ability to communicate and present to technical and non-technical audiences
Ability to write accurate, concise technical documentation
A self-starter who can work well independently with minimal direction
Ability to think outside the box and infuse creativity into problem solving","Jane.com
4.3",Vancouver
530,Data Engineer - ETL (Insights),"Data Engineer - ETL (Insights)

AdGear (belonging to the Samsung Ads business), is an advanced Advertising Technology Company located in the heart of downtown Montreal. AdGear/Samsung Ads focuses on enabling brands to connect with Samsung TV audiences as they are exposed to digital media across all devices. Being part of an international company such as Samsung and doing business around the world means that we get to work on big complex projects with stakeholders and teams located around the globe.

Samsung Ads is an advanced advertising platform where advertisers find and connect with audiences across over 100M Samsung Households around the world. Samsung Ads delivers high-quality audience targeting powered by three key components: first-party audience data at scale, world-class data science, and brand-safe cross-device ad inventory. Using our data, insights, and scale, we help advertisers reach consumers across CTV, our native apps, mobile and desktop. With Samsung Ads, advertisers can buy the way they want, reach who they need, and prove business results.

Our purpose is to deliver unparalleled results for our customers. By using the industry’s most comprehensive data to build the world’s smartest connected audience platform, Samsung Ads is uniquely positioned to transform the advertising landscape. We deliver on Samsung Electronics’ 51-year commitment to excellence through smart, easy, effective advertising solutions to make advanced video advertising work.


About “Reporting and Insights”

Our group is responsible for developing a cohesive set of powerful reporting & insights features to empower our service and analytics teams, as well as inform our customers. Our playground includes reporting facilities and dashboards to serve both internal and external users as well as various ETL pipelines ingesting 1 terabyte of data per hour, around the clock.

Our tech stack includes a mixture of Java/Scala/Akka, Spark, Hive, AWS Athena/RDS, EMR, Vertica, Kafka, Airflow, Concourse, Docker and Kubernetes.


What you’ll do

As a Data Engineer, you will be designing and developing ETLs and data processing pipelines at scale. As a consequence, there will be opportunities to contribute to open source, conduct research and development, review code, participate in shaping our engineering practices and share knowledge. You will work with some incredibly talented and passionate developers within an engineering team with a strong technological background. You will also interact on a day-to-day basis with software engineers, scrum masters and product owners.

In this position, the chosen candidate is expected to have a hands-on, problem-solving approach and a friendly human-facing side to communicate and manage expectations.


KEY RESPONSIBILITIES

Develop and maintain ETL pipelines
Develop and maintain streaming jobs
Develop and maintain data extraction tools (REST API clients)
Occasionally provide ad hoc data


REQUIRED SKILLS AND/OR EXPERIENCE

Prior experience in a similar role
Experience in Java, Scala, Python, Bash, C, etc.
Solid understanding of Unix/Linux systems
Prior experience in streaming technologies like Akka, Kafka or Spark Streaming
Prior experience in Airflow
Prior experience in working in a Agile environment
Good communication skills and capacity/willingness to work in a multi-teams environment.
Be resourceful, inventive and passionate
You are eager to challenge the status quo and willing to learn new programming languages
Demonstrated ability to prioritize tasks and resolve problems in a timely manner;
Ability to work autonomously, multi-task and work in a fast-paced and stressful environment;
Be proactive, addressing potential problems before they occur;
Attention to detail;
Problem-solving outlook, can-do attitude is a must

The candidate should thrive in a fast-paced and dynamic environment and effectively handle working across different teams and priorities. The candidate should have an entrepreneurial mind-set, taking ownership in creating opportunities, aligning to the yearly plan but also being flexible to take advantage of new opportunities.

If you're interested in joining a rapidly growing team working to build an outstanding, world-class advertising organization with a relentless focus on design and customer experience, you've come to the right place.


About our culture…

We are proud to have built a world-class organization, grounded in an entrepreneurial and collaborative spirit. Working at Samsung Ads offers one of the best environments in the industry to learn just how fast you can grow, how much you can achieve, and how good you can be. We thrive on problem-solving, breaking new ground, and enjoying every part of the journey.

1rZUbPNECF","AdGear
3.6",Montreal
531,Architecte de données / Data Architect - 312699,"Architecte de données

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Architecte de données pour une entreprise dans le domaine manufacturier. Notre client est situé à Montréal.





Description des tâches et responsabilités – Architecte de données

Les responsabilités du poste incluent :

Participer à l’établissement et au maintien du modèle de données global de l'entreprise, en collaboration étroite avec les lignes d'affaire, l'équipe de gouvernance des données et les ingénieurs de données de l'organisation;
Capturer les requis d'affaire afin d'établir les modèles de données de type relationnel, dimensionnel ou data vault afin de supporter différents cas d'utilisation de la donnée;
Revoir les modèles de données proposés par les ingénieurs de données, les analystes et les scientifiques afin de les optimiser, de les aligner avec le modèle global, et de les opérationnaliser, tout en assurant une adhésion aux standards de l'industrie et aux lois en lien avec GDPR et SOX;
Définir et mettre en place les éléments d'architecture qui assureront la disponibilité, la qualité, la sécurité et la mise à disposition des données;
Voir à la conformité de la plateforme BI, depuis la capture des données brutes jusqu'à la couche de présentation;
Être un/une leader dans la définition des meilleures pratiques et de la pensée créative.




Exigences du poste – Architecte de données

Maîtrise en informatique, intelligence d'affaire ou expérience équivalente;
Expérience solide et démontrée en différents types de modélisation de données :
Modèles relationnels;
Modèles dimensionnels;
Data Vault 2.0.
Travail en équipe, être ouvert d'esprit et toujours être prêt à discuter du modèle proposé ou de l'approche à prendre;
Très organisé, capable de bâtir un ""plan de match"", et de prioriser ses propres tâches avec des dates de livraison conflictuelles;
Propose sans cesse des idées d'amélioration créatives, et adore mettre les mains dans des technologies nouvelles;
Excellent communicateur oral et écrit, en français et en anglais, capable de préparer et de faire des présentations exécutives;
A déjà travaillé dans un modèle de livraison agile;
Une expérience avec SAP ECC et S4, Azure, Snowflake est un plus.




Type de poste
Contractuel 12 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH312699




____________ENGLISH VERSION___________

Data Architect

As a part of its agreements with its various clients, Procom is currently seeking a Data Architect for a company in the manufacturing sector. Our client is located in Montréal.





Job details – Data Architect

Key responsibilities for this position include:

Participate in the establishment and maintenance of the overall enterprise data model, working closely with business lines, the data governance team and the organization's data engineers;
Capture business requirements to establish relational, dimensional or data vault data models to support different data use cases;
Review data models proposed by data engineers, analysts and data scientists to optimize them, align them with the overall model, and operationalize them, while ensuring adherence to industry standards and laws related to GDPR and SOX;
Define and implement the architecture elements that will ensure data availability, quality, security and delivery;
Ensure compliance of the BI platform, from raw data capture to the presentation layer;
Be a leader in defining best practices and creative thinking.




Mandatory Skills – Data Architect

Master's degree in Computer Science, Business Intelligence or equivalent experience;
Strong and demonstrated experience in various types of data modeling:
Relational models;
Dimensional models;
Data Vault 2.0.
Team player, open minded and always willing to discuss the proposed model or approach to be taken;
Highly organized, able to build a ""game plan"", and prioritize own tasks with conflicting delivery dates;
Constantly comes up with creative ideas for improvement, and loves to get his hands into new technologies;
Excellent oral and written communication skills, in French and English, with the ability to prepare and deliver executive presentations;
Previously worked in an agile delivery model;
Experience with SAP ECC and S4, Azure, Snowflake is a plus.




Assignment Length
12-month contract – renewable

Start date
Immediately

Reference number
BH312699","Procom
4.3",Montreal
532,Architecte de données / Data Architect - 312699,"Architecte de données

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Architecte de données pour une entreprise dans le domaine manufacturier. Notre client est situé à Montréal.





Description des tâches et responsabilités – Architecte de données

Les responsabilités du poste incluent :

Participer à l’établissement et au maintien du modèle de données global de l'entreprise, en collaboration étroite avec les lignes d'affaire, l'équipe de gouvernance des données et les ingénieurs de données de l'organisation;
Capturer les requis d'affaire afin d'établir les modèles de données de type relationnel, dimensionnel ou data vault afin de supporter différents cas d'utilisation de la donnée;
Revoir les modèles de données proposés par les ingénieurs de données, les analystes et les scientifiques afin de les optimiser, de les aligner avec le modèle global, et de les opérationnaliser, tout en assurant une adhésion aux standards de l'industrie et aux lois en lien avec GDPR et SOX;
Définir et mettre en place les éléments d'architecture qui assureront la disponibilité, la qualité, la sécurité et la mise à disposition des données;
Voir à la conformité de la plateforme BI, depuis la capture des données brutes jusqu'à la couche de présentation;
Être un/une leader dans la définition des meilleures pratiques et de la pensée créative.




Exigences du poste – Architecte de données

Maîtrise en informatique, intelligence d'affaire ou expérience équivalente;
Expérience solide et démontrée en différents types de modélisation de données :
Modèles relationnels;
Modèles dimensionnels;
Data Vault 2.0.
Travail en équipe, être ouvert d'esprit et toujours être prêt à discuter du modèle proposé ou de l'approche à prendre;
Très organisé, capable de bâtir un ""plan de match"", et de prioriser ses propres tâches avec des dates de livraison conflictuelles;
Propose sans cesse des idées d'amélioration créatives, et adore mettre les mains dans des technologies nouvelles;
Excellent communicateur oral et écrit, en français et en anglais, capable de préparer et de faire des présentations exécutives;
A déjà travaillé dans un modèle de livraison agile;
Une expérience avec SAP ECC et S4, Azure, Snowflake est un plus.




Type de poste
Contractuel 12 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH312699




____________ENGLISH VERSION___________

Data Architect

As a part of its agreements with its various clients, Procom is currently seeking a Data Architect for a company in the manufacturing sector. Our client is located in Montréal.





Job details – Data Architect

Key responsibilities for this position include:

Participate in the establishment and maintenance of the overall enterprise data model, working closely with business lines, the data governance team and the organization's data engineers;
Capture business requirements to establish relational, dimensional or data vault data models to support different data use cases;
Review data models proposed by data engineers, analysts and data scientists to optimize them, align them with the overall model, and operationalize them, while ensuring adherence to industry standards and laws related to GDPR and SOX;
Define and implement the architecture elements that will ensure data availability, quality, security and delivery;
Ensure compliance of the BI platform, from raw data capture to the presentation layer;
Be a leader in defining best practices and creative thinking.




Mandatory Skills – Data Architect

Master's degree in Computer Science, Business Intelligence or equivalent experience;
Strong and demonstrated experience in various types of data modeling:
Relational models;
Dimensional models;
Data Vault 2.0.
Team player, open minded and always willing to discuss the proposed model or approach to be taken;
Highly organized, able to build a ""game plan"", and prioritize own tasks with conflicting delivery dates;
Constantly comes up with creative ideas for improvement, and loves to get his hands into new technologies;
Excellent oral and written communication skills, in French and English, with the ability to prepare and deliver executive presentations;
Previously worked in an agile delivery model;
Experience with SAP ECC and S4, Azure, Snowflake is a plus.




Assignment Length
12-month contract – renewable

Start date
Immediately

Reference number
BH312699","Procom
4.3",Montreal
533,Product Manager and Data Scientist,"You will own, from a product management perspective, the successful definition and delivery of our new API services.

You will work closely with our R&D department and ensure project execution, profitability and customer satisfaction. You will join a team of very skilled, talented and passionate people, always bringing the software industry best practices to our workflow.
The ideal candidate has a good business acumen and has previously been exposed to data analytics, data science, has evolved into a product management role and is at ease in speaking both technical and business languages.
Your Impact
Gather business requirements and use cases from customers, sales and customer service. Use this data in the roadmap strategy.
Prioritize the roadmap deliverables and secure required development resources to ensure timely delivery of those roadmap items.
Track roadmap execution plan accordingly and teams’ alignment around implementation trade-offs that might be required.
Translate the data gathered to build a case for decisions presented in the roadmap.
Champion the product vision and strategy, exhibiting good product judgement, continuously setting clear and measurable objectives and monitoring the product's progression to achieve these.
Communicate this strategy to all the relevant participants and stakeholders.
Support PM leadership for pricing
Work with the R&D teams to define functional architecture, processes, and development efforts required for the delivery of API services.

Here’s what your day-to-day will look like in this role :
Maintain an understanding and knowledge of the competition including competition analysis.
Research and analyse market, the users, and the roadmap for the product
Define product vision, road-map and growth opportunities
Plan and prioritize product feature backlog and development for the product
Provide backlog management, iteration planning, and elaboration of the user stories
Provide commercial input into pricing and marketing strategies
Attend conferences and exhibitions, meeting with customers and agents.
Work closely with the sales team on RFIs, RFPs, ITTs and provide technical input in relation to bids, proposals etc.
Accompany area sales managers on prospective customer visits & assist in identifying and qualifying opportunities.
Regular interactions with existing customers with pro-active visits, educational sessions, seminars, webinars and workshops to promote the full and effective use of the software and data
To assist with implementation of API services on customer vessels both remotely and hands-on and the management of customer sea-trials
Work with the marketing department to produce and maintain technical manuals, user guides, marketing material and computer-based training.
Requirements
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
BS in Mathematics, Economics, Computer Science, Information Management or Statistics or an equivalent experience.
A strong technical background in product management, operations or sales and the ability to progress deals or other relevant experience.
Outstanding communication, presentation and leadership skills
Great problem solver - who can think through problems and develop solutions quickly.
Training will be provided but the ability to quickly absorb information and understand and communicate USPs and product differentiation is essential.
Must be willing and able to travel on a global basis
Fluent spoken and written English
This role can be based out of our head office in Enfield, UK or from our Montreal office in Canada.

What about us?
We have successfully completed a large merger and have become the leader in a tight maritime market. Now we want to act accordingly by reworking our product line, investing in long-term technology to provide our customers the best solutions. We want to transform our field into a smarter, leaner maritime industry.
We are designing our new products generation using the latest innovative technologies with web applications and APIs deployed to more than 10,000 users worldwide. We are structured in autonomous and Agile squads (multidisciplinary team) where the status quo is prohibited and in which everyone has a word in the organization, architecture, or design of the product.
If building our future generation of software, making life easier for ship owners, ship managers and crews and resolving navigation challenges to revolutionize the maritime world inspires you, send us your application!
Benefits
Friday innovation’s afternoons, continuous learning policy, open-source initiatives, publication of tech articles
Beautiful and well-located office (downtown) with secure bike room and showers
Extended Healthcare Plan (Medical, Disability, Dental & Vision)
RPP - Group RRSP
Group Life - AD&D - Critical Illness Insurance
Paid Time Off Benefits
Work From Home - Flexible hours
Training & Development
Employee Assistance Program - Counseling
What you need to get cosy (fresh fruits, tea, and coffee obviously)","OneOcean
3.5",Montreal
534,CPXE-Data & AI Growth Analytics Analyst,"Who We Are

Cisco’s Customer Experience (CX) organization is one of Cisco’s fastest growing teams, and the Customer and Partner Experience Engineering (CPXE) group is redefining how Cisco delivers value to our customers & partners via our product portfolio.

The CXPE product growth team leads analytics and growth initiatives for the Cisco product po rtfolio . Our mission is to measure, understand and optimize the Cisco experience for customers (CX Cloud) and partners (PX Cloud) across enterprise, mid-market and growth segments .

We are a small data-driven team passionate about customer value acceleration, delivering delightful experiences and accelerating lifecycle growth through rapid experimentation. We spend our time determining the highest impact variables and l evers to unlock growth and optimize the path to product value.

We use data to drive product led growth.

What You’ll Do

As part of the product growth team, you will wo rk across a multi -functional team to identify, prioritiz e and execut e data-driven growth activities.

You will focus on using experimentation to drive growth and enhance the Cisco value experienc e for customers and partners.

You will build analytica l narratives t hat help solve business, marketing , and growth problems such as conversion and adoption optimization, LTV forecasting, churn analysis, causal inference, and more.

Who You’ll Work With

You will be part of a fun , loving, diverse team, with an inclusive culture. Duties collaboratively span strategy to execution across the CX organization to promote business growth and customer lifecycle acceleration . In addition to customers and partners , you’ll partner with Engineering, Product Management, IT, Digital Transformation, Data Scientists, UX Researchers & our executive team.

Specifically, y ou will:
Identify and investigate numerical and qualitative data sets , assemble disparate sources of data to provide insight into how customers using Cisco products.
Collaborate with product and engineering teams to establish hypothesis, set up experiments , and interpret results
Convert numerical results into concrete, meaningful recommendations for business or product improvement
S uccinctly communicate s olutions to cross-functional partners and leadership across engineering, data science, UX research, marketing and more.

Must have s :
BS in Computer Science, Engineering, Statistics or related work experience.
P roven track record of setting up and optimizing metrics tracking systems and A/B testing methodologies , multivariate testing , power analysis and regressions.
Proven experience working with extremely large datasets, ETL processing and Machine learning pipelines.
Proficiency with decision modeling techniques and software; SQL, Python, R

Nice to haves:
4+ years of experience in business data analysis. You can easily give us an example of a data project you’ve work on and what impact it had on driving business outcomes.
Knowledge of customer experience, product growth functions, understanding of customer lifecycles, familiarity with bookings and pipeline reporting.
Proficiency with decision modeling techniques and software; SQL, Python, R
Highly collaborative and communicative, with ability to effectively manage business expectations and regularly work with both business and technical stakeholders.

Why Cisco

#WeAreCisco, where each person is unique, but we bring our talents to work as a team and make a difference. Here’s how we do it. We embrace digital, and help our customers implement change in their digital businesses. Some may think we’re “old” (30 years strong!) and only about hardware, but we’re also a software company. And a security company. An AI/Machine Learning company. We even invented an intuitive network that adapts, predicts, learns and protects. No other company can do what we do – you can’t put us in a box! But “Digital Transformation” is an empty buzz phrase without a culture that allows for innovation, creativity, and yes, even failure (if you learn from it.)

Day to day, we focus on the give and take. We give our best, we give our egos a break, and we give of ourselves (because giving back is built into our DNA.) We take accountability, we take bold steps, and we take difference to heart. Because without diversity of thought and a commitment to equality for all, there is no moving forward. So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool.

CPXE","Cisco Systems
4.3",Vancouver
535,Staff Data Engineer,"OPEN- CANADA /
ENGINEERING – DATA /
FULL-TIME

TextNow is based around a simple idea: Communication belongs to everyone. We work hard to help people stay connected by offering a solution that makes phone service free. At TextNow, we work together to solve complex and interesting problems that have a positive impact on our customers lives.

Join us in our mission to help people stay connected with technology that is free (or as close to free as possible.)

TextNow is looking for a Staff Data Engineer with hands-on experience designing and developing real-time data platforms. You’ll be a central figure in evolving the design, architecture and performance of TextNow’s data platform. You'll lead cross functional efforts with SRE, product, backend engineering and data science to build a next level data platform that scales and supports all TextNow’s business and data product. This is a senior level position and accordingly, you’re expected to be a technology thought leader throughout the org.
What You’ll Do:
Play a key role in building out a large scale, distributed, and event-based Data Platform that serves as an underpinning for all TextNow’s Business and data products.
Lead product requirements and advanced technical requirements gathering efforts, interfacing with Data Engineering, Data Scientists, Analytics, and stakeholder teams.
Recommend and advise to improve data reliability, efficiency, and quality.
Build a scalable technology platform to support a growing business.
Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, and scalability. Perform capacity planning and cost estimates of proposed solutions.
Be a champion of TextNow’s data ecosystem by working with engineering and SRE to guide data strategy for governance, security, privacy, quality and retention that will satisfy business policies and requirements.
Be an expert on big data technologies e.g., Spark, Kafka, Presto, Delta Lake, etc.
Advise team on engineering best practices around CI/CD, Secure coding, etc.
Enable real time data applications by designing Machine Learning based real time data services.
Drive data team to adopt industry best practices in data platform engineering.
Mentor other Data Engineers/Interns on the data team.
Who You Are:
Creator of cool stuff that will be instrumental in building a modern data platform that is used for multiple internal use cases e.g., monetization, personalization, finance, data science, data engineering, user acquisition.
Brilliant collaborator with 10+ years of experience in data engineering and/or data infrastructure. Experience working with various data stores such as SQL, No SQL and key-value stores (Redshift, Snowflake, DynamoDB, redis). At least 7+ years of development experience with Python and/or Scala. Hands on experience with designing real-time data streaming pipelines using spark structured Streaming, Kafka and/or Kinesis is preferred.
Someone who takes action and ownership with hands-on experience designing Multi TB/PB scaled distributed data systems on cloud infrastructure such as AWS.
Respectfully candid with the ability to initiate and drive projects to completion. Highly organized, structured work approach, and dependable. Ability to manage and communicate data platform engineering plans to internal partners.
A bold risk-taker and self-starter who proactively sees areas of improvement and drives the change the needed to make it happen.
Resourceful and scrappy with a keen eye on ROI - knowledge of ad serving platforms and online advertising systems is a plus.
#LI-RS1

Benefits:
Strong work life blend
Flexible work arrangements (wfh, remote)
Employee Stock Options
Unlimited vacation
Competitive pay and benefits
Parental leave top up
Benefits for both physical and mental well being

DIVERSITY AND INCLUSION:
At TextNow, our mission is built around inclusion and offering a service for EVERYONE, in an industry that traditionally only caters to the few who have the means to afford it. We believe that diversity of thought and inclusion of others promotes a greater feeling of belonging and higher levels of engagement. We know that if we work together, we can do amazing things, and that our differences are what make our product and company great.","TextNow
4.3",Canada
536,"Data Engineer, Omnia AI (Montreal)","Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.




You have a passion for analytics and advanced Data Management? You want to build solutions that will allow customers to go further with the best of the existing Data solutions (AI/ML/ETL/Data lakes…)? Are you ready to uncover the possibilities of AI in your career and set the foundation for success tomorrow?
Then we have an opportunity waiting for you!

What will your typical day look like?

As a Data Engineer within our Omnia AI practice, you will be a team player to a portfolio of Deloitte’s Omnia AI engagements (projects). You will have the opportunity to be involved in the full life-cycle over AI projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. You will be able to work on the largest and most advanced Analytics projects on the market : 2019, 2020, 2021 Gartner Data & Analytics Service Provider leader.

Specifically, you will:

Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer.
Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed).
About the team

Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. We work closely with the Omnia AI Strategy, AI Data Science and AI Factory (custom developed AI assets) teams to drive successful business outcomes. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. To support our continued growth, we are looking to add many team players with hands-on work experience ideally in the data, analytics and/or AI domains.

Enough about us, let’s talk about you

You are someone with:

Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications
2+ years of experience in Data Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes
An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms
Team player attitude
Superior communication skills, intellectual curiosity, and strong analytical skills
Undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous

Differentiators but not required:

Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects
Bilingual (English / French)

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.
The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?


Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Montreal
537,Senior Data Scientist,"Parkland is an independent supplier and marketer of fuel and petroleum products and a leading convenience store operator. We power a growing family of locally known brands and our team members serve retail, commercial, and wholesale customers across Canada, the United States, the Caribbean region and the Americas. Our purpose as Parklanders is to energize people and businesses to get them where they want to go. We’re a passionate team of down-to-earth achievers, committed to getting our customers, colleagues and communities further, faster.

Job Title: Senior Data Scientist

Location: Calgary, AB (we are open to candidates in Vancouver, Calgary, Montreal, or Toronto)

Position Summary:

Parkland Corporation is deeply invested in building next-generation Enterprise Data, Digital & Analytics capability, with an aspiration to improve our value to customers, our customers‘ experiences, and drive profitable growth and industry leadership for Parkland.

Parkland is seeking a Senior Data Scientist to be part of our newly forming Enterprise Digital Team – consisting of skillsets spanning machine learning, AI, Statistics, Data Engineering and full stack development. You will work as part of a high caliber team that works on solutions across Parkland’s business areas including Supply, Pricing and Loyalty, Retail, Commercial, Trading and Refining to drive high value solutions. As Canada and Caribbean’s largest and one of America’s fastest growing independent suppliers of fuel and marketing products and a leading convenience store operator, Parkland’s operations provide a rich and varied set of analytics opportunities, including over 1 mm retail transactions per day.

Key Responsibilities:

Develop a close working relationship with a subset of business segments. Translate ambiguous business needs/questions into analytical approaches using available data (including Machine Learning and other approaches).
Able to assemble and guide small technical teams appropriate to the problem at hand. Provide strategic technical direction. Be able to take on accountability for business value.
Scope out and operationally deliver outcomes while making critical decisions regarding priorities, technologies and leadership guidance.
Oversee and guide the building, testing and deploy pipelines for Machine Learning (or other models) including, but not limited to, feature engineering, model train/test/validate, and repeatable analysis/measurement of results.
Be able to present internally and externally on technical matters and benchmark with peers in the technology space.
Keep the business and leadership abreast of next generation technology needs and help them develop and maintain a multi year roadmap consistent with Parkland’s growth.
Work with and support other team members, management, and partners.

Qualifications and Skills:

Advanced degree (MS/PhD) in a relevant technical field (e.g., Computer Science, Mathematics, Applied Mathematics, Statistics, Machine Learning, Data Science).
A minimum 10 years’ experience in data science, analytics, and model building roles in a business context.
Track record of working with, mentoring and leading technical teams towards measurable business output.
Fluency in statistical, machine learning (including neural network) methods from a mathematical and computational perspective.
Strong practical knowledge of applying analytical techniques and methodologies to business objectives, including: machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques.
Experience working with large complex data sets, real time/near real time analytics, and distributed big data platforms (Hadoop & MapReduce and/or Cassandra/Spark).
Strong knowledge of analysis tools such as Python, R, Spark, PySpark/R/Spark on Hadoop or Cassandra preferred.
Strong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc).
Proficiency in programming in Python, R, SQL, Javascript, Java/Scala/Ruby and shell scripting.
Natural curiosity and a strong passion for empirical research and problem solving.
Strong written and verbal communications skills; comfortable communicating with senior levels of both business and technology leadership.
The following are considered as asset:
Capability in data ingest and connector rools particularly Talend
Proficiency in workflow and CI/CD tools e.g., Airflow, CircleCI, Jenkins
Proficiency in consuming REST based API (with JSON payload)
Capability in big data platforms including Hadoop, MapReduce, Hive, Spark, PIG
Familiarity with Cloud based HaaS/PaaS solutions such as AWS EMR

We Offer:

Participation in Parkland Pledge, an employee-driven charitable giving program.
Our Performance-based Annual Incentive Plan, an annual bonus awarding your performance.
A share in our success through the Employee Share Purchase Plan and 100% company matching.
Flexible medical and dental packages, a Health Care Spending Account, along with a supportive Employee and Family Assistance Program.
In-house learning and development opportunities, leadership training, international opportunities.
An employee referral program – earn up to $2000 for your referral.
A focus on healthy living through wellness initiatives and an annual fitness reimbursement program.
Discount Programs and Educational Scholarship Programs for family members.

Candidates must be legally able to work in Canada or the United States at this time. Parkland regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.

We thank all candidates in advance for their interest, however only those being considered will be contacted.

Parkland Fuel Corporation is committed to the principles of Employment Equity.

We strive to provide accessibility in employment to ensure equal access to employment opportunities for candidates, including persons with disabilities. Parkland Fuel Corporation will endeavour to provide accommodation to persons with disabilities in the recruitment process upon request. If you are selected for an interview and you require accommodation due to a disability, please notify us upon scheduling your interview.","Parkland Corporation
3.3",Calgary
538,Senior Data Scientist,"Parkland is an independent supplier and marketer of fuel and petroleum products and a leading convenience store operator. We power a growing family of locally known brands and our team members serve retail, commercial, and wholesale customers across Canada, the United States, the Caribbean region and the Americas. Our purpose as Parklanders is to energize people and businesses to get them where they want to go. We’re a passionate team of down-to-earth achievers, committed to getting our customers, colleagues and communities further, faster.

Job Title: Senior Data Scientist

Location: Calgary, AB (we are open to candidates in Vancouver, Calgary, Montreal, or Toronto)

Position Summary:

Parkland Corporation is deeply invested in building next-generation Enterprise Data, Digital & Analytics capability, with an aspiration to improve our value to customers, our customers‘ experiences, and drive profitable growth and industry leadership for Parkland.

Parkland is seeking a Senior Data Scientist to be part of our newly forming Enterprise Digital Team – consisting of skillsets spanning machine learning, AI, Statistics, Data Engineering and full stack development. You will work as part of a high caliber team that works on solutions across Parkland’s business areas including Supply, Pricing and Loyalty, Retail, Commercial, Trading and Refining to drive high value solutions. As Canada and Caribbean’s largest and one of America’s fastest growing independent suppliers of fuel and marketing products and a leading convenience store operator, Parkland’s operations provide a rich and varied set of analytics opportunities, including over 1 mm retail transactions per day.

Key Responsibilities:

Develop a close working relationship with a subset of business segments. Translate ambiguous business needs/questions into analytical approaches using available data (including Machine Learning and other approaches).
Able to assemble and guide small technical teams appropriate to the problem at hand. Provide strategic technical direction. Be able to take on accountability for business value.
Scope out and operationally deliver outcomes while making critical decisions regarding priorities, technologies and leadership guidance.
Oversee and guide the building, testing and deploy pipelines for Machine Learning (or other models) including, but not limited to, feature engineering, model train/test/validate, and repeatable analysis/measurement of results.
Be able to present internally and externally on technical matters and benchmark with peers in the technology space.
Keep the business and leadership abreast of next generation technology needs and help them develop and maintain a multi year roadmap consistent with Parkland’s growth.
Work with and support other team members, management, and partners.

Qualifications and Skills:

Advanced degree (MS/PhD) in a relevant technical field (e.g., Computer Science, Mathematics, Applied Mathematics, Statistics, Machine Learning, Data Science).
A minimum 10 years’ experience in data science, analytics, and model building roles in a business context.
Track record of working with, mentoring and leading technical teams towards measurable business output.
Fluency in statistical, machine learning (including neural network) methods from a mathematical and computational perspective.
Strong practical knowledge of applying analytical techniques and methodologies to business objectives, including: machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques.
Experience working with large complex data sets, real time/near real time analytics, and distributed big data platforms (Hadoop & MapReduce and/or Cassandra/Spark).
Strong knowledge of analysis tools such as Python, R, Spark, PySpark/R/Spark on Hadoop or Cassandra preferred.
Strong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc).
Proficiency in programming in Python, R, SQL, Javascript, Java/Scala/Ruby and shell scripting.
Natural curiosity and a strong passion for empirical research and problem solving.
Strong written and verbal communications skills; comfortable communicating with senior levels of both business and technology leadership.
The following are considered as asset:
Capability in data ingest and connector rools particularly Talend
Proficiency in workflow and CI/CD tools e.g., Airflow, CircleCI, Jenkins
Proficiency in consuming REST based API (with JSON payload)
Capability in big data platforms including Hadoop, MapReduce, Hive, Spark, PIG
Familiarity with Cloud based HaaS/PaaS solutions such as AWS EMR

We Offer:

Participation in Parkland Pledge, an employee-driven charitable giving program.
Our Performance-based Annual Incentive Plan, an annual bonus awarding your performance.
A share in our success through the Employee Share Purchase Plan and 100% company matching.
Flexible medical and dental packages, a Health Care Spending Account, along with a supportive Employee and Family Assistance Program.
In-house learning and development opportunities, leadership training, international opportunities.
An employee referral program – earn up to $2000 for your referral.
A focus on healthy living through wellness initiatives and an annual fitness reimbursement program.
Discount Programs and Educational Scholarship Programs for family members.

Candidates must be legally able to work in Canada or the United States at this time. Parkland regrets that it is unable to sponsor employment Visas or consider individuals on time-limited Visa status for this position.

We thank all candidates in advance for their interest, however only those being considered will be contacted.

Parkland Fuel Corporation is committed to the principles of Employment Equity.

We strive to provide accessibility in employment to ensure equal access to employment opportunities for candidates, including persons with disabilities. Parkland Fuel Corporation will endeavour to provide accommodation to persons with disabilities in the recruitment process upon request. If you are selected for an interview and you require accommodation due to a disability, please notify us upon scheduling your interview.","Parkland Corporation
3.3",Calgary
539,Data Engineer,"BE authentic . BE influential . BE the expert . Be all that and more at Colliers.

At Colliers, we help leaders succeed by helping them build amazing workplaces, businesses and communities around the world. We do this by thinking differently, sharing innovative ideas and offering a unique and collaborative workplace where you can succeed.

Who you are

You will work directly with Global Finance management and North America Accounting on strategic projects to support and enhance our systems. Various reporting and data analysis tools will be used to design solutions that best meet business needs, both current and long term. This role will work closely with other IT, finance, payroll and accounting teams around the world to effectively deliver projects.


What you bring

5+ years of relevant experience in a similar role.
3+ years of experience with Microsoft SQL Server tools (SSRS, SSAS, SSIS).
5+ years of overall progressive financial reports development and 2+ years’ experience with SQL Server programming.
3+ years of experience with design and development of ETL processes.
Experience with best practices of information visualization, user interface design, and iterative customer-driven design processes.
Experience with Financial and Reporting applications.
Experience with developing test plans, test cases and training materials.
Knowledge of oriented object programming (Java, C++, C#, X++).
A “customer service” orientation and demonstrate a “can do” attitude.
Ability to think critically and analytically.
Ability to multi-task in a fast paced environment.
An eye for automation and process improvements.


Bonus skills and experience

Experience in the following applications/systems would be considered an asset:
IBM Cognos TM1
IBM Cognos BI
Microsoft Dynamics AX
Azure DevOps
Office 365


What success looks like

You develop and maintain ETL (MS SSIS) processes between Third Party systems and the North America ERP and Global Finance data store
You successfully Develop and maintain Microsoft SQL databases including creating and maintaining databases, tables, views, stored procedures, and database triggers.
You successfully work with managers, technical staff, and users to implement new reporting and integration solutions . This includes involvement in requirement analysis, test plans, individual and group training, meetings and documentation as well as ensuring that proper processes are followed in the systems life cycle to maintain responsive, reliable, and functional systems.
You analyze, design, develop, test and maintain complex Business Intelligence reports and dashboard using various front-end tools (Excel, Cognos BI, SQL SSRS, Power BI).

#LI-ON1

BE who you are and what you want to be with Colliers. We’d love to meet you. Apply today to join our team.



Direct applicants only please, no agencies.



Colliers is an equal opportunity employer and values diversity in its workforce. Colliers encourages applications from all qualified individuals and will accommodate applicants' disability-related needs, up to the point of undue hardship, throughout all stages of the recruitment and selection process. If you require a disability-related accommodation in order to participate in the recruitment process, please contact the recruitment team by email at careers@colliers.com.","Colliers International
3.7",Vancouver
540,Director- Data Strategy & Analytics,"Working under minimal supervision, the Director, Data Strategy & Analytics, is a business minded individual responsible for understanding the data needs across the enterprise and to develop and execute a roadmap to maximize data capabilities and business insights. The Director is responsible for scaling the data function as new products and services are implemented and transforming data into insights that inform strategy and decision making to support profitable growth.

Job Responsibilities:

Guide the future direction of data strategy and processes, including intake, sources, database design and structure, data integrity and database tools.
Transform data and information into insights that inform high-level strategy and tactical decision-making in support of revenue and profitability objectives.
Be a champion for a data driven culture, lead a team of cross-functional analysts and support and train staff in data systems and reporting.
Develop and execute a plan to maximize self-service capabilities for internal users and customers.
Proactively communicate and collaborate with internal and external customers to ensure information needs are formalized and understood and be conversant in the functional requirements for information exchange.
Oversee internal and external application/tool development, integration and support. Where required, supervise and evaluate external consultants.
Liaising with HSB US, UK and Munich Re as we forecast our needs, and business requirements.
Implementing business intelligence and analytics solutions and gaining support of multiple stakeholders.
Implementing formal data governance approach and increasing the maturity of the enterprise data capability and environment.
Influencing and effecting business process changes to support an efficient and cost-effective business operations environment.



Driven by technology and fuelled by innovation, HSB is Canada’s premier specialty insurance and applied technology services provider. Offering 150 years of technical and service excellence, we are focusing on emerging trends and unlocking new opportunities for clients. Today, we are accelerating, changing the future of insurance and risk solutions, for a modern world.

At HSB, we value the strengths and contributions of our diverse workforce. We offer continuous learning opportunities, giving you flexibility to grow in your career while enjoying a healthy work-life balance and a collaborative approach in our coast-to-coast network of offices. Become part of a rewarding and impactful workplace experience while seeing first-hand technologies and risk solutions that are changing the way we live and work.

HSB is much more! It’s Engineering, Insurance, Technology. To learn more about us, please visit www.hsb.ca



Seven years as an analyst, data scientist or data engineer preferably in the Property and Casualty insurance industry,
Masters or bachelor’s degree in one of the following: Analytics, Business Intelligence, Data Science, Economics, Engineering or Statistics,
Strategic mindset with demonstrated experience in implementing data frameworks and driving continuous improvement,
Expert communication skills and ability to influence leadership,
Experienced manager with focus on coaching and mentoring cross functional team members,
Knowledge of (re)insurance & products, financial metrics used in insurance and industry data sources,
Exposure to insurance company processes and functions,
Strong teamwork skills in order to collaborate and build strong relationships with co-workers and internal clients to support development and implementation of business solutions,
Project management skills plans, organizes, motivates, and controls resources to achieve specified project goals and objectives while respecting defined constraints,
Decision making skills: Solicits and objectively considers input from appropriate sources; Considers implications of actions on other areas, people, and processes when deciding,
Agility: Adapts approaches that are appropriate for each situation, Accepts and adapts to new situations.

We thank all candidates for their interest; however only those selected for interview will be contacted.","HSB BI&I
2.6",Midtown Toronto
541,"Data Engineer, Omnia AI (Montreal)","Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.




You have a passion for analytics and advanced Data Management? You want to build solutions that will allow customers to go further with the best of the existing Data solutions (AI/ML/ETL/Data lakes…)? Are you ready to uncover the possibilities of AI in your career and set the foundation for success tomorrow?
Then we have an opportunity waiting for you!

What will your typical day look like?

As a Data Engineer within our Omnia AI practice, you will be a team player to a portfolio of Deloitte’s Omnia AI engagements (projects). You will have the opportunity to be involved in the full life-cycle over AI projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. You will be able to work on the largest and most advanced Analytics projects on the market : 2019, 2020, 2021 Gartner Data & Analytics Service Provider leader.

Specifically, you will:

Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer.
Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed).
About the team

Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. We work closely with the Omnia AI Strategy, AI Data Science and AI Factory (custom developed AI assets) teams to drive successful business outcomes. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. To support our continued growth, we are looking to add many team players with hands-on work experience ideally in the data, analytics and/or AI domains.

Enough about us, let’s talk about you

You are someone with:

Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications
2+ years of experience in Data Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes
An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms
Team player attitude
Superior communication skills, intellectual curiosity, and strong analytical skills
Undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous

Differentiators but not required:

Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects
Bilingual (English / French)

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.
The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?


Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Montreal
542,"Data Engineer, Omnia AI (Montreal)","Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Enjoy flexible, proactive, and practical benefits that foster a culture of well-being and connectedness.




You have a passion for analytics and advanced Data Management? You want to build solutions that will allow customers to go further with the best of the existing Data solutions (AI/ML/ETL/Data lakes…)? Are you ready to uncover the possibilities of AI in your career and set the foundation for success tomorrow?
Then we have an opportunity waiting for you!

What will your typical day look like?

As a Data Engineer within our Omnia AI practice, you will be a team player to a portfolio of Deloitte’s Omnia AI engagements (projects). You will have the opportunity to be involved in the full life-cycle over AI projects, which includes contributing in proposal development and pursuit assistance, project delivery, and internal projects aiming to leverage top data management applications. You will be able to work on the largest and most advanced Analytics projects on the market : 2019, 2020, 2021 Gartner Data & Analytics Service Provider leader.

Specifically, you will:

Bring your expertise to customers who want to transform their company into a data-driven organization. You will be able to leverage all the existing assets created by Deloitte around AI applications, and combine them with your knowledge to build perfectly tailored applications for each customer.
Work with high profile clients on a variety of Canadian and international engagements, including opportunity to travel across Canada and internationally (as needed).
About the team

Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. We work closely with the Omnia AI Strategy, AI Data Science and AI Factory (custom developed AI assets) teams to drive successful business outcomes. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes. To support our continued growth, we are looking to add many team players with hands-on work experience ideally in the data, analytics and/or AI domains.

Enough about us, let’s talk about you

You are someone with:

Strong interest to bring Artificial Intelligence and Advanced Analytics to Enterprise applications
2+ years of experience in Data Modeling and ETL processes within Enterprise systems & Modern Analytic platforms: data lake, data warehouse, Datamart, dimensional models, ETL processes
An experience writing SQL queries or python scripts, extracting and importing disparate data from source systems to Analytics Platforms
Team player attitude
Superior communication skills, intellectual curiosity, and strong analytical skills
Undergraduate studies in Business/Engineering/Mathematics/Computer Science; postgraduate studies in Computer Science related specializations advantageous

Differentiators but not required:

Projects experiences with the following: Azure Data lakes, Snowflake, Databricks and Agile development methods in data-oriented projects
Bilingual (English / French)

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.
The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?


Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Montreal
543,Data Engineer,"Function: Data Science/Data Engineering
Reports to: Interim to SVP, Analytics and Optimization
Location: Toronto
Type: Full Time, Permanent**

Role Description
The Data Engineer is responsible for the deployment and maintenance of Machine Learning
systems and supporting data streaming pipelines in production. The role reports to the
Director, Data Science & Machine Learning.
As Data Engineer, you'll work closely with Data Scientists deploying and managing machine
learning solutions and build data streaming pipelines that support these solutions. You will
work with internal product and technology project teams involving large-scale data sets,
building Machine Learning pipelines for Machine Learning model training, and serving up the
personalized offers that power Exchange Solutions products.
This role is a unique opportunity to join a dynamic team of analytical professionals that
partners up with Business and Technology to design innovative, value-adding customer
engagement solutions for our clients. The role is a great fit for motivated individuals seeking
to further develop their expertise in the area of Machine Learning in the area of e-commerce
and customer loyalty personalized offers.

Primary Responsibilities
Be a part of a cross-functional organization that includes business product management,
technical product management, technical solution architects, data scientists, data
management, data analysts, software and Machine Learning engineers, etc.
Work closely with Product Managers, Architects, and Data Scientists to design, build,
maintain and optimize our data streams and machine learning applications.
Work with data scientists and engineers to deploy machine learning models in production.
Build and manage kinesis streams, feature stores used in Machine Learning model
training, and real-time prediction
Implement and automate continuous integration (CI), continuous delivery (CD), and
continuous training (CT) for machine learning (ML) systems.
Apply DevOps best practices and automated deployments, model and data versioning,
model validation, data validation, and monitoring Machine Learning production systems

Closely collaborate with Data Scientists and Machine Learning Engineers on the
implementation, scaling, and maintenance of data science solutions within personalized
offers products
Ensuring all relevant operational data sources ingest appropriately into standardized data
warehouse (Snowflake) schemas, working collaboratively with the Data Management
team
Implement and maintain model management and A/B testing framework for evaluating
test and trial of model and rule optimizations.
Participate in ESI Innovation labs as needed to support rapid product prototyping and
product development
Contribute to the overall operations and culture of the company, fostering our values and
policies.

Capability Requirements – education, skills & experience
Post-secondary education with a graduate degree in Computer Science, Machine
Learning, or related fields
Minimum 3-5 years’ experience with 1-2 years of data streaming experience
Proficiency with SQL and Python
Proficiency with SQL and NoSQL database technologies
Proven experience in implementation and maintenance of Machine Learning solutions
using AWS tooling such as kinesis streams, feature stores, Sagemaker, Lambdas
Understanding of open source streaming processing systems (Apache Kafka, Storm,
Spark streaming, Kinesis Analytics or Flink) will be a plus
Exposure to automated testing and CI/CD in the Machine Learning context
Understanding of fundamental Machine Learning concepts
Critical thinking, attention to detail and accuracy, high aptitude for problem-solving.
Excellent communication skills, both verbal and written.
Driven self-starter looking to learn, teach and contribute significantly to the energy of a
high-performing team.

Job Types: Full-time, Permanent","Exchange Solutions
4.0",Midtown Toronto
544,Senior Data Engineer | Ingénieur de Données Senior,"With thousands of beautiful spaces built for travel and living, Sonder is transforming the future of hospitality. Each Sonder is purposefully selected, designed and maintained - customized to reflect the vibe of its neighborhood. Whether your stay is two days, two months or two years, in a studio or a six-bedroom, Sonder ensures a unique, yet consistent experience. And with 24/7 contactless service, professional cleanings that exceed PHAC recommendations, and over 200 other quality standards, we're taking stay further for guests all around the world.

Sonder started in 2014, and now has thousands of spaces in cities across the globe.

The Data Engineering team is mainly focused on building and operating our data infrastructure, data warehouse, data and ETL pipelines, ML platform, and performing data modeling for analytics purposes. The team also partners with product engineering and data science teams to deliver data products to the business.

AT SONDER YOU WILL:
Build and operate our data infrastructure by building and maintaining the data platform, data pipelines, and the tools that ingest, process, transform and serve data
Build software libraries that standardize the acquisition, ingestion and integration of external data sources critical for real-time competitive intelligence and pricing
Use your expert SQL and data modeling skills to build the data warehouse base layer data models that will power Sonder's reporting dashboards
Establish and maintain the company's data lake/data warehousing strategy, define the appropriate data architecture, implement the best technical solution, and continue to meet the growing needs of the business;
Work with product and business analytics teams to ensure availability and accessibility of relevant business data and business metrics for product analytics and business performance reporting.
Understand Sonder's business intimately and model data that will be the source of truth for Sonder's business KPIs and metrics
Design and develop scalable platforms and processes for feature extraction, model training, and simulation
Own tools, processes and controls to help the team grow at scale.

WHAT WE LOOK FOR:
5+ years of experience working as a Data Engineer at a progressive company
Expert Python coding skills
Expert SQL and data modeling skills
Knowledge of data warehouse principles and methodologies
Experience in writing ETL jobs, performance tuning and query optimization
Strong communication skills and ability to gather requirements and translate them to specs and design
Experience with AWS cloud services and data warehouse stores like Redshift or Snowflake
Background in real estate or hotel industry is desirable
Self-driven, highly motivated and able to learn quickly

We offer great benefits to make your life easier so you can focus on what you're best at:

Competitive salary
Generous stock option plan
Medical, dental and vision insurance
Discretionary vacation/ Paid vacation and sick time
Annual free credits and discounts to stay in Sonders
Monthly culture budget: join your fellow colleagues for a monthly get together
A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues!

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Avec des milliers de beaux espaces construits pour le voyage et la vie, Sonder transforme l'avenir de l'hospitalité. Chaque Sonder est sélectionné, conçu et entretenu de manière ciblée, et personnalisé pour refléter l'ambiance de son quartier. Que votre séjour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, Sonder vous garantit une expérience unique, mais cohérente. Et grâce à un service sans contact 24 heures sur 24, 7 jours sur 7, à des nettoyages professionnels qui dépassent les recommandations de l'ASPC et à plus de 200 autres normes de qualité, nous allons encore plus loin pour nos clients du monde entier.

Sonder a débuté en 2014, et compte aujourd'hui des milliers de chambres dans des villes du monde entier.

L'équipe d'ingénierie des données se concentre principalement sur la construction et l'exploitation de notre infrastructure de données, de notre entrepôt de données, de nos pipelines de données et d'ETL, de notre plateforme ML et sur la modélisation des données à des fins d'analyse. L'équipe s'associe également à des équipes d'ingénierie de produits et de science des données pour fournir des produits de données à l'entreprise.

À SONDER VOUS LE FEREZ :
Construire et exploiter notre infrastructure de données en construisant et en entretenant la plate-forme de données, les pipelines de données et les outils qui ingèrent, traitent, transforment et servent les données

Créer des bibliothèques de logiciels qui normalisent l'acquisition, l'ingestion et l'intégration de sources de données externes essentielles pour la veille concurrentielle et la tarification en temps réel

Utilisez vos compétences en matière de SQL et de modélisation des données pour construire les modèles de données de la couche de base de l'entrepôt de données qui alimenteront les tableaux de bord de Sonder

Établir et maintenir la stratégie de l'entreprise en matière de lac de données/entreposage de données, définir l'architecture de données appropriée, mettre en œuvre la meilleure solution technique et continuer à répondre aux besoins croissants de l'entreprise ;

Travailler avec les équipes d'analyse des produits et des activités pour garantir la disponibilité et l'accessibilité des données commerciales pertinentes et des mesures commerciales pour l'analyse des produits et les rapports sur les performances commerciales.

Comprendre intimement l'activité de Sonder et modéliser les données qui seront la source de vérité pour les KPI et les métriques de l'activité de Sonder

Concevoir et développer des plates-formes et des processus évolutifs pour l'extraction de caractéristiques, la formation de modèles et la simulation

Des outils, des processus et des contrôles propres pour aider l'équipe à se développer à l'échelle.

CE QUE NOUS RECHERCHONS :
5+ ans d'expérience en tant qu'ingénieur de données dans une entreprise progressiste

Compétences d'expert en codage Python

Compétences d'expert en SQL et en modélisation de données

Connaissance des principes et des méthodologies de l'entrepôt de données

Expérience dans la rédaction de travaux ETL, l'optimisation des performances et des requêtes

Solides compétences en matière de communication et capacité à rassembler les exigences et à les traduire en spécifications et en conception

Expérience avec les services de cloud computing AWS et les entrepôts de données comme Redshift ou Snowflake

Une formation dans l'immobilier ou l'hôtellerie est souhaitable

Autonome, très motivé et capable d'apprendre rapidement

Nous vous offrons de grands avantages pour vous faciliter la vie afin que vous puissiez vous concentrer sur ce que vous faites de mieux :

Un salaire compétitif

Un plan d'options d'achat d'actions généreux

Assurance médicale, dentaire et visuelle

Vacances discrétionnaires/ Vacances payées et congés de maladie

Crédits annuels gratuits et réductions pour séjourner à Sonders

Budget mensuel de la culture : rejoignez vos collègues pour une réunion mensuelle

Une entreprise qui a une grande vision, un environnement de travail dynamique et une équipe de collègues intelligents, ambitieux et agréables à travailler!

Nous sommes un employeur souscrivant au principe de l'égalité des chances et valorisons la diversité au sein de notre entreprise. Nous ne faisons aucune discrimination fondée sur la race, la religion, la couleur, l'origine nationale, le sexe, l'orientation sexuelle, l'âge, l'état civil, le statut d'ancien combattant ou le handicap.","Sonder
3.2",Montreal
545,Junior Project Scientist / Junior Project Technician,"Junior Project Scientist / Junior Project Technician

Why join us?

This position is based out of our Environment & Geoscience (E&G) office in Fort St. John and reports to a Project Manager. You will be responsible for supporting our local environment team on a variety of projects in the site assessment and remediation and environmental monitoring sectors. The ideal candidate is a junior environmental engineering professional or recent graduate with an environmental engineering degree or diploma with some previous relevant experience which would be an asset.

E&G offers consulting services in the following areas: land reclamation, environmental studies, environmental impact assessments and social impact assessments, habitat assessments and compensation, aquatic life assessments, air quality assessments and greenhouse gas emissions, carbon credits, sustainability, environmental management and planning, geographic information systems, contaminated sites, waste management, mining, water distribution and treatment, pollution control and rural development.

Our offices are located in attractive regions of BC, with quick access to arts & culture and a variety of outdoor activities including mountain biking, skiing, hiking, hunting, and water sports. SNC-Lavalin offers a flexible work schedule and a relaxed office environment.

How will you contribute to the team?

Work directly with Project Managers and other project team members to meet client deliverables on time and on budget.
Conduct local and remote field work as directed on a diverse range of sites, with a focus on health & safety.
Execution of field programs including groundwater level monitoring, soil, sediment, groundwater, surface water and air sampling and surveying.
Supervision of contractors. Calibration and operation of field instruments and equipment.
Collection of field data and detailed documentation (e.g., field notes, site sketches, photographs).
Submission of field data and preparation of summaries for project managers

What will you contribute?

A bachelor's degree or diploma in environmental studies science, environmental, or a related discipline.
Eligible for professional registration (current registration is considered an asset).
Previous environmental or consulting work experience is preferred.
As the position will involve field work, the candidate must be able to lift up to 40 lbs, be willing to work in varying climatic conditions, and be willing to travel to remote locations and work away from home for extended periods.
Mechanical aptitude is considered an asset.
Excellent verbal and written communication skills.
Demonstrated organizational and time management skills.
Strong teamwork and collaboration skills.
Working knowledge of Outlook, Word and Excel.
Valid Class 5 BC driver's license.","SNC-Lavalin
3.6",Fort St. John
546,Big Data Engineer,"We are looking for a savvy Big Data Engineer to join our growing team of Enterprise Data and Advanced Analytics Platform. Reporting to the Head of Enterprise Data Delivery, the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. This individual will be be self-directed and comfortable supporting the data needs of multiple teams, systems , and products

Please note: this opportunity is available in one of the following locations: Toronto, Montreal, Calgary or Vancouver

Responsibilities:
Build and maintain efficient data pipeline architecture.
Assemble large, sophisticated data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Administration and managing of all AWS services, such as S3 buckets, RDS databases, EC2 instances, VPC network, Security Groups, Cloud Formation stacks, CloudWatch, Simple Notification Services SNS and EMR.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Practice established development subject areas such as good code management, branching , and merging of code in a GIT repository.
Has relevant and highly developed professional and technical skills; experience level of knowledge in the field of expertise of business/context
External client technical team teamwork to set up new clients on grapevine system
Support TMX internal/external users for application-related inquiries.

Qualifications:
University degree, College diploma or relevant job experience in Computer Science, Statistics or Mathematics at minimum
5-8 years of overall IT experience and 3+ years in Big Data development/design including the following Hadoop ecosystem components – HDFS, Hive, Sqoop, Flume, Pig, Kafka, Spark / Spark SQL, Oozie, Hue, Python and Java programming
Strong knowledge of various DBMS systems including NoSQL architectures and design principles.
Good understanding of AWS cloud technology and hadoop implementation on AWS including S3, EC2 and EMR
Experience working with Big data development tools like Zaloni, Talend, Pentaho will be advantageous
Experience in Scala, Ranger a plus
Experience in performance tuning Hive tables required
Experience in the configuration of YARN, MapReduce for performance, security is a plus
Experience crafting a technology stack for machine learning is a plus
Experience with development using Agile methodologies

Qualities:

Excellent interpersonal and communication skills
Strategic problem solver
Ability to multitask
Excellent analytical and problem-solving skills
Strong analysis/design experience
Meticulous attention to detail
Must be a self-starter with ability to follow through on projects assigned

TMX is committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and one which reflects the diversity of the community in which we operate. We provide accommodations for applicants and employees who require it.","TMX Group Limited
4.2",Midtown Toronto
547,Architecte Solutions Infonuagiques - Data (Cloud Solution Architect- Data),"Microsoft a comme mission de permettre à chaque personne et à chaque organisation de la planète d’en accomplir davantage. Poussés vers le haut par notre culture, nous adoptons une mentalité de croissance, inspirons l’excellence et encourageons les équipes et les dirigeants à donner le meilleur d’eux-mêmes chaque jour. Ce faisant, nous créons des innovations qui changent les vies de milliards de personnes dans le monde entier. Vous pouvez nous aider à accomplir notre mission.

Microsoft souhaite aider ses clients à réaliser leur propre transformation numérique grâce à la puissance de ses solutions et services Microsoft Cloud. C’est dans cette optique que Microsoft investit dans une équipe consacrée à la réussite de ses clients, qui aidera ces derniers à atteindre leurs résultats commerciaux.

Azure est à l’heure actuelle la plateforme infonuagique la plus complète, la plus novatrice et la plus souple qui soit. Par conséquent, Microsoft embauche des professionnels qui favoriseront l’adoption du nuage par les clients au sein des entreprises les plus importantes du marché.

Nous ne cessons jamais d’apprendre. Nous sommes animés d’une insatiable curiosité. Nous faisons face à l’incertitude, prenons des risques et apprenons rapidement de nos erreurs. Nous nous développons grâce aux idées des autres, car nous sommes meilleurs tous ensemble. Nous sommes émerveillés par ce que l’humain peut accomplir, et cela nous motive à encourager les autres à en faire plus grâce à nos technologies et à nos innovations. Ensemble, nous changeons les choses.

Pour en savoir plus sur la mission de Microsoft, visitez le site : https://careers.microsoft.com/mission-culture

Découvrez tous nos produits au : http://www.microsoft.com/fr-ca

Nous recherchons un architecte de solutions infonuagiques pour plateforme de données spécialisé en analyses avancées et en intelligence artificielle. Cette personne, qui devra être fortement motivée et passionnée, sera amenée à conduire des initiatives clients hautement prioritaires sur la plateforme Microsoft Azure en collaboration avec les clients et les secteurs d’activité de nos comptes entreprise. Il s’agit d’un poste en lien direct avec les clients, ayant pour responsabilité d’assurer la relation technique globale entre les clients et la plateforme de données, d’analyses avancées et d’intelligence artificielle de Microsoft.

Vous serez chargé des engagements techniques liés à la plateforme de données et aux analyses avancées envers les clients, y compris des séances de conception architecturale, des projets de mise en œuvre particuliers et des PPPV. Le candidat idéal aura de l’expérience dans des fonctions en lien direct avec les clients et aura réussi à mener, avec son équipe dirigeante, les architectes d’entreprise, l’équipe de gestion des TI et les développeurs, des discussions axées sur une architecture technique approfondie dans le but de mettre en œuvre les solutions de plateforme de données et d’analyses avancées.

Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us to achieve our mission.
Microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of Microsoft Cloud solutions and support offerings. To this end, Microsoft invests in a dedicated Customer Success team that will help Microsoft customers successfully realize their business outcomes.

Azure is the most comprehensive, innovative and flexible cloud platform today and Microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market.

We are always learning. Insatiably curious. We lean into uncertainty, take risks, and learn quickly from our mistakes. We build on each other’s ideas because we are better together. We stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. Together we make a difference.

To learn more about Microsoft’s mission, please visit: https://careers.microsoft.com/mission-culture

Check out all of our products at: http://www.microsoft.com/en-us

We are looking for a highly motivated and passionate Data Platform & Advanced Analytics/Artificial Intelligence Cloud Solution Architect to drive high priority customer initiatives on the Microsoft Azure Platform in collaboration with customers and the Microsoft field in Enterprise accounts segment of our business. This is a customer facing role, owning overall technical relationship between customer and Microsoft Data, Advanced Analytics and Artificial Intelligence Platform.

You will own the Data Platform & Advanced Analytics technical customer engagements including architectural design sessions, specific implementation projects and/or MVPs. The ideal candidate will have experience in customer-facing roles and success leading deep technical architecture discussions with senior customer executives, Enterprise Architects, IT Management and Developers to drive Data Platform and Advanced Analytics solutions to productions.
Responsibilities

Parmi les principales responsabilités :

Comprendre l’ensemble des données des clients, leurs priorités informatiques et d’affaires et les mesures de réussite afin de concevoir des solutions et des architectures de mise en œuvre.
Appliquer des connaissances techniques pour élaborer l’architecture de solutions qui répond aux besoins commerciaux et informatiques, créer des feuilles de route pour la plateforme de données, les analyses et l’IA, et assurer la viabilité technique à long terme des nouveaux déploiements en intégrant des technologies d’analyses clés au besoin (p. ex., SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.).
S’assurer que les solutions présentent de hauts niveaux de performance, de sécurité, d’évolutivité et de maintenabilité, ainsi qu’une réutilisabilité et une fiabilité adéquates au moment du déploiement.
Établir des liens étroits avec les principaux décideurs des TI et d’entreprise pertinents (comme l’IA ou l’analyse), qui ont la capacité d’encourager l’adoption de l’infonuagique au sein de leur entreprise pour faire d’eux des défenseurs du nuage.
Être la voix du client pour partager des renseignements et des pratiques exemplaires et pour interagir avec l’équipe d’ingénierie dans le but de supprimer les obstacles principaux.
Évaluer les connaissances des clients de la plateforme Azure et de la préparation globale à l’infonuagique de manière à soutenir les clients au moyen d’un plan d’apprentissage structuré et à assurer sa mise en œuvre grâce aux partenaires.
Collaborer avec d’autres architectes de solutions infonuagiques et intervenants MS pour développer des solutions d’entreprise complexes de bout en bout sur les plateformes infonuagiques Microsoft.
Maintenir les connaissances et les compétences techniques, suivre les tendances du marché et recueillir des renseignements concurrentiels, et collaborer et partager ses découvertes avec la communauté technique tout en renseignant les clients sur la plateforme Azure.
Être un évangéliste de la plateforme Azure auprès des clients, des partenaires et des communautés externes.

Key responsibilities include:
Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.
Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.)
Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment
Develop deep relationships with key customer IT decision makers and relevant business decision makers (like AI or Analytics), who drive long-term cloud adoption within their company to enable them to be cloud advocates
Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.
Collaborate with other Cloud Solution Architects and MS stakeholders in developing complex end-to-end Enterprise solutions on Microsoft Cloud platforms.
Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform
Be an Azure Platform evangelist with customers, partners and external communities.
Qualifications

Expérience requise en matière de formation, d’expériences clés, de connaissances et de compétences : expérience professionnelle. Au moins 5 ans de succès dans le domaine des ventes techniques consultatives ou complexes et du déploiement de projets de plateforme de données et d’analyses, ainsi que d’expérience en architecture, conception, mise en œuvre ou soutien d’applications distribuées à grande échelle obligatoire.

Développement de relations. Expérience reconnue en ce qui concerne l’établissement de relations techniques approfondies avec des dirigeants des TI de clients importants ou hautement stratégiques. Expérience de gestion des relations avec divers intervenants afin d’obtenir un consensus au sujet d’une solution ou de projets obligatoire.
Bon sens des affaires pour comprendre rapidement le secteur et les affaires du client de manière à avoir des discussions pertinentes avec les décideurs commerciaux.
Résolution de problèmes. Aptitude à résoudre les problèmes des clients au moyen de technologies infonuagiques
Collaboration et communication. Reconnaissance pour son expertise en matière de prise de décisions collaborative, de résolution de conflits et de suivi des mesures et décisions prises, en plus de compétences exceptionnelles en matière de communication verbale et écrite Aptitude à organiser et à mener avec influence des équipes virtuelles pour assurer le succès de la mise en œuvre des projets clients. Compétences de présentation avec très grande aisance face à des publics vastes ou plus restreints (dirigeants, équipe de gestion des TI, administrateurs de bases de données et scientifiques des données) obligatoires.


Profil technique

Expérience technique en milieu d’entreprise avec conceptions architecturales infonuagiques et hybrides de données et d’analyses, migrations de base de données et gestion de la technologie obligatoire
Expérience et aptitude technique à apprendre de nouvelles technologies et à comprendre les tendances infonuagiques pertinentes, en particulier dans les plateformes de données et l’analyse
Concurrence : connaissance des plateformes de développement infonuagique
Partenaires : compréhension des écosystèmes des partenaires et capacité à mettre à profit les solutions partenaires pour répondre aux besoins des clients souhaitables

Vastes connaissances et expérience technique avec expertise approfondie en la matière dans au moins deux des solutions de plateforme infonuagique pour les analyses de données et l’IA obligatoires

SQL, y compris les logiciels à code source libre (Postgres, MySQL, etc.), Azure SQL
Bases de données NoSQL, y compris les logiciels à code source libre (Maria, Mongo, etc.), Cosmos DB
Données massives, y compris SQL DW, Snowflake, Big Query, Redshift
Analyses avancées, y compris Azure Data Bricks, outils de visualisation comme PowerBI, Tableau
Gouvernance des données
Ingénierie des données
Science des données
Apprentissage automatique, y compris Azure ML, ML Server
Intelligence artificielle, y compris BOT framework, Cognitive Services, Cognitive Search
Expertise dans les charges de travail de l’environnement de données comme HDInsight, Hadoop, Cloudera, Spark, Python

Formation

Baccalauréat en informatique, en technologies de l’information, en ingénierie ou dans un domaine connexe souhaitable
Certification souhaitable dans au moins une des technologies suivantes : infonuagique, mobile, base de données, données massives, veille stratégique, science des données, apprentissage automatique, intelligence artificielle

Expérience

Expérience de travail dans un poste de consultation ou d’architecture au sein d’une entreprise de logiciels ou de services comme Amazon, VMware, Google, IBM ou Oracle souhaitable
Expérience antérieure de livraison de solutions chez des fournisseurs spécialisées en analyse et en IA


Microsoft souscrit au principe de l’égalité d’accès à l’emploi. Tous les candidats admissibles seront considérés pour le poste, peu importe l’âge, l’ascendance, la couleur, la nécessité d’un congé familial ou d’un congé de maladie, l’identité ou l’expression sexuelle, l’information génétique, l’état civil, l’état de santé, l’origine nationale, le handicap physique ou mental, l’allégeance politique, le statut d’ancien combattant, la race, la religion, le genre, l’état de grossesse, l’orientation sexuelle ou toute autre caractéristique protégée par les lois applicables, les réglementations ou les ordonnances.


Les avantages énumérés ci-dessous peuvent varier en fonction de la nature de votre emploi chez Microsoft et du pays où vous travaillez.


Knowledge and Skills: Professional Experience

5+ years of success in consultative/complex technical sales and deployment Data Platform and Analytics projects, architecture, design, implementation, and/or support of highly distributed applications required
Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. Required
Good business acumen to quickly understand the customer’s industry and business to have relevant discussions with business decision makers.
Problem Solving. Ability to solve customer problems through cloud technologies Required
Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) Required
Technical
Enterprise-scale technical experience with cloud and hybrid Data and Analytics architecture designs, database migrations, and technology management. required
The technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in Data Platforms and Analytics
Competitive Landscape: Knowledge of cloud development platforms
Partners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred
Breadth of technical experience and knowledge, with depth / Subject Matter Expertise in two or more of the following Data Analytics and AI Platform Cloud solutions required
SQL including OSS (postgres, MySQL etc), Azure SQL
NoSQL Databases including OSS (Maria, Mongo etc), Cosmos DB
Big Data including SQL DW, Snowflake, Big Query, Redshift
Advanced Analytics including Azure Data Bricks, visualization tools as PowerBI, Tableau
Data Governance
Data Engineering
Data Science
Machine Learning including Azure ML, ML Server
Artificial Intelligence including BOT framework, Cognitive Services, Cognitive Search
Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python
Education
Bachelor's degree in Computer Science, Information Technology, Engineer, or related field preferred
Certification in one or more of the following technologies preferred: Cloud, mobile, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence
Experience
Prior work experience in a Consulting/Architecture position within a software and/or services company such as Amazon, VMware, Google, IBM, Oracle desired
Prior solution delivery experience in Analytic and AI specialized solution providers

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Montreal
548,Lead Data Scientist,"We’re building a brand-new team to deliver the next-generation new product suites. This is a golden opportunity to join the team on the ground floor and you’ll have opportunity to not only to define and execute on the architecture, but also to build and shape the culture of the team.

Who We Are

To succeed in the modern world you must exploit digital resources and empower human capital. Often companies struggle to identify underlying opportunities and miss exploiting exponential technologies. IntegrityCo helps companies make the right investment with the best result. We help them beat the competition and reach their fullest potential. We make legendary products. This role is dedicated to help a client located in Washington; a Human Performance company, existing at the intersection of well-being and performance. Together we are unlocking human potential in the workplace by providing expert coaching, interactive content, meaningful incentives, and personalized insights in a fun, inspiring way. This helps to ignite cultures, create inclusivity, and build social connections that promote growth and flourishing of people in life and work.

Responsibilities
Position Description & Responsibilities
The role responsibilities include but are not limited to:

Design, prototype, and implement new machine learning system architectures and predictive models with a focus on classification and inference from time-series data.
Use statistical methods and machine learning techniques to create scalable prediction systems.
Conduct exploratory analysis - go deep into the data to develop hypotheses and to answer complex metric driven questions.
Make recommendations for new metrics, techniques, and strategies to improve methods to prioritize the performance of the platform.
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation.
Play the role of tech lead on the data science team, mentor fellow or junior data scientists.

Qualifications:

PhD or MSc in mathematics, statistics, computer science, physics, machine learning, micro-economics or other quantitative field or equivalent years of experience
5+ years working as a Data Scientist, Applied Researcher, or Machine Learning Scientist
5+ years of professional experience with a scripting language with fluency in Python and SQL.
Knowledgeable in two or more of the following: machine learning, information retrieval, statistical inference, and time-series analysis.
Solid understanding of statistical analysis and experimentation, and capacity to drive conclusions from the analysis in a scientific way.
Experience working with large scale data platforms such as Spark, Hadoop and cloud-based computing (preferably AWS).
Linux skills is a plus.
Exemplary communication skills, both verbal and written, ability to work with large cross functional teams of technical and non-technical members.
Ability to work across disparate data sources to obtain sensible results
Ability to draw conclusions from data and provide recommendations
Experience leading and managing a technical team
A strong passion for data, charts, analysis, trends, and evangelizing data usage with experience in data visualization software such as Tableau, and Power BI.
Proven track in leading, mentoring and growing teams of data scientists
Experience with defining organizational research and development practices in an industry setting
Experience in managing stakeholders and distilling complex requirements into analytical solutions

Community 
We are avid Zoom collaborators until we can be together again in our office space. Our community fosters collaboration, so be ready to converse and let ideas percolate! We believe diversity is a necessary element to our success as a business. We are committed to building a community that represents and celebrates a variety of backgrounds, perspectives and skills; we want you to bring your verve!

Location
We are currently fully remote.

Job Types: Full-time, Permanent

Salary: $140,000.00-$200,000.00 per year

Benefits:

Casual dress
Dental care
Extended health care
Life insurance
Vision care

Schedule:

Monday to Friday

Education:

Master's Degree (required)

Experience:

Python: 4 years (required)
statistical analysis: 2 years (required)
Machine Learning: 4 years (required)",integrityCo Solutions Inc.,Vancouver
549,Senior Data Engineer // Ingénieur·e des données,"Mistplay is the first Loyalty Program for mobile gamers. Players use our platform to play games, connect with friends, and earn awesome rewards; such as Amazon gift cards and prepaid Visas.

We leverage a wealth of in-game data and Machine Learning to recommend the best games to our users and coach developers of all sizes to help them build games. We use our marketing expertise and platforms to make sure our studio partners' games reach millions of players around the world.

With a growth of over 10 million users in under 3 years, Mistplay is one of the fastest-growing companies in North America. Join us as we continue to level up!



Mistplay is seeking a Data engineer to join our Engineering & Infrastructure team. We are a fast-growing start-up, which means you can jump into action and make significant contributions right away! Join our skilled, diverse and multidisciplinary team to build the data, analytics, and machine learning platform that we depend on. You'll have a unique opportunity to wear different hats so don't be afraid to roll up your sleeves and think of creative solutions to develop and improve our existing AI, database and pipeline solutions.

We're looking for self-starters who are focused on detail and quality while being passionate about making meaningful impacts within the company. Technical skills are important, but so is being a positive addition to our culture. A can-do attitude will take you a long way with Mistplay!

********************************************************************************************************************************

Mistplay recherche un·e ingénieur·e des données pour rejoindre notre équipe d'ingénieurie et d'infrastructure. Nous sommes une start-up à croissance rapide, ce qui signifie que vous pourrez passer à l'action et apporter des contributions significatives immédiatement ! Rejoignez notre équipe d'experts, diversifiée et multidisciplinaire, pour développer les données, l'analyse et la plateforme d'apprentissage automatique dont nous dépendons. Vous aurez l'occasion unique de prendre différentes casquettes, alors n'ayez pas peur de retrousser vos manches et de réfléchir à des solutions créatives pour développer et améliorer nos solutions d'IA, de base de données et de pipeline de données actuelles.

Nous recherchons des personnes capables de prendre des initiatives, qui ont le souci du détail et de la qualité, et qui ont à cœur d'avoir un impact significatif sur l'entreprise. Les compétences techniques sont importantes, mais il est tout aussi important de contribuer de manière positive à notre culture. Une attitude positive vous mènera loin chez Mistplay !


What You'll Be Doing:
Write and test code that is performant, scalable, maintainable and meets functional requirements
Build scalable data warehouses and ETL processes for consumption by various machine learning and analytics products in collaboration with the analysts and data scientists
Develop and maintain our current data architectures (Hive, Spark, Flink)
Develop tools to automate and handle data lifecycle and metadata management
Collaborate with other departments (Sales, Marketing and Product) to improve the quality and reliability of data
Vos responsabilités seront les suivantes:
Écrire et tester du code performant, évolutif, facile à maintenir et qui réponde aux exigences fonctionnelles.
Créer des data warehouses et des processus ETL évolutifs qui seront utilisés par divers produits d'apprentissage automatique et d'analyse en collaboration avec les analystes et scientifiques des données.
Développer et maintenir nos solutions d'architecture de données actuelles (Hive, Spark, Flink)
Développer des outils pour l'automatisation et la gestion du cycle de vie des données, ainsi que la gestion des métadonnées.
Collaborer avec les autres services (Ventes, Marketing et Produit) pour améliorer la qualité et la fiabilité des données.


What We're Looking For:
Bachelors degree in Computer Science or equivalent
Strong experience working with Python
3-5 years experience in working with big data tools (Hadoop, Spark & related technologies)
3-5 years with AWS or equivalent cloud provider
Knowledge of data persistence paradigms (relational, columnar, key-value etc.)
Curiosity and a willingness to learn
Ce que nous recherchons:
Baccalauréat (Bachelor's degree) en informatique ou équivalent.
Solide expérience professionnelle avec Python
3 à 5 ans d'expérience dans l'utilisation d'outils Big Data (Hadoop, Spark et technologies connexes).
3 à 5 ans d'expérience avec AWS ou un fournisseur de cloud computing équivalent.
Connaissance des paradigmes de persistance des données (relationnel, en colonnes, clé-valeur, etc.).
Curiosité et envie d'apprendre.
We work hard to make our work atmosphere as inviting and fun as possible! Working at Mistplay is coupled with a whole array of perks that we've adopted virtually and in-person: Team Lunches, game nights, company-wide events, and so much more.



Our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. We utilize data to constantly learn, improve, and adapt. We foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life.



Think you have what it takes? We'd love to meet you!","Mistplay
4.7",Montreal
550,Senior Data Engineer // Ingénieur·e des données,"Mistplay is the first Loyalty Program for mobile gamers. Players use our platform to play games, connect with friends, and earn awesome rewards; such as Amazon gift cards and prepaid Visas.

We leverage a wealth of in-game data and Machine Learning to recommend the best games to our users and coach developers of all sizes to help them build games. We use our marketing expertise and platforms to make sure our studio partners' games reach millions of players around the world.

With a growth of over 10 million users in under 3 years, Mistplay is one of the fastest-growing companies in North America. Join us as we continue to level up!



Mistplay is seeking a Data engineer to join our Engineering & Infrastructure team. We are a fast-growing start-up, which means you can jump into action and make significant contributions right away! Join our skilled, diverse and multidisciplinary team to build the data, analytics, and machine learning platform that we depend on. You'll have a unique opportunity to wear different hats so don't be afraid to roll up your sleeves and think of creative solutions to develop and improve our existing AI, database and pipeline solutions.

We're looking for self-starters who are focused on detail and quality while being passionate about making meaningful impacts within the company. Technical skills are important, but so is being a positive addition to our culture. A can-do attitude will take you a long way with Mistplay!

********************************************************************************************************************************

Mistplay recherche un·e ingénieur·e des données pour rejoindre notre équipe d'ingénieurie et d'infrastructure. Nous sommes une start-up à croissance rapide, ce qui signifie que vous pourrez passer à l'action et apporter des contributions significatives immédiatement ! Rejoignez notre équipe d'experts, diversifiée et multidisciplinaire, pour développer les données, l'analyse et la plateforme d'apprentissage automatique dont nous dépendons. Vous aurez l'occasion unique de prendre différentes casquettes, alors n'ayez pas peur de retrousser vos manches et de réfléchir à des solutions créatives pour développer et améliorer nos solutions d'IA, de base de données et de pipeline de données actuelles.

Nous recherchons des personnes capables de prendre des initiatives, qui ont le souci du détail et de la qualité, et qui ont à cœur d'avoir un impact significatif sur l'entreprise. Les compétences techniques sont importantes, mais il est tout aussi important de contribuer de manière positive à notre culture. Une attitude positive vous mènera loin chez Mistplay !


What You'll Be Doing:
Write and test code that is performant, scalable, maintainable and meets functional requirements
Build scalable data warehouses and ETL processes for consumption by various machine learning and analytics products in collaboration with the analysts and data scientists
Develop and maintain our current data architectures (Hive, Spark, Flink)
Develop tools to automate and handle data lifecycle and metadata management
Collaborate with other departments (Sales, Marketing and Product) to improve the quality and reliability of data
Vos responsabilités seront les suivantes:
Écrire et tester du code performant, évolutif, facile à maintenir et qui réponde aux exigences fonctionnelles.
Créer des data warehouses et des processus ETL évolutifs qui seront utilisés par divers produits d'apprentissage automatique et d'analyse en collaboration avec les analystes et scientifiques des données.
Développer et maintenir nos solutions d'architecture de données actuelles (Hive, Spark, Flink)
Développer des outils pour l'automatisation et la gestion du cycle de vie des données, ainsi que la gestion des métadonnées.
Collaborer avec les autres services (Ventes, Marketing et Produit) pour améliorer la qualité et la fiabilité des données.


What We're Looking For:
Bachelors degree in Computer Science or equivalent
Strong experience working with Python
3-5 years experience in working with big data tools (Hadoop, Spark & related technologies)
3-5 years with AWS or equivalent cloud provider
Knowledge of data persistence paradigms (relational, columnar, key-value etc.)
Curiosity and a willingness to learn
Ce que nous recherchons:
Baccalauréat (Bachelor's degree) en informatique ou équivalent.
Solide expérience professionnelle avec Python
3 à 5 ans d'expérience dans l'utilisation d'outils Big Data (Hadoop, Spark et technologies connexes).
3 à 5 ans d'expérience avec AWS ou un fournisseur de cloud computing équivalent.
Connaissance des paradigmes de persistance des données (relationnel, en colonnes, clé-valeur, etc.).
Curiosité et envie d'apprendre.
We work hard to make our work atmosphere as inviting and fun as possible! Working at Mistplay is coupled with a whole array of perks that we've adopted virtually and in-person: Team Lunches, game nights, company-wide events, and so much more.



Our culture is deeply rooted in growth and upheld by a team of smart, dynamic, and enthusiastic people. We utilize data to constantly learn, improve, and adapt. We foster an environment where everyone is encouraged to share their ideas, push boundaries, take calculated risks, and witness their visions come to life.



Think you have what it takes? We'd love to meet you!","Mistplay
4.7",Montreal
551,Data Engineer,"ABOUT AVID
Avid makes technology and collaborative tools so creators can entertain, inform, educate and enlighten the world. Our customers are the visionaries behind the most inspiring feature films, television programs, news broadcasts, televised sporting events, music recording and live concerts. To learn how Avid powers greater creators or for more information, visit www.avid.com.
JOB SUMMARY
The Data Engineer will work to design and develop data process to support Avid’s Master Data Management and Enterprise Analytics programs. The Data Engineer will focus primarily on designing and implementing the data pipeline and common data models that will create the new data foundation for our enterprise analytics function. This will include building the ETL/ELT processes and orchestration layer that will drive the development of our Enterprise Data Warehouse and fuel the successful implementation of 360 views of our Customer and Products, to aid Avid in optimally nurturing our customer relationships.
RESPONSIBILITIES AND DUTIES

Partner with business and IT management and develop relationships to solve data problems
Assist in development of principles, policies, standards and guidelines for data management
Develop (master) data processes and data models to ensure our enterprise data is structured for ease of use and optimized for performance
Design and build automated and scalable data processes to support Master Data Management and Enterprise Reporting applications
Collaborate with Integrations Team to create real-time and near real-time data connectivity between core business applications and data management platforms
Assist in implementing comprehensive testing and monitoring processes to ensure data quality and timely error detection
Build and support ETL/ELT and data architectures
QUALIFICATIONS & SKILLS

Bachelor’s degree in Computer Science or related field
Expert proficiency with SQL required, Python or other scripting language preferred
Proficiency with data management and data warehousing, experience with Snowflake or other cloud data warehouse solutions preferred
~5 years of experience in data management, data engineering and ETL/ELT development
~5 years of experience with schema design and dimensional data modeling
Must be able to effectively communicate both verbally and written with senior management
Demonstrates capacity for organization and planning of work-related activities and workloads
Ability to analyze and solve practical business problems, demonstrates good decision making, analytical and problem-solving skills, as well as a strong technical aptitude.
Experience with data virtualization tools a plus
Experience with API & JSON a plus
Experience with Python, R, Java or C# is a plus
Avid is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

#LI-MR1","SkipTheDishes
3.5",Montreal
552,Data Engineer,"At Neo, we empower people to get the most out of their money and time. We're a tech company reimagining everyday banking from the ground up to create rewarding experiences and build community for all Canadians. We're looking for passionate go-getters who want to move fast and create a lasting impact.

Neo Financial is looking for full-time Data Engineers to join our team in Calgary. As a Data Engineer at Neo, you'll be building out cutting edge data transformation, transmission, and storage systems for a team of data analysts & scientists. You’ll be hands-on working with the data lake and populating the store from a diverse and ever-changing set of sources. Tools like Databricks, Kafka and Airflow are your bread and butter! This is a ground-level role with the opportunity to set an example for the entire financial industry.

Our engineering team casts a wide net of problem solvers and self-starters, who are all energized by fast-paced work and can adjust their footing swiftly on any given day. Make your mark with transformative products and technologies, alongside some of Canada’s most successful developers and tech minds.
What you’ll be doing:
Use Spark (PySpark) in Databricks to perform data ingestions, transformations, and augmentations on large sets of data
Create and orchestrate data pipelines from a variety of different sources using Airflow
Supporting BI/analytics through building out an explorable data-lake in S3
Work with product management and analytics teams to take new ideas to production
Help integrate diverse systems into our data lake or data warehouse
Assist with the development of automated reports and delivery of analytics data
Who we're looking for:
2+ years of experience working in a data-intensive environment, preferably using Python and SQL
Experience using Apache Spark (PySpark)
Experience working in AWS
Able to create and maintain data pipelines in a production environment
Strong understanding of data engineering principles
Familiarity with BI/analytics tools such as Looker
Applicants must be eligible to work in Canada and willing to relocate to Calgary
What will help you succeed:
Adaptable, high-achievers energized by a startup environment
Team players who love being part of an agile ecosystem
Project owners who can engage with developers or other stakeholders
Makers with a drive to finish, impress users, and delight customers
What it’s like to work with us:

At Neo, you’ll be working with industry-leading technology that changes the way we live and realize a better financial future. It’s a serious deal, but that doesn’t mean we don’t know a thing or two about having fun. Our entrepreneurial environment gets our adrenaline pumping and beats the regular 9-5 job. We’re in it together, always. Gain hands-on experience and be part of the future.

About applying with Neo:

Please apply using Chrome, as applications are only supported using Chrome on desktop.

Neo Financial is an equal opportunity employer. We are excited to meet with and hire the top talent out there. We appreciate your interest in working with us; however, only those applicants selected for interviews will be contacted. Successful candidates for this position will be required to undergo a security screening, including a criminal records check and may require a credit check.","Neo Financial
4.3",Calgary
553,Data Engineer,"At Neo, we empower people to get the most out of their money and time. We're a tech company reimagining everyday banking from the ground up to create rewarding experiences and build community for all Canadians. We're looking for passionate go-getters who want to move fast and create a lasting impact.

Neo Financial is looking for full-time Data Engineers to join our team in Calgary. As a Data Engineer at Neo, you'll be building out cutting edge data transformation, transmission, and storage systems for a team of data analysts & scientists. You’ll be hands-on working with the data lake and populating the store from a diverse and ever-changing set of sources. Tools like Databricks, Kafka and Airflow are your bread and butter! This is a ground-level role with the opportunity to set an example for the entire financial industry.

Our engineering team casts a wide net of problem solvers and self-starters, who are all energized by fast-paced work and can adjust their footing swiftly on any given day. Make your mark with transformative products and technologies, alongside some of Canada’s most successful developers and tech minds.
What you’ll be doing:
Use Spark (PySpark) in Databricks to perform data ingestions, transformations, and augmentations on large sets of data
Create and orchestrate data pipelines from a variety of different sources using Airflow
Supporting BI/analytics through building out an explorable data-lake in S3
Work with product management and analytics teams to take new ideas to production
Help integrate diverse systems into our data lake or data warehouse
Assist with the development of automated reports and delivery of analytics data
Who we're looking for:
2+ years of experience working in a data-intensive environment, preferably using Python and SQL
Experience using Apache Spark (PySpark)
Experience working in AWS
Able to create and maintain data pipelines in a production environment
Strong understanding of data engineering principles
Familiarity with BI/analytics tools such as Looker
Applicants must be eligible to work in Canada and willing to relocate to Calgary
What will help you succeed:
Adaptable, high-achievers energized by a startup environment
Team players who love being part of an agile ecosystem
Project owners who can engage with developers or other stakeholders
Makers with a drive to finish, impress users, and delight customers
What it’s like to work with us:

At Neo, you’ll be working with industry-leading technology that changes the way we live and realize a better financial future. It’s a serious deal, but that doesn’t mean we don’t know a thing or two about having fun. Our entrepreneurial environment gets our adrenaline pumping and beats the regular 9-5 job. We’re in it together, always. Gain hands-on experience and be part of the future.

About applying with Neo:

Please apply using Chrome, as applications are only supported using Chrome on desktop.

Neo Financial is an equal opportunity employer. We are excited to meet with and hire the top talent out there. We appreciate your interest in working with us; however, only those applicants selected for interviews will be contacted. Successful candidates for this position will be required to undergo a security screening, including a criminal records check and may require a credit check.","Neo Financial
4.3",Calgary
554,"Sr. Data Scientist, Architectural Services / Scientifique de données sénior, Services d'architecture","The opportunity

The Architectural Services group provides Unity's developers with crucial opportunities for technical collaboration across the company that meaningfully improves how we build our products. This is accomplished by integrating with, storing, and analyzing large data sets that are enablers to make value-based business decisions that directly influence the way that we work as a company. As a Sr. Data Engineer working with the VP of Architectural Services, you will make an impact by navigating globally distributed data, provide insight on significant correlation and causality events, and improve our overall understanding of a given problem space. We do this in service to support the creation of sophisticated and engaging digital content.
What you'll be doing

Data integration, maintenance, and analysis using your problem-solving skills to reach data-informed conclusions

Develop, optimize, data models to improve our technology and development practices

Identify, define, and lead data engineering projects end-to-end

Research and collaborate on solutions that achieve specific measurable goals

Collaborate on your analysis, code, and approach with leadership to align with Unity's overall direction and needs

What we're looking for

Applied experience identifying, integrating, extracting, shaping data (Data warehousing & ETL) from various sources in production via on-prem or Cloud environments (e.g. MySQL, Postgres, GCP Big Table, AWS Aurora, or others)

Applied experience publishing and communicating data in a production environment by setting up dashboards, websites, and building presentations

Extensive experience developing applications with various programming/scripting languages utilizing light-weight front-end frameworks and microservices (e.g. Node/JS, Python, Go, Scala, R, or others)

Professional experience leading data-centric projects from problem identification to production with excellent analysis and interpersonal skills.

A Bachelor's degree in one of the following areas or equivalent experience: Computer Science, Mathematics, Data Analysis, or Data Engineering

You might also have

Prior experience with the Unity engine

Worked on large projects in a globally distributed, collaborative, and diverse environment

Life at Unity

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com .

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

L'opportunité

Le groupe Architectural Services offre aux développeurs de Unity des possibilités cruciales de collaboration technique à l'échelle de l'entreprise, qui améliorent de manière significative la façon dont nous concevons nos produits. Pour ce faire, nous intégrons, stockons et analysons de grands ensembles de données qui permettent de prendre des décisions commerciales basées sur la valeur qui influencent directement la façon dont nous travaillons en tant qu'entreprise. En tant que développeur de données principal travaillant avec le vice-président des Architectural Services, vous apporterez votre contribution en parcourant les données distribuées à l'échelle mondiale, en fournissant des informations sur les événements de corrélation et de causalité significatifs et en améliorant notre compréhension globale d'un espace-problème donné. Nous agissons ainsi pour soutenir la création d'un contenu numérique sophistiqué et attrayant.

Ce que vous allez faire :
Tirer parti de vos compétences en résolution de problèmes pour l'intégration, la maintenance et l'analyse des données afin de parvenir à des conclusions fondées sur les données

Développer et optimiser les modèles de données pour améliorer notre technologie et nos pratiques en matière de développement

Identifier, définir et diriger des projets de développement des données de bout en bout

Rechercher et collaborer à la mise en place de solutions qui permettent de réaliser des objectifs spécifiques et mesurables

Collaborer sur votre analyse, votre code et votre approche avec la direction pour s'aligner sur la direction générale et les besoins de Unity

Ce que nous recherchons :
Expérience appliquée d'identification, d'intégration, d'extraction et de mise en forme de données (entreposage de données et ETC) à partir de diverses sources en production au moyen d'environnements sur site ou infonuagiques (p. ex., MySQL, Postgres, GCP Big Table, AWS Aurora, ou autres)

Expérience appliquée de publication et de communication de données dans un environnement de production par la configuration de tableaux de bord, de sites Web et la création de présentations

Grande expérience de développement d'applications avec divers langages de programmation/script utilisant des environnements de développement frontaux légers et des micro-services (p. ex., Node/JS, Python, Go, Scala, R ou autres)

Expérience professionnelle dans la direction de projets liés aux données, de l'identification des problèmes à la production, avec d'excellentes compétences d'analyse et interpersonnelles

Baccalauréat dans l'un des domaines suivants ou expérience équivalente : informatique, mathématiques, analyse des données ou développement des données

Vous avez peut-être également

Expérience avec le moteur Unity

Expérience de travail sur de grands projets dans un environnement mondialement distribué, collaboratif et diversifié

La vie chez Unity

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com .

Unity est un employeur axé sur l'égalité qui s'engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d'emploi qui ne tiennent pas compte de l'âge, de l'ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l'identité sexuelle ou d'un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n'hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n'acceptons pas d'être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-LL2 #SEN","Unity Technologies
4.6",Montreal
555,Data Engineer,"Our client is seeking a Data Governance Analyst to be responsible for the design and implementation of enterprise data governance tooling i.e. Collibra and related. This role will also manage the sustainment and support operations, and delivery of new project workstreams. This is a 12-month contract available to candidates in Vancouver and Calgary. It is remote until further notice.

The Role:

Primarily responsible for configuring, monitoring, operating and supporting the primary Data Governance and metadata management tool, Collibra.
Is a subject matter expert with metadata and data governance solutions, specifically Collibra Data Governance Center (DGC), and is proficient in Collibra Connect as well as workflow development and design.
Collaborates with the Data Governance Team to define and document requirements for Collibra implementations and integrations. Understands and contributes to the development of Collibra integration solutions using MuleSoft. Integrates Data Governance automation software and metadata source systems using MuleSoft. This includes definitions, coding and implementing requirements for Collibra integrations.
Responsible for monitoring and operating metadata management software workflows / jobs and assisting in discovering, sourcing, transforming, loading, and linking metadata in and out of the metadata repository.
Responsible for operating and monitoring integration components between the metadata management software and other repositories.
Supports and contributes to process documentations, operations design, and automation of processes.
Ensure the confidentiality, integrity and availability of the data and ensure that backup and recovery procedures are in accordance with the business’ tolerance for data loss and the time available to recover.
Comply with and enforce the corporate policies for change management and release management when implementing system changes.
Comply with and enforce the corporate procedure for controlling and granting of application access permissions.
The Ideal Candidate:

Diploma / degree in Computer Science or equivalent experience
Experience in a variety of technologies including - Collibra DGC, Collibra Connect, Mulesoft, JDBC, MSFT SQL and Azure stack to name a few, including advance level experience working with data formats such as XML, CSV and JSON.
Hands-on working experience with the automation of data lineage provisioning and maintenance.
Strong experience in Data Governance of wide variety of data types (structured, semi-structured and unstructured data) and wide variety of data sources including Big Data technologies.
3+ years hands-on experience designing and implementing Collibra Connect custom integrations for data ingestion (Data Service Agreements, Data Elements, Data Quality Controls, Data Quality Results) into Collibra; and Collibra Integration solutions with downstream applications and databases;
3+ years hands-on experience designing and implementing API integrations using Mulesoft and Anypoint Studio or equivalent technologies, ideally integrating Collibra or similar metadata repositories with other IT systems.
3+ years hands-on experience designing and implementing Collibra workflows using Eclipse.
Experience with Azure DevOps software and Agile practices.
Ability to convert/translate requirements into design specifications.
A strong commitment to ensuring the privacy of information related to employees and third-parties.
Spanish language would be considered an asset.
If you are interested in this position and meet the above criteria, please click the Apply button to send your resume in confidence directly to Meagan Tunley, Consultant, Aplin Information Technology. Visit our website at www.aplin.com to view our job opportunities, career tips, and tools. We thank all applicants; however, only those selected for an interview will be contacted.

WE APPRECIATE YOUR INTEREST IN DAVID APLIN GROUP.

If this is your first introduction to us, we invite you to become one of our satisfied candidates. David Aplin Group has been Canadian owned since 1975. Our professional consultants are passionate about helping you find a fulfilling job or career and ensuring your complete satisfaction with our process. Our proven track record, over four decades long, is largely due to our team of highly skilled and successful specialists. Through superior service and a commitment to long-term relationships, we provide deep specialization in core areas for complete recruiting and HR solutions across Canada - all from one source. We look forward to exceeding your expectations!

Learn more about David Aplin Group and view all our current job opportunities, career tips, and tools at www.aplin.com","David Aplin Group
4.0",Calgary
556,Research Scientist – Protein Engineering & Lead Optimization,"AbCellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease. We are seeking a highly motivated scientist with experience engineering antibody sequences. Our ideal candidate is a self-directed scientist, a team-player who thrives in a fast-paced work environment with multiple competing priorities, and above all, someone who can learn and grow with us. This is an exciting opportunity to join one of Canada's fastest growing biotechs and to contribute to our cutting-edge research on next-generation antibody-derived therapies.

How you might spend your days:
Engineering antibody sequences, including bispecifics and single-chain antibodies to improve therapeutically relevant molecular properties

Performing data analysis of biophysical datasets from UPLC and SPR-based methods.

Implementation and evaluation of novel protein engineering techniques

Developing and iterating workflows to streamline common protein engineering tasks

Collaborating with teams across the company to understand protein engineering challenges and propose solutions

Organizing, supporting, and collaborating with team members to meet project deliverables and timelines

We'd love to hear from you if:
You are a creative problem solver and fast learner who believes in team work to tackle the most challenging scientific problems

You are self-motivated and have the initiative and drive to meet goals under tight project timelines

You think critically, and are passionate about the integration of computational and experimental protein engineering methods

Required qualifications and experience:
A PhD in Biochemistry (or related) or Computational Biology or MSc with 5+ years in an academic or industry lab environment

Great interpersonal skills with the ability to work collaboratively as a member of cross-functional team

Strong data analysis skills and the ability to interpret, communicate, and document large data sets. Familiarity with Python data analysis (Pandas, Numpy) is preferred.

Experience with common antibody engineering tasks, including humanization, reformatting, and bispecific antibody generation

Excellent verbal and written communication skills, including public presentation of complex data

Offers & benefits:
The opportunity to work with an inspired team on challenging problems that matter

An attractive compensation package, including health and lifestyle benefits

A minimum of 3 weeks' vacation

Opportunities for personal and professional development

About AbCellera:
At AbCellera, we're solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We're revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You'll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We're a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn't just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We're looking for someone like you to help us get there.

To apply:
Please submit your application through our website and refer to Job ID 21154 in your cover letter. We apologize in advance, but we receive a large volume of applications and are only able to contact those who are selected for an interview.","AbCellera
4.8",Vancouver
557,Solution Architect (Customer Data Platform),"A CDP Solution Architect helps clients get value out of their investment into a Customer Data Platform (CDP) by strategizing a scalable architecture with a strong focus on data governance and security. You will be working with a multidisciplinary team of Consultants, Data Engineers, Data Scientist, and Digital Marketers.

This is a remote opportunity.

Role and Responsibilities
Be a platform expert in leading CDP solutions like AEP, TreasureData, RedPoint or similar
Provide deep domain expertise in our client’s business, technology stack, and data infrastructure
Assess and audit the current state of a client’s marketing technology stack together with a Consultant
Work with a Consultant to strategize, architect, and document a scalable CDP implementation, tailored to the client’s needs
Translate business requirements into technical specifications
Lead technical delivery and provide guidance to the Data Engineers
Help implement the proper data governance for the CDP platform
Preferred Qualifications
College degree in Computer Science, Data Science, Analytics or related field
7+ years of experience architecting and building data pipelines
5+ years of experience working with multi-channel marketing hubs by Adobe, Salesforce or similar
Strong understanding of working with APIs
Strong understanding of customer data platforms and the modern data infrastructure
Experience working with cloud technologies such as AWS, Google Cloud, Azure or similar
Experience working with data warehouse solutions like Amazon Redshift, Google BigQuery, Snowflake, or similar
Exposure to Spark, Hadoop, and other big data technologies is a plus
Experience with analytics tools like Google Analytics or Adobe Analytics is a plus
Experience with marketing automation tools is a plus
Experience with A/B testing tools is a plus
#LI-Remote

If you have passion and intelligence, and possess a technical knack (even if you’re missing some of the above), we encourage you to apply.

Bounteous is focused on promoting an inclusive environment and is proud to be an equal opportunity employer. We celebrate the different viewpoints and experiences our diverse group of team members bring to Bounteous. Bounteous does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, physical or mental disability, national origin, veteran status, or any other status protected under federal, state, or local law.



Bounteous is willing to sponsor eligible candidates for employment visas.

For employment opportunities based in Canada:
Bounteous is an equal opportunity employer. We embrace diversity and are committed to creating an inclusive workplace. In accordance with the Ontario Human Rights Code and Accessibility for Ontarians with Disabilities Act, 2005, accommodation will be provided at any point throughout the hiring process, provided the candidate makes their accommodation needs known to Bounteous. We welcome applications from all qualified candidates.

**Must be legally eligible to work in Canada.","Bounteous
4.2",Canada
558,DATA ENGINEER,"DATA ENGINEER
POSITION CODE: 2021-063
LOCATION: The Globe and Mail, Toronto (Temporarily Remote)
SALARY: Commensurate with qualifications and experience
POSITION OVERVIEW:
The Globe and Mail is looking for a self-motivated data engineer with a passion for rapidly evolving tech and the media publishing industry. The ideal candidate is an experienced data pipeline developer and data wrangler who enjoys optimizing data systems and building them from the ground up. The incumbent will support DevOps, database architects, data analysts and data scientists on a variety of data initiatives and will ensure development activities are compliant with industry best practices.
The ideal candidate must be able to work autonomously in a fast-paced setting and be comfortable with supporting the data needs of multiple teams, systems and products. The candidate will be excited by the prospect of enhancing or even re-designing our company’s data architecture to support our next generation of products, pipelines and analytics.
RESPONSIBILITIES:
Create and maintain optimal and efficient data pipeline architecture that meet various functional/ non-functional business requirements
Identify, design, and implement internal process improvements including automating manual processes, optimizing data delivery workflows, re-designing infrastructure for greater scalability and cost savings, improving reporting query performance, etc.
Build the infrastructure required for efficient extraction, transformation, and loading of data from a wide variety of disparate data sources
Work with various internal stakeholders including Ad Operations, Revenue, Finance and Marketing supporting their data infrastructure initiatives
MINIMUM QUALIFICATIONS:
Formal training in software engineering, computer science or computer engineering
Strong analytical, problem-solving and project management skills
Deep understanding of good programming practices, design patterns, Functional Programming, and Object-Oriented Analysis and Design
Successfully implemented and released a large number of complex data pipelines using modern engineering frameworks in the past 3 years
Experience performing root cause analysis on internal and external data and processes to answer specific business questions, resolve performance bottlenecks and identify opportunities for improvement or enhancement
TECHNICAL CAPACITY:
Expert proficiency in SQL and relational database structures including 3 to 5 years of experience in cloud-based data warehousing technologies such as Snowflake or Redshift
Proven experience ingesting and transforming structured and non-structured data
Established experience developing and querying various REST and SOAP open/public, web and internal APIs
Established experience with big data tools including Hadoop, Apache Spark and Databricks
Expert proficiency with at least two object-oriented/object function scripting languages including Java, Scala and Python
Proven ETL pipeline automation and data propagation experience including authoring, scheduling and monitoring workflows using Airflow
Established experience with AWS Cloud Services including: EC2, EBS, S3, KMS Key Management, Landing Zone
Experience with Docker and software Containerization
NICE TO HAVE:
Experience with OLAP and OLTP Systems and large-scale ERPs Including Salesforce CRM and SAP ECC
Experience ingesting and modelling web/app analytics, clickstream or click path data
Working knowledge of message queuing, micro-batch and stream processing
Working knowledge of modern-day BI and data visualization tools including Tableau, PowerBI or BigQuery
Tableau Server and Site Management: deploying, configuring, maintaining and upgrading Tableau Server
Habitual in storing and maintaining source code versioning in Git
THE GLOBE AND MAIL IS DEDICATED TO DIVERSITY AND INCLUSION IN THE WORKPLACE
The Globe and Mail is committed to fostering an inclusive, accessible work environment, where all employees feel valued, respected and supported. We believe this strengthens our business and our journalism. We welcome and encourage applications from individuals from all groups, regardless of race, ethnicity, culture, gender, sexual orientation, religion, socio-economic status, age, and physical ability. As required by the Federal Contractors Program, The Globe also tracks the proportion of staff in the four Employment Equity categories (Women, Aboriginal Peoples, Persons with Disabilities, and Members of Visible Minorities) to ensure we are reflecting the areas in which we work.
The Globe and Mail offers accommodation for applicants with disabilities as part of its recruitment process. If you are contacted to arrange for an interview, please advise us if you require an accommodation.","The Globe and Mail
3.8",Midtown Toronto
559,SENIOR DATA SCIENTIST,"We are looking for a Senior Data Scientist who is enthusiastically driven to generate actionable insights and create new growth opportunities. You must have proven leadership skills to grow and foster a highly effective team capable of rapid learning and application. You will lead a team conducting research experiments, advanced statistical modelling and develop data-driven products across several domains including infrastructure optimization, logistics efficiency, and data visualization. This is a unique opportunity to apply your leadership skills in a growing company and lead our next generation products.

REQUIREMENTS
M.Sc. or Ph.D. in a quantitative field (e.g., Computer Science, Statistics, Financial Economics, Applied Mathematics, Computer Engineering, or other related discipline).
Significant experience solving problems with the required the use of advanced statistical modelling techniques.
Proven programming skills including experience conducting modelling and statistical analysis (e.g., R, Matlab), object-oriented software development (e.g., Python, Scala), and massive parallel processing (e.g., Spark, Apache Hadoop).
Excellent communication skills and ability to describe and present complex technical concepts in clear language.
Ability to lead teams and create an environment of continuous learning and open communication.
Ability to structure and lead a project from idea to experimentation to prototype to delivery.
WHAT WE EXPECT?
Self-starter that is focused and driven with amazing follow-through.
Enthusiastically tackling problems with a love for teaching and celebrating the successes of others.
Ability to synthesize information, evoke good conversation and consider problems from new perspectives.
Desire to share information with others and contribute to our top-notch learning environment.
Driven to delivery quality solutions.",Temetrix,Ottawa
560,Ingénieur de données - Data & Analytic / Data engineer - Data & Analytic - 313669,"Ingénieur de données - Data & Analytic

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Ingénieur de données - Data & Analytic pour une entreprise dans le domaine du transport. Notre client est situé à Montréal.





Description des tâches et responsabilités – Ingénieur de données - Data & Analytic

Les responsabilités du poste incluent :

Construire et concevoir des applications à grande échelle;
Architecture de base de données et entreposage de données;
Modélisation et extraction de données;
Modélisation statistique et analyse de régression;
Calcul distribué et algorithmes de fractionnement pour une précision prédictive.




Exigences du poste – Ingénieur de données - Data & Analytic

Développement Spark / Python;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks et / ou Snowflake;
Expérience ETL / Data;
Compréhension et expérience de travail avec le processus et le pipeline DevOps (nous utilisons Azure DevOps).




Type de poste
Contractuel 5 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH313669




____________ENGLISH VERSION___________

Data engineer - Data & Analytic
As a part of its agreements with its various clients, Procom is currently seeking a Data engineer - Data & Analytic for a company in the transport sector. Our client is located in Montréal.





Job details – Data engineer - Data & Analytic

Key responsibilities for this position include:

Building and designing large-scale applications;
Database architecture and data warehousing;
Data modeling and mining;
Statistical modeling and regression analysis;
Distributed computing and splitting algorithms to yield predictive accuracy.




Mandatory Skills – Data engineer - Data & Analytic

Spark / Python development;
Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Databricks and/or Snowflake;
ETL / Data experience;
Understands and experience working with DevOps process & pipeline (we use Azure DevOps).




Assignment Length
5-month contract – renewable

Start date
Immediately

Reference number
BH313669","Procom
4.3",Montreal
561,Cloud Data Engineer,"Role: Cloud Data Engineer

Location: Toronto, ON

Duration- Long Term

Mandatory skills and experience: (Please include skills related to technical as well as domain and non-technical skills and experience as applicable to the position)

Working on EMR, good knowledge of CDK and setting up ETL and Data pipeline

Coding - Python

AWS EMR, Athina, Supergule, Sagemaker, Sagemaker Studio

Data security & encryption

ML / AI

Pipeline

Redshift

AWS Lambda

Nice to have skills & experience:

Oracle/SQL Database administration

Data modelling

RDS & DMS

Serverless Architectrure

DevOps

Job Type: Contract

Schedule:

8 hour shift

Experience:

Lambda: 2 years (preferred)",apptoza inc,Midtown Toronto
562,Staff Data Engineer,"Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest.
What you'll do

Help shape the technical direction of a domain within the Data@ organization.

Build a reliable and scalable single source of truth core model data product for internal and external analytics and enable self-service.

Partner with product, data analyst, engineering teams and other data engineers to translate business requirements into data models with measurable transformation quality under SLA.

Develop and automate large-scale, high-performance data processing systems and visualization to ensure reliability and meet critical business requirements.

Lead data engineering projects, and overall strategy for data governance, security, privacy, quality, and retention.

Mentor data engineers and continue promoting data engineering and analytics tooling & standards.

What we look for

7+ years of experience in data modeling, data architecture, and other areas directly relevant to data engineering.

Technical leadership; capable of handling mentorship, cross functional project execution, and solid individual contributions.

Advanced SQL, ETL pipelines, Data modeling & design, SQL performance tuning in OLAP and Data Warehouse/Data Lake environments

Proficiency with programming languages (e.g. Python) and Data Warehouse technologies (NoSQL, logging, columnar, Snowflake, etc.), Big Data technologies (e.g Hadoop, Spark, etc.), analytics (Looker, Tableau, etc.)

Familiar with data governance frameworks and Agile methodology

Excellent written and verbal communication and interpersonal skills; able to effectively collaborate with technical and business partners.

Eager to learn new things and have a growth mindset.

BS/MS degrees in Computer Science, Engineering, or a related technical field.

Location

We're excited to announce that Affirm is now a remote-first company! This role can be located anywhere Canada with the exception of Quebec . Remote based employees may occasionally travel to an Affirm office for meetings or team building events. Our offices in San Francisco, New York City, Pittsburgh, Chicago, and Salt Lake City will remain operational and accessible for anyone to use on a voluntary basis.

#LI-Remote
Check out our remote-first approach to learn more about the new ways we work.

If you got this far, we hope you're feeling excited about this role. Even if you don't feel you meet every single requirement, we still encourage you to apply. We're eager to meet people who believe in Affirm's mission and can contribute to our team in a variety of ways—not just candidates who check all the boxes.

At Affirm, People Come First is one of our core values, and that's why diversity and inclusion are vital to our priorities as an equal opportunity employer. You can read about our D&I program here and our progress thus far in our 2020 DEI Report .

We also believe It's On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.

We will consider for employment qualified applicants with arrest and conviction records in accordance with applicable federal, state, and local laws, including the San Francisco Fair Chance Ordinance. By clicking ""Submit Application,"" I acknowledge that I have read the Affirm Employment Privacy Policy , and hereby consent to the collection, processing, use, and storage of my personal information as described therein.","Affirm
4.5",Ontario
563,Data Analyst Health Surveillance - BC Centre for Disease Control,"Data Analyst Health Surveillance
Epidemiology, BC Centre for Disease Control, $36.41 to $38.49 per hour


These roles will support various COVID-19 initiatives including COVID surveillance, overdose surveillance, environmental health surveillance, and data provision within public health reporting warehouse.

What you’ll do
Perform data management and preparation activities, including data extraction, transformation, and documentation. Develop and maintain data collection and recording systems such as databases, spreadsheets, and web-sites, including designing ad hoc reports. Write computer code and data queries to capture and edit data, and/or liaises with information systems department for same. Create analytic reporting tools to allow internal and external users to analyze data. Receive and respond to ongoing requests to evaluate data, systems, processes and procedures. Automate routine data management tasks using standard programming tools.
Perform descriptive analyses and produces summaries and analytical reports using statistical software and coding, identifying all data limitations that apply. Identify issues, trends, and developments. Communicate findings to Centre staff and external stakeholders at the local, provincial and federal level. Automate routine analyses using standard programming tools.
Monitor data quality in the information systems like the Public Health Information System and disease databases, proactively identify and communicate anomalies that indicate data quality issues, and ensure that data used for analysis purposes or distributed to stakeholders is of the highest quality possible. Follow up with regional health authorities on missing, erroneous, and duplicate data to achieve high quality data. Correct data errors in a timely manner. Document processes for these procedures.
Prepare and maintain documentation and report such as user guides, procedure manuals, metadata, code documentation, data security policies and data dictionaries.
Support data security by assigning and deleting access for various applications and network file systems. Ensure the secure transfer of patient data to stakeholders when authorized to.
Assist as needed with gathering data, entering data, researching historical and archival data, accessing on-line databases, performing interviews, and obtaining data from national, provincial and local agencies and individuals. Link data from separate sources such as the client registry and MSP.


What you bring
Bachelor’s Degree in Health Information Science or Computer Science or equivalent.
Three (3) years’ experience as a data analyst/scientist, preferably in community health and/or the health information field, or an equivalent combination of education and experience.
You will have the ability to:
Write data management and analysis programs using data programming tools such as SAS or R.
Manage and query data in large relational or multidimensional databases and data warehouses an asset.
Create data visualizations.
Use standard software packages, spreadsheet, statistical, graphical, database, communication and web software.
Have knowledge of descriptive statistics, PC systems, and applications.
Communicate effectively, both verbally and in writing.
Operate related equipment
Physically carry out the duties of the position.
What’s in it for you


Every PHSA employee enables the best possible patient care for our patients and their families. Whether you are providing direct care, conducting research, or making it possible for others to do their work, you impact the lives of British Columbians today and in the future. That’s why we’re focused on your care too – offering health, wellness, development programs to support you – at work and at home.
Join one of BC’s largest employers with province-wide programs, services and operations – offering vast opportunities for growth and development.
Access to more than 2,000 in-house training programs.
Enjoy a comprehensive benefits package, including municipal pension plan.
12 annual statutory holidays with generous vacation entitlement and accruement.
Perks include onsite fitness classes and discounts to 350 BC-wide recreational programs, travel, technology, car and bike sharing, and more.


Temporary Full-Time (until March 31, 2022)
$36.41 to $38.49 per hour
655 West 12th Avenue, Vancouver
Applications will be accepted until position is filled.
Monday to Friday; 0830-1630
Requisition Numbers: 105558, 105562, 105694, & 105835


What we do


BC Centre for Disease Control (BCCDC) bccdc.ca is dedicated to preventing and controlling communicable disease and promoting environmental health for the province.


Provincial Health Services Authority (PHSA) plans, coordinates and evaluates specialized health services with the BC health authorities to provide equitable and cost-effective health care for people throughout the province. Our values reflect our commitment to excellence and include: Respect people – Be compassionate – Dare to innovate – Cultivate partnerships – Serve with purpose. Learn more about PHSA and our programs: jobs.phsa.ca/programs-and-services


PHSA is committed to employment equity and hires on the basis of merit, encouraging all qualified individuals to apply. We recognize that our ability to provide the best care for our diverse patient populations relies on a rich diversity of skills, knowledge, backgrounds and experiences, and value a safe, inclusive and welcoming environment.


ATTN: PHSA Employees:


To be considered as a PHSA employee (internal applicant) for this position, you must apply online via your internal profile at http://internaljobs.phsa.ca


Please note the internal job posting will no longer be accessible after the expiry date of April 1, 2021. If the internal job posting has expired, please contact the Internal Jobs Help Desk and advise that you would like to be considered as a late internal applicant for this position. Please do not apply for the external job posting.


If you have not registered your internal profile, a password is required to log in for the first time. To obtain your password, please contact the Internal Jobs Help Desk at 604-875-7264 or 1-855-875-7264. Please note regular business hours are Monday – Friday (excluding stats), 8:30am to 4:30pm. For inquiries outside of regular business hours, please email the Internal Jobs Help Desk at internaljobshelpu@phsa.ca and a Help Desk Representative will contact you the next business day.","PHSA
3.6",Vancouver
564,"Senior Data Scientist, Advanced Analytics, Global Risk Management","Requisition ID: 106855

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.


The Senior Data Scientist, Advanced Analytics will taking a leading role in business use-cases delivery, in an agile rapid lab environment, aimed at accelerating benefits for customers and the bank, leveraging enterprise-level data management tools and advanced analytics. She/he will work closely with peers across Global Risk teams, the business lines, IT, and Digital Banking to expand the ‘Credit Science’ practice and drive the Global Risk Management Analytics COE interaction model. The candidate will identify and prioritize opportunities to deliver innovative Business Banking credit solutions leveraging liquidity, risk-reward predictions and strategy optimization frameworks.

Is this role right for you? In this role you, will:

Work in Agile Rapid Lab environment to deploy new credit solutions in 90-day increments
Support forward-thinking, high impact analytical use cases focused on supporting GRM Data, Analytics and Technology Strategy and deliver actionable insights to capitalize on business opportunities
Collaborate with GRM Analytics COE key stakeholders and partners to define machine learning and artificial intelligence best-practices for agile rapid labs
Support risk-reward predictions delivery, strategy optimizations and machine learning playbooks to drive innovative credit solutions within risk appetite thresholds
Build 1-2 analytical playbooks (i.e. Cashflow Insights, Pre-approved Credit, Credit Optimization, High Risk Account Management, Collections, Fraud, etc.) across global retail and business banking footprint to support growth or de-risking initiatives
Support Research & Development work focused on the effective application of design thinking and scalable advanced techniques to drive ideation and innovation in analytics, machine learning and artificial intelligence
Lead and support a high-performance environment and implements a people strategy that attracts, retains, develops and motivates their team by fostering an inclusive work environment; communicating vison/values/business strategy and managing succession and development planning for the team
Support GRM Analytics COE with thought leadership and R&D activities to influence GRM stakeholders on trends regarding practical applications of machine learning and artificial intelligence to banking
Understand how the Bank’s risk appetite and risk culture should be considered in decision making

Do you have the skills that will enable you to succeed in this role? - We'd love to work with you if you have:

University/Post graduate degree in relevant STEM discipline (Science, Technology, Engineering and Mathematics)
Ability to ingest and work with large volumes of structured and unstructured non-traditional data
Working experience with big data tools such as SQL, Hive, Spark
Working experience with open-source programming languages such as Python, R, Scala
Working experience with ML/AI techniques for strategy design (supervised, unsupervised, NLP, decision tree, reinforcement learning, recommendation engines, APIs)
Knowledge of strategy optimization leveraging operations research principles would be an asset
Working experience with cloud computing platforms such as MS Azure and Google Cloud
Working experience with DevOps principles and/or software engineering best practices would be an asset
Corporate, Commercial and Capital Markets experience is an asset
Working knowledge of visualization tools such as Tableau and Power BI would be an asset
Strong collaboration skills with ability to translate technical knowledge into business value
Effective communication skills with ability to prepare project documentation and presentations

What’s in it for you?

The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers.
A rewarding career path with diverse opportunities for professional development.
Internal development to support your growth and enhance your skills.
A competitive compensation and benefits package.
An organization committed to making a difference in our communities– for you and our customers.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown Toronto

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
565,Scientist 1 Immunology,"At Charles River, we are passionate about improving the quality of people’s lives. When you join our global family, you will help create healthier lives for millions of patients and their families.




Charles River employees are innovative thinkers, who are dedicated to continuous learning and improvement. We will empower you with the resources you need to grow and develop in your career.




As a Charles River employee, you will be part of an industry-leading, customer-focused company at the forefront of drug development. Your skills will play a key role in bringing life-saving therapies to market faster through simpler, quicker, and more digitalized processes. Whether you are in lab operations, finance, IT, sales, or another area, when you work at Charles River, you will be the difference every day for patients across the globe.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Designs and/or executes scientific testing strategies and studies. Leads assay development, assay validation or study conduct, or is involved in preparation of material [e.g. protein, nucleic acid, cells, etc.]. Reviews and interprets study data, communicates results to clients and writes final reports. Serves as Project Scientist, Principal Investigator, Contributing Scientist, Project Leader or Study Director, as applicable. Ensures compliance with protocols and all applicable SOPs. Troubleshoots and resolves assay or technical issues in the laboratory when scientific expertise is needed. May introduce new technologies or introduce improvements in existing technologies. Provides advisory functions to clients designing a program or experiment, dealing with specific dataset interpretation, or when appropriate answering questions from regulatory authorities.




We are seeking a Scientist 1 for our Immunology department site located Laval (Greater Montreal area) in Canada.




The following are responsibilities related to the Scientist 1:

Prepare and/or review study-related documentation (e.g. worksheets and technical procedures);

Prepare study schedules and draft study plans and amendments for Immunology studies (in collaboration with the study director, as applicable);

Ensure that the studies are planned efficiently with regard to the experiment required, staff requirements and their qualifications, health and safety legislation, such that the study will satisfy its objectives;

Monitor the laboratory activities during the study by conducting regular visits to the lab, by supervising critical activities and reviewing the records as appropriate;

Coordinate Immunology laboratory staff in the execution of method development/transfer, validation and sample analysis;

Perform appropriate analysis and interpretation of study data generated and advise accordingly.




The following are minimum qualifications related to the Scientist 1 position:

Master’s or Doctorate’s degree is a definite asset;

Minimum of 3 years of relevant experience including a minimum of 1 year in a scientific position relevant to Immunology

Working experience in more than one of the following areas: ELISA/ligand-binding assays, multiplex assays, flow cytometry, molecular biology, and/or cell-based assays;

Good knowledge and application of GLP;

Good practical experience in project management;

Bilingualism (French/English), verbal and written, is required;

Good organizational, interpersonal, leadership and communication skills;

Good problem solving and analytical skills;

Ability to work under time constraints and adapt to change;

Strong customer service orientation.





IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Corporate Functions
The Corporate Functions provide operational support across Charles River in areas such as Human Resources, Finance, IT, Legal, Sales, Quality Assurance, Marketing, and Corporate Development. They partner with their colleagues across the company to develop and drive strategies and to set global standards. The functions are essential to providing a bridge between strategic vision and operational readiness, to ensure ongoing functional innovation and capability improvement.","Charles River Laboratories
3.4",Laval
566,Cloud Data Engineer,"Summary

Operations Research and Analytics (ORA) is an emerging innovative team within Health Informatics Department at Providence Healthcare (PHC). The team is committed to design, develop, and deploy state-of-the-art analytical solutions and applications. Scope of the work is diverse and touches on a wide variety of challenges in the health sector, such as the patient flow management, patient scheduling, capacity planning, inventory management, and others.

Reporting to the Manager, Operations Research & Analytics, the Cloud Data Engineer develops and establishes scalable, efficient, automated processes for large scale data analyses, model development, validation and implementation. The position will closely collaborate with the other members of the ORA Team to create and deploy automated data pre-processing and machine learning models through the innovative understanding and use of large data sets to improve clinical processes and patient outcomes, and support data-driven decision making. The ideal candidate will have experience in data modeling, data warehousing, building ETL pipelines for machine learning models, and excellent problem solving ability dealing with huge volumes of medical and clinical data. The position will also stay apprised of current trends and research on all aspects of data engineering and machine learning techniques and works in collaboration with provincial and national colleagues.

Skills

Demonstrated strength in data modeling, ETL development, and data warehousing with solid knowledge of various industry standards such as dimensional modeling, and star schemas etc.
Knowledge of business intelligence environments (ETL tools, data profiling, data access, data model, etc.)
Good knowledge of SSIS and data modeling techniques with SQL Server.
Coding proficiency in Python.
Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).
Demonstrated skills in AI product design and proven ability to plan, organize, and coordinate AI product activities.
Demonstrated understanding of data privacy, security and related tools such as anonymization and encryption.
Excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non-technical partners and to communicate to multiple audiences using data storytelling and through graphics.
Demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building.
Physical ability to perform the duties of the job.

Education

Master’s Degree in Computer Science, Mathematics, or Engineering and at least five (5) years’ experience as a Data Engineer or related specialty (e.g., Software Developer, Business Intelligence Engineer, Data Scientist) including at least two (2) years’ experience building cloud solutions in Azure or AWS. An equivalent combination of education, training and experience would also be considered.

Job Types: Full-time, Permanent

Benefits:

Company pension
Dental care
Employee assistance program
Extended health care
Paid time off
Vision care

Schedule:

8 hour shift
Monday to Friday","Providence Health Care
4.1",Vancouver
567,Process Data Engineer,"The Chapman Group is pleased to support our client Eigen with the recruitment of their next Process Data Engineer.

As a Process Data Engineer, you will be the team member focused on digitizing our customers' quality and process control data into the Eigen platform. You will be responsible for managing the data and performance of AI models deployed to customer production environments. This process will require being involved in the full lifecycle of customer onboarding, helping define data dictionaries, definitions, analytics, and metrics for performance, and standardizing the model performance between Eigen and the customer. You will be the primary person tasked with monitoring and managing the performance of Eigen algorithms and models operating in the field.

In this role, you will be part of the Customer Engineering and Delivery team. You will be required to interact regularly on customer calls, and present findings and recommendations for optimizing Eigen AI performance in the field.

Responsibilities

As a Process Data Engineer, you will have the following responsibilities:

Work with customers to understand their manufacturing process and the data connected with their process.
Define the dictionary of data to be captured and processed for a given customer install.
Define the analytics and insights to be derived from the customer data.
Define the data labeling dictionary and lexicon for anomalies and defects in the customer's manufacturing process.
Work with the Eigen software engineering and data science teams to optimize the inputs and outputs required to train an AI model with machine learning to be used for real-time detection in a customer's production environment.
Use the Eigen data processing pipeline and tools (Jupyter, Python, etc.) to execute data analytics and derive insights from customer data.
Monitor the performance of models deployed in customer applications.
Work with the Eigen data processing pipeline, tools, and engineering team to tune and optimize the performance of models and algorithms deployed to customers.
Analyze data from customer escalations and provide recommendations to improve model performance in deployed customer applications.
Assist in root cause analysis where needed to respond to customer escalations.
Recommend opportunities for process improvement and automation within the Eigen monitoring and data processing pipeline.
Qualifications
A post-secondary degree in engineering. (Candidates with a mathematics degree may be considered if they have industrial manufacturing experience.)
Experience in industrial manufacturing, process control, quality assurance and quality control.
Expertise in quality and process control methodologies such as Six Sigma and Statistical Process/Quality Control.
Exposure and understanding of Information Technology, Artificial Intelligence/Machine Learning, and Industrial Automation.
Exposure and understanding of Industry 4.0 and Internet of Things (IoT) technologies and solutions.
Exposure and understanding of industrial manufacturing technologies and processes.
Strong programming skills in python and/or R
Database skills in relational databases and NoSQL data stores and experience in SQL and Jupyter Notebooks and familiarity with AWS.
Strong communications, presentation, interpersonal, and relationship skills, and experience interacting with customers.
Work With Us

We help leading, global manufacturers realize massive savings and reduce waste from their processes through our industrial vision solution. Our dedicated team has not only built a truly scalable AI-enabled solution, we're actually taking industrial vision to the next level. If you are interested in working in a fast-paced environment and like being on the cutting edge of technology, drop us a line at careers@eigen.io",The Chapman Group,Fredericton
568,Data Engineer,"Summary:

The Data Engineer will be responsible for supporting, defining, and executing plans to create reporting solutions for our business and support teams. Primarily, the Data Engineer will be accountable for the movement of data from our enterprise systems (SAP BW, SQL) and landing it into a structured dataset for reporting solutions to utilize. These solutions include, but are not limited to, Business Intelligence and Data Visualization tools (SQL Server Analysis Service / Azure Analysis Services, Power BI Desktop). This position will work with business leads and IT to gather the reporting requirements and will help develop the solution. SAP BW, SAP Business Object, Power BI, Excel, SQL, SSIS, Azure Data Factory, and other tools will be used as necessary to provide the best solution possible. This position will create and/or support data models of varying complexity from concept to completion including documenting the solution. This position will be a part of the global business intelligence team and must be able to work in a team environment and share knowledge.

Essential Job Duties:

Data Engineering responsibilities include, but are not limited to (90%):

Create and build robust data structures to support end user's analysis and decision making across multiple business verticals. This includes both end-to-end architecting and business solutioning.
Collaborate with end users and peers to understand requirements, formulate use cases, and then translate into an effective technical solution.
Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products.
Effectively communicate and interact with business and technical personnel in solving complex data related business and technical problems.
Monitor data warehouse eco-system and identify opportunities to make enhancements.
Ensure data processes run and complete on a timely basis to ensure business continuity.
Adhere to timelines and excel in a fast-paced, high-energy environment.
Coach and develop other data professionals.
Drive data best practices and contribute to development of overall data strategy and roadmap.

Stay informed of latest engineering methodologies and industry direction (10%):

Stay informed of the latest Data Engineering industry news and direction.
Other duties as assigned


Reporting Relationships:

Data Engineering works under general supervision and may take direction from BI Engineering and the Data & Analytics Management
Reports to Data & Analytics Manager


Credentials:

Required:

Associate’s Degree or two years relevant experience
Strong understanding of relational and dimensional data modeling (Kimball Dimensional Modeling Methodology). Advanced experience working with data warehouses and ETL applications with expert-level knowledge of relational data.
Clear communication skills; the ability to explain complex technical concepts to non- technical internal clients.
Expertise in SQL (e.g. MS SQL, T-SQL, PostgreSQL, SPARQL)
Advanced experience leveraging various strategies for ingesting, modelling, processing, and persisting data as well as excellent analytical and problem-solving skills.
Experience with cloud data warehousing and management solutions.
Familiarity with Power BI and other visualization solutions (e.g. Tableau, Looker, Qlik, etc.).
Be a self-starter, with the ability to learn new technologies and work independently - an ideal candidate is curious and always willing to implement the latest and greatest technologies.
Demonstrated experience with Azure Data Factory, Azure SQL Managed Instance, and Azure DevOps, SQL Server Integration Services and other industry grade ETL tools.

Preferred:

Bachelor’s Degree or four years relevant experience as a Data Engineer or related specialty with demonstrable track record in developing data solutions that are correct, stable, and high performing; provide business value; and use resources efficiently (e.g. system hardware, data storage, query optimization, cloud infrastructure, etc.).
Coding proficiency in one or more languages (e.g. Python, Scala, Ruby, Java), expertise
SAP Experience
Expertise with Power BI, SSAS/AAS, and SSIS/Azure Data Factory
Cloud Experience preferred (e.g. AWS, Azure, Google Cloud Platform, etc.).
Proficiency in foreign language (Spanish, Portuguese, French, German)

Physical Requirements:

Ability to sit at a computer terminal for long periods of time.
Ability to be physically in attendance at workstation at designated company office location during normal business hours designated for the position.
Ability to handle considerable stress at times.


ScanSource, Inc. is an Equal Opportunity Employer

EOE/M/F","ScanSource Canada Inc.
5.0",Mississauga
569,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","Mississauga, ON, Canada
Full-time


Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2020, Eurofins generated total revenues of EUR € 5.4 billion, and has been among the best performing stocks in Europe over the past 20 years.

Eurofins CDMO Alphora Inc. provides a fully integrated suite of services to support drug substance and drug product development from the IND enabling development stage, through to phase II & III supply, and commercial validation and manufacturing for niche APIs. In addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, Eurofins CDMO Alphora Inc. is committed to growing its state-of-the-art organization, with continued investments in its people, modern facilities, equipment, and instrumentation.

Job Description

We are currently sourcing for 3 upcoming roles:

Research Scientist
Senior Research Scientist
Group Leader

The successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients (APIs).

Responsibilities will include but are not limited to:

Research Scientist, Senior Research Scientist

Planning and execution of experiments in R&D laboratories
Data analysis, interpretation, and documentation in development reports
Development of inherently safe processes based on thermal hazard assessment
Maintaining a safe and well-organized laboratory work area
Technology transfer to both internal and external manufacturing facilities

Group Leader

In addition to above:

Leading API technology programs and Scientists associated
Provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project-related issues, generating interim and final reports, preparing executive summaries for Clients and executive management team
Qualifications

Experience and Education Requirements:

B.Sc. or M.Sc. in Chemistry with >10 years experience or Ph.D in Chemistry with >5 years experience in the pharmaceutical or biotechnology industry
The Group Leader position will require a Ph.D in Chemistry with >10 years experience in the pharmaceutical or biotechnology industry
Must have a strong knowledge of organic chemistry and hands-on experience in the synthesis of complex organic molecules
Experience in process scale-up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset
Must be highly motivated and have a proven record of success in multiple projects
Must be well organized and able to meet project timeline commitments
Must work well in a multi-disciplinary team environment and have excellent written and verbal communication skills.
Additional Information

What we offer:

Excellent full time benefits including comprehensive and medical coverage, dental, and vision options
Life and disability insurance
RRSP/DPSP eligibility with company match
Paid vacation and holidays
Employee Assistance Plan, Tuition Program and much more

WORKING CONDITIONS:

This position will be working in a laboratory/manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. Intermediate lifting requirements of no more than 50 lbs. Hazardous materials are handled using established safety procedures and appropriate PPE.
Shift work and overtime may be required, as well as working periodic weekends and/or evenings.

Eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply; if accommodations are required in the application or interview process, please contact us via www.eurofins.ca. Only shortlisted candidates will be contacted - no phonecalls or emails please. Selected candidates can expect to be contacted in 3-6 weeks.

NO AGENCIES, PHONECALLS OR EMAILS PLEASE","Eurofins Central Laboratory
3.4",Mississauga
570,Cloud Data Engineer,"Summary

Operations Research and Analytics (ORA) is an emerging innovative team within Health Informatics Department at Providence Healthcare (PHC). The team is committed to design, develop, and deploy state-of-the-art analytical solutions and applications. Scope of the work is diverse and touches on a wide variety of challenges in the health sector, such as the patient flow management, patient scheduling, capacity planning, inventory management, and others.

Reporting to the Manager, Operations Research & Analytics, the Cloud Data Engineer develops and establishes scalable, efficient, automated processes for large scale data analyses, model development, validation and implementation. The position will closely collaborate with the other members of the ORA Team to create and deploy automated data pre-processing and machine learning models through the innovative understanding and use of large data sets to improve clinical processes and patient outcomes, and support data-driven decision making. The ideal candidate will have experience in data modeling, data warehousing, building ETL pipelines for machine learning models, and excellent problem solving ability dealing with huge volumes of medical and clinical data. The position will also stay apprised of current trends and research on all aspects of data engineering and machine learning techniques and works in collaboration with provincial and national colleagues.

Skills

Demonstrated strength in data modeling, ETL development, and data warehousing with solid knowledge of various industry standards such as dimensional modeling, and star schemas etc.
Knowledge of business intelligence environments (ETL tools, data profiling, data access, data model, etc.)
Good knowledge of SSIS and data modeling techniques with SQL Server.
Coding proficiency in Python.
Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).
Demonstrated skills in AI product design and proven ability to plan, organize, and coordinate AI product activities.
Demonstrated understanding of data privacy, security and related tools such as anonymization and encryption.
Excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non-technical partners and to communicate to multiple audiences using data storytelling and through graphics.
Demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building.
Physical ability to perform the duties of the job.

Education

Master’s Degree in Computer Science, Mathematics, or Engineering and at least five (5) years’ experience as a Data Engineer or related specialty (e.g., Software Developer, Business Intelligence Engineer, Data Scientist) including at least two (2) years’ experience building cloud solutions in Azure or AWS. An equivalent combination of education, training and experience would also be considered.

Job Types: Full-time, Permanent

Benefits:

Company pension
Dental care
Employee assistance program
Extended health care
Paid time off
Vision care

Schedule:

8 hour shift
Monday to Friday","Providence Health Care
4.1",Vancouver
571,"Research Scientist, Senior Research Scientist, Group Leader - Synthetic Organic Chemistry in R&D - Eurofins CDMO Alphora Inc.","Mississauga, ON, Canada
Full-time


Company Description

Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins believes it is a global leader in food, environmental, pharmaceutical and cosmetics products testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.

In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to over 50,000 staff across a network of more than 900 independent companies in over 50 countries and operating more than 800 laboratories. Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.

In 2020, Eurofins generated total revenues of EUR € 5.4 billion, and has been among the best performing stocks in Europe over the past 20 years.

Eurofins CDMO Alphora Inc. provides a fully integrated suite of services to support drug substance and drug product development from the IND enabling development stage, through to phase II & III supply, and commercial validation and manufacturing for niche APIs. In addition to a continuing flow of interesting and challenging projects for global pharmaceutical and biotech companies, Eurofins CDMO Alphora Inc. is committed to growing its state-of-the-art organization, with continued investments in its people, modern facilities, equipment, and instrumentation.

Job Description

We are currently sourcing for 3 upcoming roles:

Research Scientist
Senior Research Scientist
Group Leader

The successful candidates will work on research, development, and implementation of process technologies for the manufacture of active pharmaceutical ingredients (APIs).

Responsibilities will include but are not limited to:

Research Scientist, Senior Research Scientist

Planning and execution of experiments in R&D laboratories
Data analysis, interpretation, and documentation in development reports
Development of inherently safe processes based on thermal hazard assessment
Maintaining a safe and well-organized laboratory work area
Technology transfer to both internal and external manufacturing facilities

Group Leader

In addition to above:

Leading API technology programs and Scientists associated
Provide project leadership by generating plans and timelines, preparing regular project updates, organizing and leading project meeting, communicating to the clients and other departments on project-related issues, generating interim and final reports, preparing executive summaries for Clients and executive management team
Qualifications

Experience and Education Requirements:

B.Sc. or M.Sc. in Chemistry with >10 years experience or Ph.D in Chemistry with >5 years experience in the pharmaceutical or biotechnology industry
The Group Leader position will require a Ph.D in Chemistry with >10 years experience in the pharmaceutical or biotechnology industry
Must have a strong knowledge of organic chemistry and hands-on experience in the synthesis of complex organic molecules
Experience in process scale-up, selection and sourcing of raw materials, setting specifications, economic and regulatory constraints will be an asset
Must be highly motivated and have a proven record of success in multiple projects
Must be well organized and able to meet project timeline commitments
Must work well in a multi-disciplinary team environment and have excellent written and verbal communication skills.
Additional Information

What we offer:

Excellent full time benefits including comprehensive and medical coverage, dental, and vision options
Life and disability insurance
RRSP/DPSP eligibility with company match
Paid vacation and holidays
Employee Assistance Plan, Tuition Program and much more

WORKING CONDITIONS:

This position will be working in a laboratory/manufacturing environment where most of the time will be standing or sitting at a lab bench, or sitting at desk working on a computer. Intermediate lifting requirements of no more than 50 lbs. Hazardous materials are handled using established safety procedures and appropriate PPE.
Shift work and overtime may be required, as well as working periodic weekends and/or evenings.

Eurofins supports equal opportunities for inclusion and invites all qualified applicants to apply; if accommodations are required in the application or interview process, please contact us via www.eurofins.ca. Only shortlisted candidates will be contacted - no phonecalls or emails please. Selected candidates can expect to be contacted in 3-6 weeks.

NO AGENCIES, PHONECALLS OR EMAILS PLEASE","Eurofins Central Laboratory
3.4",Mississauga
572,Data Engineer,"Summary:

The Data Engineer will be responsible for supporting, defining, and executing plans to create reporting solutions for our business and support teams. Primarily, the Data Engineer will be accountable for the movement of data from our enterprise systems (SAP BW, SQL) and landing it into a structured dataset for reporting solutions to utilize. These solutions include, but are not limited to, Business Intelligence and Data Visualization tools (SQL Server Analysis Service / Azure Analysis Services, Power BI Desktop). This position will work with business leads and IT to gather the reporting requirements and will help develop the solution. SAP BW, SAP Business Object, Power BI, Excel, SQL, SSIS, Azure Data Factory, and other tools will be used as necessary to provide the best solution possible. This position will create and/or support data models of varying complexity from concept to completion including documenting the solution. This position will be a part of the global business intelligence team and must be able to work in a team environment and share knowledge.

Essential Job Duties:

Data Engineering responsibilities include, but are not limited to (90%):

Create and build robust data structures to support end user's analysis and decision making across multiple business verticals. This includes both end-to-end architecting and business solutioning.
Collaborate with end users and peers to understand requirements, formulate use cases, and then translate into an effective technical solution.
Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products.
Effectively communicate and interact with business and technical personnel in solving complex data related business and technical problems.
Monitor data warehouse eco-system and identify opportunities to make enhancements.
Ensure data processes run and complete on a timely basis to ensure business continuity.
Adhere to timelines and excel in a fast-paced, high-energy environment.
Coach and develop other data professionals.
Drive data best practices and contribute to development of overall data strategy and roadmap.

Stay informed of latest engineering methodologies and industry direction (10%):

Stay informed of the latest Data Engineering industry news and direction.
Other duties as assigned


Reporting Relationships:

Data Engineering works under general supervision and may take direction from BI Engineering and the Data & Analytics Management
Reports to Data & Analytics Manager


Credentials:

Required:

Associate’s Degree or two years relevant experience
Strong understanding of relational and dimensional data modeling (Kimball Dimensional Modeling Methodology). Advanced experience working with data warehouses and ETL applications with expert-level knowledge of relational data.
Clear communication skills; the ability to explain complex technical concepts to non- technical internal clients.
Expertise in SQL (e.g. MS SQL, T-SQL, PostgreSQL, SPARQL)
Advanced experience leveraging various strategies for ingesting, modelling, processing, and persisting data as well as excellent analytical and problem-solving skills.
Experience with cloud data warehousing and management solutions.
Familiarity with Power BI and other visualization solutions (e.g. Tableau, Looker, Qlik, etc.).
Be a self-starter, with the ability to learn new technologies and work independently - an ideal candidate is curious and always willing to implement the latest and greatest technologies.
Demonstrated experience with Azure Data Factory, Azure SQL Managed Instance, and Azure DevOps, SQL Server Integration Services and other industry grade ETL tools.

Preferred:

Bachelor’s Degree or four years relevant experience as a Data Engineer or related specialty with demonstrable track record in developing data solutions that are correct, stable, and high performing; provide business value; and use resources efficiently (e.g. system hardware, data storage, query optimization, cloud infrastructure, etc.).
Coding proficiency in one or more languages (e.g. Python, Scala, Ruby, Java), expertise
SAP Experience
Expertise with Power BI, SSAS/AAS, and SSIS/Azure Data Factory
Cloud Experience preferred (e.g. AWS, Azure, Google Cloud Platform, etc.).
Proficiency in foreign language (Spanish, Portuguese, French, German)

Physical Requirements:

Ability to sit at a computer terminal for long periods of time.
Ability to be physically in attendance at workstation at designated company office location during normal business hours designated for the position.
Ability to handle considerable stress at times.


ScanSource, Inc. is an Equal Opportunity Employer

EOE/M/F","ScanSource Canada Inc.
5.0",Mississauga
573,Data Engineer,"Summary:

The Data Engineer will be responsible for supporting, defining, and executing plans to create reporting solutions for our business and support teams. Primarily, the Data Engineer will be accountable for the movement of data from our enterprise systems (SAP BW, SQL) and landing it into a structured dataset for reporting solutions to utilize. These solutions include, but are not limited to, Business Intelligence and Data Visualization tools (SQL Server Analysis Service / Azure Analysis Services, Power BI Desktop). This position will work with business leads and IT to gather the reporting requirements and will help develop the solution. SAP BW, SAP Business Object, Power BI, Excel, SQL, SSIS, Azure Data Factory, and other tools will be used as necessary to provide the best solution possible. This position will create and/or support data models of varying complexity from concept to completion including documenting the solution. This position will be a part of the global business intelligence team and must be able to work in a team environment and share knowledge.

Essential Job Duties:

Data Engineering responsibilities include, but are not limited to (90%):

Create and build robust data structures to support end user's analysis and decision making across multiple business verticals. This includes both end-to-end architecting and business solutioning.
Collaborate with end users and peers to understand requirements, formulate use cases, and then translate into an effective technical solution.
Participate in brainstorming sessions and contribute ideas to our technology, algorithms and products.
Effectively communicate and interact with business and technical personnel in solving complex data related business and technical problems.
Monitor data warehouse eco-system and identify opportunities to make enhancements.
Ensure data processes run and complete on a timely basis to ensure business continuity.
Adhere to timelines and excel in a fast-paced, high-energy environment.
Coach and develop other data professionals.
Drive data best practices and contribute to development of overall data strategy and roadmap.

Stay informed of latest engineering methodologies and industry direction (10%):

Stay informed of the latest Data Engineering industry news and direction.
Other duties as assigned


Reporting Relationships:

Data Engineering works under general supervision and may take direction from BI Engineering and the Data & Analytics Management
Reports to Data & Analytics Manager


Credentials:

Required:

Associate’s Degree or two years relevant experience
Strong understanding of relational and dimensional data modeling (Kimball Dimensional Modeling Methodology). Advanced experience working with data warehouses and ETL applications with expert-level knowledge of relational data.
Clear communication skills; the ability to explain complex technical concepts to non- technical internal clients.
Expertise in SQL (e.g. MS SQL, T-SQL, PostgreSQL, SPARQL)
Advanced experience leveraging various strategies for ingesting, modelling, processing, and persisting data as well as excellent analytical and problem-solving skills.
Experience with cloud data warehousing and management solutions.
Familiarity with Power BI and other visualization solutions (e.g. Tableau, Looker, Qlik, etc.).
Be a self-starter, with the ability to learn new technologies and work independently - an ideal candidate is curious and always willing to implement the latest and greatest technologies.
Demonstrated experience with Azure Data Factory, Azure SQL Managed Instance, and Azure DevOps, SQL Server Integration Services and other industry grade ETL tools.

Preferred:

Bachelor’s Degree or four years relevant experience as a Data Engineer or related specialty with demonstrable track record in developing data solutions that are correct, stable, and high performing; provide business value; and use resources efficiently (e.g. system hardware, data storage, query optimization, cloud infrastructure, etc.).
Coding proficiency in one or more languages (e.g. Python, Scala, Ruby, Java), expertise
SAP Experience
Expertise with Power BI, SSAS/AAS, and SSIS/Azure Data Factory
Cloud Experience preferred (e.g. AWS, Azure, Google Cloud Platform, etc.).
Proficiency in foreign language (Spanish, Portuguese, French, German)

Physical Requirements:

Ability to sit at a computer terminal for long periods of time.
Ability to be physically in attendance at workstation at designated company office location during normal business hours designated for the position.
Ability to handle considerable stress at times.


ScanSource, Inc. is an Equal Opportunity Employer

EOE/M/F","ScanSource Canada Inc.
5.0",Mississauga
574,Sr. Data Analyst,"Since being founded in 2011, Prodigy Education has grown from 3,000 local users to more than 100 million registered users worldwide. As one of the fastest-growing EdTech startups in North America, Prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. Anyone with an internet connection is welcome to create a free account for Prodigy’s popular Math Game for grades 1 to 8. Prodigy Education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. For more information visit www.prodigygame.com.

Our passion is our mission - to help every student in the world love learning!

Our data and marketing teams are scaling rapidly as we continue to hit our product and growth milestones! The work you do here will aid the educational advancement of millions of students. You will have the chance to apply your analytics skills to not only help kids learn but also help our marketing team to make better decisions.

We are looking for a marketing data analytics expert to join our growing team. As we scale our marketing efforts, the team will be looking to you for insights on the effectiveness of initiatives, and opportunities for optimization and growth. You will have the chance to apply your marketing analytics expertise to add real strategic value and ensure that we are asking and answering the right questions.
Your Impact:
Collaborate with data analysts, data scientists, data engineers, and team leads to create solutions which will directly affect Prodigy’s growth
Help our marketing team explore, analyze, and understand their data to help marketing make channel investment decisions
Improve data visibility by building dashboards and charts to inform strategy, and capture market and user insights
Benchmark performance across all channels and inform campaign optimization based on performance analysis
Work with the marketing and data teams to improve data quality to provide high quality insights and recommendations
Help design, execute, and evaluate experiments (e.g., A/A, A/B, multivariate tests etc)
Communicate insights, analysis, and recommendations clearly and accurately to stakeholders with a variety of technical and non-technical backgrounds.
Who You Are:
At least 2 years demonstrated analytics experience
Worked extensively with Marketing teams
Expert skills and knowledge of SQL.
Expertise in working with various BI platforms (Tableau, Looker, Periscope)
Experience working with A/B testing and experimentation
Experience in marketing analytics
Ability to work simultaneously on different projects with a variety of timelines
Ability to translate data insights into actionable steps
A team and customer centric mindset
Love for our mission of helping kids everywhere enjoy learning
Bonus Points For:
Experience in cloud ecosystems and their data tooling (AWS, GCP)
Knowledge of Python/R languages
Knowledge of Google Analytics and Google Tag Manager
Experience with Spark
Demonstrated ability to solve hard mathematical, algorithmic, and statistical problems.
Significant accomplishments that required both technical and strategic capabilities, such as research projects, open-source software contributions, and entrepreneurship
What We Offer:
A culture of transparency, where team members are involved in important conversations
Full health benefits from day one (1) for you and your family, fully covered!
We are a profitable company, with eligibility to participate in stock options for all full-time permanent employees
Learning and development budget for all full-time employees to use towards career growth and development opportunities
We recognize 9-5 is not for everyone! We offer flexible working hours that will allow you to schedule your workday with a bit more freedom!

While we operate 100% remotely, for the time being, we understand the importance of togetherness. We offer frequent and fun team and company events, to stay connected and in the know.

Please note: During the Covid-19 pandemic, in order to keep all our candidates and team members safe, Prodigy is operating, hiring and onboarding 100% remotely for the time being.

Come as you are. We believe the power of our collective potential will transform education. We are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. We welcome applications from people from all underrepresented groups, including (but not limited to) people of any gender, age, or religion, members of the LGBTQIA2+ community, BIPOC and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of Prodigy Education. If you feel like you don’t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we’d still love for you to apply!

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Education will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require accommodation, please notify us and we will work with you to meet your needs.","Prodigy Game
4.8",Oakville
575,Data Engineer/Analyst - Active Safety & Autonomous Data Recording and Analytics,"About GM

There’s never been a more exciting time to work for General Motors.

To achieve our vision of a world with Zero Crashes, Zero Emissions and Zero Congestion, we need people to join us who are passionate about creating safer, better and more sustainable ways for people to get around. This bold vision won’t happen overnight, but just as we transformed how the world moved in the last century, we are committed to transforming how we move today and in the future.

Why Work for Us

Our culture is focused on building inclusive teams, where differences and unique perspectives are embraced so you can contribute to your fullest potential as you pursue your career. Our locations feature a variety of work environments, including open work spaces and virtual connection platforms to inspire productivity and flexible collaboration. And we are proud to support our employees volunteer interests, and make it a priority to join together in efforts that give back to our communities.

Job Description

Core Responsibilities

Own and develop software and data analysis solutions as part of a larger team; leading and participating in data pipeline development and maintenance
Collaborate with others to develop requirements and perform design reviews to create data pipeline schemas, tools, and/or GUIs
Create pipelines to acquire and compile structured and unstructured data from various data sources, and verify data quality, accuracy, and robustness
Conduct data pipeline verification (e.g. bench, and in-vehicle tests as needed)
Prepare and deliver BI reports that translate analytic insights into tangible, actionable solutions for data customers to implement
Provide clear and complete documentation per the software development process
Collaborate with team members through Scrum/Agile
Take ownership of each project, make design and implementation decisions autonomously, and mentor junior members
Be an integral part of a new and energetic team
Average travel requirements of 2-3 weeks a year, including travel to the US

Required Skills and Experience

3+ yrs industry experience in developing, deploying, and monitoring performance of data pipelines, data analysis and BI reporting
Experience utilizing:
Scripting languages (Python, PySpark and SQL)
Databases (Hadoop, Hive, Kafka, Cassandra, Elastic, and/or S3)
Data Visualizations (PowerBI and/or Kibana)
Proven technical ability to navigate highly complex data management projects and effectively interface with global colleagues
Ability to investigate issues based on limited information. Demonstrated high level of ability to resolve complex problems
Strong leadership and interpersonal communication skills
Must be legally allowed to work in Canada and be able to travel to the US
Must have a valid Canadian driver’s license

Preferred Skills and Experience

Understanding of major automotive vehicle systems such as Advanced Driver-Assistance (ADAS), Motion Control, Automotive Network, and Powertrain
Experience with automotive related data (e.g. warranty and diagnostics)
Experience with vehicle data acquisition tools (e.g. Vehicle Spy, CANalyzer)
Experience with Big Data using Spark/Scala
Experience with Machine/Deep Learning algorithms
Experience with website, SharePoint and/or GUI development
Exposure to embedded software (C/C++ and/or Matlab Simulink)

Minimum Education Required

Bachelor’s Degree in Mathematics, Statistics, Computer Science, Data Science or Engineering
Advanced degrees preferred

Diversity Information

General Motors is committed to being a workplace that is not only free of discrimination, but one that genuinely fosters inclusion and belonging. We strongly believe that workforce diversity creates an environment in which our employees can thrive and develop better products for our customers. We understand and embrace the variety through which people gain experiences whether through professional, personal, educational, or volunteer opportunities.

We encourage interested candidates to review the key responsibilities and qualifications and apply for any positions that match your skills and capabilities.

Equal Employment Opportunity Statement

Accommodation is available for applicants with disabilities. Should you be contacted by General Motors of Canada, please advise if you require accommodation. General Motors of Canada values diversity and is an equal opportunity employer.","General Motors
4.1",Ontario
576,"Sr. Manager, Data Engineering","FreshBooks has a big vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high performing team working towards a common goal: building an elite online accounting application to help small businesses better handle their finances. Known for extraordinary customer service and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity - Manager, Data Engineering

As an Engineering Manager for Data Engineering at FreshBooks, you'll be responsible for the development of our data infrastructure/operations team and will work with the team to scale data pipelines to millions of users. As a leader and manager, you'll handle a group of data engineering team members and help accelerate their execution and growth.

You're already a skilled leader, able to recruit new talent and champion development teams and their leaders. Your technical experience with scalable software or data platform technologies allows you to lead by example. Strong communication and interpersonal skills allow you to effectively influence across the organization. In all areas, you're able to anticipate and plan for the future.

What you'll do:
Drive the execution of the technical vision of our Data Infrastructure.
Manage a group of data engineers, data modellers, and other data-related roles.
Set, maintain and raise the level of technical excellence across your group and the entire development organization.
Work closely with the Analysts, Data Scientists, and Product to build a world-class engineering and data organization.
Attract and recruit talent to help execute the FreshBooks mission.
Anticipate and prepare for the future - technology, people, culture and process.

What you have:
Enthusiasm for data engineering!
Proven technical management experience with a team of 5 or more developers over a period of at least 2 years, in an agile or scrum environment.
Strong technical background with experience working with large codebases and large amounts of data.
History of establishing teams by developing leaders and recruiting exceptional talent.
The ability to influence through strong communication and interpersonal skills.
A demonstrated ability to navigate ambiguity, develop plans and successfully execute over multiple quarters.
A love of learning, a drive for self-improvement and a desire to help everyone be better.
Experience with Google Cloud, or another major cloud provider such as AWS.
Experience with Git workflows, automated testing, continuous integration and automated build pipelines.
Strong programming skills in SQL, Python or a similar language.
Experience with Big Query, Redshift, Snowflake, or similar cloud data warehouse technology.

What you may have:
A degree in Computer Science/Engineering or Data Engineering.
Experience developing and/or managing real-time data pipelines and fast data architectures.
Experience with Spark, Kafka, Flink, Gearpump, Dataflow, or other streaming technologies.
Experience with Docker, Kubernetes, Ansible, and Terraform, and other DevOps and infrastructure as code technologies.
Experience with other modern storage technologies such as Cassandra, MongoDB, and others.
A track record of staying at the forefront of data engineering technology.
A limitless imagination for where data could go and what we can do with it to make our customers and our people awesome!

Why Join Us

We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. You'll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world-class one, right here in Toronto, Canada.

Apply now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer that embraces the differences in all of our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position.

FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com","FreshBooks
4.0",Midtown Toronto
577,"Data Engineer, Analytics, Global Risk Management","Requisition ID: 107041

Join a purpose driven winning team, committed to results, in an inclusive and high-performing culture.

Data Engineer, Analytics COE, Global Risk Management


The Data Engineer will contribute to the definition of best practices in terms of data management and data operations, and will lead the execution of efficient data pipelines to automate data processes in a Big Data environment (for Traditional and Non-traditional/non-structured data).

The candidate will identify and prioritize opportunities to leverage data properly and take a leading role in project-based initiatives to drive innovation and digital transformation throughout the Bank and Global Risk Management. The Data Engineer role requires strong technical skills on Big Data and Cloud environments as well as flexibility, collaboration and great teamwork abilities.


Is this role right for you? In this role you, will:

Report to the Director Data Engineering while operating in a team-based environment, you will build data pipelines on cloud and on-prem environments
Lead the gathering and processing of data at scale
Guide the processing of unstructured data into a form suitable for analysis
Provide technical expertise, guidance, advice and knowledge transfer on aspects of code management, automated release builds and code deployment
Collaborate with GRM key stakeholders and partners to define data engineering and technical training best-practices for data projects
Maintain a good understanding of the Bank's business strategies, business policies, risk management and IT processes and disciplines. This requires working with enterprise data management office, Governance and Technology teams to ensure that the data captured through other initiatives is readily available for usage within Analytics teams.
Able to work in an Agile environment if required
Maintain an active participation in various Global Risk Management value-added initiatives from time to time (in addition to routine credit-related matters)
Be customer-focused and proactive, while maintaining a healthy partnership with business line counterparts


Do you have the skills that will enable you to succeed in this role? - We'd love to work with you if you have:

University degree in relevant STEM discipline (Science, Technology, Engineering and Mathematics)
5+ years’ experience in development and cloud Data Processing applications
Experience cleaning, transforming and visualizing large data sets working with various data formats (e.g. unstructured logs, XML, JSON, flat files)
Capability to architect highly scalable distributed data pipelines using open source tools and big data technologies such as Hadoop, HBase, Spark, etc.
Experience in Python or Scala. (Production level coding)
Familiar with Machine Learning libraries/framework (e.g. scikit-learn, MLib, etc.).
Hands-on experience with Cloud-based environments, e.g. Azure and Databricks
Experience with UNIX tools and shell scripting
Solid SQL skills for querying relational databases (e.g., SQL Server, DB2, MySQL, Sybase)
Data Quality/Lineage Solutions
Strong ETL Experience
Curiosity, ability to learn and to apply newly acquired knowledge to daily tasks
Strong time management and organizational skills to manage multiple (often shifting) priorities in a fast-paced environment
Sound oral and written communication skills to elaborate and support credit decisions before internal stakeholders

What’s in it for you?

The opportunity to join a forward-thinking company surrounded by a collaborative team of innovative thinkers.
Exposure to different data-driven business lines including Retail and Business Banking
Be part of a diverse and knowledgeable risk team
A rewarding career path with diverse opportunities for professional development.
Internal development to support your growth and enhance your skills.
A competitive compensation and benefits package.
An organization committed to making a difference in our communities– for you and our customers.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success!

This position is located Downtown Toronto

Location(s): Canada : Ontario : Toronto

Scotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
578,Ingénieur de données / Data Engineer,"*English will follow*

Altitude Sports est le leader de la vente en ligne au Canada, et se spécialise dans la rencontre de la mode avec le plein air. Fondée en 1984, l’entreprise offre des conseils de premier plan en matière d’équipement et de vêtements techniques haut de gamme, en plus d’un programme d’avantages destinés à ses membres et d’une multitude de produits soigneusement sélectionnés pour les aventures urbaines et en plein air.l

Description de Poste

En tant que membre fondateur de l'équipe, vous serez responsable de la conduite de la vision et de l'architecture à long terme de l'équipe, de la conduite / mise en forme des feuilles de route et du leadership technique. Vous ferez partie d'une équipe d'ingénieurs talentueux et passionnés, vous ferez l'expérience de nombreuses facettes du monde de la vente en ligne (e-tail) et participerez à une poussée toujours croissante vers une expérience client de classe mondiale et l'excellence opérationnelle. Les nouvelles idées sont toujours les bienvenues dans une culture de travail axée sur la communauté qui s'efforce continuellement d'être à la pointe du progrès. En tant qu'ingénieur des données, vous avez la possibilité d'aider à mener une transition vers une architecture de données de streaming évolutive et polyvalente. Vous travaillerez en étroite collaboration avec les développeurs, les parties prenantes et les analystes BI sur les données opérationnelles et stratégiques. Essentiellement, vous serez témoin de l'essentiel de ce qui fait fonctionner une opération de commerce électronique sérieuse.

Rôles et responsabilités

Participer à l'architecture, au développement, aux tests, au déploiement et à la livraison de flux de données en continu qui communiquent entre les sources de données de service, le lac de données, l'entrepôt de données et les systèmes tiers

Appliquer les normes, la nomenclature et les meilleures pratiques pour le stockage et la transformation des données;

Maintenir les processus ETL / ELT existants et en mettre en œuvre de nouveaux à des fins opérationnelles et de BI;

Créer et maintenir l'EDI et d'autres intégrations tierces;

Collaborer étroitement avec les opérations et l'intelligence d'affaire pour répondre à leurs besoins;

Travailler de manière proactive avec l'équipe produit pour concevoir des solutions techniques ou fonctionnelles;

Amener l'équipe vers de nouveaux sommets en présentant de nouveaux concepts à un comité technique

Assurer la résilience des produits en automatisant les tests dans le cadre du processus CI / CD

Exigences et compétences requises

Baccalauréat ou supérieur en informatique, en génie ou dans un domaine connexe. Maîtrise ou équivalent étranger en informatique, ingénierie, mathématiques, un atout

2 + années d'expérience professionnelle dans le commerce électronique sur des ressources de streaming distribuées telles que Kafka / Spark, Spring, AWS Kinesis / SNS / EventBridge, etc.

2 + années d'expérience professionnelle avec le traitement par lots ETL (par exemple Pentaho, Talend, SSIS)

4 ans d'expérience avec les bases de données relationnelles basées sur les lignes (MySQL, MS-SQL) et les colonnes (Snowflake, BigQuery, Cassandra) ainsi que NoSQL (MongoDB, DynamoDB, Elastic Search)

Connaissance de Python, Bash ou technologies similaires

Expérience pratique de la création et de l'exploitation de systèmes évolutifs et sécurisés sur AWS / Google cloud / Azure ou similaire

Connaissance des pratiques professionnelles d'ingénierie logicielle et des meilleures pratiques pour le cycle de vie complet du développement logiciel, y compris les normes de codage, les revues de code, la gestion du contrôle des sources, les tests, les déploiements et les opérations continus

Capacité démontrée à encadrer des ingénieurs logiciels débutants dans tous les aspects de leurs compétences en ingénierie

La connaissance des pratiques de science des données est un atout certain

Pourquoi te joindre à nous?

Une assurance collective (médicale et dentaire);

Des rabais employés sur plus de 400 marques techniques et urbaines

La possibilité d'effectuer ses tâches en télétravail pendant la COVID-19;

Un environnement de travail convivial au cœur du Mile-Ex;

La possibilité d'évoluer au sein d'une entreprise de e-commerce en pleine croissance;

Joindre une équipe de talent!


Altitude Sports is Canada's e-commerce leader, working and playing at the intersection of fashion and the outdoors. Founded in 1984, the company offers best-in-class advice on premium gear and technical apparel, a members-only benefits program and a curated selection of products for outdoor adventures and urban pursuits retailer .


Job Description


As a foundational member of the team, you will be responsible for driving the team’s long-term vision and architecture, drive/shape roadmaps, and provide technical leadership. You will be part of a talented and passionate squad of engineers, you will experience many facets of the world of online retail (e-tail) and take part in an ever growing push towards world class customer experience and operational excellence. New ideas are always welcome in a community driven work culture that continuously strives to be on the bleeding edge. As a Data Engineer, you are given the opportunity to help lead a transition to a scalable and versatile streaming data architecture. You will work closely with developers, stakeholders and BI analysts on operational and strategic data. Essentially, you will witness the core of what makes a serious e-commerce operation tick.


Main Responsibilities

Participate in the architecture, development, testing, deployment and delivery of streaming data flows that communicate between service data sources, the data lake, the data warehouse and 3rd party systems

Enforce standards, nomenclature and best practices for data storage and transformation

Maintain existing ETL / ELT processes and implement new ones for operational and BI purposes

Create and maintain EDI and other 3rd party integrations

Collaborate closely with operations and Business Intelligence to meet their needs

Proactively work with the product team to conceive technical or functional solutions

Requirement and Skills

BS degree or higher in Computer Science, Engineering or related field. Master's degree or foreign equivalent in Computer Science, Engineering, Mathematics, is an asset

2 + years of professional ecommerce experience working on distributed streaming resources such as Kafka / Spark, Spring, AWS Kinesis / SNS / EventBridge, etc.

2 + years of professional experience with ETL batch processing (eg. Pentaho, Talend, SSIS)

4+ years Experience with relational row-based (MySQL, MS-SQL) and column-based DBs (Snowflake, BigQuery, Cassandra) as well as NoSQL (MongoDB, DynamoDB, Elastic Search)

Knowledge of Python, Bash or similar technologies

Hands on experience in building and operating scalable and secure systems on AWS/Google cloud/Azure or similar

Knowledge of professional software engineering practices & best practices for full software development life cycle, including coding standards, code reviews, source control management, testing, continuous deployments and operations.

Demonstrated ability to mentor junior software engineers in all aspects of their engineering skill-set

Knowledge of data science practices is a definite asset

Why work with us?

A complete benefits package (medical, paramedical and dental);

Staff discount on 400+ urban and technical brands;

The possibility to work remotely during COVID-19;

A welcoming work environment in the heart of Montreal's Little Italy;

Be part of a fast-growing company in the booming e-commerce space;

Be part of a talented team.

Kafka ,Spark, Spring, AWS Kinesis ,SNS, EventBridge,ETL batch processing,Pentaho, Talend, SSISMySQL, MS-SQL,Snowflake, BigQuery, Cassandra,MongoDB, DynamoDB, Elastic Search, Python, Bash AWS/Google cloud/Azure","Altitude Sports
3.9",Montreal
579,Data Arch Consultant,"Data Architect Consultant

Location: Toronto, ON

We Are:

Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.

You are:

A hands-on Solution Architect who knows how to develop, design and maintain technologies that work for our clients. You are a next-generation thinker when it comes to what we call Data in the New. Your superpower? Using the latest data and analytics technologies to help clients glean the most value from their data. And you know how to come up with strategies, solutions, and processes for managing enterprise-wide data throughout the data life cycle. You’re a digital native who’s right at home when the challenge calls for teamwork and originality


The work:

Defining the policies & standards for cloud native data management for structured, semi- and unstructured data use
Defining the data architecture for cloud native data management with expert level knowledge on
Popular Cloud Platforms (e.g. AWS, Azure, GCP)
Data Layers (e.g. raw, curated)
Integration design (e.g. APIs), ETL (Extract, Transform & Load), velocity (e.g. streaming)
Data architecture design patterns
Defining the data architecture for cloud native data management with focus to
Business process flows to support data sourcing & lineage
Data Modelling methodologies & tools
Reference Architectures
Defining the data architecture for cloud native data management with focus to
(Business) Data Definitions & Metadata
Reference Data Management
Master Data Management (core & critical business data entities)
Data Lineage
Defining the data management vision & strategies, managing the change journey and/or playing serving as the “architect” to design and scale end to end data management with special focus to
Data Quality Rules & KPIs
Automated Data Cleansing (e.g. use of AI / ML)
Compliance Rules & KPIs
Data democratisation
Data security
Compliance & security policies for data access, use & integration


Qualifications - External

Here’s What You Need:

A minimum of 3 years of working as a Data Governance consultant or directly with clients leveraging popular tools like Informatica, Collibra, IBM, ASG etc.
A minimum of 3 years in a role that had taken ownership of the data assets for the organization to provide users with high-quality data that is accessible in a consistent manner.
A minimum of 3 years facilitating Data cleansing and enrichment through data de-duplication and construction
A minimum of 3 years in a role that discovered captures the current state of the system, encompassing processes such as data discovery, profiling, inventories.
A minimum of 3 years in a role that defined processes include data classification, business glossary creation and business rule definition.
A minimum of 3 years in a role that applied processes with aim to operationalize and ensure compliance with policies and include automating rules, workflows, collaboration etc.
Bonus Points if:
Experience in a role that led measurement and monitoring to determine the value generated and include impact analysis, data lineage, proactive monitoring, operational dashboards and business value.
Experience in a role that led repeatable, iterative, and standardized processes to define how the data should be governed. At a minimum, below processes and procedures must have been practiced
Defining data domains
Change Management
Data stewardship and ownership
Conflict resolution
Technology Automation
Communication
Experience performing:
Master Data Management
Metadata Management
Data Management and Integration
Systems Development Lifecycle (SDLC)
Data Modeling Techniques and Methodologies
Database Management
Database Technical Design and Build
Extract Transform & Load (ETL) Tools
Cloud Data Architecture, Data Architecture Principle
Online Analytical Processing (OLAP)
Data Processes
Data Architecture Principles
Data Architecture Estimation","Accenture
4.1",Midtown Toronto
580,Data Engineer,"Next Pathway - The Automated Cloud Migration Company

Listed as one of Canada’s hottest start-ups by the Globe and Mail, Next Pathway is a technology services company providing clients a pathway from existing to emerging technologies. Our automation technology helps our customers accelerate the migration of complex applications and workloads to the cloud.

Next Pathway is located in the heart of the Financial District, minutes from Union Station and the Subway.

We are looking for skilled Data Engineers (ETL/SQL) to join our team!

Contract to December 31, 2021.

The candidate needs to have extensive experience as follows:

· Minimum of 3 years of proven experience in a core competency

· Proven hands-on Software Development experience

· Strong Data Warehouse knowledge and experience, include data modeling, data ingestion, transformation, data consumption patterns

· Strong SQL knowledge and experience, including developing and optimizing complex queries, creating efficient UDFs to extend the functionalities

· Experience in at least 3 of below RDBMS: Teradata, Netezza, SQL Server, Greenplum, Oracle, Sybase, DB2, MySQL, Redshift, SQLDW.

· Experience with Cloud Technologies (Azure, GCP, Snowflake, AWS, Yellowbrick)

· Experience with ETL tools (Informatica, DataStage, SSIS, Talend)

· Experience with major programming languages (Java, Pcorrespondenceython, Scala, C++, Java Script)

· Strong understanding and experience of relational database, include design and implementation

· Develop and maintain unit tests and integration tests, and test automation.

· Adoption of Agile and Scrum development methodology

· BA/MS/PHD degree in Computer Science, Engineering, or a related subject

.

Other Technologies you Might Work with Include:

· Microsoft Office Suite (Excel, Word, PowerPoint, Outlook)

· Basecamp: Project Management & Team Communication

· Slack: Messaging Platform

· Zoom: Meetings and Video Conferencing

· Confluence: Collaboration Tool

· JIRA: Project Management Software

.

Other Skills:

· Team Player with Excellent Interpersonal and Communication Skills (Written and Verbal)

· Strong Work Ethic with a Positive Attitude and a Passion for Data and Development

· Strong Analytical and Problem-Solving Skills

· Excellent Time Management Skills

Contract length: 9 months

Job Types: Full-time, Contract

Schedule:

Monday to Friday

Experience:

SQL: 4 years (preferred)
ETL: 4 years (preferred)
Netezza: 2 years (preferred)
Oracle: 2 years (preferred)

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process","Next Pathway
4.5",Midtown Toronto
581,Cloud Data Engineer,"Role: Cloud Data Engineer

Location: Toronto, ON

Duration- Long Term

Mandatory skills and experience: (Please include skills related to technical as well as domain and non-technical skills and experience as applicable to the position)

Working on EMR, good knowledge of CDK and setting up ETL and Data pipeline

Coding - Python

AWS EMR, Athina, Supergule, Sagemaker, Sagemaker Studio

Data security & encryption

ML / AI

Pipeline

Redshift

AWS Lambda

Nice to have skills & experience:

Oracle/SQL Database administration

Data modelling

RDS & DMS

Serverless Architectrure

DevOps

Job Type: Contract

Schedule:

8 hour shift

Experience:

Lambda: 2 years (preferred)",apptoza inc,Midtown Toronto
582,Data Engineer,"Mogo Finance Technology Inc. (Mogo) (TSX: MOGO; NASDAQ: MOGO) — a financial technology company — offers a finance app that empowers consumers with simple solutions to help them get in control of their financial health and be more mindful of the impact they have on society and the planet. We all know it’s time to do things differently. It’s time for a new way to manage our money, one that’s inclusive and sustainable. One that takes into account our financial health, the planet’s health and the health of our society. At Mogo, users can sign up for a free account in only three minutes and begin to learn the 4 habits of financial health and get convenient access to products that can help them achieve their financial goals and have a positive impact on the planet including a digital spending account with Mogo Visa* Platinum Prepaid Card featuring automatic carbon offsetting, free monthly credit score monitoring, ID fraud protection and personal loans. The Mogo platform has been purpose-built to deliver a best-in-class digital experience, with best-in-class products all through one account. With more than one million members and a marketing partnership with Canada's largest news media company, Mogo continues to execute on its vision of becoming the go-to financial app for the next generation of Canadians. To learn more, please visit mogo.ca or download the mobile app (iOS or Android).

Mogo is looking for a Data Engineer to be a key member of Mogo’s team. Based in Vancouver, this role will be responsible for the architecture, integration and analysis of both traditional and non-traditional data sources used for model building. Check out the list of qualifications below and if this sounds like you, send us your resume - we want to hear from you!

What you'll do:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.

What you'll need:
3-5 years experience in a similar role with an emphasis on translating quantitative data into meaningful insights.
Experience working in the Financial services industry and/or with digital products.
Degree in Computer Science, Statistics, Mathematics or other related discipline
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.

Proficient with the the following software/tools:
Big data tools: Hadoop, Spark, Kafka, etc.
Relational SQL and NoSQL databases, including Postgres and MongoDB.
AWS cloud services: EC2, EMR, RDS, Redshift
Object-oriented/object function scripting languages: Python, Javascript.

Salary range for this role is $80,000-$90,000 per annum based on experience.

Interested applicants can submit an application online or through email at hr@mogo.ca","Mogo
3.5",Vancouver
583,Cloud Data Engineer,"Who is DigitalOnUs?

At DigitalOnUs, we not only provide Agile and DevOps methodologies to our customers, but we have also adopted the same within the company as well. Our nimble processes are not mired in red tape, yet robust, flexible and results oriented. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators, and challengers. Each day, we strive to make great come alive. Our lemma: ""work smart and play hard""

Our technology partners are Hashicorp, Cloudbees, Chef, Pagerduty, Docker and SAP .

We are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family !

We are looking for a data engineer responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow.

Will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Location: Canada

Qualifications we are looking for:
Azure data engineers collaborate with business stakeholders to identify and meet data requirements. They design and implement solutions. They also manage, monitor, and ensure the security and privacy of data to satisfy business needs. The role of a data engineer is different from the role of a database administrator.

+5 years of experience in data Engineering

Familiarity with eClinical Works (ECW) data, HL7 or FHIR

Experience with machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, hidden Markov models and graph algorithms.

Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.

Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch, Databricks etc.)

Experience with real-time data processing and API platforms.

Experience in using Python, Java and/or other data engineering languages.

Experience with data visualization and presentation, turning complex analysis into insight.

Healthcare domain and data experience

IDEAL BACKGROUND: Healthcare data background, especially provider data (versus payer data), including clinical data. Experience with FHIR is highly desirable. Experience and deep background in various methods of ETL is required. Programming and full-stack development experience would be a great addition.

Key Activities- Maintain, improve, clean, and manipulate data in the business operational and analytics databases Design and deploy data platforms across multiple domains ensuring operability Transform data for meaningful analyses Improve data efficiency, reliability and quality Create data enrichment Build high performance Ensure data integrity Create and manage data stores at scale Ensure data governance - security, quality, access and compliance

Why you will love this job?

We look for people who are thoughtful, can break down problems, work individually sometimes, and in pairs or teams at other times.

You are trusted to work on your own but ask for help when you are blocked

We will work with you to find the balance of what you want to do, what you are good at, and how that fits in with the company goals.

What you can expect from us

At DigitalOnUs, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness lead to quality, innovation, commitment to deliverables, efficiency, and cost-effectiveness for all our customers.

Empathy for your coworkers and our customers is an important part of success here. As an early-stage startup, most people wear many hats.

We are growing at a phenomenal pace! We have lots of opportunities to grow and learn

Hear your voice, nurture your talent, and help you strengthen your footprint!

Health, Life, Dental, and Vision Insurance

Flexible Work Hours

Work-from-Home Options

Company-wide retreats

If you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the ""Company""). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and / or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https://www.digitalonus.com/privacy-policy/","Digital On Us
4.5",Midtown Toronto
584,Scientist - Biological Sciences Platform - Regular Full-time (06082021),"Scientist – Sunnybrook Research Institute

The Sunnybrook Research Institute (SRI), the research arm of Sunnybrook Health Sciences Centre – a research hospital fully affiliated with the University of Toronto – is currently seeking candidate for a scientist position in the Biological Sciences Platform.

As the research enterprise of a premier academic health sciences centre and one of Canada’s largest hospitals, SRI’s groundbreaking research changes the way patients are treated around the world. SRI is one of the fastest growing hospital-based research enterprises in Canada with well-established programs in basic and applied research, developing innovations in care for more than 1 million patients annually.

SRI is located in Toronto, one of the most populous cities in Canada. It is located on the northwestern side of the Lake Ontario. Toronto is an international centre of business, finance and cultures, and is known to be one of the most multicultural cities in the world.

Position: The successful candidate will hold a PhD and/or MD, have demonstrable scientific leadership in their field and a proven track record in publishing high quality, peer reviewed research. The successful candidate will lead an independent academic program of research excellence in high content cellular analysis dedicated to the identification and characterization of basic cellular mechanisms and of new targets governing diseases. Expertise in high content screening of cells and/or tissues and automated data analysis are assets.

Academic appointments in the Faculty of Medicine, University of Toronto at the Assistant or Associate Professor level and the Sunnybrook Research Institute, will be commensurate with experience. The term of the appointment will be three years and is renewable in accordance with Hospital and University policies.

Career Interruptions: Sunnybrook Research Institute recognizes that scientists have varying career paths and understands the impact that career interruptions can have on a candidate’s record of research achievement. Candidates are encouraged to explain interruptions in order to allow for a fair assessment of their application. Search committee members have been instructed to give careful consideration to, and be sensitive to the impact of, career interruptions in their assessments.

Environment: Conducting $125 million in research each year, SRI is home to 1000 scientists, clinician scientists; research associates and more than 400 trainees, operating in ~500,000 sq.ft. of state-of-the-art infrastructure [http://sunnybrook.ca/research/].

How To Apply: Applications should include:

1) A letter of interest. The letter should describe the applicant’s research accomplishments

2) A complete curriculum vitae including professional services, outreach, mentoring / training of highly qualified personnel and other contributions appropriate to the specific position; and

All materials should be addressed to Dr. David Andrews, Chair of the Search Committee.

Please submit your application via email to Carmen Ho (carmen.ho@sunnybrook.ca) with subject line “Scientist – Biological Sciences”)

This post will stay active until the position is filled. We would like to thank all applicants, but only those selected for an interview will be contacted.

All qualified candidates are encouraged to apply; however, Canadians and permanent residents will be given priority.

Diversity Statement: Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: women, visible minorities or persons of colours, indigenous peoples, people from all genders, religions and ethnicities, persons with disabilities, LGBTQ+ persons, and all others who may contribute to the further diversification of ideas.

Accommodation Policy: Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Job Information:

Company operating name: Sunnybrook Research Institute

Business address: 2075 Bayview Ave. Toronto, Ontario, M4N 3M5

Title: Scientist

NOC: 2121

Number of positions: 1 (One)

Education Requirements: Doctoral/PhD

Language Requirements: Verbal: English

Written: English

Duration of Employment: Permanent, Full-time

Benefits: 4 weeks vacation per year with full time benefits (i.e. extended health and dental plan, Healthcare of Ontario Pension Plan and etc.)

Wage: 120,000 to 130,000 (CDN)

Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: visible minorities, all religions and ethnicities, persons with disabilities, LGBTQ persons, and all others who may contribute to the further diversification of ideas.

Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: visible minorities, all religions and ethnicities, persons with disabilities, LGBTQ persons, and all others who may contribute to the further diversification of ideas.","Sunnybrook Health Sciences Centre
4.2",Midtown Toronto
585,Scientist - Biological Sciences Platform - Regular Full-time (06082021),"Scientist – Sunnybrook Research Institute

The Sunnybrook Research Institute (SRI), the research arm of Sunnybrook Health Sciences Centre – a research hospital fully affiliated with the University of Toronto – is currently seeking candidate for a scientist position in the Biological Sciences Platform.

As the research enterprise of a premier academic health sciences centre and one of Canada’s largest hospitals, SRI’s groundbreaking research changes the way patients are treated around the world. SRI is one of the fastest growing hospital-based research enterprises in Canada with well-established programs in basic and applied research, developing innovations in care for more than 1 million patients annually.

SRI is located in Toronto, one of the most populous cities in Canada. It is located on the northwestern side of the Lake Ontario. Toronto is an international centre of business, finance and cultures, and is known to be one of the most multicultural cities in the world.

Position: The successful candidate will hold a PhD and/or MD, have demonstrable scientific leadership in their field and a proven track record in publishing high quality, peer reviewed research. The successful candidate will lead an independent academic program of research excellence in high content cellular analysis dedicated to the identification and characterization of basic cellular mechanisms and of new targets governing diseases. Expertise in high content screening of cells and/or tissues and automated data analysis are assets.

Academic appointments in the Faculty of Medicine, University of Toronto at the Assistant or Associate Professor level and the Sunnybrook Research Institute, will be commensurate with experience. The term of the appointment will be three years and is renewable in accordance with Hospital and University policies.

Career Interruptions: Sunnybrook Research Institute recognizes that scientists have varying career paths and understands the impact that career interruptions can have on a candidate’s record of research achievement. Candidates are encouraged to explain interruptions in order to allow for a fair assessment of their application. Search committee members have been instructed to give careful consideration to, and be sensitive to the impact of, career interruptions in their assessments.

Environment: Conducting $125 million in research each year, SRI is home to 1000 scientists, clinician scientists; research associates and more than 400 trainees, operating in ~500,000 sq.ft. of state-of-the-art infrastructure [http://sunnybrook.ca/research/].

How To Apply: Applications should include:

1) A letter of interest. The letter should describe the applicant’s research accomplishments

2) A complete curriculum vitae including professional services, outreach, mentoring / training of highly qualified personnel and other contributions appropriate to the specific position; and

All materials should be addressed to Dr. David Andrews, Chair of the Search Committee.

Please submit your application via email to Carmen Ho (carmen.ho@sunnybrook.ca) with subject line “Scientist – Biological Sciences”)

This post will stay active until the position is filled. We would like to thank all applicants, but only those selected for an interview will be contacted.

All qualified candidates are encouraged to apply; however, Canadians and permanent residents will be given priority.

Diversity Statement: Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: women, visible minorities or persons of colours, indigenous peoples, people from all genders, religions and ethnicities, persons with disabilities, LGBTQ+ persons, and all others who may contribute to the further diversification of ideas.

Accommodation Policy: Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Job Information:

Company operating name: Sunnybrook Research Institute

Business address: 2075 Bayview Ave. Toronto, Ontario, M4N 3M5

Title: Scientist

NOC: 2121

Number of positions: 1 (One)

Education Requirements: Doctoral/PhD

Language Requirements: Verbal: English

Written: English

Duration of Employment: Permanent, Full-time

Benefits: 4 weeks vacation per year with full time benefits (i.e. extended health and dental plan, Healthcare of Ontario Pension Plan and etc.)

Wage: 120,000 to 130,000 (CDN)

Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: visible minorities, all religions and ethnicities, persons with disabilities, LGBTQ persons, and all others who may contribute to the further diversification of ideas.

Sunnybrook Research Institute is committed to providing accessible employment practices that are in compliance with the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation for disability during any stage of the recruitment process, please indicate this in your cover letter.

Sunnybrook Research Institute is strongly committed to inclusion and diversity within its community and welcomes all applicants including but not limited to: visible minorities, all religions and ethnicities, persons with disabilities, LGBTQ persons, and all others who may contribute to the further diversification of ideas.","Sunnybrook Health Sciences Centre
4.2",Midtown Toronto
586,Data Integration and Big Data Processing( Data Engineer),"12 month contract

Remote within Canada (Work time as per PST or MST zone)

Required Skills:

Big data engineers are responsible for developing, maintaining, evaluating and testing big data solutions. In addition, they are generally involved in the design of big data solutions.
MUST GCP Knowledge & experience

Responsible for Hadoop development.
Implementation including loading from disparate data sets, preprocessing using Hive and Pig.
Scope and deliver various Big Data solutions.
Ability to design solutions independently based on high-level architecture.
Manage the technical communication between the survey vendor and internal systems.
Maintain the production systems (Kafka, Hadoop, Cassandra, Elasticsearch).
Collaborate with other development and research teams.
Building a cloud based platform that allows easy development of new applications.
Proficient understanding of distributed computing principles.
Management of Hadoop cluster, with all included services.
Ability to solve any ongoing issues with operating the cluster.
Proficiency with Hadoop v2, MapReduce, HDFS.
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming.
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala.
Experience with Spark.
Experience with integration of data from multiple data sources.
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB.
Knowledge of various ETL techniques and frameworks, such as Flume.
Experience with various messaging systems, such as Kafka or RabbitMQ.
Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O .
Good understanding of Lambda Architecture, along with its advantages and drawbacks.
Experience with Cloudera/MapR/Hortonworks.

Reference ID: TI090421-I

Contract length: 12 months

Job Types: Full-time, Contract

Schedule:

Monday to Friday

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process","EmergiTel
3.8",Midtown Toronto
587,Senior Data Integrator,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Are you a go-getter who has a passion in building next gen data solutions for business problems? Are you a big fan of simplification and automation?

Manulife is seeking a Senior Data Integrator, to join our rapidly expanding IT Organization and assist us as we work to be a digital leader in our industries.

Responsibilities for this role include:

Work closely with source system SMEs to produce source to target mappings, business glossaries, data lineages and data access requirements

Produce clear, concise business requirement documents

Capture acceptance criteria along with specification of test cases associated

Experience with SDLC and/or Agile methodologies for project development, and able to contribute to all phases of project development, is required

Solid understanding of Hadoop and complementary big data services/technologies

Familiarity with data modeling and diagram practices, such as ER, EER, ERD, and UML

Thrive on turning ambiguity and conflicting information into clarity in a fast-changing environment

Solid foundation in SQL and good understanding of various data source systems (RDBMS, web services, files, mainframe, etc.)

Build relationships, communicate, and collaboratively work with both business and technical partners.

Ability to break down complex problems into logical, digestible steps

Ability to effectively manage multiple projects and priorities simultaneously

Designs and ensures consistent data flow through the organization

Collaborates with data scientists and data engineers on moving data analysis models into production

Assesses middleware tools for data integration, transformation and routing

Utilizes a variety of data interchange formats to ensure that data requirements for the business are met

Monitors mapping and data integrity across the organization

Evaluates data integration assets and capabilities across BU's and divisions for overlap, consolidation and reuse potential.

Supervises and reviews data dictionaries for accuracy on a periodical basis

Identifies emerging technologies for future use

Has positive impact to specific organizational entities & has some understanding of the nature of the impact

Usually a top contributor to team's success

Job Requirements for this role include:

Demonstrated ability to interpret business needs and translate business cases into manageable, detailed technical requirements, identifying key features to be delivered

Understanding of how data strategy supports Manulife's strategy

Understanding of drivers of data demand and how data is used

Attends advanced training sessions and is certified on multiple domains of expertise

Demonstrates all core skills, and good interpersonal skills for the role

Uses and combines knowledge of the field and the market to formulate the right approach

Strong knowledge of the business or ability to come up to speed in a short time.

Constantly learns from both success and failure

Good organizational and problem-solving abilities that enable you to manage through creative abrasion.

Good verbal and written communication; able to effectively articulate technical vision, possibilities, and outcomes.

Experiments with emerging technologies and understanding how they will impact what comes next.

Good analytical skills, copes with complex situations through deliberate analysis and planning

Master’s and/or Bachelor’s degree in Computer Science or related field

Experience/exposure to data engineering, data architecture, system design, business intelligence, QA and data science

Programming experience in Python, Spark, HQL, Scala, and shell scripting

Experience/exposure to CI/CD code flow and tooling, and an understanding of the principles and pragmatics for build pipelines, artefact repositories, zero-downtime deployment

Knowledge and understanding of cloud technologies/platform

Familiarity and domain expertise in data and analytics initiatives

This is a full time permanent role located in Toronto, ON.



If you are ready to unleash your potential, it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. As of December 31, 2020, we had $1.3 trillion (US$1.0 trillion) in assets under management and administration, and in the previous 12 months we made $31.6 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an Equal Opportunity Employer

At Manulife /John Hancock , we embrace our diversity. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex (including pregnancy and pregnancy-related conditions), sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will work with applicants who request a reasonable accommodation during the application process . All information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and Manulife/John Hancock policies . To request a reasonable accommodation in the application process, contact recruitment@manulife.com .","Manulife
4.0",Midtown Toronto
588,Software Engineer / Data Engineer,"XGen AI is seeking a Software Engineer (with crossover Data Engineer experience) to join our Development team in Vancouver, BC.

The ideal candidate would have a strong desire to learn, work hard, and play an important role as part of a high-performance team. As a Software Engineer at XGen AI, you will contribute to the design, development, and implementation of state-of-the-art, Cloud-based, AI-First systems powered by XGen’s AI Technology.

Responsibilities:

Contribute to the design, development, and evolution of XGen AI's SaaS and Machine Learning platform.
Design, document, implement, and unit test microservices that run on AWS, using the latest AWS technologies.
Manage analytics data, datastore, and databases such as S3, RDS, Datalake/Athena, DynamoDB, Redis cache...etc)
Ensure products meet all relevant specifications and quality standards
You are also playing an important role in managing data queries, importing, transforming, and storing strategies.

Qualifications:

Hands-on experience with Python 3
Experience in Java is a plus.
Familiar with Object-Oriented Design & Programming
Familiar with Agile, Scrum, and DevOps
Working knowledge of databases (Relational and NoSQL) and SQL
Proficiency with SQL complex queries and aggregation which make use of analytics
Excellent oral, written, and interpersonal communication skills
The ability to learn quickly in a dynamic environment
Must be eligible to work full time
Experience with Cloud (especially AWS), BigData, and Stream Processing
Knowledge of System Monitoring and Dashboards
Must be located in Vancouver

Job Types: Full-time, Permanent

Pay: $70,000.00-$100,000.00 per year

Benefits:

Casual dress
Company events
Dental care
Disability insurance
Employee stock purchase plan
Paid time off
Vision care
Work from home

Schedule:

8 hour shift
Monday to Friday

Education:

Bachelor's Degree (preferred)

Experience:

Python 3: 3 years (preferred)
Java: 3 years (preferred)
Data and analytics processing: 3 years (preferred)
DB and SQL queries: 3 years (preferred)

Work remotely:

Temporarily due to COVID-19",XGenesis Inc,Vancouver
589,Junior Business Intelligence Developer - Data Science and Analytics,"Our subsidiary is in PropTech and real estate analytics spaces, founded by serial entrepreneurs and experienced management. A data, analytics, and technology leading cloud services specializing in the Canadian real estate industry. Delivering AI-driven analytics data solutions that enable homeowners, investors, brokers, advertisers, industry professionals, and researchers to assess, understand, engage and transact within the real estate industry. Our headquartered in Toronto.

The Business Intelligence Developer will be working under the guidance of the program supervisors and working directly with other team members including data scientists, interns and our business team.

Duties and responsibilities Junior BI Developer will:
- Develop predictive models. You will apply insights and best practices to build models that increase and optimize customer experiences with our data platforms, software solutions, and service offerings.
- Develop tools. You will build tools and processes to monitor and analyze model performance and data accuracy.
- Advice on continuous improvements. You will provide recommendations on new data sources to enhance the current data sets, identify new data sources, and work with the data engineering and development team to automate ingestions and transformations.

Development:
- Works independently or as a team member to design, develop, test, and implement our solutions to support AraData’s initiatives
- Designs and develops web applications, APIs, and software utilities using; R (Shiny, Tidyverse), Python (Flask, Pandas, Dash, Bokeh), Bash, JavaScript (JQuery, Node.js, React.js), CSS, HTML, and other web development languages, as appropriate.
- Creates visual tool mock-ups and prototypes to validate with end-users.
- Identifies and remedies problems/issues to ensure a secure and well-functioning environment.
- Optimizes system efficiency by analyzing performance indicators and changing software
- Responsible for application deployments, minimizing avoidable downtime.
- Assists with initiatives to upgrade application deployment infrastructure
- Performs systems monitoring activities, utilizing expert knowledge to identify areas that required improvement, adjustment, etc., to maintain optimal operations at peak performance on servers
- Coordinates Quality Assurance activities which include reviewing test plan/test cases to facilitate the optimal provision of guidance on testing and defect reporting
- Identifies, as required and schedules/coordinates problem reviews, following up on assigned actions in a timely manner utilizing expertise to resolve and/or facilitate the resolution of problems, where appropriate.
- Collaborates with project teams to identify and define application requirements, making recommendations and outlining technical initiatives with the goal of improving the current situation.
- Maintains responsibility for the development and delivery of project presentations to various stakeholders, in a timely manner to gain full buy-in and corporate with endeavors.
Knowledge and skills- An undergraduate degree in, Engineering, Computer Science and/or a related discipline
- Minimum 2 years of full-stack development experience
- Relevant experience in mining, analyzing, and visualizing large amounts of data and programming skills (e.g., SQL, Hive, HQL)
- Relevant experience in reporting, analysis, and insights
- Extensive experience with HTML, CSS and JavaScript, including JavaScript libraries(e.g, JQuery, Node.js and React)
- Experience in one or more of the following: Python, R, JavaScript
- Expert-level knowledge of relational databases (eg. PostgreSQL). Experience in non-relational databases (e.g. MongoDB) is an asset.
- Experience with popular web development frameworks, such as React, Django, Flask, Express.js, or Ruby on Rails
- Comfortable working in a Linux environment
- Proficient with version control systems (e.g., Git)
- Experience in providing supervision, guidance, leadership and feedback to project teams and junior resources
- Ability to multi-task and work effectively both individually and as part of a team
- Proficiency with R Shiny, R Markdown, and/or R Studio Connect is an asset.
- Experience with Data Science and Machine Learning tools and methods is an asset.
- Experience with UI/UX design best practices is an asset
- Strong interpersonal skills, able to build relationships, effectively interact, influence,
- Superior communication skills with proven ability to communicate quantitative/ qualitative
- Disciplined with a proven track record of delivering results and executing with excellence
- Demonstrated ability to work with various data sources
- Expertise with reporting techniques and report automation using platforms such as SQL, HIVE
- Excellent written and verbal skills and keen attention to detail

Nice to have:
- Experience with real estate and/or mortgage businesses is an asset
- Knowledge of statistical analysis techniques such as regression, clustering algorithms using programming languages such as Python, PySpark, or R is an asset
- Academic qualifications with a focus on business, finance, or statistical analysis is an asset Education required an undergraduate degree in, Engineering, Computer Science and/or a related discipline

Contract length: 6 months

Expected start date: 2021-07-01

Job Types: Full-time, Contract

Benefits:

Tuition reimbursement
Work from home

Schedule:

Monday to Friday

COVID-19 considerations:
All employees are working remotely during the COVID-19

Application question(s):

Do you have any experience with data science and modelling?
What is your salary expectation?

Education:

Bachelor's Degree (required)

Experience:

Data Science Professional Work: 1 year (preferred)
Software Development Professional Work: 1 year (preferred)

Work remotely:

Temporarily due to COVID-19",CAPRiser Group,Midtown Toronto
590,Ingénieur de données senior / Sr. Data Engineer,"English version to follow

McKesson touche la vie des patients en œuvrant dans pratiquement tous les secteurs des soins de santé dans le but d'améliorer la santé en général. Chez McKesson Canada, nous créons un impact dans la vie de 12 millions de Canadiens, chaque jour. Nous distribuons plus de 35 000 produits à partir de 17 centres de distribution à 6 300 pharmacies de détail, 1 350 hôpitaux, centres de santé longue durée, cliniques et établissements de santé partout au Canada. Toutefois, nous sommes beaucoup plus qu'une entreprise de distribution. Nous avons automatisé 2 500 pharmacies de détail et distribuons annuellement plus de 100 millions de doses de médicaments grâce à nos solutions d'automatisation. Les fabricants, les fournisseurs de soins de santé et les patients comptent sur nous pour une gamme complète de services qui contribuent à la qualité et l'intégrité des soins de santé pour le bénéfice de tous.

Chez McKesson, vous participerez à la création de produits et de solutions qui contribuent à la réalisation de la mission de l'entreprise, soit améliorer la qualité de vie et faire progresser les soins de santé. Travailler ici représente une occasion d'édifier une industrie qui est vitale pour nous tous.

Ce que vous ferez:

Concevoir, développer et maintenir des solutions de plateforme de données.
Exécuter un cycle de développement complet, y compris:
Analyser et évaluer les besoins en données;
Analyser les données, créer des modèles et des mappages de données;
Développer des bases de données et des processus d'extraction, de transformation et de chargement de données à partir de zéro;
Mettre en œuvre des pipelines de données, planifier, orchestrer et automatise les tâches;
Produire des documents de définition selon une méthodologie ou un processus prédéterminé;
Concevoir, coder et déboguer conformément aux normes prédéterminées; réviser les codes au besoin;
Créer des jeux de tests;
Effectuer des tests d'unités, d'intégration et de rendement;
Effectuer des promotions dans différents environnements;
Fournir du soutien à la production;
Produire de la documentation.
Être proactif et indiquer l'état de l'effort accompli, les estimations des efforts restants et les problèmes ayant une incidence sur les progrès.
Superviser occasionnellement les ressources pour les activités de conception et de développement et assurer le suivi des efforts.
Collaborer avec les intervenants internes (architectes, analystes, administrateur des bases de données, etc.) ou externes, au besoin, pour résoudre les problèmes.
Former et encadrer les gens et leur fournir des conseils dans divers domaines de spécialisation; favoriser le travail d'équipe et l'innovation en faisant participer les gens à la résolution de problèmes et à la pensée créative.
Participer à l'évaluation et à l'établissement de nouvelles technologies.
Faire en sorte que les engagements envers les clients internes et externes sont respectés en temps opportun et de manière rentable; demander de la rétroaction aux clients pour déterminer les occasions d'amélioration des produits ou services.

Qui vous êtes:

Baccalauréat ès sciences spécialisé en sciences informatiques ou en génie informatique;
Au moins sept ans d'expérience pratique en tant que développeur en informatique décisionnelle et en processus d'extraction, de transformation et de chargement de données dans un environnement d'entrepôt de données, incluant la conception, le développement, les essais et le déploiement desdits processus;
Au moins cinq ans d'expérience en modélisation d'entrepôt de données dans un environnement d'entreprise à grande échelle;
Expérience démontrée et connaissance spécialisée de Microsoft SQL Server (y compris SSIS, SSAS et SSRS);
Expérience et connaissance de SQL et d'Oracle PL/SQL;
Expérience et connaissance de la plateforme de données Snowflake;
Solide compréhension de l'ingénierie et de la conception de bases de données, y compris les bases de données relationnelles ou dénormalisées et les lacs de données;
Expérience et connaissance de la plateforme Azure;
Expérience et connaissance de la passerelle Power BI;
Capacité de travailler de façon autonome ou au sein d'un groupe sous une supervision limitée;
Expérience de travail avec JIRA et la gestion de code source;
Expérience des méthodes de livraison Agile;
Esprit d'équipe avec la capacité de motiver les gens et d'être un modèle positif pour eux.
Capacité à travailler efficacement sous pression et à gérer plusieurs tâches.
Capacité à participer à une rotation sur appel (3heures par semaine);
Fortes aptitudes à la communication, tant à l'oral qu'à l'écrit, en anglais et en français.

McKesson is in the business of better health and we touch the lives of patients in virtually every aspect of healthcare. At McKesson Canada, we touch the lives of 12 million Canadians every day. We carry more than 35,000 products in 17 distribution centers and ultimately provide distribution to 6,300 retail pharmacies, 1,350 hospitals, long-term care centers, clinics and institutions all over Canada. But we're so much more than a distribution company. We've automated 2,500 retail pharmacies and dispense over 100 million doses a year through our automation solutions. Manufacturers, healthcare providers and patients count on us for a full range of services that contribute to the quality and safety of care for us all.

At McKesson Canada, you'll help us carry out our mission to improve lives and advance healthcare. Working here is your opportunity to shape an industry that's vital to us all.

What you will do:

Design, develop and maintain Data platform solutions
Perform full development lifecycle, including:
Analyze / evaluate business data requirements,
Analyze data, create data models, data mappings,
Develops databases and ETLs from scratch,
Implements data pipelines, schedule and orchestrate jobs, automate tasks,
Produce design documents according pre-determined methodology or process,
Design, code and debug according to pre-determined standards; code review as required,
Create test cases
Perform unit testing, integration and performance testing
Promotions to different environments
Production support
Documentation.
Be proactive and provide status of effort accomplished, estimates of remaining effort, and issues impacting progress
May supervise resources for design/development activities and follow up on efforts
Collaborate with internal (architect, analyst, DBA and others) and/or external stakeholders where needed to solve problems
Train, coach and provide guidance to others in area(s) of specialization; foster teamwork and innovation by involving others in problem solving and creative thinking
Participate in the evaluation and identification of new technologies
Ensure that commitments toward internal and external customers are met in a timely and cost-effective manner; solicits feedback from customers to identify opportunities to improve products and/or services.

Who you are:

Bachelor's degree in Computer Science/Computer Engineering
7+ years of hands-on experience as a BI / ETL Developer in a data warehouse environment, including ETL design, development, testing, and deployment
5+ years of data warehouse modeling experience in large-scale enterprise data warehouse environment
Experience and expert knowledge of SQL Server (including SSIS, SSAS, SSRS)
Experience and knowledge of SQL and Oracle PL/SQL
Experience and knowledge of Snowflake data platform
Solid understanding of database engineering and design, including relational, de-normalized, and data lakes
Experience and knowledge of Azure platform
Experience and knowledge of Power BI Gateway
Ability to work independently or in a group under a limited degree of supervision
Experience working with JIRA and source code control
Agile delivery experience
Team player, with an ability to motivate and be a positive role model for others
Ability to work efficiently under pressure and manage multiple assignments
Able to participate in on-call rotation (3 hours per week)
Strong written and oral communication skills in English and French

Worker Type
Regular

McKesson is an Equal Opportunity employer.

The material contained herein is provided for informational purpose only. All open jobs offered by McKesson on this recruitment system are subject to specific job skill requirements. The job skill requirements, qualifications, and preferred experience are determined by a subsidiary, office or department within the company which is offering the position, and all positions are subject to local prevailing employment laws and restrictions. This would include immigration laws pertaining to work authorization requirements and any other applicable government permissions or compliance.

The materials on this site are provided without warranties of any kind, either expressed or implied, including but not limited to warranties regarding the completeness of information contained on this site or in any referenced links. While McKesson attempts to update this site on a timely basis, the information is effective only as of the time and date of posting.

McKesson is an equal opportunity employer and values diversity in its workforce. We encourage applications from all qualified individuals and will accommodate applicants' needs, up to the point of undue hardship, throughout all stages of the recruitment and selection process.

The information on this site is for information purpose only and is not intended to be relied upon with legal consequence.

Current employees must apply through internal career site.

Join us at McKesson!","McKesson Canada Corporation / La Corporation McKesson Canada
3.7",Saint-Laurent
591,"Research Scientist, Core ML | Chercheur/chercheuse scientifique, apprentissage automatique de base","Facebook is seeking a Research Scientist to join our AI Research Team, a research organization focused on making significant progress in AI. Individuals in this role are expected to be recognized experts in identified research areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. The ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. To learn more about our research, visit https://ai.facebook.com/.-Facebook est en quête d’un chercheur ou d’une chercheuse scientifique pour compléter son équipe de recherche en intelligence artificielle, un organisme de recherche dont l’objectif est de permettre de grandes avancées dans le domaine. Ce poste requiert une expertise dans des domaines de recherche tels que l’intelligence artificielle (IA), l’apprentissage automatique, les statistiques informatiques, les mathématiques appliquées, notamment sur des sujets comme l’apprentissage profond, les modèles graphiques, l’apprentissage par le renforcement, la perception artificielle, le traitement automatique du langage naturel et la représentation de données. La candidate ou le candidat idéal(e) sera avide de réussir des percées scientifiques permettant de comprendre l’intelligence et la technologie pour développer encore davantage l’intelligence informatique. Pour en savoir plus sur nos recherches, visitez le site https://ai.facebook.com/.
Lead research to advance the science and technology of intelligent machines | Mener des recherches pour faire évoluer la science et la technologie des machines intelligentes.
Lead research that enables learning the semantics of data (images, video, text, audio, speech and other modalities) | Mener des recherches permettant l’apprentissage de la sémantique des données (formats image, vidéo, texte, audio ou autre).
Devise better data-driven models of human behavior | Concevoir de meilleurs modèles de comportement humain fondés sur les données.
Work towards long-term ambitious research goals, while identifying intermediate milestones | Participer à la poursuite d’ambitieux objectifs de recherche à long terme, tout en définissant les étapes intermédiaires nécessaires à leur réussite.
Influence progress of relevant research communities by producing publications | Influencer les avancées de groupes de chercheurs et de chercheuses pertinents grâce à la publication d’articles.
Contribute research that can be applied to Facebook product development | Contribuer aux recherches pouvant être appliquées au développement de produits de Facebook.
Lead and collaborate on research projects within a globally based team | Mener des projets de recherche et y participer aux côtés de collaborateurs et de collaboratrices du monde entier.
Experience holding a faculty, industry, or government researcher position | Expérience dans un poste de chercheur au sein d'une faculté, d'une industrie ou d'un gouvernement.
Ph.D. and publications in machine learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields | Doctorat et publications dans le domaine de l’apprentissage automatique, de l’IA, des sciences informatiques, des statistiques, des mathématiques appliquées, de la science des données, ou dans d’autres domaines techniques pertinents.
Experience leading a team in solving modeling problems using AI/ML approaches | Expérience de l’encadrement d’une équipe chargée de résoudre des problèmes de modélisation à l'aide d'approches IA/ML.
Experience in theoretical and empirical research and for addressing research problems | Expérience de la recherche théorique et empirique et de la résolution de problèmes de recherche.
Experience communicating research for public audiences of peers | Expérience en communication des recherches pour un public de pairs.
Knowledge in a programming language | Connaissance d’un langage de programmation.
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment | Doit obtenir un permis de travail dans le pays où se trouve l’emploi à la date d’embauche et maintenir ce permis pendant la durée de l’emploi.
1+ year(s) of work experience in a university, industry, or government lab(s), in a role with primary emphasis on AI research | Au moins un an d’expérience dans un laboratoire d’une université, de l’industrie ou du gouvernement dans un poste principalement axé sur la recherche dans le domaine de l’IA.
Experience driving original scholarship in collaboration with a team | Expérience dans la conduite de recherches originales en collaboration avec une équipe.
First-author publications at peer-reviewed AI conferences (e.g. NeurIPS, CVPR, ICML, ICLR, ICCV, and ACL) | Publications à titre d’auteur principal ou d’autrice principale présentées lors de congrès sur l’intelligence artificielle et évaluées par des pairs. (p. ex., NeurIPS, CVPR, ICML, ICLR, ICCV et ACL).
Experience in developing and debugging in C/C++, Python, or C# | Expérience de développement et de débogage en C/C++, Python ou C#.
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.","Facebook
4.3",Montreal
592,Data Science Consultant,"Do you view data as an art and a science? So do we.

How we support you:
We believe in gender equity and an inclusive community. We offer a comprehensive benefits package: generous vacation allowance disability coverage, retirement plans, paid maternity and paternity leave, life insurance, hotel and travel discounts, extended benefits to cover items that support your well-being, health, dental, and vision insurance, professional development and paid Microsoft certification opportunities.

As an Industry Data Scientist, you will help clients understand and extract insight and value from their data using Machine Learning and AI techniques. Working as part of a team, you're involved in all phases of analytics projects including question formulation, design, research and development, implementation, and testing. This role will explore and understand data and build advanced solutions that could be predictive, prescriptive, or optimize. You are able to translate client problems into quantitative language, find or build algorithms to solve those problems and implement them in code. You will be working on full data science pipeline, bringing solutions from research to production.

The work:

Lead and run a small team of data scientists
Deliver data science insights using statistical, data mining, and machine and deep learning
Understand client needs and build solutions for them
Provide thought leadership for projects and about leading technologies
Keep up-to-date on AI trends
Here’s what you need:

5+ years of demonstrated ability using statistics and data science
Proven track record developing machine learning using clustering, regression, optimization, recommendation, and neural networks, among other techniques
2+ years of experience with data science tools like Python, R, Scala, Julia, SAS, SPSS, MATLAB, MicroStrategy, or Tableau
Proficiency in SQL.
Strong vision and critical thinking
Contribute new ideas and challenge the status quo when appropriate
Form and motivate the team at the different stages of growth
Excellent written and verbal communication skills
Passion for problem-solving
Experience working with cloud services like AWS, Google, and Azure
Ability to travel to client locations
Bonus points if:

You’ve got a master’s degree in a related field
You’ve worked as a consultant on big data projects
You’re passionate, creative, and forward-thinking
You know how to use big data tools like Hadoop, Hive, and Spark","Avanade
4.1",Calgary
593,Data Engineer,"A Day in the Life

The Data Engineer is a critical part of our software development and delivery team. They have a deep understanding of our data model and how to capture, structure and deliver data to help us and our partners make insightful decisions and gain competitive advantage. They are a relentless problem solver who improves the overall warehouse management system (WMS) product and plays a crucial role in helping our organization continue to thrive.

For the right person this position is open to be remote or in any of our locations we do business.


All About You

The Perfect Fit:

Has the ability to work under pressure, be flexible and adapt to changing priorities.
Can communicate in an open, helpful, and engaging manner both internally and with clients.
Has the ability to organize information and convey the meaning across the organization.
This person owns the tasks and projects they get involved with and sees them through from front to end.
Is self-directed, confident, and motivated. Can take a user story through the research, development, testing and deployment process without micromanagement.
Has a deep understanding of data engineering processing, including relational and NoSQL databases, RESTful APIs and data warehousing.
Has attention to detail and discipline to meet complex acceptance criteria.
Has excellent problem-solving skills, including the ability to draw reasonable conclusions from incomplete information.
Lives in accordance to and can make decisions based on our company values and leadership principles.


The Must Haves:

Must have 1+ years’ experience in high-quality software development.
Must have 1+ years’ experience in data engineering or a similar discipline.
Microsoft SQL Server or other database experience.
Comfortable in a Scrum/Kanban environment with emphasis on continuous delivery, automated testing, pair programming and rigorous peer review.

Assets:

Exposure to a .NET language (VB, C++, C#, ASP, etc.).
Microsoft Azure cloud development experience.
Experience in automation.
Experience in software architecture design or database administration.
Experience with Power BI.
Experience optimizing database performance.


Things You Will be Doing

Demonstrates leadership and accountability at every level.
Embraces personal ownership of the product and commits to helping our team succeed at meeting our objectives.
Suggests ways to improve our process and products, both during sprint retrospective and during the sprint.
Steps up where needed with insight and guidance that will help build the skills and competence of the entire development organization. Calls out problems in a constructive way that helps us find the path to success.
Takes initiative and works in a self-driven way, while maintaining open lines of communication with other team members and remaining humble enough to ask for help when needed.

2. Designs and develops new data pipelines to support new features and integrations.

Keeps up to date on new technologies and explores new ways to work with and store our data.
Researches/implements best practices and designs patterns to deliver scalable, maintainable data solutions.
Communicates effectively with end users to create actionable reports and data transformations that will enhance our understanding of the business.
Collaborates with other team members on challenging deliverables and pivot as needed to ensure we succeed as a team.

3. Champions clean data design and helps manage our existing data sources and stores.

Leverages their expert knowledge of database/dataflow design to ensure our WMS software and associated systems are extended in a way that maximizes value and speeds delivery.
Understands our existing data systems and recommends improvements that will improve performance and integrity for the future.

4. Ensures quality is baked into every step of the development process.

Implements appropriate unit tests during the development process.
Verifies that we solved the right problem in a way that meets user needs and enhances the overall quality of the system and code base.
Works with other developers and our Quality Assurance/Automation specialists to ensure that new code is well covered with automated integration and UI tests.

5. Participates in team Scrum meetings (sprint planning, daily scrums, sprint reviews and retrospectives).

6. Performs other duties as requested.


Benefits

We offer attractive working conditions and benefits to our team members and their families:

Competitive salaries;
Vacation;
Choice benefits plan;
Flexible and fun work environment;
Ability to order directly from our amazing Clients;
Autonomy in decision making;
Profit share program;
Development and ongoing learning opportunities;
Ability to have a say and make an impact on the organization.

fnlxjwg2n4","NRI
3.7",Kirkland
594,Data Science Instructor,"About the Position

Exciting things are happening at Juno College! We’re in the midst of building out our Data Science Career Pathway and are seeking a full-time Instructor to join our Data Science team in May. We’re looking for someone who is collaborative, empathetic, and passionate about teaching, with a strong background in Data Science. This is a flexible role that’ll allow you to inspire and lead others, mould new pedagogies, research and test innovative ways of delivering content, and support the growth of our Data Science program offerings, while also still having the chance to practice your craft by taking on data science projects for Juno, exploring our various data sets, and delivering insights that can change the trajectory of our business.


We are currently offering all of our courses Live Online, and will only move back to in person learning when it's safe to do so. We anticipate having most, if not all, courses Live Online for all of 2021 and so this role is remote-friendly.


About Us

Founded in 2012, Juno College of Technology (formerly HackerYou College of Technology) is a well-loved provider of hands-on, project-based training for people who want to launch new careers in tech! From our 12,000 square foot office in downtown Toronto (pre- and post-COVID-19) to our Live Online classrooms, we run Bootcamps and continuing education courses year-round. With thousands of alumni and 1000+ students a year, there’s a large community of people ready to welcome you to Juno!


Responsibilities:

Work with a team of instructors and mentors to lead Data Analytics and Data Science courses, helping students learn through lessons, code-alongs and interactive exercises
Work directly with our students in the classroom and give project support
Help resolve issues, and coach through debugging and technical problem-solving
Provide a thoughtful, stimulating, and positive classroom experience
Participate in supporting student events
Create, update and refine curriculum using student feedback and new developments in the Data Science field according to our Curriculum Roadmap
Collaborate with the team to create and review program improvements and innovations
Contribute expertise to in-house data science projects using Juno’s data sets
Other tasks as required



About You

As a private career college, all of our instructors are required to have at least 2 years of practical, real-world experience as Data Analysts, Data Scientists or similar. Candidates who do not have the required experience will not be considered for this position. It would be great if you also have any experience as a teacher, instructor, or mentor, in any discipline.


Your Qualifications

Hold a degree, diploma, or certification from an Ontario college, university, private career college, or equivalent, and
Have 24 months occupational Data Science experience

Or

Have 36 months of teaching Data Science experience, and
Have 24 months occupational Data Science experience

Or

Have 48 months of occupational Data Science experience



You could be a great fit if you:

are an excellent public speaker and written communicator
are passionate about teaching data science and data fluency skills
have demonstrable hands-on industry experience in data science
are collaborative, energetic, and empathetic, and a great technical problem solver
have expertise in using Python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization
have practical knowledge of working with big data, performing customer segmentation, and using cloud services
are comfortable using Git, GitHub, Google Docs, Sheets, and Drive
have a positive attitude and a desire to help others.



Salary, Perks and Benefits

Position type: Full-Time, Permanent
Starting salary: $70,000 - $85,000
Clear growth paths
Three weeks paid vacation plus extra time off in December
Seven paid personal days each year
Health spending account refreshed annually
& more



Visit our Careers page at junocollege.com/careers for a full list of perks & benefits.


How to Apply

Please apply through the link below and answer the provided questions. We’d love to see your resume, and anything else you’d like to provide us! All applications are appreciated, but we will only contact successful applicants to move on to the next stage.","Juno College
2.8",Midtown Toronto
595,Air Quality Engineer or Scientist,"Air Quality Engineer or Scientist - ( 210001AZ )

Description

Grounded in safety, quality, and ethics, our experts lead their fields and guide our work with rigor, a creative spirit, and vision for growth. We draw from more than 20 technical specialties around the globe and are committed to fostering an inclusive community of diverse talents, backgrounds, and expertise. We’re a place to apply your passion and collaborate with top environmental talents on work that’s critical to our clients and the communities they support. Join a team that has the environment down to a science.

Your Opportunity

We have an opening for an Intermediate Air Quality Engineer or Scientist to join our team in Dartmouth, NS, Fredericton, NB, Charlottetown, PEI or St. John’s, NL. Stantec’s Atmospheric Environment group is dedicated to helping our clients manage air quality and climate change issues professionally and proactively. Our professional engineers and scientists provide specialized services to a wide variety of sectors including manufacturing, industry, commercial, transportation, mining, oil and gas, power and government. We offer a full suite of services including design and permitting, monitoring programs, predictive modelling, Greenhouse Gas emission quantification and verification, climate adaptation assessments as well as planning and policy studies.

Your Key Responsibilities

Conducting field monitoring
Collection of data and information (desktop and at client sites)
Data analysis and interpretation
Regulatory and literature review
Predictive air dispersion modelling
Authoring technical air quality related reports
Assist with the preparation of proposals

Qualifications

Your Capabilities and Credentials

Excellent communication skills (written, verbal, listening skills, etc.).
Proven and verifiable leadership skills.
Positive can-do attitude.
Successful track record.
Strong professional references.
Good quantitative and computer skills with Microsoft Office software needed.
Familiar with air dispersion modelling of stationary and mobile emission sources using modelling programs such as AERMOD, CALPUFF, CAL3QHC, MOVES, etc.
Familiar with preparation of Emission Summary and Dispersion Modelling Reports.
Experience conducting ambient air quality monitoring field work.
Experience with programming, numerical modelling, and statistical analysis would be an asset.
Experience in climate change adaptation and vulnerability assessments, GHG and energy evaluations would be an asset.
Able to work independently with minimal supervision and in a multi-disciplinary team.
Flexibility in scheduling is required for travel necessary for site work (normally travel would be within Atlantic Canada).
Experience with ambient air quality monitoring and stack testing
Experience with Greenhouse Gas quantification, verification, mitigation, and reduction planning
A valid drivers' license is required.

Education and Experience

A Bachelor’s degree in Engineering, Meteorology, or Physical Sciences.
A Master’s degree in Engineering, Meteorology, or Physical Sciences would be an asset. Minimum 3-5 years related experience necessary, or an equivalent combination of education (e.g., advanced degree) and experience.

Typical office environment working with computers and remaining sedentary for long periods of time. Field work may include exposure to the elements including inclement weather. Ability to lift and move items and equipment up to 50 lbs.

This description is not a comprehensive listing of activities, duties or responsibilities that may be required of the employee and other duties, responsibilities and activities may be assigned or may be changed at any time with or without notice.

Stantec is a place where the best and brightest come to build on each other’s talents, do exciting work, and make an impact on the world around us. Join us and redefine your personal best.

Primary Location : Canada-Nova Scotia-Dartmouth

Other Locations : Canada-New Brunswick-Fredericton, Canada-Newfoundland and Labrador-St. John's, Canada-Prince Edward Island-Charlottetown

Job : Environmental Scientist

Organization : BC-1214 Environment Services-CA Atlantic Canada

Employee Status : Regular

Job Level : Individual Contributor

Travel : Yes, 10 % of the Time

Schedule : Full-time

Job Posting : May 25, 2021, 8:17:16 AM

Req ID: 210001AZ

Stantec provides equal employment opportunities to all qualified employees and applicants for future and current employment and prohibit discrimination on the grounds of race, color, religion, sex, national origin, age, marital status, genetic information, disability, protected veteran status, sexual orientation, gender identity or gender expression. We prohibit discrimination in decisions concerning recruitment, hiring, referral, promotion, compensation, fringe benefits, job training, terminations or any other condition of employment. Stantec is in compliance with local, state and federal laws and regulations and ensures equitable opportunities in all aspects of employment. EEO including Disability/Protected Veterans","Juno College
2.8",Dartmouth
596,Big Data Engineer - Analytics,"Help us catch bad guys with math.




Our team is growing and we’re looking to add a Big Data Engineer - Analytics that can focus on extending our existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. This will include enabling Data Scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer.





Although there is a lot of uncertainty in the market today, especially considering the COVID-19 crisis, we are set up to accommodate fully remote work, and a fully virtual interview, selection, and onboarding process.




We are looking for someone who is passionate about what they do, takes a creative approach to problem-solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments.





Here’s what you'll do:




Implement model data flows to support running cutting-edge machine learning techniques on massive amounts of data.
Work with product managers and data scientists to turn new features and algorithms into beautiful, battle-tested code.
Work with the technologies we use to analyze and identify cyber-security threats for our customers (Elasticsearch, Spark, HBase, Kafka, Vertica, NiFi, using Java and Scala).
Work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics.
Create efficient and robust cloud-based solutions, leveraging the best in cloud technologies.



In order to be considered, you must have:




An undergraduate or Master’s degree in Computer Science or equivalent engineering experience.
Strong interest in software design, distributed computing, and databases.
Experience developing in a JVM environment (Java, Scala, Clojure).
At least two years of experience developing with or using Big Data & Analytics stacks/tools such as Hadoop, HBase, Spark, Presto, and Vertica.
Experience implementing and using streaming platforms such as SparkSQL, Flink, Kafka, Storm, etc.
Experience with Kubernetes, Docker, Ansible or any other infrastructure or containerization management/automation platform.
Familiarity leveraging AWS EMR, Azure, GCP cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset.



We’d also love it if you had the following (though not required):




Familiarity with data science or machine learning packages (pandas, R, TensorFlow, etc…).
Familiarity with virtualization technologies (VMWare ESX, Docker).
Contributions to open-source software (code, docs or mailing list posts).
Interest in understanding and analyzing diverse types of data.



Interset is an equal opportunity employer. Should you require accommodation in any aspect of our selection process, please contact our recruitment team at hiring (at) interset (dot) com.




About Interset:




We use big data and advanced behavioural analytics to detect and prevent the theft of intellectual property...simply put, we catch bad guys with math. Part of the Micro Focus group of companies, we are a fast-paced, all hands on deck kind of environment where you are respected and listened to from day one. We have a startup feel within the stability and structure of a large global company. We hire people with a wide scope of knowledge and experience that want to jump into self-organizing, cross-functional teams. We manage our own schedules, we support our teammates, and we always make time for fun.","Interset
4.6",Ottawa
597,"Sr. Data Scientist, Wish Local","Company Description


Wish is a mobile e-commerce platform that flips traditional shopping on its head. We connect hundreds of millions of people with the widest selection of delightful, surprising, and—most importantly—affordable products delivered directly to their doors. Each day on Wish, millions of customers in more than 160 countries around the world discover new products. For our over 1 million merchant partners, anyone with a good idea and a mobile phone can instantly tap into a global market.

We're fueled by creating unique products and experiences that give people access to a new type of commerce, where all are welcome. If you’ve been searching for a supportive environment to chase your curiosity and use data to investigate the questions that matter most to you, this is the place.



Job Description


We are looking for a Data Scientist who will work cross-functionally with technical and non-technical teams to take on a variety of tasks including but not limited to mining data, building models, building dashboards, and conducting detailed analysis. The ideal candidate should be passionate about Wish and e-commerce, has a strong analytical and consultative mindset, deep understanding of databases, visualization, and modeling techniques, and the ability to thrive in a dynamic, fast-paced environment delivering against tight deadlines. This role is looking for a data scientist that will drive high impact to the company through its newest function: Wish Local. The data scientist will help shape the data strategy of this program from the ground up.

What you'll be doing:

Design, development and evaluation of highly innovative models
Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation
Work closely with software engineering teams to drive real-time model implementations and new feature creations
Analyze internal behavior tracking data and forecast Wish demand
Implement the strategies and set up A/B test experiments to gauge the impact, and reiterate
Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process
Create & own dashboards and analytical reports to track progress & share learnings

#LI-MB1
#LI-REMOTE



Qualifications

Bachelor's or advanced degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics or similar)
3+ years of hands-on experience in predictive modeling and analysis
3+ years experience writing complex SQL queries in a business environment
2+ years in Python
A/B test experience
Experience collaborating with business & eng teams

Preferred Qualifications:

Analytical mindset and ability to see the big picture and influence others
Detail-oriented and must have an aptitude for solving unstructured problems
Ability to work effectively in a multi-task, high volume environment
Ability to be adaptable and flexible in responding to deadlines and workflow fluctuations
Experience operating in a Unix/Linux environment
Strong presentation skills

Additional Information


Wish values diversity and is committed to creating an inclusive work environment. We provide equal employment opportunity for all applicants and employees. We do not discriminate based on any legally-protected class or characteristic. Employment decisions are made based on qualifications, merit, and business needs. If you need assistance or accommodation due to a disability, please let your recruiter know. For job positions in San Francisco, CA, and other locations where required, we will consider for employment qualified applicants with arrest and conviction records.

Individuals applying for positions at Wish, including California residents, can see our privacy policy here.","Wish
3.3",Midtown Toronto
598,Data Engineer,"Commure enables innovators to build modern health software that improves the quality of care and its efficiency of delivery. We believe that better software for doctors, nurses and patients – and ultimately for the entire healthcare system – comes from connecting the top minds in technology, healthcare and design.

We are seeking talented Data Engineers to join our growing Engineering team. At Commure, engineers work side by side with designers, architects, researchers, product managers, healthcare partners, as well as physicians within our company to design, implement, and maintain solutions that meet the concrete needs of providers.



We are a welcoming and diverse team with a wide range of backgrounds and experiences. We pride ourselves on building robust, high-quality software using a modern tech stack. If you share our commitment to improving healthcare innovation and value close partnerships between developers and doctors, come work with us!
As a Data Engineer at Commure, you will:
Architect and implement tools and cloud agnostic products to satisfy the analytics and data demand of the organization
Contribute to the continuous building of our DataOps culture
Implement data management policies
Identify and solve issues to improve data quality
Improve data foundational procedures, guidelines and standards
Have end-to-end ownership of projects throughout their lifecycle
Join our collaborative Engineering, Product, and Design team and provide a valued voice as we scale our team and culture
We are looking for Data Engineers who:
Are inspired by our mission to improve health software and reduce burnout among providers
Have a solid foundation in SQL and in at least one programming language
Experience with streaming processing frameworks and messaging queues (Kafka, Event Hubs)
Share a commitment to high-quality engineering practices using modern tools and languages
Exhibit grit, high integrity, a team mindset, and an affinity for continuous learning
Enjoy wrangling real-world complexity into deceivingly simple solutions
Thrive in a collaborative, diverse environment
Benefits:
Medical, Dental, and Vision Coverage
FSA & HSA Accounts
Commuter Benefits
Flexible Time Off
401k
Commure is committed to creating and fostering a diverse team. We are open to all backgrounds and levels of experience, and believe that great people can always find a place. We are committed to providing reasonable accommodations to all applicants throughout the application process.","Commure
4.4",Montreal
599,GCP Data Engineer,"ProCogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.




At ProCogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.




We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.




The Position




ProCogia are looking to add a Data Engineer with GCP Big Query experience to our Engineering team based in Vancouver.

The Data Engineer is a key member of the Data Engineering team. Your position will be based around building Enterprise Data Warehouse and Data Lake.


Main Responsibilities



Work in building and architecting multiple Data pipelines, end to end ETL and ELT process for Data ingestion and transformation in Google Cloud Platform (GCP)
Coordinating tasks amongst the team
Build, maintain, and monitor batch, micro-batch and real-time ETL pipelines in a Google Cloud Platform architecture (BigQuery, Dataproc, Cloud Composer, Cloud DataFlow, Google Cloud functions, etc.)
Work closely with the Data Science and Analytics teams to develop a clear understanding of data and data infrastructure needs; assist with data-related technical issue
Research and evaluate various approaches to data architecture and applications, including big data technologies; review existing artifacts and recommend solutions and technologies to implement
Analyze corporate data, design and develop Business Intelligence and other data management solutions
Perform data validation and quality assurance.
Document requirements and business rules into appropriate technical specifications
Participate in work planning and estimation
Present technical solutions to various stakeholders
Provide day-to-day support of the EDW and DL environments, with excellent customer service to internal clients, monitor new deployments and services, escalating issues where appropriate
Create Tableau data sources and dashboards for various Business stakeholders



Requirements



5+ years experience working in a directly comparable role responsible for data warehouse and/or data lake development
2+ years experience with Google Cloud Platform (BigQuery, GCS, Cloud Functions, Cloud Dataflow, Pub/Sub, Cloud Shell, GSUTIL, BQ command line utilities, DataProc, Cloud Operations)
2+ years experience with other cloud data technologies such as AWS (S3, Glue, Lambda, Lake Formation, CloudFormation, Athena, Redshift)
5 years working directly with relational databases with strong SQL programming skills; significant experience with SQL Server (DBMS, SSAS Tabular Model, SSRS), including MDX and DAX
3 years experience designing, building, and optimizing ‘big data’ pipelines, architectures, and data sets
3 years experience with modern programming languages (Python, PySpark, Java, etc.)
2 years experience working with NoSQL databases/repositories
2 years experience with big data solutions (Kafka, Hadoop, Spark, etc.), including data stream processing
Experience designing a new data solution or new subject area
Understanding of dimensional modeling, star schemas, and associated Kimball methodology
Excellent verbal and written skills in English
Exceptional attention to detail
Experience working on an Agile development team
Strong analytical, troubleshooting, and problem-solving skills
A proven ability to effectively prioritize and execute tasks in a high-pressure environment
A strong work ethic without sacrificing your sense of humor or your ability to have fun on the job.","ProCogia
4.7",Vancouver
600,"Data Engineer, Alexa Speech","Bachelor’s degree in math, finance, engineering, statistics, or related discipline is required.
Computer Science or equivalent experience.

5 years + experience as a Data Engineer, Business or similar roles
Strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams
Proficient in scripting languages(python, SQL, NoSQL, etc.)
Ability to self-direct, multitask, and prioritize a constantly evolving workload
Obsession with quality, operational excellence, and customer experience
Are you customer-obsessed and interested in Speech and Language Understanding? Do you find creating cutting-edge voice control in the automotive market exciting? If so, the Alexa team is looking for a talented Data engineer to help revolutionize our voice-forward experience. Alexa is the Amazon service that powers the groundbreaking Echo family of devices, Fire TV, tablets, third party Alexa providers, and soon, cars! We believe voice is the most natural user interface for interacting with technology across many domains; we are inventing the future.

You’ve found the right team if you are a passionate Data Engineer with experience building innovative, mission critical applications that customers love. You will help to kick-start a new organization in Toronto and have an enormous opportunity to make an impact on cutting edge products used every day by people you know.

We’re working hard, having fun, and making history; come join us!

The ideal candidate will have excellent analytical skills and the ability to synthesize data into data stores and data pipelines for use by data scientists, business leaders, and engineers. To be successful in this role, you should have broad skills in database design, be comfortable dealing with complex, medium to large data sets, and understand how self-service dashboards are built and used with your data sets. The successful candidate will have a passion for data and analytics, be a self-starter comfortable with ambiguity, strong attention to detail, an ability to work in a fast-paced and entrepreneurial environment, and driven by a desire to innovate.

Responsibilities include:
·

Develop the end-to-end automation of data pipelines, making datasets readily-consumable by visualization tools, machine learning platforms, and notification systems
·

Establish new, scalable, efficient, automated processes for ingesting data used by scientists to model and forecast Alexa traffic
·

Maintain and enhance existing data pipelines
·

Work with data scientists to source data for machine learning algorithms that forecast traffic coming to Alexa
·

Work with dashboard owners and business owners to understand data needed for key business cost metrics and building data stores and data pipelines to deliver the needed data
Master’s degree in Computer Science, Engineering, Math, Finance, Statistics or a related discipline.
Familiarity with AWS solutions such as EC2, DynamoDB, S3, and Redshift.
Knowledge and direct experience using business intelligence reporting tools. (OBIEE, Business Objects, Cognos, Tableau, MicroStrategy, SSAS Cubes, etc.).
Experience coding with scripting languages (R or Python) to do basic data manipulation and mathematical computations
Experience in partnering with business owners to understand requirements and develop supporting analysis to solve business problems.
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contracted for employment opportunity, advice Human resources if you require accommodation, including in order to apply for a position.","Amazon Dev Centre Canada ULC
3.8",Midtown Toronto
601,Chercheur scientifique - Principal - Research Scientist,"***English will Follow***

Résumé :

En tant que chercheur principal au sein du groupe de recherche ASR, le candidat effectuera des recherches algorithmiques sur des ensembles de données à l'échelle de production dans le but d'optimiser la précision, la vitesse et l'évolutivité, principalement pour les systèmes ASR de bout en bout qui équipent les produits Nuance. Ces recherches porteront notamment sur les architectures de réseaux neuronaux, les algorithmes d'entraînement et d'adaptation ([non/semi-]supervisés), ainsi que sur le traitement et l'augmentation des données.

Principales tâches et responsabilités -

Fournir une analyse expérimentale et théorique des problèmes de reconnaissance de la parole.
Formuler et mettre en œuvre de nouveaux algorithmes et concevoir/réaliser des expériences pour les vérifier.
Explorer de nouvelles architectures de modélisation de séquence à séquence pour améliorer la précision de la reconnaissance.
Optimiser la précision des systèmes de reconnaissance vocale de bout en bout sur des données réelles difficiles.
Suivre les développements externes en matière d'algorithmes de reconnaissance vocale afin de maintenir nos recherches à la pointe du progrès.
Discuter et présenter les idées et les résultats, en rendant compte régulièrement des progrès réalisés.
Rédiger des rapports techniques internes et des articles pour une publication externe.

Connaissances, compétences et qualifications -

Formation : Doctorat en informatique ou équivalent

Nombre minimum d'années d'expérience professionnelle : 3


Compétences requises :

Expérience et connaissances approfondies des algorithmes d'apprentissage automatique, y compris l'apprentissage profond.
Compréhension approfondie des algorithmes de reconnaissance vocale.
Capacité démontrée à mener des recherches inédites sur les algorithmes de reconnaissance vocale.
Expérience avec les boîtes à outils open source d'apprentissage profond (en particulier TensorFlow ou PyTorch).
Python et script shell dans un environnement UNIX.
Bonnes compétences en communication écrite et orale.
Capacité à prendre des initiatives, mais aussi à suivre un plan et à bien travailler au sein d'une équipe.

Compétences préféré :

Bonnes capacités d'analyse et de diagnostic.
Expérience de l'exécution d'expériences à grande échelle dans un environnement de calcul GPU en grille ou en nuage.
Expérience des techniques de modélisation de séquence à séquence.

-

Summary –

As a Principal Research Scientist in the ASR Research group, the candidate will perform algorithmic research on production-scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end-to-end ASR systems powering Nuance products. This will include research into neural network architectures, ([un/semi-]supervised) training / adaptation algorithms, and data processing / augmentation.


Principal duties and responsibilities-

Provide experimental and theoretical analysis of speech recognition problems.
Formulate and implement new algorithms and design/conduct experiments to verify them.
Explore new sequence-to-sequence modeling architectures for improving recognition accuracy
Optimize the accuracy of end-to-end speech recognition systems on challenging real-world data.
Follow external developments in speech recognition algorithms to keep our research state-of-the-art.
Discuss and present ideas and results, reporting progress on a regular basis.
Write internal technical reports and papers for external publication.


Knowledge, skills and qualifications –

Education: PhD in CS or equivalent

Minimum years of work experience: 3 years

Required skills:

· Strong background and knowledge of machine learning algorithms including deep learning.

· In-depth understanding of speech recognition algorithms

· Demonstrated ability to conduct novel research in speech recognition algorithms.
Experience with open source deep learning toolkits (especially TensorFlow or PyTorch)

· Python and shell scripting in a UNIX environment.

· Good written and oral communications skills.

· Ability to take initiative, but also follow a plan and work well as part of a team.

·

Preferred skills:

· Good analytical and diagnostic skills.

· Experience of running large scale experiments in a grid / cloud GPU computing environment.

· Experience with sequence to sequence modeling techniques.

What we offer!

Unique environment for collaborative teamwork on cutting-edge technology:

Location is in the heart of downtown Montreal

Flexible hours

Transit reimbursement and parking

Working with international teams to push the boundaries of technology

Contributing to and collaborating with international teams that drive innovation

Competitive benefit package

4 weeks’ vacation

10 paid sick days

Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan

Award-winning Top Employer:

Canada's Top 100 Employers – 7 consecutive years

Montreal’s Top Employers – 6 consecutive years

Canada's Top Employers for Young People - 3 consecutive years","Nuance
3.8",Montreal
602,Chercheur Scientifique Senior - Senior Research Scientist,"***English Will Follow***

Résumé :

En tant que chercheur senior au sein du groupe de recherche ASR, le candidat effectuera des recherches algorithmiques sur des ensembles de données à l'échelle de production dans le but d'optimiser la précision, la vitesse et l'évolutivité, principalement pour les systèmes ASR de bout en bout qui équipent les produits Nuance. Ces recherches porteront notamment sur les architectures de réseaux neuronaux, les algorithmes d'entraînement et d'adaptation ([non/semi-]supervisés), ainsi que sur le traitement et l'augmentation des données.





Principales tâches et responsabilités

Fournir une analyse expérimentale et théorique des problèmes de reconnaissance de la parole.
Formuler et mettre en œuvre de nouveaux algorithmes et concevoir/réaliser des expériences pour les vérifier.
Explorer de nouvelles architectures de modélisation de séquence à séquence pour améliorer la précision de la reconnaissance.
Optimiser la précision des systèmes de reconnaissance vocale de bout en bout sur des données réelles difficiles.
Suivre les développements externes en matière d'algorithmes de reconnaissance vocale afin de maintenir nos recherches à la pointe du progrès.
Discuter et présenter les idées et les résultats, en rendant compte régulièrement des progrès réalisés.
Rédiger des rapports techniques internes et des articles pour une publication externe.

Connaissances, compétences et qualifications -

Formation : Doctorat en informatique ou équivalent

Nombre minimum d'années d'expérience professionnelle : 3

Compétences requises :

Expérience et connaissances approfondies des algorithmes d'apprentissage automatique, y compris l'apprentissage profond.
Compréhension approfondie des algorithmes de reconnaissance vocale.
Capacité démontrée à mener des recherches inédites sur les algorithmes de reconnaissance vocale.
Expérience avec les boîtes à outils open source d'apprentissage profond (en particulier TensorFlow ou PyTorch).
Python et script shell dans un environnement UNIX.
Bonnes compétences en communication écrite et orale.
Capacité à prendre des initiatives, mais aussi à suivre un plan et à bien travailler au sein d'une équipe.

Compétences souhaitées :

Bonnes capacités d'analyse et de diagnostic.
Expérience de l'exécution d'expériences à grande échelle dans un environnement de calcul GPU en grille ou en nuage.
Expérience des techniques de modélisation de séquence à séquence.

-

Position summary:

As a Senior Research Scientist in the ASR Research group, the candidate will perform algorithmic research on production-scale datasets with the aim of optimizing accuracy, speed and scalability, primarily for end-to-end ASR systems powering Nuance products. This will include research into neural network architectures, ([un/semi-]supervised) training / adaptation algorithms, and data processing / augmentation.


Principal duties and responsibilities –

Provide experimental and theoretical analysis of speech recognition problems.
Formulate and implement new algorithms and design/conduct experiments to verify them.
Explore new sequence-to-sequence modeling architectures for improving recognition accuracy
Optimize the accuracy of end-to-end speech recognition systems on challenging real-world data.
Follow external developments in speech recognition algorithms to keep our research state-of-the-art.
Discuss and present ideas and results, reporting progress on a regular basis.
Write internal technical reports and papers for external publication.



Knowledge, skills and qualifications –

Education: PhD in CS or equivalent

Minimum years of work experience: 3

Required skills:



Strong background and knowledge of machine learning algorithms including deep learning.
In-depth understanding of speech recognition algorithms
Demonstrated ability to conduct novel research in speech recognition algorithms.
Experience with open source deep learning toolkits (especially TensorFlow or PyTorch)
Python and shell scripting in a UNIX environment.
Good written and oral communications skills.
Ability to take initiative, but also follow a plan and work well as part of a team.

Preferred skills:

Good analytical and diagnostic skills.
Experience of running large scale experiments in a grid / cloud GPU computing environment.
Experience with sequence to sequence modeling techniques.

What we offer!

Unique environment for collaborative teamwork on cutting-edge technology:

Location is in the heart of downtown Montreal

Flexible hours

Transit reimbursement and parking

Working with international teams to push the boundaries of technology

Contributing to and collaborating with international teams that drive innovation

Competitive benefit package

4 weeks’ vacation

10 paid sick days

Bonus Plan, Group RRSP, Deferred Profit Sharing Plan, Employee Stock Purchase Plan

Award-winning Top Employer:

Canada's Top 100 Employers – 7 consecutive years

Montreal’s Top Employers – 6 consecutive years

Canada's Top Employers for Young People - 3 consecutive years","Nuance
3.8",Montreal
603,"Compliance Manager, Data Protection & Cybersecurity","Do you want to join a rocket ship that is passionate about data protection and
building a compliant product the right way?
Do you want to leverage your GDPR, HIPAA or SOC 2 compliance expertise to help us
cure COVID and cancer?
Do you want to work with a gender-balanced team of highly recognized experts in the
field of Cybersecurity, AI and Genomics?
My Intelligent Machines (MIMs) is looking for a talented Compliance Manager, Data Protection & Cybersecurity to help build a world class augmented intelligence R&D platform for life scientists working in BioPharma and agriculture companies. MIMs is a fast-growing software company, with recurring revenues, that embraces Agile and Privacy by Design methodologies. Reporting directly to the COO, you will be working closely with our Cybersecurity Analysts, DevOps Engineers, System Administrators, bioinformaticians, life scientists, data scientists, AI and software developers to establish best practices for the AI revolution in genomics.
Main Responsibilities
Collaborate with our open-minded teams to maintain compliance with these guidelines and standards:
European General Data Protection Regulation (GDPR)
US Health Insurance Portability and Accountability Act of 1996 (HIPAA)
SOC 2
Cybersecurity Framework of the US Nat Inst. of Stand. and Tech. (NIST)
Canada Personal Information Protection and Electronic Documents Act
(PIPEDA)
California Consumer Privacy Act (CCPA)
ISO 27001
Hébergeur de Données de Santé (HDS)
Translate legislation and regulations into policy and procedures in order to embed them smoothly in day-to-day activities
Be the company expert and champion on new regulatory developments (e.g. consultation papers, communication from regulators), industry trends, and how they apply to MIMs
Assessment and review of Company’s service level agreements with outsourced companies and regularly review compliance of outsourced companies with these agreements
Provide advice, assistance and support to the business on compliance related matters
Assuring the design, implementation and execution of compliance framework in line with all policies
Setting up compliance by design especially in customer journeys or digital initiatives and while setting up playbooks for a further explanation of specific topics
Promoting a strong compliance culture and contributing to training and awareness on the topic of data protection and cybersecurity
Plan & support Internal and External Audits
Regularly monitors and reviews risks as part of the compliance risk management process
Advise on further mitigation or on specific control testing
Provide guidance and feedback to the security team and compliance teams in implementing the various initiatives launched by MIMS
Guides on incident learning reports, investigates (whistleblowing) incidents. Takes the lead in person oriented investigations
Carry out due diligence checks on new clients and suppliers or consultants
Qualifications
Minimum of 5 years of experience in a similar role
A relevant certification from this list or the desire to achieve one, fully paid by
MIMs:
Certified Ethical Hacker (CEH)
Certified Information Systems Security Professional (CISSP)
Certified Compliance Professional (CAMS)
CompTIA Security+
GIAC Information Security fundamentals (GISF)
ISACA CSX
Microsoft Technology Associate (MTA) Security Fundamentals
System Security Certified Practitioner (SSCP)
Experience with identifying and resolving IS (security) technology related problems in an industrial and international company is a plus
High-level of professionalism, even in the midst of multiple engagements
Experience in working on multiple projects concurrently using Agile methodologies
Experience with programming and/or scripting languages is a plus
High level of proficiency in English
High level of proficiency in French is a plus
A confident approach and an ability to communicate with a wide range of people including regulators, legal advisors, outsourced partners and senior management
Relevant University Degree
Who you are
A flexible attitude to job roles as well as a willingness to contribute wherever needed
The ideal candidate will take full ownership of their core responsibilities, and will be comfortable with those responsibilities evolving with the changing needs of the company
The ideal candidate is exceptionally detail-oriented and derives joy from bringing rigor, structure, and organization to complex systems
Ability to contribute in a multidisciplinary team as a strong team player, focused on delivering results against multiple deadlines in a fast-paced growing environment
Submission
Please submit your resume or any questions you may have to hr@mims.ai. We would like to hear from you even if you are not sure you have all the qualifications.
By applying to this position, you are confirming you possess either a Canadian citizenship,
permanent resident status or work permit.
We thank all those who apply but only those selected for further consideration will be contacted.
About MIMs
My Intelligent Machines (MIMs), based in Montreal, is a leader in artificial intelligence applied to life sciences. We provide Biopharma and Agtech companies with augmented intelligence systems enabling life scientists working in this space to model patients, cells, tissues or farm animals to develop more efficient and personalized treatments and agro-products. The company is growing at a fast pace and has a strong and active research and development team.
MIMs is a dynamic tech company with an exceptional culture which embraces diversity and gender equity. New team members consistently rate our onboarding and integration process as one of the best they have seen in their career. We are currently one of the few tech companies reaching gender balance, as half of the team is composed of women. We received the 2020 Red Herring’s Top 100 North America Award, one of the most prestigious prizes granted each year to the 100 most promising private tech companies.
For more information, please visit https://www.mims.ai",My Intelligent Machines,Montreal
604,Data Engineer,"Full-timeVancouver




JUNE 14, 2021

Job ID: 21275

AbCellera is a young, energetic, and rapidly growing tech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease.

We are seeking an ambitious and experienced Data Engineer to join our Data Management team and contribute towards building a dynamic and scalable architecture in support of our rapidly advancing data pipeline. The ideal candidate will have experience working with ambiguity and be a creative thinker as our data landscape continues to evolve in scale, complexity, and demand. We are a fast-moving and innovative company that lives on the frontier of discovery, both scientifically and technically. As such, the successful candidate will spend their days focused on the design and implementation of a sophisticated data architecture that maximizes data quality, value, and velocity based on the needs of a talented team of scientists and developers.

How you might spend your days:

Identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Working with our team of developers to help improve the flow of data across the technology stack.
Building the infrastructure required for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources using SQL and AWS big data technologies.
Working with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Designing and publishing data models with supporting architecture that reflect on the prevailing needs of the organization; ensuring proposed solutions are scalable and dynamic.
Leveraging experience with multiple AWS services (S3, Redshift, Kinesis and RDS., etc.) or equivalent to design solutions in response to the data needs of key stakeholders and teams.
Together with the software development teams, optimizing and ensuring data security through integration and management of identity management tools within proposed data architecture.
Working with the Data Governance Office to ensure proposed solutions adhere to and align with the published data recommendations, practices, and policies.
Sharing your knowledge in data engineering with team members and colleagues, helping to elevate the core understanding for big data architecture and its impact on improving business processes.

We'd love to hear from you if you have:

5+ years of work experience with ETL, Data Modeling, and Data Architecture.
4+ years of work experience in writing advanced SQL
Bachelor’s Degree in quantitative areas such as Computer Science, Information Systems, Big Data & Analytics, or related fields.
Experience with Relational SQL and NoSQL databases: Postgres, MS SQL Server, and Cassandra, etc.
Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirement
Experience building and optimizing big data data pipelines, architectures and data sets.
Experience with data lakes, data warehousing, and the associated tools and applications for managing the flow of data across these environments.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong project management and organizational skills.
Experience with Agile development methods in data-oriented projects
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience in tracking data lineage, ensuring data quality, and improving discoverability of data.

Preferred Qualifications:

Experience with native AWS technologies for data and analytics such as Redshift Spectrum, Athena, S3, Lambda, Glue, EMR, Kinesis, SNS, CloudWatch, etc. or equivalent relevant technologies (e.g. Snowflake, Alteryx, Matillion, Boomi , etc.)
Expertise in one or more programming languages, preferably Scala, PySpark, Python and/or Java.
Experience with big data tools (e.g. Hadoop, Spark, Kafka, etc.).

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 3 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please send us your application through our website and refer to Job ID 21275 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera Biologics
4.8",Vancouver
605,"Data Engineer, Trust and Safety Operations","Dapper Labs is at an inflection point in our journey and it might be the perfect time for you to join us. Less than 6 months ago we launched NBA Top Shot on the new Flow blockchain and it is already on track to be the fastest-growing marketplace in history. Over $200 million in sales in the past 30 days and counting – we need to scale our systems to handle the demand!

We're looking for product-minded data engineers to build out our fraud protection team. You'll join a small team that's scaling rapidly and build sustainable foundations for the future.



Our data pipeline currently include Segment and Tableau. Most of our backend systems are in Go, frontends in React. We use vanilla postgres as well as Kafka event-driven architecture in NBA Top Shot. This is an opportunity to help define the company's data strategy, while laser focused on enabling the organization to make data-driven decisions by unlocking the distribution, collection, and tooling of data.

We believe in an open digital future: one where people own the assets they pay for and have full transparency into the software they're using. We believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they're helping create. Crypto, or blockchain, is the technology that enables this future. Blockchains are public computers that anyone can access, everyone can trust, and no-one can block or take down. Currencies and collectibles are only scratching the surface of what's possible.



Titles or years of experience don't matter to us – impact, authenticity, and values alignment do. We are now a remote-first team and open to hiring anywhere in the world.



About the role:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity
Work with Google Cloud Platform, BigQuery, Cloud Composer, etc, and drive adoption of other key technologies
Cleaning, processing, transposing data from our data lake to endpoints like Tableau
Create predictive models to understand user-level fraud risk
Consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality
Research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities
Innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the Dapper product team and our finance department
Bonus points if you have the following:
You have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made
You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply
You have a bachelor's degree in a highly quantitate field (Computer Science, Machine Learning, Statistics, Mathematics), and a master's degree preferred
You have 5+ years working experience in data science and or machine learning. Strong knowledge of SQL and python programming and graph databases
You are naturally curious and passionate about fraud prevention: if something seems off, you want to investigate what's going on and solve the true problem
You are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions

More about Dapper Labs:

Dapper Labs is the world's first blockchain entertainment company. We are the creators of industry-leading experiences including CryptoKitties and NBA Top Shot, as well as Dapper Wallet, the simplest way to manage your assets and use the blockchain. We are also the original developers behind Flow, a new decentralized blockchain designed from the ground up for scalability and ease of use.

Our mission at Dapper Labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. We have raised over $350M from leading VCs including Fred Wilson (USV) and Chris Dixon as well as Venrock, Samsung, Google Ventures, Coatue, NBA players, and global artists, among others. Dapper Labs partners include the NBA and NBPA, the NFL-PA, Ubisoft, Warner Music, Turner, Dr. Seuss, Genies, and the UFC, as well as 100+ others.

Visit our website to learn even more about Dapper Labs, including information about benefits and perks.","Axiom Zen
4.3",Vancouver
606,"Data Engineer, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Vancouver; Montreal; Ottawa; Toronto

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the office.


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Data Engineer on our Data & Analytics Modernization team within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in technical data solutions including ETL, data integration, data warehousing, dimensional models, in-memory architectures, master data/reference management, and business analytics. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Engineer and architect ETL and BI/DW solutions to enable business analytics and drive insights
Translate business rules and requirements into data objects, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly
Plan/schedule tasks, lead small development teams, and mentor junior colleagues
Facilitate technical meetings with client staff, and advise client with technical option analyses based on leading practices
About the team


Omnia AI, Deloitte’s Artificial Intelligence (AI) practice is comprised of a collaborative team of experts who use their hands-on experience with cutting-edge information assets to facilitate successful AI transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

Enough about us, let’s talk about you


You are someone with:

3+ years experience with analysis, design, development, testing and deployment of ETL services in relational data warehouse environments on DB2, Oracle, SQL Server and/or SAP/HANA using technologies such as Informatica PowerCenter, IBM DataStage, Microsoft SSIS and/or Talend for batch and/or real-time data processing
3+ years implementation experience with data warehouse architectures, data vaults, dimensional models, and/or star schema designs implemented on MPP, in-memory/columnar databases, cloud-based and/or RDBMS platforms
Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirements
Experience with Agile development methods in data-oriented projects
Completed Bachelor’s Degree (or higher) in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or related field is desired

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.","Deloitte
3.9",Midtown Toronto
607,"Data Engineer / Power BI Developer, Omnia AI","Job Type: Permanent
Primary Location: Vancouver, British Columbia, Canada
All Available Locations: Vancouver; Calgary; Edmonton

Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the officev


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Data Engineer / Power BI Developer within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in technical data solutions including ETL, data integration, data warehousing, dimensional models, in-memory architectures, master data/reference management, business visualization and business analytics. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Engineer and architect ETL and BI/DW solutions to enable business analytics and drive insights

Translate business rules and requirements into data objects, visualizations, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly

Plan/schedule tasks, lead small development teams, and mentor junior colleagues

Facilitate technical meetings with client staff and advise client with technical option analyses based on leading practices

About the team


Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge BI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

The Integration Modernization Practice helps clients manage the complexity inherent in today’s diverse business landscape while supporting them in consolidating or customizing multiple technologies. You will be part of a multi-disciplinary team focused on delivering a breadth of solutions to solve our clients most challenging business problems, with a focus on Integration Platforms, API design, and Micro and Web Services. We help our customers to reduce costs and risks by simplifying integration with existing systems and supporting them in all aspects of creating customized and innovative digital solutions.

Enough about us, let’s talk about you


You are someone with:

Bachelor’s Degree in Computer Science, Mathematics or Statics; Master’s Degree desirable

5 or more years of BI – Data Engineering related experience with high proficiency in PL/SQL coding, Power BI, Python, Cloud-based data platforms (AWS and Azure preferred), database management, and ETL from job creation to performance testing and tuning

Ability to tackle tight deadlines and work under pressure

Experience working in fast-paced Agile environments an asset

Competent decision-making capabilities with ability to respond and react to emergency situations effectively and communicate to stakeholders, client leadership, and individuals at several organization levels

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Vancouver
608,Data Engineer,"Open up to the Possibilities!
At Purolator, you’ll be proud knowing you’re working for a Canadian company that truly values its employees. And it’s community. This is an exciting and evolving industry and we’re leading the change as we strive to deliver the future. Here you will be empowered to help move the business forward. Each and every day. Are you open to the possibilities?


Job Description


Successful candidates will demonstrate excellent skill and maturity, be self-motivated as well as team-oriented, and have the ability to support the development and implementation of solutions to meet the needs of our customers. Your strong experience and skills in Business Intelligence and Data Architecture will help Purolator leverage its data for a variety of analytic use cases to support strategic decision making, in a way that is governed, sustainable, and scalable.

You are passionate about data, and not only do you understand the mechanics of how to access, move and manipulate data, you also understand how data can be leveraged to empower reporting and analytics. While you are strong technically, you are also adept at consulting with non-technical business users to understand the root of their requirements, to develop BI solutions that truly meet their needs.


Responsibilities

Serve as a subject matter expert in Data Engineering technology and related processes.
Understand business issues and decompose them into measurable data or data modelling requirements.
Curate data for governed reporting and self-service data discovery and analytics
Contribute to consultations workshops with various business stakeholders to understand the root business needs for new reporting and analytics use cases
Build experimental data processes and BI assets for rapid prototyping of reports and dashboards from new data sources
Help administer the Business Intelligence platforms to ensure the environment is secure, up to date, and accessible

Skills:

A seasoned Business Intelligence professional with hands-on experience developing and administering front-end BI tools such as PowerBI, Qliksense
A savvy data architect with strong understanding of datawarehouse principles and methodologies
Great communication skills, you can effectively convey highly technical concepts to a non-technical audience
Excellent problem-solving skills, able to systematically analyze, hypothesize, and solution problems and issues
Hands-on experience with datawarehouse technologies, preferably with cloud-based platforms such as AWS Redshift and Azure Synapse
Experience developing and building ETL/ELT pipelines using GUI based tools such as Glue, Pyspark and ability to code custom data workflows via Java and Python a strong asset
Energized by working on a small team with the ability to make an immediate impact on the business
Experience working in an Agile environment (developing stories, prioritizing tasks, grooming)

Qualifications:

Bachelor or Master degree in a technology/analytical field such as Computer Science, Management of Information Systems, Mathematics, Statistics, Machine Learning/AI, Engineering, or other relevant technical fields.
Experience in an Agile environment
Excellent programming knowledge in any of the languages (Phyton, R, Hadoop, Kafka, Spark/Scala).
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Experience with relational SQL and NoSQL databases.


POSTING DETAILS
Location: 530 - Corporate
Working Conditions: Office Environment

Reports to: Manager Reporting and Data Delivery
-

Purolator is an equal opportunity employer committed to diversity and inclusion. We consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Indigenous status or any other factors considered discriminatory. If you require an accommodation during the recruitment process, we will work with you to meet your needs.


We recognize that our employees and their families are key stakeholders. We will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. We hire for attitude and train for skills. To learn more about us and our values, go to www.purolator.com.


At Purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.","Purolator
3.9",Mississauga
609,Cloud Data Engineer- GCP/BigQuery,"Job Description:
Applied Systems, Inc., a worldwide leader in insurance technology, is currently searching for a knowledgeable and talented Cloud Data Engineer-GCP/BigQuery to join our Data Engineering Team. This team works to build data solutions and implement tools to help improve data accuracy and reliability so our customers can make data-driven decisions with confidence. As the Cloud Data Engineer, you will be responsible for the design and implementation of our data lake ensuring reliable data infrastructure and creating data solutions for business partners.

RESPONSIBILITIES
Drive innovation within Data Engineering by playing a lead role in technology decisions for the future of our data science, analysis, and reporting needs
Work with business partners and software engineers to gather, understand, and bridge definitions and requirements
Lead the design and development for highly complex and critical data projects with strict timelines
Drive efficiency gains through improved reliability and stakeholder adoption of self-serve tools
Leverage research and previous experience to ensure we’re up to date and continuously exploring
Identify gaps and weaknesses in our data stack and continues to drive learning advancements for the team
Provide technical expertise, leadership, and mentor the Data Engineering team in all phases of work including analysis, design, and development of architecture
Design, build and work with dispersed engineering teams and business users to implement data pipelines into our centralized data platform
Developing in Python leveraging a wide range of technologies, notably: GCP, BigQuery, Google Pub/Sub, Google DataFlow, Kubernetes, and Docker
Develop cloud data pipelines to transform and process data between systems
Maintaining, improving existing continuous integration/delivery (CI/CD) pipelines
QUALIFICATIONS FOR THIS JOB
3+ years of development experience building large scale data solutions
Experience with GCP BigQuery, GCP DataFlow, GCP Pub/Sub, Apache Airflow and Python preferred
Experience with GitOps in an Infrastructure as Code culture.
Experienced with Git and common development workflows in Github/Gitlab/Bitbucket
Experienced with CI/CD declarative pipelines
Experience with Docker for containerizing applications and workloads
Experience with Terraform (or related technology) for infrastructure provisioning
Experience with reporting schema designs including data modeling, denormalization, data warehousing, and data lakes
Experience with data quality monitoring and alerting on dynamic data sources, including anomaly detection
Experience with metadata management, data governance, data catalogs, and data discovery
Proven ability to work closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality
Ability to communicate technical hurdles and challenges clearly and succinctly
Take problems from inception to completion - own the building, automated testing, deployment, and maintenance of the code that you work on

WHO WE ARE
LEADING GLOBAL PROVIDER OF CLOUD-BASED INSURANCE SOFTWARE- Applied Systems develops the top two Insurance Agency/Broker Management software products in the world. In addition, we also provide innovative mobile apps, Data Analytics, Customer Self-Service, Insurer Connectivity & Rating, eServicing, Benefits Design, and CRM software products. By automating the insurance lifecycle, Applied’s people and products enable millions of people around the world to safeguard and protect what matters most.
CLOUD SOLUTIONS & PROFESSIONAL SERVICES- We offer cloud solutions, 24x7 technical support, consulting, implementation, and education services.
AWARD WINNING TECHNOLOGY- We have been voted
2020 Company of the Year (Stevie Award)
2020 New Product or Service of the Year- 2 awards (Stevie Award)
2019 Best Cloud-Based Software Solutions Provider in the insurance industry (2019 Corporate Excellence Awards)
2019 Digital Service Provider of the Year (Business Excellence Awards)
2019 Best Broker Software Management House (Insurance Times)
GOOGLE’S INVESTMENT IN APPLIED- Google/CapitalG made a minority investment in Applied that will spur AI, machine learning, and digital marketing innovation in the global insurance industry.
CLIENTS- We provide technology to over 160k users within insurance agencies, brokerages, and carriers throughout the US, Canada, the UK, and Ireland.
EMPLOYEES- Applied currently has 1,800+ employees across the US, Canada, the UK, and Ireland.

COMPANY CULTURE & PERKS
JOIN A GREAT TEAM- We believe that success comes from a dynamic working environment that offers professionals an opportunity to grow and succeed alongside extraordinary people. We encourage idea sharing, problem solving, and teamwork in our environment.
DIVERSITY MATTERS- We strive to create a positive workplace culture for those of different thinking, backgrounds, experiences, expertise, and individual qualities across our organization. We want the best and the brightest to be a part of a growing culture that embraces a sense of belonging.
RELAXED DRESS CODE- Applied allows for a relaxed dress code where jeans are permitted; we call this “Dress for your Day”.
FUN PARTIES & PERKS- Fun perks are a staple at Applied, including holiday parties with games and contests, summer celebrations employee appreciation events, art contests, employee discount programs, and more!
OPPORTUNITIES FOR ADVANCEMENT- We are a growing company that offers career opportunities, and not just “another job”. Applied believes in growing our employees and promoting from within, offering many opportunities for professional advancement along the way!
CAREER STABILITY & LONGEVITY- Our average employee tenure is 9 years.
CULTURE OF RECOGNITION- Applied provides a culture of employee recognition with our Circle of Excellence program, and our internal social network recognition program.
APPLIED CARES- We have a culture that embraces and promotes volunteerism. Applied encourages our employees to help local charities and communities through the ‘Applied Cares’ program

BENEFITS & REWARDS
BENEFITS FROM DAY ONE- Applied offers Medical, Rx, Dental, Vision, Virtual Doctors’ Appointments, Health Savings Account, Flexible Spending Accounts, Critical Illness, Group Accident, and Wellness Incentives to ensure employees are covered from day one.
FINANCIAL PEACE OF MIND- In addition to wellness benefits, Applied offers traditional and Roth 401k options, with employer match. Accidental Death & Dismemberment, Short and Long Term Disability, and Business Travel Accident insurance are also offered.
WORKLIFE BALANCE- There is more to life than work: that is why Applied offers benefits to help balance your work and home life. We offer competitive paid vacation time, personal/sick time, paid holidays, summer hours, paid parental leave, volunteer time off, and a free day off for your birthday!

TO LEARN MORE
Please visit AppliedSystems.com

Applied Systems is an Equal Employment Opportunity and Affirmative Action Employer. Diversity and Inclusion is a business imperative and is a part of building our brand and reputation. At Applied, we are committed to recruit, develop, retain, and promote regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.


#LI-Remote","Applied Systems, Inc.
4.2",Remote
610,Business Intelligence Data Engineer,"At Loblaw Digital, we know that our customers expect the best from us. Whether that means building the best, most innovative online shopping experiences, or designing an app that will impact the lives of people across the country, we’re up for the challenge. Loblaw Digital is the team responsible for building and operating the online businesses of Canada’s largest and most successful retailer. Based in downtown Toronto, we are an entrepreneurial, fast-paced, and collaborative team working towards transforming the way Canadians shop by creating leading eCommerce experiences in the online grocery shopping, beauty, pharmacy, loyalty, and apparel spaces, and we’re only just getting started! To achieve these goals, we are looking for talented and passionate individuals who want to collaborate and solve challenging problems and make significant and lasting impact on Canadians.

The impact you’ll make

As a Business Intelligence Data Engineer, you will impact our business by fueling the best in class data analytic and reporting platform at Loblaw Digital that will empower our business users in making data driven decisions and strategies in their everyday work.
We’re growing our BI team to better serve the enterprise data strategy and want you to be a part of it. You’ll work with users across the organization to understand how data helps them and translate that into solutions that will bring data from various systems into our data warehouse. We’re looking to turn our enviable wealth of data into actionable insights and meaningful recommendations that drive growth and improved engagement across all of our lines of business, and a customer-focused mindset is a must-have.
What you'll do
Develop and scale quality and performant data pipelines using GCP (Big Query, Compute Engine, Kubernetes, Cloud Composer, Dataflow) and other open source technologies
Work with stakeholders to develop solutions that support various data consumers
Work with DevOps on setting up environment for new deployment
Build and implement robust data models and semantic layer
Be a subject matter expert on the entire BI framework stack
Support reporting and analytics needs from all areas of the business. For example: Developers, Product Managers, Product Designers, Merchandizers, Marketers, and Operations Analysts
Help us in our mission to be a hypotheses-driven product development organization which means data is at the center of everything we do
Does this Sound like you?
BA/BS in computer science, engineering or related technical field
2 years experience as a BI Developer or Data Engineer
Hands-on experience with relational databases (e.g. Oracle, MySQL, DB2, etc.)
Python experience coding ETLs using various packages/connectors to databases and endpoints (or Java)
Working experience with Git and CI/CD pipelines
Experience with data pipeline automation using a code focused scheduling tool (e.g. Airflow)
Exposure to Kubernetes, docker, and streaming tools (Kafka)
Experience working with sourcing and feeding data from REST APIs is nice to have
Understanding of data warehouse concept and BI architecture is a plus
Strong oral and written communication skills
Solid stakeholder management skills
Proven team player that will work well in a dynamic and fast-paced environment
Experience working in an agile environment
Experience in retail or ecommerce is a plus
Strong desire to learn and to push the boundaries of what can be done to better empower our business with data

How you’ll succeed

At Loblaw Digital, we seek great people to continually strengthen our culture. We believe great people model our values, are authentic, build trust and make connections. We’re able to keep innovating because our colleagues are passionate about their work and excited about the future of eCommerce. You will get to work with some of the best digital minds and will have the support of world class technologies to craft products our customers will love!

Loblaw Digital recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. Accommodation is available upon request for applicants with disabilities in the recruitment and assessment process and when hired. In addition, we believe that compliance with laws is about doing the right thing. Upholding the law is part of our Code of Conduct – it reinforces what our customers and stakeholders expect of us.","Loblaw Digital
3.6",Midtown Toronto
611,Senior Scientist – Assay Development,"Deepcell is an early-stage Stanford spin-off company that has developed a unique platform for use in research, diagnostic testing, and therapeutics. We combine microfluidics, imaging, deep learning, and genomics to identify, isolate and analyze live, single cells. Our technology addresses diverse applications in the life sciences.
Come join Deepcell and make a difference! We're a small team of passionate innovators in biomedical engineering, artificial intelligence, molecular biology, and genomics. Our technology has won multiple prestigious awards and is backed by top-tier venture capitalists in Silicon Valley.
The senior scientist -assay development at Deepcell will report to principal scientist and be responsible on developing and optimizing methods and protocols for NGS-based molecular assays.
Responsibilities:
Work closely with cross-functional R&D team to design and execute experiments for cell isolation and bulk and single cell analysis
Design and optimize assays for molecular analysis of samples with small quantities of DNA and RNA.
Develop and optimize NGS-based single cell analysis workflow
Perform sample prep, instrument operation, assay design, optimization and validation
Develop new SOPs to improve consistency and accuracy
Contribute to product development milestones and company goal planning process
Key Qualifications:
PhD in Molecular biology, biochemistry, chemistry or similar fields
Broad background and knowledge of NGS technologies and data analysis
2+ years industrial experience in NGS assay development, preferably on single cells or low input samples
Demonstrated record in product development and verification/validation
Excellent experimental design, data analysis and trouble-shooting skills. Sound scientific judgement.
Strong written and oral communication skills
Strong interpersonal skills with the ability to interact with individuals from a variety of levels and functions
Self-organizer, meticulous hands-on habits, keen attention to detail
Ability to understand and execute on the company’s mission and values
Maintain a high degree of ethical standard and trustworthiness
Ability to think and adapt to a rapidly changing startup environment",Deepcell,Mountain View
612,"Data Analyst, Marketing Acquisition","FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an elite online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity – Data Analyst, Marketing Acquisition

The Analyst will enable FreshBooks reporting and help to derive insights from website, event, campaign and customer web and product interaction data to improve the volume and quality of acquired trailers, determine growth opportunities, understand the customer journey and major drop-offs.

The right person for the job will love to solve a problem and have a knack for translating data into insight and presenting that information to stakeholders. You will be collaborating with managers and a team that includes other analysts, data scientists, marketers, financial analysts, and developers all working together to drive growth at FreshBooks.

What you'll do:
Complete regular ad-hoc / deep-dive analyses by translating raw data into useable information and insights
Build dashboards for core performance metrics/monitor KPI's
Channel level reporting on trends in acquisition performance
Support with A/B testing for campaign treatments
Content / Webpage reviews and analyses
Work independently & with engineering to ensure the integrity of data flows / transfers
Monitor changes in usage behaviours (organically and due to marketing)
Performance evaluations of various customer segments
Assist with GTM tagging, maintenance and general organization
Consult with internal clients to gather requirements, scope & execute
Complex, long-term analyses on visitor trends and performance impacts
Communicate results and recommended analyses/approaches to stakeholders

What you bring:
Intermediate to advanced knowledge of SQL is required
Minimum 2-3 years in data analytics/business intelligence
Knowledge of Google Analytics data, and/or similar web analytics tools
Strong knowledge of one or more visualization tools such as Looker, Tableau etc.
Quantitative background with strong analytical skills
Experience working with relational databases
Familiarity with the marketing campaign and/or web data is preferred
Python knowledge is an asset
Google Tag Manager experience is an asset

Why Join Us

We're a motivated bunch, with our eyes laser-focused on shipping extraordinary experiences to businesses. You will be surrounded by hardworking team members who share a common vision for what an amazing software company could be, and have the opportunity to help build an elite one, right here in downtown Toronto.

Apply Now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer. We do not discriminate based on gender, religion, race, mental disability, sexual orientation, age, or any other status. All applicants are considered based on their qualifications and merits. At FreshBooks, we inspire an environment of mutual respect and we believe diversity and inclusion are crucial to our success.

FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com.","FreshBooks
4.0",British Columbia
613,Data Engineer,"Position Description




DATA ENGINEER
**This is a remote position located anywhere in Canada**


Who is a Data Engineer?

The Data Engineer will play an important role in driving forward GoodLife’s Technology & Innovation product roadmap through helping to build data services that support ‘WOW’ experiences for our Members and Associates. In our mission to be the BEST combined Live and Digital fitness experience, data plays a significant role in empowering a more personalized and informed suite of digital services. Joining the Data Operations Team, you will help design, implement and maintain batch and real-time scalable data pipelines with complex data transformations. In addition, you will support our software developers, database architects and data analysts on data initiatives to ensure an optimal data delivery architecture. You will foster a positive working culture of continuous improvement, modernized delivery and rapid go-to-market product innovation. We work in a highly dynamic, fast changing, and fluid environment, and are seeking an energetic addition to the team!

What will you be doing?

Design, build, maintain and improve data platform infrastructure for ingesting, storing, and transforming data to enable data-driven products and services
Design, implement, and maintain batch and real-time scalable data pipelines with complex data transformations
Write and optimize complex queries in order to make data easily and efficiently accessible to the consumers
Apply industry best practices when designing and building data pipelines to ensure data integrity, quality and security
Design and build prototyping solutions and conduct tests in order to support rapid product development and also to explore new design alternatives for our data platform
Assist with day-to-day support for data-related technical issues and data infrastructure needs
Maintain data governance artifacts to enable self-serve information access, including data catalog, data dictionary and data lineage documentation
Monitor the overall performance and stability of the data pipelines infrastructure
Work with cross-functional teams in a dynamic environment to support the development of data-driven products

Do you have what it takes?

Bachelor’s degree in Computer Science, Software Engineering or equivalent
5+ years’ experience in ETL/data modeling, building scalable and reliable data pipelines, architecting data stores, supporting complex ETL processes including SLA, performance measurements, and monitoring
Hands-on experience with leading Cloud platforms, including Azure Cloud Data Solutions and AWS
Experience with Informatica IICS and Snowflake considered a strong asset
Experience with message queues, batch and stream processing
Excellent SQL skills and experience in a DevOps environment
Experience with Agile development methodologies
Detail oriented: high standard of data quality and integrity
Familiarity with NoSQL databases like MongoDB is nice to have
Adaptable to a fast-paced environment and able to pivot quickly to align with changing priorities
Strong people skills; team player; excellent oral and written communication skills
Strong analytical and problem-solving skills; Able to multi-task
Committed to contributing to a culture that celebrates diversity, equity and inclusion and embraces social and environmental responsibility

What's in it for you?

Ongoing training and development to ensure a long and successful career path
Career advancement opportunities
Competitive Total Rewards Package
FREE Fitness membership
Fun and energetic atmosphere to come to every day!


At GoodLife Fitness, we are committed to fostering an inclusive, accessible environment, where all employees and members feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. We are committed to meeting the accessibility needs of persons with disabilities in a manner that respects their dignity and that is equitable. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.","GoodLife Fitness
3.7",Midtown Toronto
614,Machine Learning Scientist (Can be Remote Within Canada),"At BluWave-ai our mission is to deliver innovative AI solutions to accelerate the transformation towards renewable energy. We apply AI software to increase the use of clean energy in smart grids and microgrids with distributed energy resources and demand response. We are also driving the transition to electrification of transportation as the grid becomes the local gas station.

We are looking for talented people with entrepreneurial drive to seize on the ground floor opportunities, grow their careers, and make a positive impact for the environment.

1. Who you are

A machine learning engineer, with professional experience or equivalent applied research, strongly motivated by building impactful and dependable products based on pragmatic and rigorous application of ML techniques.
You have the drive to learn, evaluate, and apply a range of data science and ML techniques. The applications are real-time smart grid control and optimization solutions in the context of best scalability, availability, and security principles.
You are a pragmatic innovator who thrives in a fast-paced, disciplined, and team-oriented environment where we strive individually while supporting, learning from, and building on each other's ideas and efforts to succeed as a team. You have strong verbal and written communication skills with the ability to distill complex technical concepts to the level that non-specialists can comprehend. You are effective at teamwork, and you enjoy mentoring.
2. What you are Responsible for

Analysis, design, and implementation of ML solutions to prediction and optimization tasks.
Develop statistical and machine learning solutions for analysis, data mining, and modeling of IOT data.
Develop resilient testing strategies to monitor model performance.
Prepare documents and presentations to inform and demonstrate.
3. Your Knowledge, Experience, and Skills

Required:

Experience as a ML scientist within a commercial environment, or equivalent academic research experience with pragmatic experimentation or industry collaborative projects.
Experience with cleaning, reshaping, exploring, and visualizing data in various formats.
Strong programming knowledge and skills in Python.
Familiarity with machine learning tools and platforms such as TensorFlow, Keras, etc.
Considered an asset:

Experience in developing ML techniques for time-series prediction: e.g. regression, support vector machines, and neural networks.
Familiarity with control and optimization of modern power and energy systems.
Educational Requirements:

MSc or PhD in Mathematics, Statistics, Computer Science, or related data-intensive fields. Exceptional Candidates with a Bachelor's degree with strong relevant solution delivery experience are encouraged to apply.
4. What You Will Gain

Motivation to serve to the greater cause of climate change mitigation.
Knowledge, skills, and professional networking in one of the most exciting and positively impactful technology domains on the intersection of electrical engineering, machine learning, optimization, and software development.
Startup experience and ground floor opportunities for growth in an inter-disciplinary team that includes PhD Smart Grid and Machine Learning Scientists, recent grads, and seasoned business professionals.
Competitive compensation.
High quality of life and career in Canada's National Capital Region or remote work.
Working on a team with a serious approach towards our work, rather than ourselves, together with fun and random team events.
5. General Information

Level: All experience ranges are encouraged to apply
Position Type: Full-time
Location: Ottawa, ON (can be remote for exceptional candidates)
Department: Applied Science
Position Reports to: Vice President of Technology

Diversity makes us stronger. BluWave-ai provides equal employment opportunities to all employees and applicants without regard to race, color, religion, sex, gender, national origin, disability, or any other characteristic protected by applicable laws, regulations, or ordinances.

Authorization to work in Canada is required for this position.","BluWave-ai
5.0",Ottawa
615,Data Engineer,"Data engineering at EQ means you're working in the hottest areas of today's technology landscape: machine learning, big data, and geolocation data sets. You will be coming up with solutions to derive actionable insights about behavior, demographics, and personality out of our multi-terabyte dataset of location data. Examples of the type of analysis we do include:
Understanding what university students do during the summer holidays.
Predicting if someone is about to buy a house based on their visiting locations
Understanding someone at the airport is a business or leisure traveler.
And more.
Your role will involve working very closely with our CTO, data scientists, and the extended product team. With EQ leading the pack for location ad analytics in Canada and a top North American player - this role would let you define and shape the standards in this very vibrant and evolving industry.
Understand our current data sets and models and help us discover new ways to enrich the data
Creatively extracting real-world behavior and trends out of the location data
Monitor and build processes for cleaning up inbound data
Dream up a solution, perform the R&D, and deploy to production within our fluid work environment
Requirements
Ability to work with large amounts of data
Experience with map-reduce frameworks - Hive, Hadoop, and Spark (Elastic Map Reduce would be a plus)
Firm grasp of statistics, data modeling, and designing algorithms
Benefits
Cloud service credits (AWS, Google Cloud, Azure, Digital Ocean, etc.)
Public Transit allowance
Mobile data allowance
Home internet allowance
Flex days","EQ Works
3.4",Remote
616,Data Engineer - 96042,"What you do at AMD changes everything


At AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies – building blocks for gaming, immersive platforms, and the data center.


Developing great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the “extra mile” to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.




The world's most successful companies heavily leverage data to design products and services that delight their customers. At AMD, we have a culture of being customer-centric, and deliver high performance devices that are a joy to use. In this Data Engineer position, you will be part of a select team that works on the cloud-based big data analytic process and tools that will help build the analytic and data processing pipeline and to contribute to the analytic thought process that impacts AMD company-wide. You will be working on one of the fastest growing areas, with updated skill sets and hands-on access to big data.




Preferred Experience:

Proficiency in one or more of the following: Python, R, SQL, Java, Scala
Good understanding of quantitative analysis and statistical reasoning
Ability to learn new big data and analytic tools and technologies
Full stack web development, particular data dashboards
Machine learning and model creation and predictions
Examples of projects connecting data analysis with engineering or business improvements
Having worked on cloud-based technologies (any AWS services, Apache Spark, Databricks, Hortworks/Cloudera Data Platform, etc)

Academic Credentials:




Minimum of B.Sc. in Electrical/Computer Engineering or Computer Science

Location:

Canada, Ontario, Markham

#LI-CC2



Requisition Number: 96042
Country: Canada Province: Ontario City: Markham
Job Function:Design




AMD is an inclusive employer dedicated to building a diverse workforce. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective provincial human rights codes throughout all stages of the recruitment and selection process. Any applicant who requires accommodation should contact AskHR@amd.com.

AMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services.","Advanced Micro Devices, Inc.
4.1",Markham
617,Intermediate Data Engineer,"BlueDot continues to grow, and as a result we are looking for an Intermediate Data Engineer to join our Data Systems team!


As an Intermediate Data Engineer, you will create, expand, and optimize data pipelines to build upon our data platform. You thrive on writing complex queries, working with big data, and enjoy automating data pipelines and workflows. With us, you will solve problems with data integration and be working with data that has an impact on global connectivity as well as local areas of analysis. You will be working with both structured and unstructured datasets that are both spatial and non-spatial in nature.




Who we are:

BlueDot protects people around the world from infectious diseases using human and artificial intelligence. Our software-as-a-service solution combines medical and public health expertise with advanced data analytics to track, contextualize, and mitigate infectious disease risks. Our global early warning system combines more than 100 datasets with proprietary algorithms to deliver critical insights on the spread of infectious diseases. In December 2019, we flagged an undiagnosed respiratory syndrome in Wuhan, China. In January 2020, we published the world's first scientific paper on COVID-19, accurately predicting its global spread. Our team understands the complexity of the challenge in front of us – and that the urgency to solve the problem has never been greater.

Our Culture:
We are a Certified B Corp, have a Glassdoor rating of 4.7, are Diversio certified, a 2020 LinkedIn Top Start-Up and have been recognized as a Top 50 Best Place to Work in Canada, Best Place to Work for Women, Best in Technology, Best for Youth, and Best Start-Up!

Driven by a Purpose Bigger than Ourselves
United in a common purpose to create a healthier, safer, and more secure world, free from the impacts of dangerous infectious diseases, we understand the complexity of the challenge in front of us, and that it is so much bigger than any one of us. Together, we are motivated to positively impact lives around the world, to do no harm, and to elevate each other through respect and encouragement. Building careers through collaborative discovery and learning, our people tackle complex challenges with diverse expertise not assembled elsewhere. We promote personal fulfillment in the workplace by removing barriers, politics and exclusion, believing in the philosophy that by creating a positive environment we all have the opportunity do the most meaningful work of our lives.

Our values:
Our values are not just words on a wall. They are our compass and they guide us in our work, in the decisions we make and in how we treat each other:



Be the Change (our heart) - Making a meaningful difference through our work - for each other, for our customers, and for the world. Taking initiative, ownership, and action.
Think Without Borders (our mind) - Freeing our minds from conventional thinking, discovering without fear of failure, and learning from our customers - we make impossible challenges possible.
Lift Others Up (our soul) - Creating space for all those inspired by our purpose, elevating each other and fostering mutual growth. Our unique perspectives valued, respected and included.



What you will do in more detail:

Create and maintain optimal data pipeline architecture
Build and manage microservices on AWS
Design, develop, maintain cross-platform ETL processes
Use python to automate data processes and analyses to maximize efficiency
Help design, develop, test, document, and data pipeline related applications, programs and systems
Perform spatial analyses and create information products utilizing GIS and related software
Help design and implement data quality control procedures and policies
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Oversee and execute data migration from existing data stores
Assist with operationalizing data science models



What you have done to get here:

Degree in Computer Science, Engineering, related quantitative fields, or equivalent experience
Knowledge and experience with Python
Knowledge and experience with SQL
Experience with enterprise databases (MS SQL, MySQL or PostgreSQL)
Experience with source code control frameworks (Git).
Knowledge and experience with ETL software such as FME Desktop and FME Server
Knowledge and experience using NoSQL databases such as MongoDB or DynamoDB
Experience with GIS Products (QGIS, ArcGIS Enterprise, ArcGIS Pro) - nice to have
Collaborative attitude, with ability to excel in a team environment
Ability to quickly learn new tasks and systems, flexible in skills and attitude
Commitment to internal/external customer satisfaction through delivered excellence
Excellent written and verbal communication and interpersonal skills
Goal orientation with a drive to exceed expectations
Superior attention to detail and ability to produce professional deliverables & documentation on time.
Ability to manage personal time and priorities effectively



Ideally, you also have:

A basic understanding of modern techniques and tools for Data Science, Modeling and Analytics
An understanding of API architecture and integration
Experience with infrastructure as code (terraform, cloudformation)
Experience in the health sector



What we offer our team:

Meaningful work that truly has purpose
As a smaller, agile team, we offer roles with impact
Your contributions are integral, your voice will be heard
A competitive comprehensive compensation package
Outstanding health, vision and dental benefits
Employee and Family Assistance Plan
A health and wellness spending account
Generous vacation and other PTO
A home office setup allowance



We are working fully remotely due to COVID-19 until at least January 2022 – post pandemic we will continue with our remote first culture with the opportunity for a hybrid/flexible office space in downtown Toronto accessible to our team but without the requirement to work from the office.




Together let’s create a healthier, safer, and more prosperous world.




For more information, visit us at: http://bluedot.global.




BlueDot recognizes that challenges remain in achieving the full participation of equity-seeking groups (including women, Indigenous Peoples, persons with disabilities, members of visible minority/racialized groups, and members of LGBTQ2+) in tech careers and is committed to identifying and eliminating barriers that may exist within its own hiring process, programs, and practices.

BlueDot is committed to fair and accessible employment practices. If you are contacted for a job opportunity, please let us know how we can best meet your needs and advise us of any accommodations required to ensure fair and equitable access throughout the recruitment and selection process.

We thank and appreciate all applicants for their interest. Only those selected for an interview will be contacted. Please no agency calls.","BlueDot Inc.
4.7",Midtown Toronto
618,Cloud Data Engineer,"The Questrade Technology Group (QTG) is home to a unique environment, where our culture thrives and most importantly, we get stuff done! Questrade is continuing with its digital transformation initiative and our infrastructure footprint is growing beyond our data centres and into the Google Cloud Platform. We are currently working towards our exciting strategy that is driven by business value. Join us and help solve some complex challenges such as handling low latency and high traffic market data, event streams and messaging, in a hybrid cloud environment within an industry that has so much room for disruption.

The Cloud Data Engineer will work with a primary focus on delivering our data platform footprint, as an expansion of our cloud presence, enabling key initiatives such as our Digital Banking. This role will be working with several teams in the organization in a collaborative manner, helping deliver data related components that enable productivity across QTG by leveraging automation to deliver self-service components as much as possible. This key individual will be part of a team that drives the implementation of data components such as pipelines, applications, sanitation, supporting our data scientists and working with the rest of the product teams while collaborating with the architecture team, influencing the design and delivery of our data footprint and striving for greater functionality in our data systems.


What’s it like working as a Cloud Data Engineer at Questrade?

Our Data Engineer needs to be able to gather and understand data requirements, present it to software engineers, and work in the team to achieve high quality data ingestion goals. This Engineer will need a passion for complex problems, and enjoy the challenge of operating complex and mission critical systems under extreme loads. Do you think you are up to the challenge? Would you like to learn more and stretch your skills and career?

In this role, you will be a technical expert with significant scope and impact. You will work closely with a group of Software Engineers, Product Managers, Data Scientists, and Business Intelligence Engineers to create the data infrastructure and pipelines necessary to drive Questrade’s initiatives.

Successful candidates should come from a strong data engineering background. You need to have experience with structured and unstructured data, and being able to analyze/transform the data using various tools. Often, the pace of innovation and change implies a need to move to new data sources, and our Data Engineers get to participate in deep diving business data in order to understand/measure sources of disparity. Your analytical skills and knowledge of schema metadata will be essential.


Job responsibilities of the Cloud Data Engineer include...

Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Optimally extract, transform, and load data from a wide variety of data sources using SQL and Google Cloud data technologies.
Collaborate with the team to decide on which tools and strategies to use within specific data integration scenarios.
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.
Develop and maintain code and documentation for ETL and other data integration projects and procedures.
Monitor and anticipate trends in data engineering, and propose changes in alignment with organizational goals and needs.
Share knowledge with other teams on various data engineering or project related topics.


Are YOU our next Cloud Data Engineer? You are if...
Minimum 3+ years of experience working in the data engineering field.
Proficiency in SQL language.
Strong knowledge of Python language.
Experience in optimization of high volume ETL processes.
Experience with any of the popular Clouds (GCP, AWS, Azure).
Good knowledge in Message Broker systems (e.g., Kafka, PubSub).
Data modelling skills.
Good knowledge of popular data standards and formats (e.g, JSON, XML, Proto, Parquet, Avro, ORC, etc)
Experience in the financial industry is an asset.
Google GCP data platform (Dataflow, Dataprep, Cloud Composer, BigIGQuery, CloudSQL) knowledge and experience is an asset, or knowledge of the equivalent open source toolset behind those products.


At Questrade Group of Companies, with multiple office locations around the world, we are committed to fostering a diverse, inclusive and accessible work environment. We value the unique skills and experiences each individual brings, and believe that when our teams feel supported and motivated, their creativity becomes a source of innovation. We are also committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and also one which reflects the diversity of the communities we serve and operate in to help us revolutionize financial services for the benefit of all of our customers.


Candidates selected for an interview will be contacted directly. If you require accommodation during the recruitment/selection process, please let us know and we will work with you to meet your needs","QUESTRADE INC
4.1",Midtown Toronto
619,"Mentor (Development, Data Science, or Cyber Security)","Since 2013, Lighthouse Labs has been helping curious and creative people break into the tech industry with our accelerated, personalized, and outcomes-obsessed education. Our mission is to train the next generation of tech talent in coding, cyber security, and data science by looking at the unique needs of each student and helping them map out and achieve their career goals. A major part of this approach is our robust mentorship program, where students are guided through their learning journey by professionals who work in the industry themselves.


To keep serving the ever-expanding needs of our students and communities, we’re growing our team of amazing mentors that are so key to student success. We’re looking for intermediate to senior level full-stack developers, cyber security professionals, and data scientists to join our team. Are you passionate about mentoring, are creative and critical, and excited about problem-solving? We’d love to hear from you!


Mentoring with Lighthouse Labs:


As a mentor, your mission is to support our students through their academic journey, and prepare them for their transition into an exciting new career in tech. You’ll work directly with students to coach them through any roadblocks they might be experiencing, give them tips on solving problems, and generally provide them with support and advice.


Based on your personal experiences, field of knowledge, and availability, you can be matched to mentor in any of the following groups:

Web Development Bootcamp Cohorts
Introductory Program Cohorts
Junior Developers
Junior Data Scientists
Cyber Security



We’re flexible in how we work with mentors, and your schedule is structured according to how many hours you’re available for. Mentors are paid an hourly rate, and are able to work from any time zone.


What we need from you:




Mentors aren’t required to have formal training in their area of expertise. However, a true passion and curiosity for coding, cyber, or data, as well as learning and education in general, is a must.


The following qualifications are all important assets for aspiring mentors:

Minimum 2 years of professional experience in Software Development, Cyber Security, or Data Science.
Experience in a range of popular technologies in Web Development, Cyber Security and/or Data Science.
HTML, CSS, Javascript, Ruby/Rails, Python, Java, Scala, Golang, Elixir, Java, Scala,jQuery, Rails, React, NodeJS + (Express or Koa), Django, , MeteorJS, Elixir + Phoenix, Scala, AngularJS, Ember, R, Jupyter Notebooks, Tableau, Excel, AWS, MySQL, jira, Flutter, Firebase, TypeScript, Apollo, GraphQL, PostgreSQL, MongoDB
A strong understanding of open source development workflows using tools such as Github
Any experience in teaching, mentoring, or tutoring is an asset.



Lighthouse Labs is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. All positions at this time are remote, and we welcome all applicants.","Lighthouse Labs
3.9",British Columbia
620,"Data Architect, Technology Solutions","IT STARTS HERE.:
At MNP we pride ourselves on being different – it’s our entrepreneurial drive that sets us apart. It’s the same drive that’s helped us become Canada’s fastest growing national firm. We foster collaboration, value your ideas, promote based on talent, live balanced lifestyles and make time for FUN. We are one firm, one team, collaborating to support you wherever you want to take your career.

Join the momentum. We are seeking a Data Architect to join our Technology Solutions team. Driving business excellence, MNP is a leading national accounting, tax and business consulting firm in Canada. Our Consulting team works with organizations in the public, private and not-for-profit sectors to provide innovative strategies tailored to maximize efficiencies, enhance performance and increase profitability. Specifically, our recognized Technology Consulting team works with clients to translate technology issues and opportunities into meaningful results that meet organizational needs.
ROLE @ MNP:
Responsibilities
Works closely with clients and other resources to effectively communicate, design, plan, and implement capabilities that provide value to customers
Architect comprehensive data solutions that enable clients to appropriately capture, make sense of and action data.
Demonstrate value to clients through software demonstrations and prototypes; software installations/evaluations; assessment of business problems; and identification of solutions using the Microsoft Data Platform stack - on premise and hosted on Azure
Ensure delivered solutions fit within overall project plan and schedule
Provide feedback to customers and creates structured documentation, including specifications and weekly status reports
Advise clients on configuration and implementation options based on best practices
Participates in the business requirements gathering process for client customizations
Leads/Supports solution implementation, customization, testing, and deployment, including preparation of test scenarios.
Acts as a subject matter expert in transferring solution-critical knowledge
Collaborates with client team participants
Ensures that all implementation methodology deliverables are complete and on time
Generates project status, time, and expense reports as requested by management
Highly motivated, creative, and self-sufficient with the ability to work successfully under pressure
Work closely with clients and Firm stakeholder to develop in-depth knowledge of key drivers and success factors, operational processes, information systems and data sources pertaining to a client’s data domains
Work with decision makers, data scientists / analysts and other end users to define and document key performance indicators, analytic themes, reports and dashboards
Perform other tasks related to data architecture, database performance, data access and security and data quality management, as required
Help guide and implement Data Governance initiatives
Troubleshoot reporting, analytics and BI tools, systems and software and performance tune these applications, as necessary
Skills and Experience
5+ years of experience with Azure Data Lake solutions
2+ years experience Databricks solutions
2+ years experience deploying solutions using Azure Data Factory
Experience designing and implementing CI/CD pipelines
Experienced in the DevOps process design and implementation
Deep understanding of information and data and how it can be leveraged to provide business value
Comprehensive database and data warehouse analysis and design experience, with full knowledge of relational databases (Oracle & SQL Server), data warehouse methodologies and data modeling
Experience working with data integration tools
Experience with data visualization and analytics tools
Strong ability to gather, author and analyze business and technical requirements and build applications and integrations according to specifications
Strong understanding of relational database structures, theories, principles and practices
Full project management and development life cycle experience
Ability to lead projects and team members under limited supervision
Superior organizational and project management skills
The following skills would be considered an asset:
Knowledge of Data Management Tools in areas of Metadata, Master Data Management, Data Quality and Data Security
Deep knowledge of the DMBoK (Data Management Book of Knowledge)
Attained Data-related certifications such as CDMP, CBIP, etc.
Attained Vendor-related Data / Analytics / Reporting certifications (Tableau, IBM, SAAS, Microsoft, Oracle, Teradata, Hadoop, R, Python, etc.)
Knowledge in AI, Machine Learning, Data Mining and/or Blockchain
Experience as a Data Scientist including Predictive / Statistical Modeling
Experience in Cloud BI
Experience working with Google Analytics or other web analytics platforms
Experience working with SOA and ESBs
Experienced in DevOps / DataOps and Continuous Integration / Delivery / Deployment
Attained other PM and IT-related certifications such as COBIT, ITIL, CISSP, CGEIT, CRISC, CISA, CISM, PMP, Prince2, etc.)
A degree or diploma in computer science or computer programming from an accredited post-secondary educational institution
Previous success working in a customer-facing, consultative role
Experience working with different SDLC methods including Agile, Scrum, XP, RUP, and Kanban
The ability to work as part of a close-knit delivery team
Time management skills in a dynamic delivery environment
Field consulting or professional services delivery experience
Ability to travel to client locations
MY REWARDS @ MNP:

More than a paycheque, MNP is proud to offer customized rewards for our team members. With a focus on health and wealth, we provide an extensive list of benefits that support our unique culture and foster work-life integration.


Our MyRewards@MNP program offers benefits that allow you to thrive at work and outside of the office. Be rewarded with generous paid time off including 4 personal days, firm sponsored social events, a group pension plan with 4% matching contribution, voluntary savings products, bonus program eligibility, a wellness subsidy, health and dental benefits, mental health resources, exclusive access to perks and discounts, professional development assistance, learning opportunities through MNP University, a flexible dress for your day environment and more!","MNP
3.8",Toronto
621,Big Data Engineer,"EPAM is committed to providing our global team of more than 41,150 EPAMers with inspiring careers from day one. EPAMers think creatively and lead with passion and honesty. Our people are the source of our success. We value collaboration, work in partnership with our customers, and strive for the highest standards of excellence. In today’s market conditions, we’re supporting operations for hundreds of clients around the world remotely. No matter where you are located, you’ll join a dedicated, diverse community that will help you discover your fullest potential.



Description

You are curious, persistent, logical and clever – a true techie at heart. You enjoy living by the code of your craft and developing elegant solutions for complex problems. If this sounds like you, this could be the perfect opportunity to join EPAM as a Big Data Engineer. Scroll down to learn more about the position’s responsibilities and requirements.

REQ #: 225448556
What You’ll Do
We are looking for a Big Data Engineer that will work on the collecting, storing, processing, and analyzing of large sets of data
The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them
You will also be responsible for integrating them with the architecture used across the company
Requirements
Proficient understanding of distributed computing principles
Management of Hadoop cluster (Cloudera preferred), with all included services
Ability to solve any ongoing issues with operating the cluster
Proficiency with Hadoop v2, MapReduce, HDFS, Sqoop
Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming
Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala
Experience with Spark
Experience with integration of data from multiple data sources such as MsSQL Server, Oracle
Good understanding of SQL queries, joins, stored procedures, relational schemas
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB (preferred)
Knowledge of various ETL techniques and frameworks, such as Flume
Experience with various messaging systems, such as Kafka or RabbitMQ
Experience with Cloudera
FS domain knowledge a big plus but not required
What We Offer
Extended Healthcare with Prescription Drugs, Dental and Vision Insurance (Company Paid)
Life and AD&D Insurance (Company Paid)
Employee Assistance Program (Company Paid)
Unlimited access to LinkedIn learning solutions
Long-Term Disability
Registered Retirement Savings Plan (RRSP) with company match
Paid Time Off
Critical Illness Insurance
Employee Discounts","EPAM Systems
4.2",Canada
622,AI-Driven Drug Discovery Scientist (Psychedelics),"About MagicMed Industries

MagicMed is a biotechnology company focused on the discovery and commercial development of novel pharmaceuticals based on known psychedelic compounds. MagicMed’s expanding collection of psychedelic derivatives (the Psybrary™) is expected to yield the next generation of precision medicines for brain and mental health.

About The Opportunity
There is a revolution happening in mental health treating addictions and alleviating pain. Would you like to join an innovative and growing company whose goal is to make a positive impact on human health? Are you interested in participating in artificial intelligence and machine learning applications for cutting edge R&D?

MagicMed is seeking a full-time scientist to apply machine learning techniques to the problems of drug screening and discovery. You’ll be working with our Research & Development team as they evaluate new compounds, and with our technical partners who will provide direction on the AI elements of the screening pipeline. This is an opportunity to be involved in every aspect of our computational pipeline, to contribute your ideas, and have an impact in the development of novel psychedelic compounds.

Ideally this position will be based at our office in Calgary, Alberta; however, alternative options may be considered for the right candidate.
About The Candidate
Our ideal candidate is enthusiastic and has experience in the application of state-of-the-art cheminformatics and AI (machine learning, deep learning) tools to drug discovery projects. The candidate can work independently and is comfortable writing software, using libraries, and scripting data flows.

Key Responsibilities:

· Filter chemical databases by using virtual-screening approaches

· Apply existing models and techniques to assess drug candidates

· Collaborate effectively with the experimentalist team to improve biological properties (pharmacodynamics/pharmacokinetics) of drug candidates based on feedback from assay results

· Investigate, adapt, and train new models to improve the pipeline

· Provide regular reports and progress updates as required

Education:

· BSc in relevant field (Computation Chemistry, Computational Drug Discovery, Computer Science or related computational field)

· Master Degree or PhD preferred

Experience:

· Experience with computational chemistry tool sets such as Schrödinger, ACD/Labs, MOE, or similar.

· Previous experience with Artificial Intelligence and Machine Learning or Deep Learning frameworks (such as TensorFlow, PyTorch)

Core Competencies:

· An understanding of the fundamentals of drug discovery, from docking to ADMET.

· Strong analytical, trouble shooting and problem-solving skills, with the ability to exercise independent judgment

· Able to work collaboratively in cross functional multidisciplinary teams

· Excellent verbal and written communication skills

· Strong organization, prioritization and time management skills, with high attention to detail

· Motivated and self-directed with a demonstrated ability to work with minimum supervision in a fast-paced, dynamic environment

· Proficient in the use of the Microsoft Office suite

The successful candidate will have a strong interest and willingness to learn about psychedelics and the application of AI to drug discovery.
To Apply
MagicMed offers a competitive compensation and benefits package, a dynamic work environment and a great team! Please visit our web site at www.MagicMedIndustries.com for more information about our company.

To apply for this position, please send your resume and cover letter (detailing AI/machine learning and related experience).

MagicMed is equal opportunity employer, committed to an inclusive, diverse and accessible workplace. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact Human Resources.

We thank all applicants for their interest in MagicMed Industries; however, only candidates selected for interviews will be contacted.

Expected start date: 2021-06-28

Job Types: Full-time, Permanent

Schedule:

Monday to Friday

COVID-19 considerations:
COVID-19 safety precautions and temporary remote work.

Work remotely:

Temporarily due to COVID-19",MagicMed Industries Inc.,Calgary
623,Data Engineer,"We’d love to hear from you if you like:
Start-up energy working with a brilliant and passionate team
Exponential growth (5 straight quarters of 50-100%+ quarter over quarter growth)
Flat structure and access to senior leadership for continuous mentorship
Meritocracy - we promote based on performance, not tenure
Rockstar teammates. You will be working with a strong team with prior work experience at Amazon, Microsoft, NVIDIA, Alibaba, etc.

About jerry.ai:
Jerry.ai is an AI powered personal concierge for your car and home . Our mission is to make all aspects of car & home ownership hassle-free and effortless. We are starting with car insurance. Enabled by disruptive technologies, jerry.ai has built a one-click experience for saving money on car insurance. Since our product launch, we have been growing really fast for the past 15 months and our users love the product (rating 4.5 in the app store).
Jerry.ai is founded by serial entrepreneurs who previously built and scaled YourMechanic (“Uber for car repair,” the nation’s largest on-demand car repair company). We are backed by Y-combinator, SV Angel, Funders Club, and many other prominent Silicon Valley Investors.

About the role:
We are looking for a Data Engineer who is passionate and motivated to make an impact in creating a robust and scalable data platform. In this role, you will have ownership of the company’s core data pipeline that powers our top line metrics. You will also leverage data expertise to help evolve data models in various components of the data stack. You will be working on architecting, building, and launching highly scalable and reliable data pipelines to support the company’s growing data processing and analytics needs. Your efforts will allow access to business and user behavior insights, leveraging the data to fuel other functions such as Analytics, Data Science, Operations and many others.

Responsibilities:
Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth
Consistently evolve data model & data schema based on business and engineering needs
Implement systems tracking data quality and consistency
Develop tools supporting self-service data pipeline management (ETL)
SQL and MapReduce job tuning to improve data processing performance

Requirements:
2+ years of data engineering experience within a rigorous engineering environment
Proficient in SQL, specially with Postgres dialect.
Expertise in Python for developing and maintaining data pipeline code.
Experience with Apache Spark and PySpark library (experience with AWS extension of PySpark is a plus).
Experience with BI software (preferably Metabase or Tableau).
Experience with Hadoop (or similar) Ecosystem.
Experience with deploying and maintaining data infrastructure in the cloud (experience with AWS preferred).
Comfortable working directly with data analytics to bridge business requirements with data engineering

Locations:
Toronto
Boston","Jerry
3.9",Midtown Toronto
624,Data Engineer (Data Factory Experience),"1 year + Contract
French Strongly Preferred but will consider English Only Profiles
Need a Data Engineer with Data Factory Experience
Remote Across Canada

Context and mandate

The client intends in the coming years through its BI Modernisation program to migrate various business units from existing BI environments to its next-generation Enterprise Data Platform in the Cloud.

In that context, the Client is looking for a knowledgeable, experienced, and motivated Data Integration Developer. You will play a pivotal role in operationalizing the most urgent data and analytics initiatives for the Client's BI, Data and Analytics strategy.

The bulk of the work would be in the building, managing, and optimizing data pipelines and then moving these data pipelines effectively into production for key BI, data, and analytics consumers.

You will need to guarantee compliance with data governance and data management requirements while creating, improving, and operationalizing these integrated and reusable data pipelines. This would enable faster data access, integrated data reuse, and vastly improved time-to-solution for the Client's BI, data, and analytics initiatives.

Duration: June 15th until March 31st, 2022

Possibility de renew: Yes
Possibility de convert to a permanent position: To be determined

Responsibilities / Accountabilities

Build data pipelines and ETLs.
Provide data structure definition, validation, ingestion, processing, and visualization.
Collaborate with business units, architects, data modelers, data scientists, and project/product team.
Work with the information security team to define and implement data access.
Drive automation through effective data management lifecycle from governance to quality to cataloging to lineage, to ensure data compliance.

Requirements

Professional Experience

3+ years of experience in Data Integration with the required technology.
Experience in data profiling and data quality analysis.
Experience in identifying, analyzing, and interpreting trends or patterns in data sets.
Experience with MS Data integration stack, e.g. Azure Data Factory, SSIS, etc.
Experience with SQL for RDBMSs such as Azure SQL, MS SQL Server, and MySQL.
Experience working with PowerBI for semantic-layer-based data discovery.
Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata, and workload management.
Knowledge of Azure Migration stack, e.g. Azure Migrate, Azure database migration service, etc.
Experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures, and integrated datasets using traditional data integration technologies such as ETL/ELT, data replication/CDC, message-oriented data movement, event processing, API design, and access.
Experience in agile methodologies and capable of applying DataOps principles to data pipeline build engineering to improve integration, reuse, and automation of data.

Educational Experience

University degree or higher in computer science, business administration, business intelligence, statistics, mathematics, or equivalent.

Soft Skills

Ability to linearize and bridge business needs into technical requirements.
Strong communication, documentation, storytelling, creativity, and presentation skills.
Strong interpersonal, teamwork, coordination, and consensus-building skills.
Strong organizational skills, ability to perform under pressure, and manage multiple priorities with competing demands.

Language

Good verbal and written communication skills in French and English.

Other

The mandate will be carried out remotely until the return to the offices

Once back at the office, the position will be carried out according to a hybrid model (face-to-face/telework) to be confirmed.

Contract length: 12 months

Part-time hours: 40 per week

Job Types: Full-time, Part-time, Contract

Pay: $65.00-$85.00 per hour

Language:

French (preferred)

Work remotely:

Yes",Sky Systems Inc,Montreal
625,Staff Data Engineer (Americas - Remote),"Company Description


Shopify is the leading omni-channel commerce platform. Merchants use Shopify to design, set up, and manage their stores across multiple sales channels, including mobile, web, social media, marketplaces, brick-and-mortar locations, and pop-up shops. The platform also provides merchants with a powerful back-office and a single view of their business, from payments to shipping. The Shopify platform was engineered for reliability and scale, making enterprise-level technology available to businesses of all sizes.



Job Description


Our Data Platform Engineering group builds and maintains the platform that delivers accessible data to power decision-making at Shopify for over a million merchants. We’re hiring high-impact developers across teams:

The Engine group organizes all merchant and Shopify data into our data lake in highly-optimized formats for fast query processing, and maintaining the security and quality of our datasets.

The Analytics group leverages the Engine primitives to build and deliver simple and useful products that power scalable transformation of data at Shopify in batch, streaming, or for machine learning. This group is focused on making it really simple for our users to answer three questions: What happened in the past? What is happening now? And, what will happen in the future?

The Data Experiences group builds end-user experiences for experimentation, data discovery, and business intelligence reporting.

The Reliability group operates the data platform in a consistent and reliable manner. They build tools for other teams on Data Platform to leverage and encourage consistency as they champion reliability across the platform.



Qualifications


An experienced technical leader with a proven track record of delivering impactful results.

Technical engineering background in one or more areas in the next section.

Experience with technical mentoring, coaching, and improving the technical output of the people around you.

Exceptional communication skills and ability to translate technical concepts into easy to understand language for our stakeholders.

Excitement for working with a remote team; you value collaborating on problems, asking questions, delivering feedback, and supporting others in their goals whether they are in your vicinity or entire cities apart.

A Staff Data Developer would typically have 6-10 years of experience in one or more of the following areas:

Experience with the internals of a distributed compute engine (Spark, Presto, DBT, or Flink/Beam)

Experience in query optimization, resource allocation and management, and data lake performance (Presto, SQL)

Experience with cloud infrastructure (Google Cloud, Kubernetes, Terraform)
Experience with security products and methods (Apache Ranger, Apache Knox, OAuth, IAM, Kerberos)

Experience deploying and scaling ML solutions using open-source frameworks (MLFlow, TFX, H2O, etc.)

Experience building full-stack applications (Ruby/Rails, React, TypeScript)

Background and practical experience in statistics and/or computational mathematics (Bayesian and Frequentist approaches, NumPy, PyMC3, etc.)

Modern Big-Data storage technologies (Iceberg, Hudi, Delta)


Additional Information


At Shopify, we are committed to building and fostering an environment where our employees feel included, valued, and heard. Our belief is that a strong commitment to diversity and inclusion enables us to truly make commerce better for everyone. We strongly encourage applications from Indigenous people, racialized people, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities.


Shopify is now permanently remote and working towards a future that is digital by design. Learn more","Shopify
4.2",Midtown Toronto
626,Manager Product Management – Data Science,"This role will start off as work from home, gradually will be required to work in the Markham, Ontario office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat during this data-driven, technology revolution.

You will be part of a dynamic small team that helps drive innovation and growth across Aviva. You will work directly with various business stakeholders and drive the roadmap for future products and innovative solutions. You will work closely with the Data Science team to build out automated solutions that create data-driven solutions that affect millions of customers. This is your chance to join the InsureTech revolution!

Your responsibilities:

As a manager of product management, you will:

Build a comprehensive product strategy for Data Science at Aviva Canada. This role requires close collaboration with our business stakeholders across different areas of the business in building a strategy focused on driving automation, growth and profitability.

Lead a team of product managers in developing and delivering on the product strategy.

Possess an in-depth understanding of the insurance business and internal business processes across focused strategic areas.

Drive discussions, engage business partners and identify areas of opportunity for data science.

Be able to develop compelling business cases that show expected costs and benefits with a clear understanding of return on investment.

Focus on the customer journey, simplicity and ease of doing business throughout all phases of discovery, strategic planning and implementation.

Have a good technical understanding of implemented solutions, allowing you to balance technical requirements with business priorities and develop roadmaps that take into account complexity of implementation and technical debt remediation.

Regularly monitor and report on project outcomes, performance trends and insights in order to measure effectiveness of the implemented solutions.

Build a product practice within Data Science and collaborate across teams to build a cohesive understanding of product management best practices across Aviva.

What you need to succeed:

You will need the following skills and experience to succeed in the role:

6+ years of industry experience directly involved in leading product delivery.

2+ years in a leadership role in which you have led other product managers and a product management practice.

Great leadership skills coupled with expertise in the field of product management. The ideal candidate has a strong understanding of how to turn business needs into compelling technical solutions with a keen eye for customer outcomes and user experience.

A proven track record in successfully delivering end-to-end products in an Agile environment.

Excellent communication skills with the ability to influence, collaborate and drive adoption.

Ability to work closely with technical teams to develop technical solution strategies.

What sets you apart:

Experience working in the Insurance industry and developing products in the areas of underwriting, pricing, claims, fraud or data science.

Experience with AI or Machine Learning methodologies.

Additional Information

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","Aviva
3.7",Markham
627,"Data Engineer, Data Lake","Job Category:

Software

Opportunity Awaits at Altus Group!

The next stage in PropTech solutions: Unlocking the value of data and predictive analytics

Altus Group is embarking on the next evolution of data, software and technology leading cloud products and services. As pioneers in the Proptech and real estate analytics spaces, we are growing our offerings to enable our global clients to unlock the value of data and leverage predictive analytics for better decision-making.

This journey represents an expansion of our data and analytical solutions to other Altus business units, including ARGUS Software, the industry standard for valuation and asset management software. We’re adding world class talent to our technical team; people who are interested in building the data infrastructure that will support the wide variety of global opportunities aligned to our client’s needs. As we take our new and existing cloud products to the next level, this initiative is one that our leadership believes is critical to accelerating the continued and future success of Altus Group and our clients.

The opportunity

Building on established market leading software and incorporating new technologies, we are creating an unrivalled platform to serve the real estate investment industry. As part of the new team spearheaded by the Director, Application Service Delivery, Data Solutions, we are adding two Data Engineers in Toronto. You will collaborate with internal teams on both technical aspects of data migration and storage as well as in a consultative manner to understand unique data parameters, contributing to the design and build of a data lake. You will aggregate, organize and ingest data from various sources to ensure that the data can be accessed efficiently by our internal and external users and applications.

Who you are

You are a Data Engineer with a few years of experience storing, pipelining, and transforming data using a range of technologies. You want to balance your technical deliverables with internal client interaction to gain an in-depth understanding of how our platform will work and how we can meet the data needs and drive key decisions for everyone. You want to be part of building something new with great visibility across the organisation and endless possibilities ahead as we continue to grow and scale. You want to play a critical role in seeing our collaborative vision implemented.

What’s in it for you?

Unparalleled exposure and impact. You will work alongside development, architecture, and product teams who are at the top of their game, solving problems that have never been looked at before. As part of a platform team specifically assembled to collaborate on new work, you will have the freedom to create from the ground up, and work unrestricted by existing tools or legacy technology. This is an opportunity to make your mark and truly accomplish something exciting as we focus on defining and driving our data and SaaS strategy.

The latest technology, in leading-edge ways. Data is at the heart of everything we do. We are actively pursuing the latest iterations of modern technologies. Our stack encompasses Docker, Microservices, Snowflake, Glue, Spark, Python, Tableau, JavaScript, Angular, Node/JS, REST APIs, Swagger WSo2, and the AWS ecosystem. You will be part of the team working with - and continuously evolving - this tech stack and our approach to data.

Growth and career development. Altus fosters a culture of professional development and promotion from within. With retention rates double the tech industry average, and dozens of promotions within and across teams, this is a place to truly expand your skills and grow your exposure. The Data Solutions team offers individuals the chance to lead the scrums on a rotating basis and push the limits of what they do with dedicated time to further their individual areas of technical interest. As we move from building to scaling; from platform to product; and from storage to application, the opportunities to grow your skills, gain exposure, try new things, and make an impact will grow too.

Our new Data Engineer, Data Lake will:

Learn. Working in close collaboration with the Senior Data Engineer, you will be given the support you need and the information you require to come up to speed and make a valuable contribution to the team.

Elicit, understand, and translate. You will work across business lines and newly acquired businesses to understand individualized technical and practical data storage.

Design. You will create and support an ETL solution using AWS Glue to extract and import data into the new data lake. You will determine how to connect to the various data sources, bring data into our new data lake, and the appropriate method of storing the data.

Analyse. You will create data pipelines, reports, visualisations and extracts to support product and research needs. You will work with stakeholders to assist with data-related technical issues and support their data infrastructure needs.

Advise. You will research data governance and security to ensure our data storage methodology adheres to any constraints and follows best practices.

Try new things. You will take the initiative to research, test, and solve complex data engineering problems and big data storage.

Our new Data Engineer, Data Lake will have:

An eagerness and ability to learn quickly. You have a devotion to evaluating and appropriately applying emerging and alternative technologies, languages, frameworks, and platforms.

A commitment to collaboration. You thrive working across inter-disciplinary groups, including architects, developers, product, and management, to build great products. You have a way of speaking, writing, and relaying information that engages people and expresses appreciation for diverse opinions and approaches.

Hands-on experience. You have worked with a broad range of data management, analysis, and visualisation tools, including ETL/data format conversion, SQL, and NoSQL/ non-traditional database technologies, including newer tools such as Glue and Snowflake. You have worked with AWS/Cloud computing infrastructure.

Come realize your potential at Altus Group!

Altus Group is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs. If you are a person with a disability and require assistance during the application process, please contact us at accessibility@altusgroup.com or 416-641-9500.","Altus Group
3.9",Midtown Toronto
628,Data Engineer - Machine Learning,"Who we are
Creating a planet fueled by reliable, clean energy isn’t what keeps us up at night; it’s what gets us out of bed. At Opus One Solutions, our software platform GridOS® helps us pursue solutions that will change how countries access, optimize and distribute electrical energy. From microgrids that keep things running in the event of an outage, to helping electric utilities optimize their operations and allowing homeowners to feed energy into a power grid, we're powering a more sustainable future.

The Opportunity
As the shift to reliable, clean energy becomes an imperative, Opus One Solutions is at the forefront of this transition. Our software reduces the complexity of systems coordination and establishes the financial base for resource deployment, allowing countries to accelerate carbon reduction, and system operators to facilitate the distribution of carbon neutral energy.

The Opus One Solutions GridOS software platform brings intelligence to every level of the electrical grid, from smart meters that can minimize the impact of power outages to the most challenging electrical utility marketplaces that can coordinate market actors to enhance system operations. Our software enables optimization of energy systems from planning to operations, leveraging the data at not only the utility, but also the various entities connected to its infrastructure.
We have assembled a diverse group of power systems experts and distributed software system professionals who are working to tackle these challenges together and are looking to expand the team to accelerate our shared journey to a more sustainable future.
You will be working as part of the Opus One Solutions data science team focusing primarily on building and deploying high velocity machine learning models targeted at electrical distribution utility customers.
Our end users require the integration of highly accurate energy demand and generation forecasts combined with production level outcomes delivered into operational systems resulting in a need for a balanced approach of model development and deployment.
Energy demand and generation both depend on climate, weather, seasonality, and long-term trends. The data sources may be clear and well understood or sparse and require investigation by the data science team. You will be an integral part of this process.
You will work with the data science team to ensure the outcomes are repeatable, scalable, traceable, and defensible

What you will work on?
Design, build and maintain the data processing pipelines required for the Opus One Solutions machine learning based time series forecasting models and production deployments.
Create the ETL/ELT workflows to ingest measurement data timeseries forecasting engine
Support the integration with third-party data sources including Advanced Metering Infrastructure (AMI), electrical grid distribution and feeder models, meteorological services, solar and generation forecast data along (short term forecasts) with additional socio-economic information as required (long-term forecasts).
Analyze foundational data tables and metrics supporting the power flow optimization and data science teams with clear definitions, data lineage, loading patterns, test coverage and transformations to ensure that data is reliable, intelligible, and maintainable
Build and extend time series forecasting engine APIs for product and project services.
Implement systems to track data quality and consistency explaining issues/problems with data.
Communicate high-quality software engineering practices for building data infrastructure and pipelines at scale including the documentation of ETL/ELT flows and systems architecture.
Support testing processes, troubleshoot and resolve issues.
Work in an Agile/SCRUM team setting including cross-functional structures and varying levels of management.
Requirements
Who are you?
We're looking for a data engineer to help us accelerate the adoption of distributed energy resources such as wind and solar into the day-to-day operations of the electrical utilities. You will have a proven track record of shipping performant data processing systems in production environments and are comfortable developing and automating complex pipelines and workflows that underpin AI/ML powered products.
You are a data engineer with experience working in a machine learning or big data production environment.
Experience in the application of best practices for software engineering in the AI/ML and data spaces, with an emphasis on time-series data
Experience standing up services and building scalable production data workflows.
You may also have experience working within the electrical utility marketplace or an adjacent industry where experience in forecasting can be used.

Here’s what you bring:
Education
Bachelor's degree in Computer Science, Math, Statistics, Engineering, or a related quantitative field, or equivalent experience
Technical
3+ years of industry experience in software engineering or data engineering
Proficiency working with structured and unstructured data including experience with relational data stores such PostgreSQL, SQL, and ETL/ELT frameworks
Experience with implementing chronological, time series processes
Experience with Service-Oriented Architecture including designing and developing RESTful APIs
A demonstrated ability to build and maintain ETL/ELT processes including staging, cleansing, mapping, and loading
Work experience developing in Python, Java, or other programming languages
Experience building high-quality end-to-end data solutions in an agile environment from requirements to production.
Some exposure to the workflow management engines (Airflow) along with Hadoop or similar ecosystems including Hive, Spark, Pig, or others is desired.
Collaboration
Solve problems in robust and creative ways demonstrating solid verbal, interpersonal and written communication skills.
Effective in working across team boundaries to establish overarching data architecture, and provide guidance to individual teams
Collaborate across multiple development, project delivery teams along with technical and non-technical stakeholders.
Benefits
Why join Opus One Solutions?
Opus One is growing! After spending first four years under the radar focused on research and pilot projects we’re ready to shine as one of Canada’s top 10 game-changers named by CIX Cleantech, Fast Company’s 2017 World Changing Idea in Energy and one of top 100 Global Cleantech companies! We are deploying exciting microgrid projects in North America and have partnerships with leading energy players such as National Grid.
Our leadership has assembled carefully selected teams with some of the best strategic visionaries - and executors - in technology and the clean energy space. We are all driven by one common goal: to accelerate the integration of clean and sustainable energy in North America and the world.
At Opus One Solutions we understand that not everyone develops their talent and hones their skills in a traditional way. Different paths and experiences are part of the diversity we know we need to succeed. If you feel you meet all or most of the qualifications we are seeking, take a chance and express your interest here.
Opus One Solutions welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Opus One Solutions
3.3",Midtown Toronto
629,"Certified Azure Data Engineer (DP-200 & Dp-201, DP-203) 12+ yrs Exp","Azure Data Engineer

Location- Brampton, ON

Salary: 95k Full time

On contract Rate CAD $65/hr on Inc

Client- Tech M

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Databricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on NoSql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Temporary, Permanent

Salary: $79,138.00-$95,000.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Vision care
Work from home

Schedule:

8 hour shift

Work remotely:

Yes","Compest solutions Inc.
4.6",Brampton
630,Remote Data Engineer,"MonetizeMore builds industry leading ad technology that is seen by more than 300M people per month. The company has been running for 10 years achieving consistent double digit growth each year with a team of 100+ team members spread across the globe.

MonetizeMore offers location and schedule freedom to every one of its team members. That means that you would have the lifestyle autonomy to choose to work from anywhere in the world, during the time of day you prefer. This new-age work lifestyle would enable you to engineer your ideal lifestyle. Say goodbye to endless commutes, stuffy business attire and the arbitrary 9 – 5 work day. Take your life back into your hands by joining the MonetizeMore team!


The product team is the fastest and most innovative team in the company. Build greenfield technology that is disrupting the ad technology industry. Solve problems that have never been solved before. Join a company culture that replaces constant meetings and interruptions with innovation that continues to break boundaries. Take your skillset to the next level with some of the best minds in the ad technology industry to make a real difference with MonetizeMore.


Responsibilities

The day-to-day work of a MonetizeMore Data Engineer includes:

Building and maintaining data pipelines using Kubernetes, Airflow and AWS Stack
Proficient in writing complex and nested SQL queries. Experience with AWS Athena is a plus.
Analyze data using Python Pandas, Apache Spark DataFrames, ElasticSearch Kibana.
Building JavaScript applications capable of tracking and responding to billions of requests per month.
Developing APIs and integrating with 3rd party APIs to automate manual tasks.
Integration of services to maximize ad revenues and maintain strong user experience.
Planning and prototyping new applications.
Defect resolution of existing and new issues.
Unit testing new features to ensure they conform to MonetizeMore’s quality standard and meet requirements.
Code reviews.
Running performance benchmarking tests.
Staying up to date with new trends and advancements in web development and ad tech.
Attending daily stand-up meetings (30 mins) and other Scrum meetings (Every 2 weeks).


Attributes

MonetizeMore Data Engineer attributes include:

Teamwork Attributes:

Collaboration: Working remotely on complex projects necessitates that you work together with your team and share knowledge.
Communication Skills: You are comfortable communicating in English at all levels, have strong spoken and written communication skills and are an active listener.
Teamwork: You value team synergy and are excited about helping your team succeed.
Interpersonal Skills: You are able to get along, work well and coordinate with others.
Conflict Management: As a team, we are proactive in dealing with conflict.You are able to find constructive ways of resolving issues with other team members.

Technical Attributes:

Technology: A MonetizeMore developer is proficient in all stages of web development, from conception to deployment. You are a one-person army, ready and willing to attack any technical challenge that crosses your path
Analytical and Problem Solving Skills: You work hard to understand technical issues and to resolve them in an effective manner.
Detail Orientation: You work on many parts of an application or system at the same time and are able to focus on each detail meticulously.
Initiative: You work well in a team, with little supervision, making well-reasoned and effective technical decisions.
Reliability and Responsibility: You demonstrate reliability at all times. You give reasonable expectations within Agile Scrum framework and work hard and smart to achieve and surpass those expectations. You communicate what you are going to do, then meet that commitment.
Thought Leadership: You analyze MonetizeMore’s tech stack, systems and processes with the goal to iterate on a regular basis. You look for opportunities to improve to increase value to MonetizeMore and suggest them to the team.

If you think you are a good fit to join the MonetizeMore product team, please apply below and give specific reasons what sets you apart. We hire individuals not robots so don’t be afraid to show a little personality ;)




NhoveNgBx5","MonetizeMore
4.6",Montreal
631,Part-Time Content Creator - Data Analytics,"About the Position
We’ve been creating exceptional, life-changing courses since 2012. Our Web Development Bootcamp has helped over 1000 people become web developers, and we’re ready to expand into a new topic, Data Analytics. We’re looking for a Data professional, proficient in Tableau, SQL, and Python, to help us create our Data Analytics Bootcamp content. This position is a part-time role that requires 8 hours per week for 12 weeks, compensated at $100 an hour. This role is remote and is designed to be manageable along with a full-time job.


We know what makes great programs, modules, lessons, projects, exercises and breakouts, and you know what it takes to land a job and succeed as a Data Analyst. We’ll guide you through our curriculum creation process, and together, we’ll create a life-changing program featuring hands-on, project-based lessons, exercises and projects. You’ll work closely with our Director of Product and our talented team of instructors to craft approachable and fun lessons that will ensure our students learn the most important skills for landing a Data Analyst position, while having fun!


This role is perfect for someone who is currently working as a Data Analyst or Data Scientist and is looking for a way to share their knowledge to help the next generation of Analysts. This is an opportunity to create a Data Analytics program that will change the lives of thousands of people in the coming years. If this sounds exciting, we want to hear from you!


About Us

Founded by Heather Payne in 2012, Juno College of Technology is an innovative technology school based in Toronto, Canada. As a registered Private Career College, Juno offers courses for people who want to land jobs in tech - fast - and serves over 1000 students a year from a 12,000 square foot campus in downtown Toronto. Currently all of our courses and programs are offered Live Online and our team is fully remote until we are able to safely return to our office. With thousands of alumni and 1000+ students a year, there’s a large community of people ready to welcome you to Juno!


Responsibilities:

Work with a team of instructors to create the Data Analytics Bootcamp, helping students learn through lessons, code-alongs, projects and interactive exercises
Contribute expertise to student project design and create project evaluations
Other tasks as required



About You

Your Qualifications:

5+ years Data Analytics or Data Science experience working with SQL and Python
Experience using Tableau or another data visualization platform
Excellent writing skills
Passionate about creating a best-in-class Data Analytics program
You have opinions on how Data Analytics should be taught, likely from experience hiring and training for entry level Data Analyst roles



You could be a great fit if you:

have demonstrable hands-on industry experience in data analytics or data science
are collaborative, energetic, and empathetic, and a creative problem solver
have expertise in using Python for data wrangling, exploratory data analysis, predictive modelling, statistics, supervised machine learning and data visualization
have practical knowledge of working with big data, performing customer segmentation, and using cloud services
are comfortable using Git, GitHub, Google Docs, Sheets, and Drive
are passionate about improving education and accessibility to great Data jobs




Salary, Perks and Benefits



Position type: part time, contract
Hourly: $100



How to Apply:

Please apply through the link below and answer the provided questions. We’d love to see your resume, and anything else you’d like to provide us! All applications are appreciated, but we will only contact successful applicants to move on to the next stage.","Juno College
2.8",Midtown Toronto
632,Senior Optical Simulation Engineer or Scientist,"Senior Optical Simulation Engineer or Scientist




About Metamaterial Inc.

META delivers previously unachievable performance, across a range of applications, by inventing, designing, developing, and manufacturing sustainable, highly-functional materials. Our extensive technology platform enables leading global brands to deliver breakthrough products to their customers in consumer electronics, 5G communications, health and wellness, aerospace, automotive, and clean energy. META’s achievements have been widely recognized, including being named a Global Cleantech 100 company. Learn more at www.metamaterial.com.




About the role

We are seeking a Senior Optical Simulation Engineer or Scientist for our facility in Dartmouth, Nova Scotia. You will be a key member of the Optics team that develops new technologies and products for applications in augmented reality and scientific instruments. Your role will be to both design new optical systems and develop the toolset for simulating their behaviour and optimizing their performance. The ideal candidate will have extensive experience in modelling optical systems, particularly systems involving imaging waveguides, and experience developing tools in Python.




Responsibilities

Lead the development of new simulation tools for predicting and optimizing the performance of complex and novel optical systems.
Work with internal and external stakeholders to develop product concepts and designs that address the needs of the HMD, HUD and scientific instruments markets.
Support other engineering staff for the most challenging simulation and modelling tasks.
Define best practices for the development, deployment, and maintenance of a rapidly evolving codebase.
Characterize performance of optical products and sub-systems relative to the design goals and the broader system requirements; specify and design the optical evaluation systems necessary for such characterization.
Identify causal relationships between observed product or sub-system performance and design parameters.
Analyze data and communicate results through technical reports and presentations tailored to the needs of the target stakeholders.
Supervise junior members of the engineering team.



Required Skills and Experience:

Must have extensive experience in code development and data analysis for scientific applications using C/C++ and Python.
Must have experience in EM simulation techniques (e.g. RCWA, FDTD, Physical Optics, Ray Tracing) and packages (Zemax, VL Fusion, Lumerical, CODE V, COMSOL).
Experience in hands on lab work is an asset.
Excellent written, verbal and presentation skills.



Qualifications:

An MSc or PhD in Physics, Applied Physics, Optics, EE, or related field, is required.
Minimum 5 years of experience with optical engineering and optical simulation.
Canadian work authorization.



Professional Standards and Performance Review: As an experienced professional, the Senior Optical Simulation Engineer or Scientist will maintain high professional standards and act in accordance with best practice. They will support the development of the professional standards of the team and take a continuous approach to improvement and their own personal development. As a representative of the Company, the Senior Optical Simulation Engineer or Scientist will act in line with the Company Code of Conduct and will participate in the performance review process.","Metamaterial Inc.
4.1",Dartmouth
633,Data Engineer Senior Consultant (Azure) / Ingénieur(e) de données (Azure),"*English will follow*


Slalom est une société de conseil moderne axée sur la transformation de la stratégie, de la technologie et des activités. Dans 40 marchés aux États-Unis, au Royaume-Uni, au Japon, en Australie et au Canada, nos équipes ont l’autonomie nécessaire pour agir rapidement et faire ce qui est juste, toujours. Ils sont soutenus par des centres d’innovation régionaux, une culture globale d’innovation et des partenariats avec les plus grands fournisseurs de technologie au monde.

Chez Slalom, la connexion personnelle rencontre l’échelle mondiale. Nous établissons des relations étroites avec les clients au sein de nos marchés et à l’échelle mondiale, en faisant circuler nos connaissances dans tous les marchés afin que chaque engagement puisse bénéficier de toute l’étendue de l’expertise de Slalom. Nos sept centres régionaux Build agissent comme points centraux de l’innovation pour attirer des talents de haut niveau qui collaboreront rapidement à la création des produits technologiques de demain. Nous entretenons également de solides partenariats avec plus de 200 fournisseurs technologiques de premier plan, notamment Amazon Web Services, Google Cloud, Microsoft et Salesforce.

Avec notre mentalité axée sur les objectifs, nous travaillons en collaboration avec des entreprises pour repousser ensemble les limites de ce qui est possible. Chez Slalom, chaque jour, nous sommes motivés par les valeurs fondamentales et la vision de notre entreprise. Nos valeurs fondamentales sont au cœur de toutes nos activités et orientent notre façon de travailler avec nos clients, nos équipes et nos communautés. Chacune de nos valeurs fondamentales nous rappelle de rester fidèles à nous-mêmes tout en produisant des résultats incroyables pour nos clients. Notre principe directeur est « Aimez votre avenir », ce qui inspire notre culture, notre travail et nos relations. Et, plus important encore, c’est ce qui nous permet d’avoir le plus grand impact possible!

Fondée en 2001, Slalom a établi son siège social à Seattle et, selon un mode de développement par croissance interne, compte maintenant plus de 9 000 employés. Nous figurons sur la liste des 100 meilleurs employeurs de 2021 établie par le magazine Fortune pour la sixième année consécutive, et nous sommes régulièrement reconnus par nos employés comme offrant l’un des meilleurs environnements de travail. En savoir plus : https://www.slalom.com/fr-ca/?lp=1.

Au Canada depuis 2015, Slalom compte maintenant plus de 600 employés répartis dans trois marchés : Vancouver, Toronto et Montréal.

Titre du poste :

Ingénieur(e) de données (Azure)

L’équipe Slalom de Montréal recherche un(e) ingénieur(e) de données (Azure) pour notre pratique d’analytiques des données. À titre d’ingénieur(e) infonuagique de données de notre équipe, vous analyserez, concevrez et architecturez des solutions infonuagiques pour répondre aux besoins de nos clients en matière d’infrastructure sous forme de service, de plateforme sous forme de service et de logiciel sous forme de service. Ce poste vous fera utiliser des outils d’architecture modernes, y compris l’infonuagique (Azure), Hadoop, Spark, Kafka et d’autres technologies liées aux mégadonnées. En plus de bâtir la prochaine génération de plateformes de données, vous travaillerez avec certaines des organisations les plus innovatrices en analytiques des données. Nous sommes à la recherche de personnes vives d’esprit, disciplinées et motivées, qui sont passionnées par l’emploi de solutions infonuagiques pour résoudre des problèmes d’entreprise réels.


Alors, quel sera mon travail?

Travailler au sein d’une équipe sur la conception et le développement de solutions infonuagiques de données
Établir les exigences techniques, évaluer les capacités des clients et analyser les résultats afin de fournir des recommandations appropriées en matière de solutions infonuagiques et de stratégies d’adoption
Définir les stratégies infonuagiques de données, y compris la conception de feuilles de route de mise en œuvre à plusieurs phases
Diriger l’analyse, la construction, la conception et le développement d’entrepôts de données et de solutions d’intelligence d’affaires
En savoir beaucoup sur les solutions infonuagiques, l’architecture et les technologies Azure, ainsi que leurs interdépendances
Expérience démontrée avec des outils ETL (Azure Data Factory, Databricks), d’entrepôt de données (SQL Database, Synapse/Snowflake), d’intégration de données (DataLake, Blob storage), de profilage de données et de visualisation de données (PowerBI)
Connaissance de l’orchestration avec Azure Logic Apps
Connaissance de la diffusion en continu des données Azure avec Azure Event Hub
Connaissance approfondie de SQL et de débogage de problèmes complexes
Rechercher, analyser, recommander et sélectionner des approches techniques pour résoudre des problèmes de développement et d’intégration difficiles et stimulants
Découvrir et adopter de nouveaux outils et de nouvelles techniques afin d’accroître la performance, l’automatisation et l’évolutivité
Aider les équipes de développement des affaires à exécuter les activités de prévente et les demandes de proposition
Comprendre les objectifs et déclencheurs d’affaires, et les traduire en une solution technique appropriée

Et qu’offrirai-je à l’organisation?

Plus de trois ans de construction et de mise en œuvre d’infrastructures Azure
Comprendre la mise en œuvre de conceptions fondées sur l’architecture Lambda
Expérience de configuration et d’ajustement de nuages virtuels privés
Expérience concrète d’évaluation des besoins en matériel et en stockage
Solides capacités analytiques de résolution de problèmes
Personne autonome ayant la capacité de travailler de façon indépendante ou au sein d’une équipe de projet
B. Sc. en sciences informatiques, en un domaine connexe ou une expérience professionnelle équivalente
Connaissance de Python et d’Azure DevOps, un atout
Connaissance du codage en Python et .Net, un atout
Compréhension des écosystèmes infonuagiques et des technologies infonuagiques émergentes et dernier cri
Bilinguisme (anglais et français)

Qu’est-ce qui nous motive?


La culture! Notre vision est de créer un monde dans lequel tout le monde aime son travail et sa vie. Nous croyons en l’importance d’une communauté d’employés Slalom diversifiée et inclusive, et nous les encourageons tous à être fidèles à eux-mêmes au quotidien. Nous croyons qu’il nous faut rester humbles et curieux, tout en inspirant passion et aventure!
Ce n’est pas parce que nous travaillons d’arrache-pied que nous ne nous amusons pas! Slalom s’efforce de consolider ses équipes et s’assure qu’elles ont autant de plaisir qu’elles sont productives. L’entreprise adore rassembler ses employés en organisant plusieurs activités comme des événements trimestriels, des célébrations pour les fêtes, des événements de bienfaisance et, de façon plus décontractée, des événements sur place ou virtuels comme des dîners-conférences, des jeux-questionnaires, des soirées cinéma, des marathons de programmation et bien d’autres!

Slalom est un employeur inclusif valorisant l’égalité des chances et engagé à la création d’une main-d’œuvre diversifiée. Nous accueillons à bras ouverts les candidatures de toutes les personnes qualifiées et travaillerons à accommoder raisonnablement les candidats tout au long du processus de recrutement et de sélection. Veuillez communiquer avec l’équipe d’attraction de talents si vous nécessitez des accommodements lors du processus d’entrevue.


Veuillez noter que si vous êtes embauché(e) chez Slalom, vous devrez remplir une vérification des antécédents.


Slalom is a modern consulting firm focused on strategy, technology, and business transformation. In 40 markets across the US, UK, Japan, Australia, and Canada, our teams have the autonomy to move fast and do what’s right, always. They are backed by regional innovation hubs, a global culture of collaboration, and partnerships with the world’s top technology providers.

At Slalom, personal connection meets global scale. We build deep relationships with our clients within our markets and across the globe, while sharing insights across markets to bring the full breadth of Slalom's expertise to every engagement. Our seven regional Build Centers are hubs for innovation, attracting top talent to rapidly co-create the technology products of tomorrow. We also nurture strong partnerships with over 200 leading technology providers, including Amazon Web Services, Google Cloud, Microsoft, and Salesforce.

With our purpose-driven mindset, we partner with companies to push the boundaries of what’s possible—together. Here at Slalom, we are motivated every day by our company’s core values and vision. Our core values are at the heart of everything we do and guide how we work with our clients, our teams, and our communities. Each core value reminds us to stay true to ourselves while driving amazing outcomes for our clients. Our guiding principle is to “Love your Future” which inspires our culture, work, and relationships, and most importantly it is how we make our biggest impact!

Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 9,000 employees. We were named one of Fortune's 100 Best Companies to Work For in 2021 for the 6th year in a row and are regularly recognized by our employees as a best place to work. Learn more at slalom.com.

Slalom in Canada began in 2015 and has grown to over 600 employees across 3 markets – Vancouver, Toronto, and Montréal.

Job Title:

Data Engineering Senior Consultant (Azure)


So, what will I do?

Work as part of a team, to design and develop cloud data solutions
Gather technical requirements, assess client capabilities and analyze findings to provide appropriate cloud solution recommendations and adoption strategy
Define Cloud Data strategies, including designing multi-phased implementation roadmaps
Lead analysis, architecture, design, and development of data warehouse and business intelligence solutions
Be versed in Azure cloud solutions, architecture, related technologies, and their inter-dependencies
Proven experience with ETL (Azure Data Factory, Databricks), data warehousing (SQL Database, Synapse/Snowflake), data ingestion (Data Lake, Blob storage), data profiling and data visualization (PowerBI) tools
Knowledge of orchestration with Azure Logic Apps
Knowledge of Azure data streaming with Azure Event Hub
Proficient in SQL and debugging complex queries
Research, analyze, recommend, and select technical approaches for solving difficult and challenging development and integration problems
Learn and adopt new tools and techniques to increase performance, automation, and scalability
Assist business development teams with pre-sales activities and RFPs
Understand business goals and drivers and translate those into an appropriate technical solution

And, what will I bring?

3+ years architecting and implementing Azure infrastructure
Understanding implementing Lambda architecture-based data designs
Experience configuring and tuning virtual private clouds
Practical experience sizing hardware and storage needs
Strong analytical problem-solving ability
Self-starter with the ability to work independently or as part of a project team
B.S. in Computer Science, related fields or commensurate work experience
Python, Azure DevOps experience is a plus
Experience coding in Python and .Net is a plus
Understanding of cloud ecosystem and leading-edge cloud emerging technologies
Bilingualism (English & French)

What keeps us here?

Culture! Our vision is to enable a world in which everyone loves their work and life. We believe in having a diverse and inclusive community of Slalomers, encouraging everyone to bring their authentic selves to work, every day. We believe in staying humble and curious, while still inspiring passion and adventure!
Just because we work hard doesn’t mean we don’t have fun! Slalom strives to bring our teams together and ensure we have just as much fun as we do work. Slalom loves to bring their employees together by hosting many events such as quarterly events, holiday parties, charity events and more casually, in-office/virtual events like lunch & learns, trivia and movie nights, hackathons and many more!


Slalom is an inclusive, equal opportunity employer dedicated to building a diverse workforce. We encourage applications from all qualified candidates and will work to reasonably accommodate applicants’ needs throughout all stages of the recruitment and selection process. Please advise the talent acquisition team if you require accommodations during the interview process.


Please note if you are hired at Slalom you will be required to complete a background check.


#LI-LD1","Slalom Consulting
4.3",Montreal
634,Data Engineer,"Job Description:

3-6 years

Expertise on Spark Scala.
Ability to develop ETL jobs to implement business logic using Scala (Spark Framework)
Conversant with Hive Database, Able to create HQL scripts and work on Hive tables for data analysis
Performance tuning of the existing Hadoop jobs, able to trouble shoot and fix existing bugs.
Good understanding of Oracle Exadata RDBMS, able to profile telecom data residing in Exadata and derive business rules.
Co lace with business, have working session with business to identify and freeze business logic.
Understanding / experience working on scrum based Agile set up.




The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.




A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","Capgemini
3.9",Brampton
635,Data Engineer,"Job Description:

3-6 years

Expertise on Spark Scala.
Ability to develop ETL jobs to implement business logic using Scala (Spark Framework)
Conversant with Hive Database, Able to create HQL scripts and work on Hive tables for data analysis
Performance tuning of the existing Hadoop jobs, able to trouble shoot and fix existing bugs.
Good understanding of Oracle Exadata RDBMS, able to profile telecom data residing in Exadata and derive business rules.
Co lace with business, have working session with business to identify and freeze business logic.
Understanding / experience working on scrum based Agile set up.




The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.




A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","Capgemini
3.9",Brampton
636,Data Engineer,"Job Description:

3-6 years

Expertise on Spark Scala.
Ability to develop ETL jobs to implement business logic using Scala (Spark Framework)
Conversant with Hive Database, Able to create HQL scripts and work on Hive tables for data analysis
Performance tuning of the existing Hadoop jobs, able to trouble shoot and fix existing bugs.
Good understanding of Oracle Exadata RDBMS, able to profile telecom data residing in Exadata and derive business rules.
Co lace with business, have working session with business to identify and freeze business logic.
Understanding / experience working on scrum based Agile set up.




The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.




A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","Capgemini
3.9",Brampton
637,Data Management Specialist – Pharmaceutical,"At ProCogia we’re passionate about developing data-driven solutions that provide highly informed answers to our clients’ most critical challenges. Our projects are varied, from Data Warehouse builds, deploying Cloud Data Solutions, Dashboarding, & building predictive models. You may be involved in all stages of the project life cycle, from Data Engineering / Integration to building pipelines & right through to advanced analytics.

We work with industry leading clients from various sectors including Pharmaceuticals, Telecommunications, Technology, Financial Services & Retail. Our work environment ensures opportunities to gain valuable experience in various industries enhancing your personal & career development.

ProCogia has doubled in size over the last two years & core to ProCogia’s culture is ensuring we maintain a balanced male to female ratio. We are proud to share our consulting teams consist of 40-50% females compared to the industry standard of 10-20%. Our diversity, and differences allow us to create innovative and effective solutions for our clients.




Position Details



We are seeking a Data Management Specialist for our Pharmaceutical clients’ Development Sciences department.
The Data Management Specialist will be performing data management and curation tasks to support biomarker discovery and companion diagnostic development efforts. In the process of performing this work, the candidate will communicate extensively with scientists, research associates, operations managers, clinical data managers, analysts, and vendor representatives.
Responsibilities

Working with biomarker operations managers and biometrics colleagues to draft data transfer specifications and statements of work.
Acquiring and QC’ing digital pathology image data and associated metadata files from internal groups and external vendors. Capturing data in internal file systems and databases.
Monitoring data processing requests and submitting data files to analysis pipelines
Merging different data types with clinical data to generate analysis-ready data sets
Curating and cataloguing data sets, maintaining listings of available data, and distributing to collaborators
Maintaining and curating content of internal knowledge sharing repositories
Maintaining and developing data conformance checking scripts and requirements


Required Skills



Familiarity working in a Linux computing environment
Proficiency in scripting languages such as R or Python; Database skills
Familiarity with modern informatics systems, relational and non-relational databases, scripting languages, and data visualization tools.
Demonstrated experience with informatics best practices and developing well-documented, production code in non-academic environments.
Working knowledge of scientific research application development cycles and data management principles.
Working knowledge of anatomical pathology workflow and digital pathology data lifecycles
Experience managing and curating biological or clinical data
Careful, detail-oriented working style
Outstanding communication, collaboration, and problem-solving skills
Able to work independently and in a team setting.


Nice to have but not required



Relational databases and SQL
Statistical software packages such as R or SAS
Clinical trial data management
Working with medical images data
Setting up and maintaining online content management systems or wikis


Education



Bachelors or Master's degree in Life Science, Computer Sciences or Biomedical Engineering with at least >3 years work related experience.","ProCogia
4.7",Midtown Toronto
638,Data Engineer,"Elements Global Services is an award-winning HR Technology and Services Company revolutionizing the way employers expand and manage employees internationally. Global expansion is becoming more and more a part of the modern workplace, and with that comes things like remote work and spread-out teams. As Elements is a truly global company, we take care of our client's employees worldwide. From Chicago to Manila, from Johannesburg to Delhi and Hong Kong, we provide top class benefits to all the employees we serve every day. With offices all around the world and teams spread out between multiple time zones, you too can benefit from the ""Glocal"" team strategy, giving our employees the flexibility, they need to do their very best work the best way they can.

A revolution cannot be done alone, and we need the best and brightest talent to continue our growth into the new modern workplace. We are looking to expand our team by hiring a new Data Engineer, a team player who is ready to make the role their own and bring their own ideas and innovations to the table. Reporting to the VP Product & Technology, you will be supporting our Product Development team by architecting and building Analytics tools based on Data Science and Machine Learning capabilities that provide insights to empower businesses to be successful and reduce risks.

Key responsibilities:
Key member of the product team building Business Intelligence and Analytics SaaS solutions.

Collaborate with business stakeholders to gather and define data and reporting requirements.

End-to-end architecture, planning, and implementation of data pipeline, web scraping, reporting, and AI/ML driven analytics

Develop innovative solutions and customizable insights reporting on industry trends, predictions, and projected business risks.

Drive Web Scraping alternate data implementation and automation.

Build, test, and maintain scalable and robust data and analytics stack.

What we value:
You hold a bachelor's in Electrical Engineering, computer science, or related technical field; Advanced degree in Data Science, Engineering, Statistics, Computer Science, Mathematics is preferred.

You have 5+ years of experience as a Data Engineer or in a similar role working on ETL, data modelling, business intelligence architecture, alternative data, Machine Learning, reporting.

You have advanced skills in data mining using SQL, ETL, data warehouse as well as Excel.

You have experience building self-service reporting solutions for trends and predictions using proprietary software and business intelligence tools (e.g., Tableau, etc.).

You have demonstrated experience with cloud relational and NoSQL database technologies such as MySQL, MongoDB.

You are expert coding experience in modern programming languages and tools such as Python, Ruby, C#, Java, SQL, etc.

What we Offer :
Opportunity to work in a fast-growing organization with the ability to make a quick impact.

Allow your inspirational ideas to come to life in a highly creative and executional environment.

Ability to work in an organization with over 40 nationalities all over the world, which embraces diversity, inclusion, and belonging at its core.

The opportunity to challenge in a high performing organization and leave each day knowing you have made an impact.

This position description may not describe all duties, responsibilities, and skills associated with this position. It is intended to portray the major aspects of the job. Other duties or skills may be required.

Elements Global Services is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Elements is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Elements is based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Elements will not tolerate discrimination or harassment based on any of these characteristics. Elements encourages applicants of all ages.",Elements,Midtown Toronto
639,Applied Scientist II - ADCC-V4587,"PhD in Engineering, Computer Science, Statistics or related technical field plus 2 years of work experience in the job offered or related occupation
Will accept Master's degree in Engineering, Computer Science, Statistics, or related technical field plus 5 years of work experience in the job offered or related occupation
5 years (or 2 years if PhD) experience with machine learning technologies and rules-based systems
2 years of project management experience across multiple stakeholders
2 years of experience with the entire life-cycle (requirements definition through specification, design, coding, quality assurance, implementation, integration, launch and production support) of a shipped product or online service
2 years of experience producing peer reviewed research reports or publications in the field of machine learning, statistics, or data mining
Terms of employment: Full time, permanent
Job location: 595 Burrard Street, 12th floor, Vancouver, British Columbia, V7X 1L4
Salary range: $133,900- $223,500/commensurable with experience.
Language requirement: English

JOB DESCRIPTION

As an Applied Scientist, you will innovate and be responsible for working across backend, client, business development, and data engineering teams to coordinate deep-dives, inform roadmaps, visualize metrics, and create predictive models to determine how we can best serve our customers.

Your key responsibilities will include:

Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for machine learning (ML) and/or natural language (NL) applications
Develop and/or apply statistical modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications in business and engineering
Routinely build and deploy ML models on available data
Research and implement novel ML and statistical approaches to add value to the business
Mentor junior engineers and scientists.
All applicants must meet all qualifications listed above.

Benefits: Amazon provides a full range of benefits for our global employees and their eligible family members. This position is eligible for further pay increases and bonuses at the company's discretion. Eligible employees may also receive signing bonuses and Amazon Restricted Stock Units.

While they might vary from location to location, Amazon benefits for Canada may include: • Health Care • Savings Plans • Income Protection • Paid Time Off • Signing Bonuses • Employee Stock Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation","Amazon Dev Centre Canada ULC
3.8",Vancouver
640,Data Engineer,"Data Engineer
Information Technology
Remote Position – Canadian based candidates
Competitive Salary

Our client is looking for a passionate Data Engineer to join their growing team for the development and deployment of ETL processes, Data management, Data Warehousing. This role will be responsible for the development and deployment of ETL processes, Data management, Data Warehousing to improve, optimize and lead further development of their data aggregation processes. You’ll bring a deep understanding of big data and will help to build and enable big data analytics solutions. The ideal candidate is innovative, collaborative, determined and takes great pride in their work.

The Role:
Code, test, and document new or modified data systems to create robust and scalable applications for data analytics
Work with stakeholders including Analytics, Product, and Design teams to assist with data related technical issues and support their data infrastructure needs.
Engineer solutions for large data storage, management, and curation of training data models.
Explore available technologies and design solutions to continuously improve our data quality, workflow reliability, scalability while reporting performance and capabilities.
Act as an internal expert in each of the data sources so that you can own overall data quality.
Design, build and deploy new data models, ETL pipelines into production and data warehouse.
Define and manage overall schedule and availability of all data sets.
Process, cleanse, verify and work with data from multiple sources
Work with the data science team to access and understand internal and external data sources
Develop algorithms and build models to solve business problems.
Collaborate with solution engineers to integrate pipelines into our proprietary applications
Bring your great ideas for new products and features to the team

The ideal Candidate:
Masters or BS degree in Computer Science or related technical field, or equivalent practical experience.
3+ Years experience with Data gathering, Data pipelining, Data Standardization, Data Cleansing, Stitching aspects
Some experience with cloud: AWS, Azure, or GCP
Proficiency in a major programming language (e.g. Java/C) and/or a scripting language (scala/php/python)
Highly analytical and detail oriented with a dedication to analyzing data to identify deliverables, anomalies, and gaps and propose solutions to address these findings
Strong analytic skills related to working with unstructured datasets
Solid understanding and working knowledge of relational or non-relational databases
Excellent communication (both written and verbal), organizational, and trouble-shooting skills.
A preference for candidates located in Calgary, Winnipeg, GTA, Hamilton but open to Canada wide applications","TalentSphere Staffing Solutions
5.0",Midtown Toronto
641,Data Governance Analyst,"Title: Data Governance Analyst

FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an extraordinary online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity - Data Governance Analyst

FreshBooks is seeking a Data Governance Analyst to join our team. As part of the Data and Analytics Team, you will contribute to the creation of, and help implement, our data governance strategy across the enterprise. If you're committed to great work and are constantly looking for ways to improve the systems you're responsible for, we'd love to chat with you!

What you'll do:
Collaborate with data engineers, data scientists, and data analysts to design and develop data glossaries and standards and keep the metadata repositories up to date.

Work with business stakeholders to identify and map business critical and sensitive data elements.

Collaborate closely with colleagues from business and technology teams to ensure metadata requirements are well understood.

Focus on data management functional areas of data quality, data lineage, data cataloging and data privacy.

Manage, maintain and continuously update the metadata repositories/tools.

Interface with vendors to make sure the data governance tools are running and working as expected.

Be the champion for promoting data literacy within the organization.

Provide expertise around the data governance policy reviews, metrics, and reporting wherever needed by business and technical teams.

What you bring:
2-4 year's experience in a field related to information management or metadata management.

Experience applying metadata management and data governance principles.

Experience with metadata management tools is an asset (e.g. Informatica Axon, Enterprise Data Catalog, Collibra, Alation)

The ability to write accurate SQL queries.

Familiarity with data and analytics platforms and concepts (e.g. Google Cloud Platform, BI tools, SQL server, data warehouse, data lake)

Ability to create a variety of business documents (including standards) that will be positioned as enterprise artifacts.

What you might bring:
Experience implementing data solutions or rolling out new data tools/products.

Experience with industry ETL & BI tools (Informatica, Datastage, Looker, Tableau, PowerBI etc.)

Understanding of data warehouse modeling fundamentals (e.g. dimensional modeling, 3NF, star schema) and application relational database concepts (e.g. normalization, referential integrity)

Subject matter data expertise in SaaS industry.

Why Join Us

We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. You'll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world-class one, right here in downtown Toronto.

Apply now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer that embraces the differences in all our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position.

Here at FreshBooks, we welcome and encourage applications from people with disabilities. Should you require any accommodations during the recruitment process, please advise your recruiter on how we can meet your needs to ensure a fair and equitable selection process in a confidential manner.

Job Type: Full-time","FreshBooks
4.0",Midtown Toronto
642,Data Engineer,"About Us:

“GSTS is striving to become the leading provider of global maritime risk assessment / threat intelligence solutions, using machine learning, artificial intelligence and big data, saving lives, energy and the environment.”

We have been in start-up mode for the past 2 years and have grown steadily through the COVID-19 pandemic. GSTS has gained significant momentum and will be looking to increase its team over the next 12 months.

We are based in Dartmouth, NS within easy commute of both the Dartmouth and Halifax downtown core, our facility enjoys plenty of free parking and public transport is a short walk away. GSTS is committed to building its presence in the Maritimes; at the same time supporting working from home and working remotely.

GSTS is seeking exceptional talent to support product recently awarded contracts, and to continue the growth of the product. We seek individuals with drive, initiative and motivation to join our team and make the world a safer, greener place for all – www.gsts.ca

Key Responsibilities:

As part of the team, your main task will be to work on our innovative OCIANA™ platform, developing new functionality already identified by our clients. Every new team member is ‘buddied’ up with an existing team member, to ensure they are up and running as quickly as possible. We utilize Slack, Teams and many other collaborative tools that allow us all to stay in touch and remain a close team wherever we are based in the country. Your key responsibilities will be:

Design and implement ETL/data pipelines for novel data streams
Create and monitor alarms and watchdogs on data pipelines
Develop internal documentation on data assets for team use
Collaborate with Senior Engineers in data architecture design and implementation
Collaborate with Senior Engineers in management of RDS Postgres, Athena instances

Experience and Qualifications:

Bachelor’s degree or diploma in Computer Science, Data Science, Data Management, Data Engineering
Proven experience in Database operations (Prefer: Postgres or Oracle):
AWS (Athena, S3)
Experience in Extract Transform Load
Strong scripting competence (Prefer: Python, R, Bash)
Comfortable with
GB-to-TB scale data
Git
Backup and restore
Task automation
Strong troubleshooting skills
Ability to influence internal and external stakeholders, and overcoming obstacles
Team player and able to effectively interact with staff all levels of the company
Excellent written and verbal communications skills in English
Ability to listen and develop a deep understanding of product and client requirements
Strong self-initiative and work ethic
Ability to thrive within a rapidly changing and growing environment
Demonstrated ability to work well in a multi-disciplinary team environment

Additional Experience and Qualifications an asset:

AWS services: Athena, Aurora, Lambda, Elastic Container Service
PostGIS / Geospatial data
Docker
Data Modeling

Comments/Special Considerations:

Candidates must hold or be able to obtain Security and Controlled Goods clearances.

Why work for us?

While we offer very competitive salaries and extended health benefits, including flexible working hours and growth opportunities; the main reason to consider a position with us is the opportunity to work alongside great people with a shared desire to make a real difference in the world.

This is not just a position, it’s a chance to be part of something bigger; we actively promote personal growth and training – for example the company has just restructured to support the current and future growth plans and have recently promoted four internal employees to Director positions – come and join us and make a difference!

We are committed to creating a sense of belonging amongst our team. We have placed an emphasis on fostering a diverse, collaborative and inclusive working environment. We welcome applications from qualified candidates irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.

We thank all candidates that apply, but only those selected for an interview will be contacted.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Company events
Dental care
Employee assistance program
Extended health care
Flexible schedule
Life insurance
On-site parking
Vision care
Wellness program
Work from home

Schedule:

Monday to Friday

COVID-19 considerations:
GSTS is committed to providing a safe and comfortable working environment. The GSTS offices have been expanded to support working and collaborating in a safe social-distanced environment.

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process
Personal protective equipment provided or required
Social distancing guidelines in place
Virtual meetings
Sanitizing, disinfecting, or cleaning procedures in place",Global Spatial Technology Solutions Inc.,Montreal
643,Data Engineer,"You have the future of the planet at heart? Interest in smart and electrical mobility?

Effenco is a pioneer business in electrification and advanced connectivity of heavy-duty vocational vehicles. Our head office is located on the outskirts of the Lachine canal, in a historical building from the south-west industrialization era. The work atmosphere is typical of a technological start-up company, thus creative and casual. Created in 2006, this innovative business is in the high-growth phase and is looking to further expand its business unit on vehicle connectivity and data enhancements.

In this position, you will have the opportunity to be involved in the process optimizations and to suggest new ideas. Furthermore, we offer a flexible work environment that enables you to progress in your career while achieving personal development.

Responsibilities

The Data Engineer will integrate the Dev-IT team. In this role, the main responsibility will be to participate in the development and production of our new IoT and data platform. More specifically, he/she will have to:
- Define business needs in data terms.
- Plan, develop, test, and maintain enterprise data management systems.
- Use modern software deployment techniques (DevOps).
- Create or use tools for monitoring data pipelines.
- Identify and test new data management technologies.
- Automate tasks such as data cleansing and validation.
- Respond to analytical requests from various business intelligence stakeholders.
- Promote the democratization of data within the company.
- Any other related tasks.

Required profile
- University degree in information systems, computer science, or equivalent.
- Experience with databases (SQL and NoSQL).
- Experience with message brokers and pub-sub software.
- Experience using and developing REST APIs.
- Experience with cloud technologies.
- Experience with software development.
- Ability to communicate, present, and verbalize technical results or problems.
- Knowledge of data format specifics (Avro, Protobuf, Parquet, CSV, JSON, etc.).
- Mastery of the Git tool.
- Bilingualism (French and English).
- Organizational management and rigor.
- Demonstrate autonomy, be curious, and self-taught.

Used technologies

Effenco is marketing a hybrid-electric system that electrifies auxiliary equipment on heavy-duty vocational vehicles. The system reduces fuel consumption, pollutant emissions, and engine hours by shutting down the combustion engine when the vehicle is stationary. Each electrified vehicle is equipped with a connectivity module that enables the acquisition of usage data. The data is transmitted in life and batch mode. To date, Effenco has connected nearly 400 vehicles across North America and Europe.
- Effenco's software development stack consists of the following technologies: AWS: S3, Lambda, IoT Core, EKS, Glue, etc. JavaScript: TypeScript, Node.JS, React/Vue.js, NestJS;
- Java, Kotlin, Python: NumPy, Pandas, Airflow, Flask, FastAPI, Pydantic;
- Go, Gitlab, Docker, Kubernetes, Terraform, REST, JWT, GitOps.

Our offer
- A full-time permanent position with a flexible schedule.
- A company that offers real career opportunities.
- Inclusive and open-minded manager and direction.
- A company that appears on Global Cleantech 100.
- Hot coffee, nitrogen cold coffee, sparkling water, and beer available in the Effenco kegerator.
- Lunch provided on Friday at noon.

Type d'emploi : Permanent

Avantages :

Événements d'Entreprise
Horaires flexibles
Nourriture à Prix Réduit ou Gratuite
Stationnement sur place
Tenue Décontractée
Travail à Distance

Horaire :

Du Lundi au Vendredi
Quart de jour
Repos la Fin de Semaine

Expérience:

Consultation: 1 an (Souhaité)
SQL: 1 an (Souhaité)
Oracle: 1 an (Souhaité)
développement avec Datastage: 1 an (Souhaité)

Langue:

Français (Souhaité)

Télétravail:

Temporairement en raison de la COVID-19",Développement Effenco Inc.,Montreal
644,Data Engineer,"The Green Organic Dutchman is a global leader in cultivating premium, certified organically grown cannabis.


At The Green Organic Dutchman (TGOD), we are proud be to cultivating a great workplace from the ground up. Every day we are challenging, defining, and shaping this new industry. We are growing strong with a team that is proudly committed to creating the world’s best certified-organic cannabis.


The Data Engineer is a critical role for TGOD as our business hits unprecedented scale. You will provide and grow in-house expertise on ELT/ETL formulations and API interactions. Our data is a critical business asset – how we handle and manage that data must enable our agile business and be compliant with laws/regulations to preserve its confidentiality, availability and integrity. This role forms part of TGOD’s data science functions and will support the Director of Data Science in leading and managing all data-related activities including business intelligence.


This role is fully remote, within Canada.


Key Responsibilities

Support and develop data pipelines for all core systems and 3rd party integrations into the data lake and analytics database.
Leverage API endpoints for operational use of centralized data assets
Develop broad domain and technical knowledge in AWS solutions.
Demonstrate strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.


Basic Qualifications

Bachelor's degree in Computer Science, Information Systems Management, IT Security, Finance, Technology or related field; or 3 years relevant work experience in a data-related field
2+ years Python, SQL (Redshift, Postgres) is a must. Strong ELT/ETL background
1+ years using APIs for data extract and load (Postman, Lambda)
1+ years with linux shell/bash for automation and server administration
Experience with Apache Airflow and Docker is preferred
Experience with web scraping is preferred
Experience in the BI/Analytics/Data Warehousing space is preferred
Experience with Amazon Web Services ecosystem (Redshift, S3, Fargate, EC2, EFS, Lambda, Cloudformation, Cloudwatch, VPC, Codecommit, SES, SNS) and general cloud architecture
Demonstrate critical inquiry with attention to detail
Ability to effectively articulate recommendations/conclusions verbally and in writing


Preferred Qualifications

Tableau server(Ubuntu) and Tableau desktop
SAP HANA cloud data model, data extraction and API use cases
Version control best practices
Highly independent, organized and efficient.
Snowflake data warehouse
Data presentation skills to both business and technical teams.


The Green Organic Dutchman is an Equal Opportunity Employer and we welcome diversity in the workplace. We encourage applications from all qualified individuals, including visible minorities, Aboriginal People, and persons with disabilities. Please contact Human Resources to request any accommodations you may require to participate in the recruitment process (including alternate formats of materials or accessible meeting rooms).",The Green Organic Dutchman Holdings Ltd,Mississauga
645,Data Science Senior Manager,"We Are

The people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in AI/ML. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Accenture Applied Intelligence.

You Are

An expert at solving real-world challenges with data, analytics, AI/ML and creativity. Yes, creativity! You know the theory and you have hands-on expertise from studies, experience and/or self-taught projects. As a senior manager working at Accenture you will work on a team with diverse clients and industries delivering analytics solutions and help clients turn data into actionable insights that drive tangible outcomes, improve performance and help clients lead the market.

What You’ll Do

Collaborate with prospective clients to solve large & complex business problems with data, analytics and AI/ML
Develop innovative cloud solutions for clients across functions & industries
Educate account teams about data, analytics AI/ML and applicability to their industry/clients
Lead multiple teams and engagements to engineer & deliver value for clients
Play an active role building a practice including capability development and recruitment
Stay abreast of technologies, academic researches & hands-on techniques on cloud, data, analytics and AI/ML




What We’re Looking For

Extensive experience engaging with client senior leadership on complex business problems
Expertise developing solution offerings and communicating findings to executive audiences
Well versed with managing data science teams and engagements, and providing technical leadership
Extensive experience embracing challenges with cloud, data, analytics and AI/ML lifecycle in enterprise setting
8+ years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation

Bonus Point If

Graduate degree in data science or related disciplines: e.g. Mathematics, Statistics, Computer Science, Economics, Engineering and Physics
Ability to build, manage and foster a team-oriented environment, working creatively and analytically in a problem-solving environment
A blend of data science capability, industry and consulting expertise
High initiative and a desire/ability to persist through obstacles/ambiguity
Excellent written and oral communication skills with ability to clearly communicate findings, concepts and ideas","Accenture
4.1",Montreal
646,"Azure Data Engineer (Certified DP-200 & Dp-201, DP-203)","Title- Azure Data Engineer

Location- Brampton, ON

Rate- $60/hr or $90K

Tech Mahindra

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Data bricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on nosql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Contract, Permanent

Salary: $80,078.00-$90,207.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Work from home

Schedule:

8 hour shift","Compest solutions Inc.
4.6",Brampton
647,"Azure Data Engineer (Certified DP-200 & Dp-201, DP-203)","Title- Azure Data Engineer

Location- Brampton, ON

Rate- $60/hr or $90K

Tech Mahindra

Need Azure data Engineer with

Primary skills:

· In-depth project experience in Hadoop and Azure Cloud technologies(Azure Data bricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )

· Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.

· Work directly with Business users and convert use cases into solutions independently.

· Experience in working with very large volume of log data and building analytical insights based on user requirements

· Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

· Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.

· Write programs to pull data from External Applications and Services using REST API with different authentication methods.

· Knowledge on nosql database types like Document and Graph DB is a plus.

· Knowledge on Machine Learning Libraries for Data science and analytics is a plus.

· Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Job Types: Full-time, Contract, Permanent

Salary: $80,078.00-$90,207.00 per year

Additional pay:

Bonus pay

Benefits:

Dental care
Extended health care
Life insurance
Work from home

Schedule:

8 hour shift","Compest solutions Inc.
4.6",Brampton
648,Data Engineer,"What you'll do
Responsibilities
Use tools and custom code to implement automated data pipelines
Provide data analysis
Develop and advocate data governance best-practices
Design and implement API endpoints to be consumed by data end-users
Design, document and implement data models
What you'll need
Qualifications

Required

BS or MS degree in Computer Science or relevant experience
Strong software development background preferably in Python or Java
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Experience designing, building, and maintaining data processing systems
Strong background in Microsoft Azure, particularly Azure data analytics offerings like Azure Data Factory, Azure Managed SQL, Azure Databricks, Azure Blob storage
Experience developing analytics driven solutions in Microsoft PowerBI

Nice to have

Past experience with Apache Airflow or similar workflow management system
Exposure to Yandex Clickhouse or other column-oriented databases
We're looking for
Core Skills
Airflow Data Modeling CRISP DM Automation Java Python Data Science Data Analysis Databases","Fiddlehead
4.1",Moncton
649,Data Lab Architect,"Highly technical and analytical, possessing 5 or more years of Database and/or Analytics Systems development and deployment experience, IT systems and engineering experience, security and compliance experience, etc.
Possess significant experience of software development and/or IT and implementation/consulting experience.
Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.
Ability to think understand complex business requirements and render them as prototype systems with quick turnaround time.
Implementation and tuning experience in the Big Data Ecosystem, (such as EMR, Hadoop, Spark, R, Presto, Hive), Database (such as Oracle, MySQL, PostgreSQL, MS SQL Server), NoSQL (such as DynamoDB, HBase, MongoDB, Cassandra, design principles) and Data Warehousing (such as Redshift, Teradata, Vertica, schema design, query tuning and optimization) and data migration and integration.
Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups.
Knowledge of foundation infrastructure requirements such as Networking, Storage, and Hardware Optimization.
BS level technical degree required; Computer Science or Mathematics background preferred.
DESCRIPTION
Are you a data and analytics specialist? Do you have deep expertise in AWS services for managing data at speed and scale? Do you think big about how data can change the world, and love building software? Would you like a career that gives you opportunities to help customers and partners use cloud computing services to build new solutions, faster, and at lower cost?

At AWS, we’re hiring highly technical cloud computing architects and engineers to collaborate with our customers on building solutions in database, data management, and analytics. AWS Data Labs are a global and online based facility where customers come to build data and analytics platforms. You will focus on real time and batch-based data processing, business intelligence, analytics, and machine learning systems. These solutions are built alongside the customer and quickly put into production use in a matter of weeks. You'll work closely with AWS Field Teams including Solution Architects, Technical Account Managers, and AWS Service Developers to partner with customers to solve hard problems with data. Every day, you'll be working with AWS Services and Data Labs Customers to determine the optimal implementation, build it, prove it works, extract documents and CloudFormation templates to speed project delivery. If you are builder, and love data, then this could be your ideal job!

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.


Hands on experience leading large-scale global database, data warehousing and analytics projects.
Demonstrated industry leadership in the fields of Database and/or Data Warehousing, Data Sciences and Big Data processing.
Deep understanding of data, application, server, and network security
Experience with Statistics, Machine Learning and Predictive Modelling.
Hands on experience as a database, data warehouse, big data/analytics developer or administrator, or work as a data scientist.
Experience working within the software development or Internet industries is highly desired.
Technical degrees in computer science, software engineering, or mathematics
Working knowledge of modern software development practices and technologies such as agile methodologies and DevOps.
AWS Certification, eg. AWS Solutions Architect, Developer, or SysOps Associate/Professiona","Amazon Web Services Canada, In
3.8",Vancouver
650,Software Developer - Data Operations,"Who we are:

Geotab is a global leader in IoT and connected transportation and certified “Great Place to Work.” We are a company of diverse and talented individuals who work together to help businesses grow and succeed, and increase the safety and sustainability of our communities.

Geotab is advancing security, connecting commercial vehicles to the internet and providing web-based analytics to help customers better manage their fleets. Geotab’s open platform and Marketplace, offering hundreds of third-party solution options, allows both small and large businesses to automate operations by integrating vehicle data with their other data assets. Processing billions of data points a day, Geotab leverages data analytics and machine learning to improve productivity, optimize fleets through the reduction of fuel consumption, enhance driver safety and achieve strong compliance to regulatory changes.

Our team is growing and we’re looking for people who follow their passion, think differently and want to make an impact. Ours is a fast paced, ever changing environment. Geotabbers accept that challenge and are willing to take on new tasks and activities - ones that may not always be described in the initial job description. Join us for a fulfilling career with opportunities to innovate, great benefits, and our fun and inclusive work culture. Reach your full potential with Geotab. To see what it’s like to be a Geotabber, check out our blog and follow us @InsideGeotab on Instagram, Twitter or Facebook.

Who you are:

You will have deep knowledge in developing and documenting processes for onboarding new data into Geotab’s production data environment. You are highly organized and are able to manage multiple tasks and projects simultaneously. Also a strong team-player with the ability to engage with all levels of the organization. If you love technology, and are keen to join a data driven company — we would love to hear from you!

What you'll do:

The Software Developer, DataOps is the foundation of Geotab’s Data Factory. They are responsible for the development of scalable and reusable pipelines that minimize time from insight to production. The role continuously collaborates with data analysts and data scientists to design innovative pipelines using new tools and frameworks. They also work closely with the Data Architect and Data Quality experts to ensure all data assets are delivered with the highest quality, with the right schema and into the right location.
How you’ll make an impact:
Deploy and maintain ETL/ELT pipelines using SQL, Python and Airflow.
Design and publish reusable pipeline templates through in-house Python package (i.e. templates for data integration, derived metrics, reporting, custom runs).
Collaborate with data analysts and data scientists to develop complex pipeline templates involving big data tools (i.e. Spark, Apache Beam, Kubepods).
Lead optimization of pipelines based on requirements and pipeline performance.
Develop connectors to extract/receive data from external sources.
Manage pipeline releases through Git and CI/CD.
Contribute to the development of an alerting framework for production pipelines.
Ensure metadata is captured and stored across the pipeline lifecycle (i.e. creation, execution, deprecation/update).
Support remediation of issues within production pipelines.
Collaborate with data quality analysts and specialists to ensure all pipelines include automatic quality checks.
Collaborate with data architect to ensure data schemas comply with DataOps guideline.
Support data architect in evaluation of model-based pipelines through Dataform.
Recommend features and enhancements to infrastructure and pipeline framework.
Contribute to the migration of data assets and pipelines from legacy data structures
What you’ll bring to this role:
Post-secondary Degree/Diploma specialization in Computer Science, Engineering, Mathematics, or a related field.
3-5 years of Python development experience.
3-5 years of experience building ETL/ELT production pipelines.
1-2 years of experience with SQL and Databases.
Previous experience interacting with REST APIs in Python is an asset.
Hand-on experience using Apache Airflow in a work setting is an asset.
Experience working in a cloud based infrastructure, especially Google Cloud Platform, is an asset.
Previous experience with python package development is highly regarded.
Must stay relevant to technology and have the flexibility to adapt to the growing technology and market demands.
Strong team-player with the ability to engage with all levels of the organization.
Why job seekers choose Geotab:

Work from home and flex work arrangements
Baby bonus
Home office reimbursement program
Online learning and networking opportunities
Electric vehicle purchase incentive program
Competitive medical and dental benefits (full-time employees only)
Retirement savings program (full-time employees only)

How we work:

At Geotab, we understand that the world is always changing and that we need to change with it. Geotab has adopted a hybrid model for working, including a flexible work from home program, with the opportunity to work in our safe, clean offices. When working from home, you are required to have a reliable internet connection with at least 50mb DL/10mb UL. Virtual work is supported with cloud-based applications, collaboration tools and asynchronous working. The health and safety of employees are a top priority. We encourage work-life balance and keep the Geotab culture going strong with online social events, chat rooms and gatherings. Join us and help reshape the future of technology!

We believe that ensuring diversity is fundamental to our future growth and progress and is an integral part of our business. We believe that success happens where new ideas can flourish – in an environment that is rich in diversity and a place where people from various backgrounds can work together. Geotab encourages applications from all qualified individuals. We are committed to accommodating people with disabilities during the recruitment and assessment processes and when people are hired. We will ensure the accessibility needs of employees with disabilities are taken into account as part of performance management, career development, training and redeployment processes. If you require accommodation at any stage of the application process or want more information about our diversity and inclusion as well as accommodation policies and practices, please contact us at careers@geotab.com. Click here to learn more about what happens with your personal data.","Geotab
4.2",Oakville
651,Data Engineer,"Keyrus Canada, a leader in Data Intelligence is looking for a Data Engineer.

The Toronto team is expanding rapidly! Our team has doubled in the last two years and is continuing to grow. If you are looking for an innovative startup-style company with a good team-spirit that has the support of an internationally recognized brand, we encourage you to apply and join us!

Who we are:

With offices in 18 countries and more than 20 years of experience in North America, Keyrus is a trusted leader in Data Intelligence.

Keyrus Canada offers stimulating projects to increase companies’ performance, with 2 areas of expertise:

Data Strategy to help organizations identify business objectives, build a strategy, and leverage their data to achieve their goals (BI Roadmap | Master Data Management | Data Governance and Architecture…)
Data Intelligence to enable companies to draw critical insights from their data and shape business decisions (Data Integration | Cloud Migration | Business Intelligence | Analytics & Machine Learning…)

About the role:

We are looking for a Data Engineer expert to join our Toronto office! As a part of the Keyrus team, you will combine your business acumen and statistical knowledge with strong problem solving abilities to analyze large sets of data and deliver insightful, actionable results to our clients.

You will play a key role in providing our clients with business intelligence and ETL solutions to manage their data assets. You will work directly with our client's business to add value to their data intelligence environment through the use of tools such as Alteryx and Tableau. You will be responsible for the entire end to end analytics solution, from backend data engineering, manipulation, and cleansing, to front-end data visualization.

Our ideal candidate:

At least 3+ years of experience as a Business Intelligence Developer, working directly with a tool such as Alteryx, Talend or SSIS for ETL, data manipulation, etc. as well as with a data visualization tool such as Tableau
Experience working with a relational database (SQL, Oracle, etc.) and data modeling
Experience working with business teams to translate functional requirements into technical requirements
Knowledge of data visualization best practices and cloud warehouses (i.e. Snowflake, Redshift) would be an asset
Minimum of a Bachelor's Degree in IT or related field.

What we offer:

A stimulating environment driving you to discover new horizons and surpass yourself
A strong innovative and entrepreneurship DNA
A space that promotes mutual respect, where you can express your ideas and share your opinion
A positive, multicultural work atmosphere and a strong team spirit
Lots of opportunities to celebrate your successes: afterworks, team activities, birthdays, breakfasts and other special events
Benefits such as: insurance, RRSPs, almost full repayment of the transport card, etc.","Keyrus
3.9",Canada
652,Data Engineer - 313378,"Ingénieur de données

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Ingénieur de données pour une entreprise dans le domaine des assurances. Notre client est situé à Montréal.





Description des tâches et responsabilités – Ingénieur de données

Les responsabilités du poste incluent :

Contribuer à la planification et à l'exécution de pipelines de données pour divers projets d'apprentissage automatique;
Concevoir, mettre en œuvre et maintenir des pipelines de données avec des transformations de données complexes;
Assembler des ensembles de données volumineux et complexes qui répondent aux exigences commerciales fonctionnelles / non fonctionnelles;
Collaborer avec les parties prenantes pour résoudre les problèmes techniques liés aux données et répondre à leurs besoins en infrastructure de données;
Effectuer la collecte des exigences commerciales et fonctionnelles et fournir des estimations de projets.

Exigences du poste – Ingénieur de données
Expérience de travail avec des équipes commerciales pour traduire les exigences fonctionnelles en exigences techniques;
- Excellente capacité de communication - vous pouvez expliquer votre travail d'une manière que tous les membres de l'équipe peuvent comprendre, et vous pouvez formuler les problèmes de manière à garantir que la bonne question est posée;

Expérience de soutien et de travail avec des équipes interfonctionnelles dans un environnement dynamique.




Type de poste
Contractuel 6 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH313378




____________ENGLISH VERSION___________

Data Engineer

As a part of its agreements with its various clients, Procom is currently seeking a Data Engineer for a company in the insurance sector. Our client is located in Montréal.





Job details – Data Engineer

Key responsibilities for this position include:

Contribute to the planning and execution of data pipelines for various machine learning projects;
Design, implement, and maintain data pipelines with complex data transformations;
Assemble large, complex data sets that meet functional / non-functional business requirements;
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs;
Conduct business and functional requirements gathering and provide projects estimates.




Mandatory Skills – Data Engineer

Experience working with business teams to translate functional requirements into technical requirements;
Excellent communication ability – you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked;
Experience supporting and working with cross-functional teams in a dynamic environment.




Assignment Length
6-month contract – renewable

Start date
Immediately

Reference number
BH313378","Procom
4.3",Montreal
653,FULLSTACK DEVELOPPER & DATA ENGINEER (bank of candidates),"Position Description:

We are looking for a savvy Data Engineer to join our growing Data Analytics and Business Intelligence local practice team.
In the role of Fullstack Developer, the ideal candidate will assume Front-End and/or Back-End analysis, design and development on all types of programming languages required by the client mandates to which he or she will be assigned.
The Date Engineer will be responsible for expanding and optimizing our client’s data and data pipeline architecture, as well as optimizing data flow and collection from a variety of sources for cross-functional teams.
The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.
The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.
They ensure that data is ready for use in digital products, data science, reporting, and analytics. They will design and maintain data warehouses and data marts, and structure volumes of data.

They must be self-directed and comfortable supporting the data needs of multiple teams and systems

#WeareCGI

Your future duties and responsibilities:
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc..
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud-based ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep data separated and secure across national boundaries through multiple data centers and cloud providers regions..
Improve data availability, acting as a liaison between source systems and Data Science and BI teams
Collect, blend, and transform data using ETL tools, database management systems, and code including SQL and Python
Perform aggregation on data across various warehousing models, such as OLAP cubes and star schemas for BI purposes
Provide training or coaching for junior members
Managing a team as a Lead Developer/ScrumMaster
Ensure the analysis, design, estimation, planning and Front-End and/or Backend development of cloud computing, Web, Ecommerce or Big Data applications (Java, Microservices, Angular, PHP, NodeJS, VueJS, React, .Net, C#, Androïd, Hybris Java, Python, HTML, CSS, Kafka, Azure, AWS, GCP etc.).
Required qualifications to be successful in this role:
2-5 years of experience in a Data Engineer role
5-6 years experience in a backend and/or front-end developer role
Computer Science, Statistics, Informatics, Information Systems degree or equivalent education and experience.
Advanced working SQL knowledge and experience working with relational databases.
Experience building and optimizing ‘big data’ data pipelines.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytics skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong proficiency in Python (especially data science packages like pandas, numpy etc) and SQL for analytics, database development, and data modelling
Working knowledge of message queuing, stream processing and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Should also have experience using the following software/tools:
o Experience with big data tools: Python, Hadoop, Spark, Kafka, etc.
o Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
o Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
o Experience with AWS, MS Azure, Google cloud services, DataBricks
o Experience with stream-processing systems: Storm, Spark-Streaming, etc.
o Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.

Fluency in French and English, oral and written
Strong understanding of Agile methodologies and experience on an agile team
Keen collaborator and clear communicator, responsive to service needs and operational demands
Passionate about the impact of emerging technologies and learning new skills and ideas

Optional:

Experience with ERP and CRM environments and data: SAP, SalesForce, PeopleSoft, MS Dynamics, etc.
What you can expect from us:

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer.","CGI Inc
3.8",Shawinigan
654,Data Science Associate - Montreal,"Company presentation


World leader in gases, technologies and services for Industry and Health, Air Liquide is present in 80 countries with approximately 65,000 employees and serves more than 3 million customers and patients. Oxygen, nitrogen and hydrogen have been at the core of the company’s activities since its creation in 1902. Air Liquide’s ambition is to be the leader in its industry, delivering long-term performance and acting responsibly.


Entity and activity description


Founded in 1911, Air Liquide Canada has over 2,200 employees and serves over 80,000 customers in Canada’s aeronautics, automobile, agri-food, chemical, defence, electronics, energy, metallurgy, metal fabrication, mining and healthcare industries from our sites located in key industrial regions from coast to coast.


Missions and Responsibilities


The R&D Data Science group at Air Liquide has an opening for a Data Scientist. The researcher will have the opportunity to work on challenging problems focusing on customers, patients and operations.The researcher will also interact with multi-disciplinary teams composed of Business, IT and Digital resources that define operating models, and build digital solutions.

Duties and Responsibilities

Collaborate with the business to define needs and challenges, translate them into functional specifications, and develop solutions to address them.
Work with IT and external organizations to obtain online/offline data. Clean, and analyze the data.
Develop solutions relying on machine learning methods such as clustering, regression, classification, time series and deep learning.
Test and verify the performance of solutions with prototypes developed in R, Python, or similar development environments.
Support the development of industrial tools and their deployment in the business units.
Train team members and the business, thus ensuring sustainability of the solutions for Air Liquide.
Publish research in internal reports, at conferences and peer-reviewed journals

Competencies and Profile

Master in Computer Science or related field
3 years of relevant experience is preferred
A strong background and experience in statistics and machine learning
Strong programming skills in Python or R
Ability to write production level, modular code
Demonstrates strong process and operational safety behavior at all times
Excellent communication and interpersonal skills (written and oral)
Ability to work in a multi-disciplinary and international team

Preferred

Experience in AWS, Azure, and SQL

Additional information


Thank you for your interest. Please note that only applicants selected for an interview will be contacted For more information on our company, visit us online at www.airliquide.ca


Job Reference: CA04024","Air Liquide
3.8",Quebec
655,Data Engineer - Level 3,"Company Description


SSENSE, pronounced [es-uhns], is a Montreal-based fashion platform with global reach. Founded in 2003, SSENSE is pacing the vanguard of directional retail with a mix of luxury, streetwear, and avant-garde labels. We produce industry-leading original content and take pride in building our own technology solutions and systems from scratch. Our field of focus has grown beyond that of a typical e-commerce entity as we explore the nexus of content, commerce, and culture.

Currently serving 150 countries, generating an average of 88 million monthly page views, and achieving high double digit annual growth since inception, SSENSE is becoming a cultural protagonist in its own right.



Job Description


SSENSE is looking for a Data Engineer to join our rapidly growing technology team. The level 3 Data Engineer will join a squad and deepen their knowledge of software development and data pipelines. They will break down, with minimal guidance, large tasks into smaller, manageable steps to deliver complex tasks required for well-defined features of the Product roadmap. The ideal candidate will contribute to knowledge dissemination within the organization and participate in the recruiting and onboarding of new employees.

RESPONSIBILITIES

Product Delivery

Build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end-user facing reports, data sciences and ad-hoc analyses
Understand the high-level product roadmap and immediate features to be developed, contributing to high-level estimation and layout of the development sequences
Complete complex development tasks with minimal guidance
Constantly and actively contribute to pushing code to production with the objective of becoming a main contributor
Review Pull Requests
Write testable, efficient, and reusable code suitable for continuous integration and deployment, that respect best practices and SSENSE development standards
Review Unified Modeling Language (UML) diagrams and technical documentation, ensuring its quality

Ownership and accountability

Be accountable for code quality and conduct adequate testing
Review and contribute to technical documentation
Knowledge sharing and coaching
Join SSENSE University (the internal peer learning platform) sessions to ramp up on various technologies and host at least two sessions per year
Lead the onboarding of new data engineers

Architecture

Contribute actively to the design of the solution, challenging other members on technical decisions
Help more junior Data Engineers understand the technical design so they can write documentation for the rest of the team

Recruiting

Participate in HR recruiting events, helping to identify and recruit top tech talent


Qualifications

Bachelor’s degree in Computer Science, Engineering, or a related technical field
A minimum of 3 years of Object Oriented Programming (OOP) and/or functional programming experience
Knowledge of Apache Spark for big data processing
Knowledge of Python programming language
Knowledge of the data modelling concepts and ability to define the architecture with minimal guidance to develop a complex microservice
Familiar with various database systems and able to write complex queries independently
Knowledge of cloud concepts and the ability to follow instructions to use them with minimal guidance
Knowledge of the AWS services (Glue, Athena, S3, Databricks, etc.) and Apache Airflow, an asset
Proficiency in Git
Bilingual in French and English

SKILLS

Fast learner and detail oriented
Solution-oriented mindset and can-do attitude to overcome challenges
Team player with a high sense of accountability and ownership
Ability to thrive in a fast-paced environment and master frequently changing technologies and techniques

Additional Information


WORLD CLASS TECHNOLOGY

Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.

WORLD CLASS TEAM

The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.

WORLD CLASS PLATFORM

The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry. Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.

Read more about us on our SSENSE Tech Blog.","SSENSE
4.0",Montreal
656,Intermediate Scientist/CAPA Specialist,"Our client in Ottawa West is currently looking for a CAPA Specialist, R&D to join their team. As a member of Research and Development team, the candidate will contribute to the team’s success by supporting key product development programs while gaining an understanding of the business. Main tasks will include, but are not limited to, data analysis, CAPA documentation, performing CAPA investigations, and root cause analysis/failure mode effects analysis of chemical/biochemical systems and mechanical/microfluidic systems. The ideal candidate for our team will bring the following education, experiences, knowledge, and skills to the position.

Required Education and Experience:

Bachelor’s Degree in Science, Engineering or related discipline preferred.

Proven technical, creative, teamwork and implementation skills to contribute to active investigations for product development.
Demonstrated problem-solving and analytical skills. Experienced using statistical tools, root cause analysis and knowledge of Failure Mode Effects Analysis.
Strong written and oral skills are required.
Comprehends and conveys information accurately and concisely, excellent technical documentation skills. Ensures documentation and resulting actions comply with all corporate and regulatory requirements.
Understands key technical issues and provides creative solutions while balancing relative risks and gains.
Excellent attention to detail, organization skills and proven ability to multitask.
Demonstrated initiative and ability to work with tight deadlines.
Demonstrated judgment and decision-making skills, organization, coordinating and planning skills, ability to work in a multi-task environment, ability to work under pressure and propensity to continuous learning.
Ability to work both independently and within small and large teams; strong interpersonal skills and ability to work cross-functionally.
Ability or aptitude to work on complex problems/issues.
Ability or aptitude to use various types of databases and other computer software.

Familiarity with any of the following areas would be an asset:

GMP, ISO 13485 standard, FDA Quality System Requirements and other applicable US Code of Federal Regulations for Devices.
Working knowledge of Quality Management Systems.
Risk management methods.
Working knowledge of CAPA procedures.

This position requires a solid knowledge of scientific principals and theories and the ability to implement these in a creative and effective manner. The individual must be flexible and be able to work in a fast paced environment with changing priorities. This position requires someone who can work Monday through Friday from 8:00 a.m. to 5:00 p.m. Compensation to be determined based on level of experience.

If you would like to be considered for this position, please click on ""Apply Now!""

AP1956","Adecco
3.7",Ottawa
657,Intermediate Scientist/CAPA Specialist,"Our client in Ottawa West is currently looking for a CAPA Specialist, R&D to join their team. As a member of Research and Development team, the candidate will contribute to the team’s success by supporting key product development programs while gaining an understanding of the business. Main tasks will include, but are not limited to, data analysis, CAPA documentation, performing CAPA investigations, and root cause analysis/failure mode effects analysis of chemical/biochemical systems and mechanical/microfluidic systems. The ideal candidate for our team will bring the following education, experiences, knowledge, and skills to the position.

Required Education and Experience:

Bachelor’s Degree in Science, Engineering or related discipline preferred.

Proven technical, creative, teamwork and implementation skills to contribute to active investigations for product development.
Demonstrated problem-solving and analytical skills. Experienced using statistical tools, root cause analysis and knowledge of Failure Mode Effects Analysis.
Strong written and oral skills are required.
Comprehends and conveys information accurately and concisely, excellent technical documentation skills. Ensures documentation and resulting actions comply with all corporate and regulatory requirements.
Understands key technical issues and provides creative solutions while balancing relative risks and gains.
Excellent attention to detail, organization skills and proven ability to multitask.
Demonstrated initiative and ability to work with tight deadlines.
Demonstrated judgment and decision-making skills, organization, coordinating and planning skills, ability to work in a multi-task environment, ability to work under pressure and propensity to continuous learning.
Ability to work both independently and within small and large teams; strong interpersonal skills and ability to work cross-functionally.
Ability or aptitude to work on complex problems/issues.
Ability or aptitude to use various types of databases and other computer software.

Familiarity with any of the following areas would be an asset:

GMP, ISO 13485 standard, FDA Quality System Requirements and other applicable US Code of Federal Regulations for Devices.
Working knowledge of Quality Management Systems.
Risk management methods.
Working knowledge of CAPA procedures.

This position requires a solid knowledge of scientific principals and theories and the ability to implement these in a creative and effective manner. The individual must be flexible and be able to work in a fast paced environment with changing priorities. This position requires someone who can work Monday through Friday from 8:00 a.m. to 5:00 p.m. Compensation to be determined based on level of experience.

If you would like to be considered for this position, please click on ""Apply Now!""

AP1956","Adecco
3.7",Ottawa
658,Big Data Engineer,"Company description

VirtueTech Inc. is an Amazon Partner Network (APN) Consulting Partner, focusing exclusively on Amazon Web Services (AWS). With a strong foot in AWS, Cloud Infrastructure and Data Analytics, we are a global technology solutions provider with a reputation for stringent quality standards.

We are a very fast growing company and a trusted analytics partner for multiple Fortune 500 companies. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. Working with us offers you an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility

Job description

Job Description-

Focus on scalability, performance, service robustness, and cost trade-offs
Continuous drive to explore, improve, enhance, automate, and optimize systems and tools to best meet evolving business and market needs
Attention to detail, coupled with ability to think abstractly
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Create prototypes and proof-of-concepts for iterative development
Keen to learn new technologies and apply the knowledge in production systems
Take complete ownership of projects and their development cycle

Contract length: 6-8 months

Application deadline: 2021-04-24

Expected start date: 2021-04-26

Job Types: Full-time, Temporary, Contract

Salary: $62,173.00-$130,000.00 per year

Additional pay:

Overtime pay

Schedule:

8 hour shift
Monday to Friday

COVID-19 considerations:
Remote job. Working from home

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process",Virtue Tech Inc.,Midtown Toronto
659,Market Conduct Data Analyst,"Job Description:
We are Canada Life

Being a part of Canada Life means you have a voice. This is a place where your unique background, perspectives and talents are valued, and shape our future success.

You can be your best here. You’re part of a diverse and inclusive workplace where your career and well-being are championed. You’ll have the opportunity to excel in your way, finding new and better ways to deliver exceptional customer and advisor experiences.

Together, as part of a great team, you’ll deliver on our shared purpose to improve the well-being of Canadians. It’s our driving force. Become part of a strong and successful company that’s trusted by millions of Canadians to do the right thing.

Be your best at Canada Life.

We are looking for a Market Conduct Data Analyst


Advisor Monitoring is a team of data analysts in Market Conduct (part of Corporate Compliance) that perform descriptive analytics looking for insights into advisor behaviour and market conduct risk while performing second line oversight of Advisory Network.

Reporting into the Manager – Advisor Monitoring, the Data Analyst role contributes to the execution of the Advisor Monitoring team by combining advanced analytical skills with strong industry knowledge. The ideal candidate is able to combine these abilities to efficiently and effectively draw conclusions and make recommendations to mitigate risk in Advisory Network. This includes detecting anomalous data patterns, analyzing these patterns using knowledge of Distribution processes and products and projecting the results across the rest of the business to recommend control changes where appropriate.

What you will do
Provide valuable data analytics to influence effective change:
Combine expert industry knowledge with advanced data analytics skills to enhance predictive capabilities of Advisor Monitoring team while detecting emerging trends.
Collaborate with data scientists and other IT partners to continuously enhance the efficiency and effectiveness of the Advisor Monitoring program.
This includes tying trends identified during advisor case assessments to population studies to determine the prevalence of trends and recommend next steps.
Assist with the execution of advisor monitoring program:
Analyze large volumes of transactional data to identify key risks with a focus on advisor misconduct. This includes ongoing advisor case assessment work.
Apply industry knowledge to assess potential advisor misconduct and resolve findings. This may require contacting advisors and/or customers where appropriate.
Conduct root cause analysis of market conduct complaints and use findings to set business requirements and execute upgrades to existing data analytics program.
Provide effective oversight of Advisory Network:
Leverage program findings and understand controls framework and leverage program findings to provide effective challenge for upstream controls.
Share analytical best practices with business partners to drive the continuous improvement of business processes across Risk & Compliance.
Follow up on referred cases to ensure successful achievement of advisor outcomes.

What you will bring
Advanced data analytics skills with ability to work effectively in Microsoft Excel, Microsoft Power BI and Tableau Software.
Creative thinker with the ability to understand the root cause of an issue and use data to establish detective controls for the issue.
Strong interpersonal skills and a demonstrated experience working effectively in a team environment as well as independently.
Well-developed planning and organizational skills with the ability to prioritize and handle multiple tasks while meeting tight deadlines.
Excellent verbal and written communication/documentation skills.
Strong influencer with the ability to provide effective challenge to legacy processes.
Advanced knowledge of insurance and wealth products, particularly for Individual Customer.
Understanding of advisor compensation is an asset.
Knowledge of internal admin systems an asset (ie. Univeris, legacy systems, OnBase, etc.)
Post-secondary education in a related field.
Professional designation or diploma (ie. CPA, CFA, CSC, IFIC) an asset

Be your best at Canada Life- Apply today

We are one of Canada's top 100 employers!

Canada Life serves the financial security needs of more than 13 million people across Canada, with additional operations in Europe and the United States. As members of the Power Financial Corporation group of companies, we’re one of Canada’s leading insurers with interests in life insurance, health insurance, investment and retirement savings. We offer a broad portfolio of financial and benefit plan solutions for individuals, families, businesses and organizations.

We are committed to providing an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of the communities in which we live, and to creating an environment where every employee has the opportunity to reach their potential.

Canada Life would like to thank all applicants, however only those who qualify for an interview will be contacted","Canada Life Assurance Company
4.1",London
660,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
661,Sr. Medical Scientist (Cell Therapy) / Scientifique Médical (Thérapie cellulaire),"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.




For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.

Job Description

Kite, a Gilead Company, is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors.

The Role:

The Medical Scientist (MS) is a field-based medical-scientific expert in the assigned therapeutic area. The MS assumes responsibility for all Medical activities within the assigned territory and executes the field medical strategy. This involves gathering insights, medical education and communication, supporting clinical research, and managing projects of various scope including educational events and regional advisory boards. The role requires close national and international collaboration with colleagues from Medical Affairs and other departments.

Implements defined goals and objectives aligned with the Medical Affairs Plan of Action and other strategic initiatives within the Cell Therapy therapeutic area

Responds to clinical inquiries regarding marketed or developmental Gilead/Kite products.

Develops and presents complex scientific and clinical data related to Gilead/Kite products.

Identifies and develops regional and national opinion leaders to support Gilead/Kite products through personal contacts and on-site visits

Establishes strong relationships with opinion leaders, clinical investigators and healthcare professionals at academic and non-academic settings

Works on phase 3/phase 4 programs that include collaboration with investigators and internal personnel

Provides input into site selection for both phase 4 and other clinical trials

Anticipates obstacles and difficulties that may arise in the field and resolves them in a collaborative manner

The candidate works collaboratively with Gilead/Kite personnel in Commercial, Marketing, Market Access, Clinical Research, Global Safety and Global Medical Affairs

Utilizes scientific resources to deliver impactful presentations in a variety of settings.

The incumbent travels to appointments, meetings and conferences on a frequent and regular basis, occasionally with short notice

Must have the ability to work as a member of several teams that may overlap such as national MS team, regional team, national accounts, and others

Well-developed experience in preparing and delivering presentations is required.

Experience in the management or investigation of clinical trials is preferred

Exhibits Gilead/Kite core values: integrity, inclusion, teamwork, accountability, and excellence

Knowledge, Experience and Skills:

Advanced health sciences degree (M.D., Pharm. D., PhD are preferred) with a minimum of 3 years of experience in healthcare or pharmaceutical industry

Two to four years of experience in Oncology (specifically Hematologic Malignancy) in a clinical/research or medical affairs capacity is preferred

Excellent oral and written communication skills and interpersonal skills (including ability to network)

Bilingualism (French and English) is required

Excellent project management ability and organizational skills, including the management of multiple priorities and resources

Excellent judgment and personal initiative are required

Advanced knowledge of Microsoft Office suite (Word, PowerPoint, Excel, Access, Outlook) is required

Must have knowledge of and be willing to comply with all regulatory/compliance policies

Candidate must be based in Quebec

Ability to travel 70% of the time; domestic and international travel is required, including potential attendance at conferences which may include occasional weekend travel





Kite, une société de Gilead, se consacre à la mise au point d’immunothérapies novatrices contre le cancer dans le but d’offrir une réponse rapide, durable et à long terme et d’éliminer le fardeau que représentent les soins de longue durée. L’entreprise concentre ses énergies sur des thérapies cellulaires, à savoir les cellules T à récepteur antigénique chimérique (CAR-T) et les récepteurs de l’antigène des lymphocytes T (TCR). Ces traitements visent à renforcer la capacité du système immunitaire à détecter les tumeurs et à les éliminer.

Rôle

Le scientifique médical (SM) est un expert scientifique du domaine médical qui travaille sur le terrain, dans le domaine thérapeutique qui lui a été attribué. Le SM assume la responsabilité de toutes les activités médicales dans le territoire attribué et exécute la stratégie médicale sur le terrain. Il doit par exemple recueillir des idées, soutenir la formation et les communications médicales, appuyer la recherche clinique et gérer des projets d’importances diverses, y compris des événements éducatifs et des conseils consultatifs régionaux. Le titulaire de ce poste doit entretenir une étroite collaboration nationale et internationale avec des collègues des Affaires médicales et d’autres services.

Mettre en œuvre des objectifs définis qui cadrent avec le Plan d’action des Affaires médicales et avec les autres initiatives stratégiques du domaine thérapeutique de la thérapie cellulaire.

Répondre aux questions cliniques portant sur les produits de Gilead/Kite actuellement sur le marché ou en cours de développement.

Développer et présenter des données scientifiques et cliniques complexes liées aux produits Gilead/Kite.

Repérer des leaders d’opinion régionaux et nationaux, et les amener à appuyer les produits de Gilead/Kite par l’intermédiaire de contacts personnels et de visites sur place.

Établir de solides relations avec des leaders d’opinion, des investigateurs cliniques et des professionnels de la santé en milieu universitaire et non universitaire.

Travailler aux programmes de phase III et IV notamment en collaborant avec les investigateurs et le personnel interne.

Contribuer à la sélection des centres où seront réalisées des études cliniques de phase IV et d’autres études cliniques.

Prévoir les obstacles et les difficultés pouvant survenir sur le terrain, puis les résoudre de manière collaborative.

Travailler avec le personnel de Gilead/Kite des secteurs Affaires commerciales, Marketing, Accès au marché, Recherche clinique, Innocuité mondiale et Affaires médicales mondiales.

Employer des ressources scientifiques pour donner des présentations convaincantes dans divers milieux.

Se rendre régulièrement et fréquemment à des rendez-vous, à des réunions et à des conférences, parfois avec un court préavis.

Pouvoir travailler en tant que membre de plusieurs équipes dont les activités pourraient se chevaucher, notamment dans l’équipe nationale des scientifiques médicaux, l’équipe régionale et l’équipe des comptes nationaux.

Posséder une grande expérience en élaboration et en animation de présentations, obligatoire.

Posséder une expérience en gestion ou en investigation d’études cliniques, un atout.

Incarner les valeurs de Gilead/Kite, soit l’intégrité, l’inclusion, le travail d’équipe, la responsabilité et l’excellence.

Connaissances, expériences et compétences

Diplôme de haut niveau en sciences de la santé (préférablement M.D., Pharm D. et Ph. D) et au moins trois ans d’expérience dans le secteur pharmaceutique ou des soins de santé.

De deux à quatre ans d’expérience en oncologie (plus précisément en hémopathies malignes) dans un poste du domaine clinique, de la recherche ou des affaires médicales, un atout.

Excellentes aptitudes en communications écrites et orales, et de solides compétences en relations interpersonnelles (y compris en réseautage).

Bilinguisme, anglais et français, obligatoire.

Remarquables compétences organisationnelles et en gestion de projets, y compris la capacité de gérer plusieurs ressources et priorités.

Jugement et esprit d’initiative hors pair, obligatoire.

Connaissance avancée de la suite Microsoft Office (Word, PowerPoint, Excel, Access, Outlook), obligatoire.

Connaissance des politiques réglementaires et de conformité , et volonté de les respecter, obligatoires.

Domicile au Québec, obligatoire.

Capacité à voyager 70 % du temps, autant à l’intérieur qu’à l’extérieur du pays, ce qui inclut d’éventuelles participations à des conférences pouvant nécessiter des déplacements les fins de semaine.



Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com . Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma .



For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.","Gilead Sciences
3.8",Quebec
662,Development Engineer / Development Scientist (Synthetic Biology),"About Precision NanoSystems Inc. (PNI)




Precision NanoSystems Inc. (“PNI”) is a manufacturer of instruments, kits and reagents in the global nanomedicine market providing tools for drug development and cell-specific delivery to study, diagnose and treat disease. PNI’s NanoAssemblr family of instruments allow scientists to rapidly develop novel nanomedicine drug candidates for pre-clinical testing. PNI’s NanoAssemblr Scale-up platform enables the translation of these drug candidates to clinical testing and eventually to commercial use. PNI’s NanoAssemblr™ Transfection Reagents use nanomedicine technology to deliver genetic materials in primary cells vitro and in vivo, enabling disease researchers to easily study gene function in high-value models of disease. PNI sells its products to leading pharmaceutical and biotechnology companies, and leading academic institutions in over 20 countries worldwide. Please find more information at http://www.precisionnanosystems.com/.




Position Summary


Precision NanoSystems Inc. has an opening for Development Engineer/Scientist, Synthetic Biology to join our growing Pharmaceutical Development department in Vancouver, BC. The successful candidate will contribute to a wide range of product development projects including the development and commercialization of novel nanoparticle reagents, microfluidics and instrumentation to enable the field of genetic medicine. The individual will have a diverse set of molecular biology and genetic engineering skills with significant experience in Vector library development, Recombinant DNA technology including PCR based molecular cloning, PCR based recombination techniques, nucleic acid recombinant DNA technologies, analytical method development, next-generation sequencing (NGS) techniques, site-directed mutagenesis, RNA or protein synthesis, Genetic engineering. The individual must have worked in the yeast or bacterial cloning, manipulating primary & immortalized mammalian cell-lines, genetic modification of cells and a wide range of cell-based assays. The successful candidate must be adaptable, work well with people from a diverse interdisciplinary background, and able to multi-task with excellent critical thinking with attention to detail and a track record of successful research contribution or significant industrial R&D research experience will be an asset.


Areas of Responsibility



Contribute to a wide range of product development projects, including establishing a nucleic acid-based platform technology for regenerative medicine and vaccine applications, that support the existing proprietary NanoAssemblr™ technology developed by Precision Nanosystems Inc.
Contribute to establishing new techniques in-house, perform routine iterative testing and supporting both internal projects and external collaborations
Responsible for designing and conducting experiments with input from the assigned supervisor
Design and perform experiments pertaining to recombinant DNA technology to generate vector library.
Collect and analyze experimental data, present data at meetings, provide conclusions and outline future work plans
Troubleshoot experiments and identify abnormal or unexpected trends in data
Support all technical documentation related to projects and product development
Collaborate with internal teams to ensure successful project completion including providing support to Contract Research, R&D, Product development, Manufacturing, and Operations when required
Provide technical support to staff and customers (product use, protocols) as needed
Provide training on laboratory/product protocols to lab personnel as needed
Set up, calibrate and perform routine maintenance on specialized laboratory equipment
Ensure that the necessary laboratory supplies are available and perform tasks related to supporting the operation of the laboratory
May be required to perform other related duties as needed or assigned



Qualifications and Experience



PhD graduates in Biochemical Engineering, Molecular Biology, Biochemistry, Genetic Engineering or Biotechnology with recent postdoctoral training/experience in RNA biology, RNA Biochemistry or recombinant DNA technology considered.
MSc in the Life Sciences (e.g., Molecular biology, Biochemistry, Biotechnology, Genetic Engineering and Pharmaceutical Sciences) with recent 6-8 years of academic or industrial experience.
Knowledge of Pharmacopeial guidance considered asset
Recent 3 years of hands-on lab-based experience in Molecular Biology laboratory focusing on mRNA biology or mRNA biochemistry
Significant experience in PCR based cloning and Cell-free nucleic acid synthesis is a considered asset
Experience working in pharma or biotech industry would be advantageous
Ability to independently design, conduct, analyze and troubleshoot experiments
Experience in developing DNA based expression vectors for mRNA and protein synthesis
Experience in working with both prokaryotic and eukaryotic cells
Experience with a wide-range of laboratory techniques including PCR, qPCR, RT-PCR, Plasmid preparation, DNA, RNA & Protein gel electrophoresis, Northern blotting, Western blotting, ELISA, chemical transfection, electroporation, expression vector library construction etc.
Experience in working with nucleic acids (e.g., plasmid DNA, mRNA, siRNA), recombinant DNA technology, and nucleic acid purification methods
Sound knowledge of genetic & epigenetic mechanism of prokaryotic and/or eukaryotic gene expression
Experience with bioinformatic software tools as well as statistical analyses of experimental data is an asset
An understanding and interest in the use of nanoparticle technology for non-viral gene delivery would be an asset
Excellent communication skills (verbal and written) both in one-on-one and in a group setting with the ability to organize and present technical summaries of scientific data
The individual must be a team player who thrives in a dynamic environment with multiple tasks and aggressive deadlines
Proven ability to apply critical and analytical thinking
Must be a resourceful, proactive, detail-oriented individual who is able to work with minimum supervision
Project management skills will be considered as an asset.



PNI provides a competitive compensation and benefits package with excellent opportunities for personal growth.




Only candidates selected for an interview will be contacted. Posting valid until filled. No solicitors please.




Precision NanoSystems, Inc. is an equal opportunity employer.","Precision NanoSystems
4.4",Vancouver
663,Big Data Engineer (Remote Optional),"WHO WE ARE

Centro delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands.

Our comprehensive ad tech platform, Basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place.

We are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. We invest in our culture and support our employees so they can do their best work.

Centro is headquartered in Chicago, with beautiful offices also in Toronto, Dallas, Denver, and New York to name a few. Post-COVID, many of us will be returning to one of our offices (by choice, not requirement - we believe results matter more than where they are produced). All of our employees have the flexibility to work in one of our office locations, completely remote, or a hybrid of the two. Please note, we are hiring on a remote working basis only in the U.S. and Canada.



ABOUT THE TEAM

Technology is at the core of what we do. Centro’s innovative Engineering team designs and develops new features and integrations for Basis, our industry-leading, comprehensive software solution. Our platform processes over 300 billion events per day and uses AI and machine learning to automate and simplify the entire digital campaign process.

WAYS YOU'LL CONTRIBUTE

This team is all about data—and in order to create value from the massive amount of data we collect, engineering leverages their dynamic Data Engineering, Data Science, and Business Intelligence teams to create insights that benefit the industry as a whole. You will contribute by:
Implementing scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment.
Developing platform services to operate the big data applications at scale.
Gathering and processing raw data at scale from diversified sources into Hadoop.
Building enterprise business analytics and reporting applications on Hadoop.
WHAT YOU BRING TO THE TABLE
Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie
Strong understanding of computer science fundamentals
Proficiency with relational databases and SQL queries (MySQL, Oracle or similar)
Understanding of how to handle high velocity, high volume data events.
Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning.
Experience implementing data pipelines moving large volumes of data a day.
Experience in implementing application in Scala on SPARK.
Experience coding in Python
BONUS POINTS
Skills in real-time streaming applications.
Knowledge of Scala.
A development workflow using Docker containers.
Compulsion for automating your day-to-day processes.
OUR TECH STACK
Ruby, Java, Python, and React.js
Hadoop, Scala, Spark, Hive
Kubernetes, Docker, Kafka
PostgreSQL, NoSQL
AWS

ANYTHING ELSE?

Don't think you have all the skills required for this role? That's okay, we recognize that experience can be built in many ways. If you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn’t match our exact requirements.

LIFE WITH CENTRO

We take care of our people and believe that Centro’s success depends on the growth and well-being of each one of our team members.

We provide a thoughtful perks and benefits package including competitive 401k/RRSP matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a work from home stipend for employees in closed offices, and more.

We are proud to be an equal opportunity employer are committed to building teams of Centrons that are diverse in thought, perspective, and culture. We celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age. Our employee-led communities enrich our culture of uniqueness, inclusivity, and empowerment.","Centro
4.1",Ontario
664,Principal Data Infrastructure Engineer,"Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science and engineering to radically improve the lives of patients and industrialize drug discovery. Our team is working to solve some of the hardest, most meaningful problems facing human health today. Come join us in our mission to decode biology to radically improve lives, while doing the most impactful work of your life.
Recursion recently announced its intention to launch its first major multidisciplinary expansion beyond its Utah headquarters, with plans to hire up to 50 people in Toronto by the end of 2021.

The Impact You'll Make

Create a world-class research platform. You'll work across teams and functions with Software Engineers, Data Scientists, ML Engineers, Biologists, and Automation Scientists in building a platform for generating and storing petabytes of data, iterating quickly on novel analyses, and rapidly prototyping new deep learning models.
Build, scale, and operate a data platform . You'll be on a team responsible for building, operating, and tuning a data platform that allows users to discover and query across the breadth of our data at Recursion, which includes a chemistry library of 3 billion compounds, nearly 8 PB of cellular microscopy images taken in 10s of millions of different experimental contexts involving 1 million different reagents, sparse bioassay data across approximately 50 drug discovery programs, and more.
Build relatability into a heterogeneous dataset. At Recursion, we generate datasets based on a wide swath of diverse biological models and treatment approaches. You'll work with Data Scientists to build relatability and queryability into these datasets so they can be used in five years to answer the sorts of questions we haven't even thought of asking yet.
Act as a mentor, coach, and sponsor. You will share your technical knowledge and experiences, delivering impact, learning, and growth across teams at Recursion.

The Team You'll Join

You will lead a new team as they plan and implement a data platform that solves the problem of making our diverse data discoverable, queryable, and relatable across datasets while we continue to add new data modalities as we grow. This will require collaboration with many different groups including teams building out reports, dashboards, and applications, teams finding and generating the required data for the machine learning problems, and teams building and iterating on new data processing pipelines.
As an early leader in the new Toronto office you will have an important impact by shaping how new technical teams embrace the Recursion Values as they deliver challenging data platform problems while effectively collaborating across physical locations, business domains, and technical functions.

The Experience You'll Need

Experience working on data platforms that enable the discovery, query, and processing of large datasets.

Be up to date on industry trends and tools. You understand the tradeoffs between different data platform architectures and technologies like a data lake, a data warehouse, a data lakehouse, or a data mesh, and can draw on this knowledge to lead the design of the data infrastructure for Recursion.

Experience working collaboratively on projects with significant ambiguity and technical complexity, ideally spanning multiple systems and involving diverse technologies.

A people-first mindset. Despite the deadlines, we always prioritize supporting our coworkers in their growth and experience.

A drive to deliver technical solutions that are easily monitored and understood as they run in production and the effects of change can be readily quantified.

Excitement to learn parts of our tech stack that you might not already know. Our current tech stack includes Python, Clojure, Kafka, Docker, Kubernetes, PostgreSQL, JavaScript, ClojureScript, and Go. Our cloud services are provided by Google Cloud Platform.

Biology or chemistry background is not necessary, but intellectual curiosity is a must!

The Benefits/Perks You'll Enjoy

100% Coverage of health, vision, and dental insurance premiums
401(k) with generous matching (immediate vesting)
Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs**
Two one-week paid company closures (summer and winter)
Flexible vacation/sick leave
Generous paid parental leave (including adoptive)
Onsite daycare facility **
Commuter benefit and vehicle parking to ease your commute**
Complimentary chef-prepared lunches and well-stocked snack bars**
Monthly fitness/wellness stipend
One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking**


Subject to change for remote-based employees during the COVID-19 pandemic
**United States based employees

More About Us

Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science, and engineering, with the goal of radically improving the lives of patients and industrializing drug discovery. Central to our mission is the Recursion Operating System, or Recursion OS, that combines an advanced infrastructure layer to generate what we believe is one of the world's largest and fastest-growing proprietary biological and chemical datasets and the Recursion Map, a suite of custom software, algorithms, and machine learning tools that we use to explore foundational biology unconstrained by human bias and navigate to new biological insights which may accelerate our programs. We are a biotechnology company scaling more like a technology company. Recursion is proudly headquartered in Salt Lake City.

Learn more at www.recursion.com , or connect on Twitter and LinkedIn .

Recursion is an Equal Opportunity Employer that values diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected under applicable federal, state, local, or provincial human rights legislation.",Recursion,Midtown Toronto
665,Principal Data Infrastructure Engineer,"Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science and engineering to radically improve the lives of patients and industrialize drug discovery. Our team is working to solve some of the hardest, most meaningful problems facing human health today. Come join us in our mission to decode biology to radically improve lives, while doing the most impactful work of your life.
Recursion recently announced its intention to launch its first major multidisciplinary expansion beyond its Utah headquarters, with plans to hire up to 50 people in Toronto by the end of 2021.

The Impact You'll Make

Create a world-class research platform. You'll work across teams and functions with Software Engineers, Data Scientists, ML Engineers, Biologists, and Automation Scientists in building a platform for generating and storing petabytes of data, iterating quickly on novel analyses, and rapidly prototyping new deep learning models.
Build, scale, and operate a data platform . You'll be on a team responsible for building, operating, and tuning a data platform that allows users to discover and query across the breadth of our data at Recursion, which includes a chemistry library of 3 billion compounds, nearly 8 PB of cellular microscopy images taken in 10s of millions of different experimental contexts involving 1 million different reagents, sparse bioassay data across approximately 50 drug discovery programs, and more.
Build relatability into a heterogeneous dataset. At Recursion, we generate datasets based on a wide swath of diverse biological models and treatment approaches. You'll work with Data Scientists to build relatability and queryability into these datasets so they can be used in five years to answer the sorts of questions we haven't even thought of asking yet.
Act as a mentor, coach, and sponsor. You will share your technical knowledge and experiences, delivering impact, learning, and growth across teams at Recursion.

The Team You'll Join

You will lead a new team as they plan and implement a data platform that solves the problem of making our diverse data discoverable, queryable, and relatable across datasets while we continue to add new data modalities as we grow. This will require collaboration with many different groups including teams building out reports, dashboards, and applications, teams finding and generating the required data for the machine learning problems, and teams building and iterating on new data processing pipelines.
As an early leader in the new Toronto office you will have an important impact by shaping how new technical teams embrace the Recursion Values as they deliver challenging data platform problems while effectively collaborating across physical locations, business domains, and technical functions.

The Experience You'll Need

Experience working on data platforms that enable the discovery, query, and processing of large datasets.

Be up to date on industry trends and tools. You understand the tradeoffs between different data platform architectures and technologies like a data lake, a data warehouse, a data lakehouse, or a data mesh, and can draw on this knowledge to lead the design of the data infrastructure for Recursion.

Experience working collaboratively on projects with significant ambiguity and technical complexity, ideally spanning multiple systems and involving diverse technologies.

A people-first mindset. Despite the deadlines, we always prioritize supporting our coworkers in their growth and experience.

A drive to deliver technical solutions that are easily monitored and understood as they run in production and the effects of change can be readily quantified.

Excitement to learn parts of our tech stack that you might not already know. Our current tech stack includes Python, Clojure, Kafka, Docker, Kubernetes, PostgreSQL, JavaScript, ClojureScript, and Go. Our cloud services are provided by Google Cloud Platform.

Biology or chemistry background is not necessary, but intellectual curiosity is a must!

The Benefits/Perks You'll Enjoy

100% Coverage of health, vision, and dental insurance premiums
401(k) with generous matching (immediate vesting)
Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs**
Two one-week paid company closures (summer and winter)
Flexible vacation/sick leave
Generous paid parental leave (including adoptive)
Onsite daycare facility **
Commuter benefit and vehicle parking to ease your commute**
Complimentary chef-prepared lunches and well-stocked snack bars**
Monthly fitness/wellness stipend
One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking**


Subject to change for remote-based employees during the COVID-19 pandemic
**United States based employees

More About Us

Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science, and engineering, with the goal of radically improving the lives of patients and industrializing drug discovery. Central to our mission is the Recursion Operating System, or Recursion OS, that combines an advanced infrastructure layer to generate what we believe is one of the world's largest and fastest-growing proprietary biological and chemical datasets and the Recursion Map, a suite of custom software, algorithms, and machine learning tools that we use to explore foundational biology unconstrained by human bias and navigate to new biological insights which may accelerate our programs. We are a biotechnology company scaling more like a technology company. Recursion is proudly headquartered in Salt Lake City.

Learn more at www.recursion.com , or connect on Twitter and LinkedIn .

Recursion is an Equal Opportunity Employer that values diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected under applicable federal, state, local, or provincial human rights legislation.",Recursion,Midtown Toronto
666,Data Engineer (contract),"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:

Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done

Here's what you'll be doing:

Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery

Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI

Why Join Us?

You can see the code getting to production faster than you used to; you will try your Big Data skills, where precise and robust code really matters; you will work with the 3.5 Billion-record tables; you will learn how difference between European and Australian privacy laws can affect your design decisions.

Bond Brand Loyalty is proud to be recognized as one of Canada’s Best Managed Companies.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

Bond Brand Loyalty welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Bond Brand Loyalty Inc
3.5",Mississauga
667,Cloud Data Engineer,"Who is DigitalOnUs?

At DigitalOnUs, we not only provide Agile and DevOps methodologies to our customers, but we have also adopted the same within the company as well. Our nimble processes are not mired in red tape, yet robust, flexible and results oriented. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators, and challengers. Each day, we strive to make great come alive. Our lemma: ""work smart and play hard""

Our technology partners are Hashicorp, Cloudbees, Chef, Pagerduty, Docker and SAP .

We are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family !

We are looking for a data engineer responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow.

Will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Location: Canada

Qualifications we are looking for:
Azure data engineers collaborate with business stakeholders to identify and meet data requirements. They design and implement solutions. They also manage, monitor, and ensure the security and privacy of data to satisfy business needs. The role of a data engineer is different from the role of a database administrator.

+5 years of experience in data Engineering

Familiarity with eClinical Works (ECW) data, HL7 or FHIR

Experience with machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, hidden Markov models and graph algorithms.

Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.

Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch, Databricks etc.)

Experience with real-time data processing and API platforms.

Experience in using Python, Java and/or other data engineering languages.

Experience with data visualization and presentation, turning complex analysis into insight.

Healthcare domain and data experience

IDEAL BACKGROUND: Healthcare data background, especially provider data (versus payer data), including clinical data. Experience with FHIR is highly desirable. Experience and deep background in various methods of ETL is required. Programming and full-stack development experience would be a great addition.

Key Activities- Maintain, improve, clean, and manipulate data in the business operational and analytics databases Design and deploy data platforms across multiple domains ensuring operability Transform data for meaningful analyses Improve data efficiency, reliability and quality Create data enrichment Build high performance Ensure data integrity Create and manage data stores at scale Ensure data governance - security, quality, access and compliance

Why you will love this job?

We look for people who are thoughtful, can break down problems, work individually sometimes, and in pairs or teams at other times.

You are trusted to work on your own but ask for help when you are blocked

We will work with you to find the balance of what you want to do, what you are good at, and how that fits in with the company goals.

What you can expect from us

At DigitalOnUs, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness lead to quality, innovation, commitment to deliverables, efficiency, and cost-effectiveness for all our customers.

Empathy for your coworkers and our customers is an important part of success here. As an early-stage startup, most people wear many hats.

We are growing at a phenomenal pace! We have lots of opportunities to grow and learn

Hear your voice, nurture your talent, and help you strengthen your footprint!

Health, Life, Dental, and Vision Insurance

Flexible Work Hours

Work-from-Home Options

Company-wide retreats

If you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the ""Company""). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and / or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https://www.digitalonus.com/privacy-policy/","Digital On Us
4.5",Midtown Toronto
668,Cloud Data Engineer,"Who is DigitalOnUs?

At DigitalOnUs, we not only provide Agile and DevOps methodologies to our customers, but we have also adopted the same within the company as well. Our nimble processes are not mired in red tape, yet robust, flexible and results oriented. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators, and challengers. Each day, we strive to make great come alive. Our lemma: ""work smart and play hard""

Our technology partners are Hashicorp, Cloudbees, Chef, Pagerduty, Docker and SAP .

We are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family !

We are looking for a data engineer responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow.

Will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Location: Canada

Qualifications we are looking for:
Azure data engineers collaborate with business stakeholders to identify and meet data requirements. They design and implement solutions. They also manage, monitor, and ensure the security and privacy of data to satisfy business needs. The role of a data engineer is different from the role of a database administrator.

+5 years of experience in data Engineering

Familiarity with eClinical Works (ECW) data, HL7 or FHIR

Experience with machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, hidden Markov models and graph algorithms.

Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.

Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch, Databricks etc.)

Experience with real-time data processing and API platforms.

Experience in using Python, Java and/or other data engineering languages.

Experience with data visualization and presentation, turning complex analysis into insight.

Healthcare domain and data experience

IDEAL BACKGROUND: Healthcare data background, especially provider data (versus payer data), including clinical data. Experience with FHIR is highly desirable. Experience and deep background in various methods of ETL is required. Programming and full-stack development experience would be a great addition.

Key Activities- Maintain, improve, clean, and manipulate data in the business operational and analytics databases Design and deploy data platforms across multiple domains ensuring operability Transform data for meaningful analyses Improve data efficiency, reliability and quality Create data enrichment Build high performance Ensure data integrity Create and manage data stores at scale Ensure data governance - security, quality, access and compliance

Why you will love this job?

We look for people who are thoughtful, can break down problems, work individually sometimes, and in pairs or teams at other times.

You are trusted to work on your own but ask for help when you are blocked

We will work with you to find the balance of what you want to do, what you are good at, and how that fits in with the company goals.

What you can expect from us

At DigitalOnUs, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness lead to quality, innovation, commitment to deliverables, efficiency, and cost-effectiveness for all our customers.

Empathy for your coworkers and our customers is an important part of success here. As an early-stage startup, most people wear many hats.

We are growing at a phenomenal pace! We have lots of opportunities to grow and learn

Hear your voice, nurture your talent, and help you strengthen your footprint!

Health, Life, Dental, and Vision Insurance

Flexible Work Hours

Work-from-Home Options

Company-wide retreats

If you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the ""Company""). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and / or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https://www.digitalonus.com/privacy-policy/","Digital On Us
4.5",Midtown Toronto
669,Data Science Instructor,"About the role::
Journey is looking for an experienced, energetic, data scientist with an interest in teaching. As a data science instructor you will be responsible for leading lectures on various topics, assigning course work, grading, and mentoring students on a 1-1 basis. You will work closely with other instructors and members of our education team, and follow along with our pre-built curriculum and teacher guide. You will work as an instructor for our Concordia Bootcamps program (a partnership between us and Concordia University) and have a direct impact on changing peoples lives through education.

This is a full-time contractual position which will last 14-weeks. Hours will be from 9:30am to 5:30pm (EST) Monday through Friday. This course will be taught remotely.

You can review the program and upcoming course dates here: https://concordiabootcamps.ca/courses/data-science-remote/ (https://concordiabootcamps.ca/courses/data-science-remote/)

Responsibilities::

Teach a class of beginners (in collaboration with 1-2 other instructors) with the goal of ensuring they graduate ready for junior level roles in Data Science
Act as coach/mentor to students as they work their way through the course
Care profoundly about every student's success
Present lectures on Math, Stats, Python, Pandas, SQL, Data Visualization, and more
Work with the Director of Education to learn and adjust to the pre-established curriculum and course content
Follow each student independently and ensure that they develop a mastery of the subject matter
Qualifications::

You have experience teaching (as a TA), coaching, managing or supporting junior staff or managing projects
You have a minimum of 2 years of professional experience in the field of Data Science
You are an outstanding presenter. You're easy to follow when you explain difficult concepts because of your ability to dissect and disseminate them into bite-sized, understandable ideas
You're energetic and have a strong ability to motivate others
Who you are::

You love the idea of helping people lead better lives through education
You're a lifelong learner, constantly learning new things in your field
You love to share your learnings and experiences with others
You don't let a bad minute ruin a good day
You're an active listener
You're empathetic
Salary and benefits::

This is a 14-week contractual position (40 hours per week)
Salary range from $10,000-$15,000 CAD for the duration of the contract - dependant on experience
Fully remote work
Work with an amazing and fun team
Possibility to extend your contract and teach more courses
About Journey Education:
Journey provides digital skills training with courses, workshops, and events all offered online. Our product lineup currently includes courses in Web Development and Data Science, with new products on the way. Founded in 2014 and headquartered in Montreal, Canada, Journey works with highly experienced instructors to develop cutting-edge, real-world training and meaningful educational products that help people unlock their potential.

At Journey, we are building an environment where our employees feel included and heard. Diversity and inclusion are important to us and we strongly encourage applications from minorities, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities.",Journey Education,Canada
670,Data Analyst (Research),"ABOUT HRI

Homewood Research Institute (HRI) invites applicants for the position of Data Analyst (Permanent, Full-time).

HRI is an ambitious and growing national charity dedicated to research that transforms mental health and addiction services in Canada and around the world. Through strategic partnerships with Homewood Health and a vital growing network including some of the world’s most influential scientists, clinicians and researchers, we are uniquely positioned to innovate, test new discoveries, and accelerate the process that brings research into solutions for the real world. For more information, visit hriresearch.com.

POSITION OVERVIEW

The HRI Data Analyst works closely with Research Associates, Research Scientists, and Investigators to ensure accurate collection, organization, documentation, analysis and sharing of data. The Data Analyst is responsible for the statistical analysis required for knowledge translation and exchange activities and for peer-reviewed publications. The Data Analyst is an integral member of the research and evaluation team.

KEY RESPONSIBILITIES

1. Data Analysis and Planning

Plans and conducts relevant analyses for internal/external collaborators involving a range of statistical methods, including multivariate analyses, structural equation modeling with cross-sectional and longitudinal data using data from a rolling cohort
Applies methods of handling missing data, such as multiple imputations
Uses external data from a variety of sources (e.g. Statistics Canada, Resident Assessment Instrument-Mental Health), in combination with internal project data
Prioritizes and responds to ad hoc and routine data inquiries

2. Development and Maintenance of Datasets

Leads the development and maintenance of datasets including the creation of standard operating procedures for creating, organizing, storing, documenting, extracting/exporting, converting, merging and manipulating large and small data files
Ensures that data are accurate, consistent, properly maintained, and shared in compliance with relevant privacy protection, confidentiality, and other ethical principles
Uses SAS or R to process and prepare datasets for HRI investigators including merging multiple data sets (different sources), deriving project-specific variables in consultation with HRI investigators, and applying appropriate de-identification techniques tailored to each unique data request
Writes documentation reports to accompany the release of datasets, including relevant procedural notes and data codebooks

3. Knowledge Translation and Communication

Contributes to the writing of peer-reviewed scientific publications and technical reports
Provides data outputs and creates reports for stakeholders including visually intuitive graphs and depictions on complex study results
Presents findings at scientific meetings when appropriate
Communicates clearly with research team members, external stakeholders, and funders

4. Consultation and Training

Provides data analysis and data management consultation/ support to researchers, graduate students, post-doctoral fellows and to affiliated scientists as needed

POSITION REQUIREMENTS

Education

Master’s degree in quantitative research (i.e., biostatistics, health sciences, psychology)

Skills and Experience

Demonstrated ability to interact effectively and build rapport with a wide range of individuals
Strong organizational skills and initiative; work well independently
Proficiency in statistical analysis software such as SAS, R, Mplus, STATA, and/or SPSS; Advanced proficiency in Microsoft Excel
Ability to perform data management and formatting for standard statistical software
Strong verbal and written communication skills with statisticians and non-statisticians including technical report writing and writing for peer-reviewed scientific publications
Ability to work on multiple analytical projects concurrently with attention to detail
Initiative to acquire new skills and remain current with new developments as required
Commitment to HRI values of Anti-Oppression Equity and Inclusion and supports related organizational goals and research activities
Knowledge of mental health and addictions research would be an asset
English/French bilingual capacity would be considered an asset

Anti-Oppression, Diversity and Inclusion Focus

At HRI, we strive to foster Anti-Oppression, Equity, and Inclusion (AOEI), because we believe living these values is the most powerful platform for social change. We believe that people and organizations thrive when we embrace the richness of the human experience and invite all voices to contribute to a shared goal.

We are passionate about our vision: “No life held back or cut short by mental illness or addiction.” This vision encompasses everyone, including (but not limited to) First Nations, Métis, and Inuit, people with disabilities, people of all cultural, religious, racial, and ethnic backgrounds, people of all income and education levels, people of all ages, non-binary and gender-nonconforming people, women, and two-spirit, lesbian, gay, bisexual, trans, queer, questioning, intersex, and asexual (2SLGBTQQIA) people.

As a research organization, we are working continuously to move AOEI values into action through our organizational culture, policies, and research activities.

JOB LOCATION

This position offers remote work arrangements due to the ongoing pandemic, however regular in-person meetings and events will be required when work returns to normal.

HOW TO APPLY

Please submit a resume and cover letter and inform us if you require accommodations during the interview process. We thank all applicants for their interest, however, only those selected to interview will be contacted.

Reference ID: HRI - 2021-03

Application deadline: 2021-06-25

Job Types: Full-time, Permanent

Pay: $29.88-$38.15 per hour

Benefits:

Dental care
Disability insurance
Employee assistance program
Extended health care
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Education:

Master's Degree (preferred)

Work remotely:

Temporarily due to COVID-19",Homewood Research Institute,Guelph
671,Employment Equity INVENTORY - Aquatic Biologist/Physical Scientist & Team Leader Opportunities @ DFO,"Fisheries and Oceans Canada - Aquatic Ecosystems
Dartmouth (Nova Scotia)
BI-03, BI-04, PC-03, PC-04
BI-03 Salary Range - $81,359 to $104,748 BI-04 Salary Range - $100,920 to $119,915 PC-03 Salary Range $88,533 to $105,353 PC-04 Salary Range $102,577 to $120,520

For further information on the organization, please visit Fisheries and Oceans Canada

Read about Fisheries and Oceans Canada’s mandate and role, departmental priorities and commitments, and the key legislation that supports our work.
Learn more about the Aquatic Ecosystems Branch
Understanding the job advertisement
Video: How to navigate the application process

Closing date: 13 October 2021 - 23:59, Pacific Time

Who can apply: **RESTRICTED TO EMPLOYMENT EQUITY MEMBERS AS FOLLOWS ** Open to Canadian citizens who are members of the following Employment Equity groups: Aboriginal persons, Visible Minorities, and Persons with Disabilities.



Apply online

Important messages

************************************************************************************
WHAT YOU NEED TO KNOW ABOUT APPLYING TO THIS INVENTORY
************************************************************************************ This inventory is open to individuals who self-declare as a visible minority, a person with a disability, or an Aboriginal person. Therefore, only those applicants who indicate in their application that they are members of the requisite Employment Equity (EE) group(s) will be considered.

In order to self-declare, please ensure to indicate this by checking off the appropriate box within the online application as part of the Employment Equity section.

The term “Aboriginal” is used within this job advertisement as it relates to the Employment Equity Act and other legislative frameworks. The term “Indigenous” is used, where feasible, in support of the United Nations Declaration on the Rights of Indigenous Peoples.

********************************************************

When you apply to this selection process, you are not applying for a specific job, but to an inventory for future vacancies. As positions become available, applicants who meet the qualifications may be contacted for further assessment.

===================================
HOW TO APPLY:
===================================
We are requesting that all job applications be submitted through the GC JOBS SYSTEM BY CLICKING ON THE “APPLY ONLINE” LINK BELOW. The benefit of applying online is that candidates are guided through a series of questions which helps them submit a complete application and therefore contains all of the information that hiring managers are looking for.

Work environment
Now is your chance to gain experience in the federal public service. Here are some reasons to apply:

Did you know that Fisheries and Oceans Canada and the Canadian Coast Guard have been recognized as top employers? We’ve been recognized as Forbes Canada’s Best Employers (2018) and, one of Canada’s Top Employers for Young People in 2017, 2018, 2019, and 2020!

The workplace, the Bedford Institute of Oceanography (BIO) Campus in Dartmouth, offers free parking and bus accessibility (Metro Transit’s route #51). BIO is next to Shannon Park's Canada 150 Trail and offers many workplace wellness initiatives. Check out www.bio.gc.ca to learn more about our Campus.

Additionally, we offer:

learning and training opportunities to support you in your current and future career
competitive salaries and benefits, such as supplemental health insurance, dental care, and vacation allowances
flexible work arrangements, volunteer days, and family-related leave
access to an Employee Assistance Program to support you through all stages of your career
an opportunity to serve Canadians by helping to protect our aquatic resources

Come join DFO / CCG for the opportunity to be a part of something bigger!

=================================================================
Have we sparked your interest? APPLY TODAY!
=================================================================
Intent of the process

Please Note: This process has been designed to have two (2) different job streams in one advertisement. There are merit criteria specific to each stream; please review them carefully.

Stream 1 – Aquatic Biologist/Physical Scientist (BI-03 and PC-03) Salary Range - $81,359 to $105,353
Stream 2 – Section Head /Team Leader (BI-04 and PC-04) Salary Range - $100,920 to $120,520

Candidates will not be required to indicate in their application the stream(s) for which they wish to be considered. Candidates who meet the essential qualifications will automatically be considered for the streams in which they are found qualified. Please note, the above two streams may be utilized for other positions with the same requirements. If no stream information is listed after a merit criterion, it will apply to both streams on this poster.

Two pools will be created as a result of this process; the results achieved in the process will determine if the candidate is placed in the BI-03/PC-03 pool only or both the BI-03/PC-03 and BI-04/PC-04 pools. Candidates may be offered positions of various tenures (permanent and temporary appointments), and will be required to meet conditions of employment depending on the position being staffed. As a result of the potential and possible use of this selection process, and subsequent pools which may be accessed by a variety of hiring managers across the region, we encourage all interested persons seeking these types of opportunities to apply.


Positions to be filled: 1

Information you must provide

Your résumé.

A response to a text question addressing the following:

Employment with the Federal Government
Interest in temporary opportunities
In order to be considered, your application must clearly explain how you meet the following (essential qualifications)

EDUCATION

For BI-03/BI-04 positions:
Graduation with a degree from a recognized post-secondary institution in a natural, physical or applied science with specialization in a field relevant to the duties of the position.

For PC-03/PC-04 positions:
Graduation with a degree from a recognized post-secondary institution, with acceptable specialization in physics, geology, chemistry or some other science relevant to the position.

Degree equivalency

Required EXPERIENCE for all positions (BI-03/PC-03 & BI-04/PC-04)

1. Experience working on projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species.
2. Experience providing information and advice to management on topics or issues related to the management or conservation of natural resources.
3. Experience assessing, synthesizing or analyzing information from a variety of sources on issues related to the management or conservation of natural resources.

………………………………………………………………………………………….

Additional Required EXPERIENCE for BI-04/PC-04 positions

1. Experience collaborating with internal teams or external stakeholders, partners or clients* .


stakeholders, partners or clients may include (but not limited to): federal, provincial and municipal departments and agencies, Indigenous partners, private sector organizations, NGOs, etc..

2. Experience leading complex** projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species.

**Complex is defined as two or more of the following characteristics: high profile (i.e. attracting public or media attention); involving multiple stakeholders; multi-jurisdictional/multi-disciplinary in nature; involving third-party interests; requiring multiple consultations; or having a significant impact

3. Significant*** experience providing information and advice to senior management**** on topics or issues related to the management or conservation of natural resources.

***Significant experience is understood to mean the depth and breadth of the experience normally associated with having performed a broad range of complex related activities.

**** Senior Management means the Director level and above.

4. Experience in assigning and supervising the work of others.
If you possess any of the following, your application must also clearly explain how you meet it (other qualifications)

EDUCATION:
Post-graduate degree from a recognized university in a natural, physical or applied science with a specialization in a field relevant to the position.

Degree equivalency

The following qualifications are specific to the work in one or more of our Directorates/Programs. **Note: While these qualifications are not under the heading of essential qualifications, depending on the position being staffed, any of the following “Asset” or “other” qualifications may be deemed as essential qualifications and only those candidates and persons with a priority or preference entitlement who possess those qualifications will be considered for that specific vacancy.**

ASSET/ESSENTIAL QUALIFICATIONS: BI-03/PC-03 (but may also be invoked for certain BI-04/PC-04 positions):

Experience supervising staff.
Experience planning and participating in public consultation process.
Experience in the process for listing or recovery of species under the Species at Risk Act.
Experience implementing laws, regulations, policies or programs with respect to the Fisheries Act, Oceans Act, or Species at Risk Act (or other federal environmental regulations).
Experience establishing relationships, consulting, engaging, or negotiating with at least two (2) of the following: Indigenous community, academic institution, government departments/organizations, public, industry or non-governmental organization.
Experience in managing , regulating or assessing marine aquaculture.
Experience in the establishment, planning, or monitoring of protected areas.
Experience working with Geographic Information Systems (GIS) or other spatial data programs.
ASSET QUALIFICATIONS: BI-04/PC-04 (but may also be invoked for certain BI-03/PC-03 positions):

Significant experience in human resources management (as a sub-delegated manager).
Experience in evaluating the effects of human activity on the aquatic environment.
Experience in coordinating work teams including several representatives from various organizations.
Experience in collaborating with partner or stakeholder groups to carry out marine planning or conservation initiatives.
Experience managing financial resources (ie a budget).
The following will be applied / assessed at a later date (essential for the job)

Various language requirements

Information on language requirements

KEY LEADERSHIP COMPETENCIES:

For more information about these competencies, please visit the following link:

www.canada.ca/en/treasury-board-secretariat/services/professional-development/key-leadership-competency-profile/examples-effective-ineffective-behaviours.html


Create Vision and Strategy
Mobilize People
Uphold Integrity and Respect
Collaborate with Partners and Stakeholders
Promote Innovation and Guide Change
Achieve Results
ABILITIES:

Ability to communicate orally.
Ability to communicate in writing.
Other information

The Public Service of Canada is committed to building a skilled and diverse workforce that reflects the Canadians we serve. We promote employment equity and encourage you to indicate if you belong to one of the designated groups when you apply.

Information on employment equity

****************************************************
APPLICATION/ASSESSMENT PROCESS
****************************************************


Step 1: Application

When applying to this selection process, you will be asked if you have any of the experience listed above and must answer a screening questions demonstrating how you meet the qualifications . For some of the qualifications only a “Yes” or “No” response is required at this time.
Step 2: Job Matching

As positions become available, the hiring manager will establish the experience requirements a candidate would require for the particular role being staffed.

Upon identifying the requirements of the position, Human Resources will review your responses to the experience questions. Should you indicate you have the experience factors the hiring manager is looking for, Human Resources will contact you to:

1. Confirm you are available and interested in the position
2. Ask you to elaborate on how you meet the experience required (for the “Yes” or “No” questions in the application) .

This communication will be sent to you using the GC Jobs communication platform and/or as well to your e-mail. Please ensure that you check your e-mail and GC Jobs account frequently as there is often a deadline for your response. Please note that we will have to consider that you are no longer interested in participating in the selection process and that you have withdrawn your candidacy should you not provide us with an up-to-date email address or respond to our communication.

Step 3: Online Interview

You will be asked to complete a video interview using an online platform which will be recorded and made available to the hiring manager. The online interview is designed to assess your verbal communication skills and assess you against the Key Leadership Competencies.

Please note: You may be asked to complete an online interview before you’ve been matched to a position.
Step 4: Additional Assessment

Depending on the position being staffed, the hiring manager may establish additional criteria that are essential qualifications which candidates must meet. These criteria may include additional abilities and/or knowledge factors for their vacancy. Therefore, in addition to reference checks, a knowledge test or additional interview may be required.
Step 5: Appointment

If the hiring manager has determined that you meet the requirements for the position, you will receive an official notification from Human Resources. Should you be selected for the position, the hiring manager will contact you directly. You will be required to meet any conditions of employment for the position, such as a valid security clearance which will be reflected in your employment letter of offer.

************************************
ASSESSMENT
************************************
Please note that your overall conduct and communications, including email correspondence, throughout the entire process may be used in the assessment of qualifications and competencies.

You will be asked to provide proof (original documentation will be required) of your education credentials. If you were educated outside of Canada, you must have your certificates and/or diplomas assessed against Canadian education standards. For more information please click on “Degree Equivalency” in the Education section above.

****************************************
OFFICIAL LANGUAGES
****************************************
Persons are entitled to participate in the selection process in the official language of their choice. Applicants are asked to indicate their preferred official language in their application.
Preference

Preference will be given to veterans and to Canadian citizens, in that order, with the exception of a job located in Nunavut, where Nunavut Inuit will be appointed first.

Information on the preference to veterans

We thank all those who apply. Only those selected for further consideration will be contacted.","Fisheries and Oceans Canada
4.0",Dartmouth
672,Big Data Engineer,"Cubert is the name and innovation is our game. As the creators behind FitTrack (https://getfittrack.com/) we know what it takes to develop new consumer hardware products and mobile applications for e-commerce/retail to a loyal customer base across the world.


But we take no credit. Cubert’s success comes down to one factor: Good people. Every person matters, so investing in hiring, developing and retaining sharp minds is our top priority.


We keep our team close knit, sharp and agile, which gives us the flexibility to constantly adapt to every situation. Why? A smaller team means high impact, strong communication and adaptability as a unit.

We are tied together by our values:


We strive to be the best in what we do
We obsess over customer experience
We challenge convention
Our foundation is built on trust
We take ownership in everything we do
We value learning and personal mastery

So if you’re tired of getting caught in red tape, or having the glass ceiling stop you from making magic, you’ve come to the right place.

Welcome to Cubert.







Role Responsibilities:



Use Big Data technologies to design and develop scalable and fault-tolerant big data ETL systems and Data Lakes in a non-Hadoop environment.
Providing leadership within enterprise data strategies and providing the framework of foundation Big Data Analytics.
Engaging stakeholders to understand their objectives for Big Data and utilizing information gathered to plan the computing framework with data sources, analytical tools and data storage.
Evaluating and recommending new and emerging data management and storage technologies and standards.
Ensuring consistency between data management, enterprise storage and all other technical system components.
Create and maintain a corporate repository of all data architecture artifacts.
Adhere to Agile principles and philosophies (Scrum or Kanban, as applicable) in fulfillment of the role.
Work as a cross-functional team member in an Agile setting to help complete and deliver the team commitments.



What you bring to the table:



Bachelor’s degree in Information Technology, Software Engineering, Computer Science, or related field.
1+ year of data architecture experience in Big Data with advanced understanding of Data architecture concepts, patterns and standards.
Experience in designing and implementing Big Data Lakes and ETL ingestion facilities.
Strong understanding of relational data structures, theories, principles, and practices.
Experience with enterprise data management technologies, including database platforms, ETL tools, and SQL.
Experience with data modelling tools.
Experience on GCP data technologies, dataflow, bigquery, pubsub, google cloud storage, dataproc, cloud function.



How we help you become successful




Flat hierarchy and co-operative international working environment
Learning support per company policy (approved courses etc.)
Health Benefits with Health Spending Accounts
Competitive compensation
Dog Friendly Office
Stocked Kitchen with healthy (and some unhealthy!) snacks




Cubert Inc. is an equal opportunity employer and encourages applications from qualified individuals. We thank all applicants for their interest: However, only those selected for an interview will be contacted. If chosen to participate in the selection process, accommodations are available upon request. We will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicant’s accessibility needs.","Cubert Inc.
4.2",Toronto
673,Cloud Solution Architect - Data,"Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us to achieve our mission.
Microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of Microsoft Cloud solutions and support offerings. To this end, Microsoft invests in a dedicated Customer Success team that will help Microsoft customers successfully realize their business outcomes.

Azure is the most comprehensive, innovative and flexible cloud platform today and Microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market.

We are always learning. Insatiably curious. We lean into uncertainty, take risks, and learn quickly from our mistakes. We build on each other’s ideas because we are better together. We stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. Together we make a difference.

To learn more about Microsoft’s mission, please visit: https://careers.microsoft.com/mission-culture

Check out all of our products at: http://www.microsoft.com/en-us

We are looking for a highly motivated and passionate Data Platform & Advanced Analytics/Artificial Intelligence Cloud Solution Architect to drive high priority customer initiatives on the Microsoft Azure Platform in collaboration with customers and the Microsoft field in Enterprise accounts segment of our business. This is a customer facing role, owning overall technical relationship between customer and Microsoft Data, Advanced Analytics and Artificial Intelligence Platform.

You will own the Data Platform & Advanced Analytics technical customer engagements including architectural design sessions, specific implementation projects and/or MVPs. The ideal candidate will have experience in customer-facing roles and success leading deep technical architecture discussions with senior customer executives, Enterprise Architects, IT Management and Developers to drive Data Platform and Advanced Analytics solutions to productions.
Responsibilities
Key responsibilities include
Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.
Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.)
Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment
Develop deep relationships with key customer IT decision makers and relevant business decision makers (like AI or Analytics), who drive long-term cloud adoption within their company to enable them to be cloud advocates
Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.
Collaborate with other Cloud Solution Architects and MS stakeholders in developing complex end-to-end Enterprise solutions on Microsoft Cloud platforms.
Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform
Be an Azure Platform evangelist with customers, partners and external communities.
Qualifications
Knowledge and Skills: Professional Experience
5+ years of success in consultative/complex technical sales and deployment Data Platform and Analytics projects, architecture, design, implementation, and/or support of highly distributed applications required
Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. Required
Good business acumen to quickly understand the customer’s industry and business to have relevant discussions with business decision makers.
Problem Solving. Ability to solve customer problems through cloud technologies Required
Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) Required
Technical
Enterprise-scale technical experience with cloud and hybrid Data and Analytics architecture designs, database migrations, and technology management. required
The technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in Data Platforms and Analytics
Competitive Landscape: Knowledge of cloud development platforms
Partners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred
Breadth of technical experience and knowledge, with depth / Subject Matter Expertise in two or more of the following Data Analytics and AI Platform Cloud solutions required
SQL including OSS (postgres, MySQL etc), Azure SQL
NoSQL Databases including OSS (Maria, Mongo etc), Cosmos DB
Big Data including SQL DW, Snowflake, Big Query, Redshift
Advanced Analytics including Azure Data Bricks, visualization tools as PowerBI, Tableau
Data Governance
Data Engineering
Data Science
Machine Learning including Azure ML, ML Server
Artificial Intelligence including BOT framework, Cognitive Services, Cognitive Search
Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python
Education
Bachelor's degree in Computer Science, Information Technology, Engineer, or related field preferred
Certification in one or more of the following technologies preferred: Cloud, mobile, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence
Experience
Prior work experience in a Consulting/Architecture position within a software and/or services company such as Amazon, VMware, Google, IBM, Oracle desired
Prior solution delivery experience in Analytic and AI specialized solution providers

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
674,Data Engineer - AWS Product BI,"Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.
Strong grasp of SQL and at least one scripting or programming language.
5+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures and hands-on SQL coding.
3+ years of large IT project delivery for BI oriented projects.
3+ years of working with very large data warehousing environment
Amazon is looking for an excellent Data Engineer to join the AWS Product BI team. This is your opportunity to be a core part of the team that has direct impact on the day-to-day decision making in the many AWS Product teams like EC2, S3 and IoT.
Since early 2006, AWS has provided companies of all sizes with an infrastructure platform in the cloud. AWS is a high-growth, fast-moving division within Amazon with a start-up mentality where new and diverse challenges arise every day. On the AWS Product BI team you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class BI is critical to our success. To help build this growing team, you should be highly analytical and possess a strong passion for analytics and accountability, set high standards with a focus on superior business success. We take working hard, having fun, and making history seriously. AWS sets the standard for functionality, cost, and performance for many cloud based services, but it’s still early days for cloud computing, and there are boundless opportunities to continue to redefine the world of cloud computing - come help us make history!

As a Data engineer on this team, you will be a technical leader in our team, and own the technical architecture of our BI and Data platforms. You will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business and technical teams in analysis on many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
Our team is serious about great design and redefining best practices with a cloud-based approach to scalability and automation. A successful candidate will be a self-starter, comfortable with ambiguity, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment, and an ability to work effectively with cross-functional teams.

Key responsibilities include

Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions.
Building secure, available, scalable, stable, and cost-effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices.
Working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs.
Designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.
Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements
Reviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and hardware selections
About Us

Inclusive Team Culture
Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.

Work/Life Balance
Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.

Mentorship & Career Growth
Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. Our senior members enjoy one-on-one mentoring and thorough, but kind, code reviews. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded engineer and enable them to take on more complex tasks in the future.


Experience in designing and delivering cross functional custom reporting solutions.
Experience with Massively Parallel Processing (MPP) databases - Redshift, Teradata etc
Experience with distributed systems and NoSQL databases - Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and more!
Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.
Proven ability to meet tight deadlines, multi-task, and prioritize workload - A work ethic based on a strong desire to exceed expectations.
Strong analytical skills
Amazon is committed to providing accommodations at all stages through recruitment and employment in accordance with applicable human rights and accommodation legislation. If contacted for an employment opportunity, please advise Human Resources if you require accommodation, including in order to apply for a position.","Amazon Dev Centre Canada ULC
3.8",Vancouver
675,Ingénieur de données / Data Engineer,"Nous sommes à la recherche d’un(e) Ingénieur de données / Data Engineer pour rejoindre notre équipe de conseillers en analytique avancé et travailler sur des projets innovants avec nos clients. Nos conseillers travaillent pour les plus grandes entreprises québécoises sur des projets à moyen ou long terme et chez nous hors de question de travailler en silo: on partage nos projets, nos compétences et notre savoir-faire au quotidien.

agileDSS, c’est quoi/qui ?

agileDSS est une entreprise de service-conseil spécialisée en analytique avancé. Depuis 15 ans, nous accompagnons les grandes entreprises québécoises à tirer le meilleur parti de leurs données par le biais d’une expertise de pointe en analytique avancé (Big Data, Intelligence d’Affaires, Visualisation de Données et Data Science).

Ce poste est pour toi si tu as :

Un minimum de 5 années d’expérience pertinente en Big Data
Forte expérience de travail avec les systèmes de base de données dans le cloud comme Google Big Query, Snowflake, Redshift ou équivalent;
Une solide expérience de travail de conception et d’optimisation de pipelines de données sur de grands volumes de données structurées et semi-structurées;
Expérience en matière de développement d'entrepôts de données, de modélisation et/ou d'analyse de données;
Expérience pertinente avec les plateformes de sciences de données tel que Azure Databricks, Spark, Hortonworks, etc. ;
Maitrise du Java, SQL, Scala et Python
Bonne connaissance de la gestion des données, de l'intégration des données et des techniques de développement des bases de données;
Expérience des technologies de base de données (par exemple, SQL, NoSQL, Oracle, Hadoop, Snowflake, Teradata);
Fait preuve de rigueur et d’objectivité dans son travail d’analyse;
Flexibilité dans la gestion de son quotidien et de ses relations professionnelles;
Excellente capacité d’identification et de résolution de problèmes;
Bon communicateur, sachant travailler efficacement en équipe;
Bonnes aptitudes au développement de relations efficaces avec les fournisseurs et prestataires de services externes;

Atout :

Expérience avec les langages de programmation et de gestion de base de données traditionnels, y compris SQL, PL/SQL, avec les langages de manipulation de données propres aux sciences des données tels que Python et R.
Anglais ""fonctionnel"" demandé

Mais les hard skills c’est pas tout !
Avant toute chose on cherche un nouveau collègue qui va s’épanouir dans notre environnement! Si tu es une personne qui aime partager ses connaissances, qui prône le self-management, qui est bienveillant, fun et gourmande, tu as de grandes chances de te plaire chez nous !

À quoi tu peux t’attendre dans ton rôle ?

Participer, en collaboration avec les concepteurs, à l’élaboration et à la réalisation, des solutions de données corporatives;
Coordonner la collecte, la formalisation et la documentation des besoins de l’organisation en ce qui a trait aux solutions de données corporatives ou sectorielles;
Mettre en œuvre des règles d’affaires de traitement et de valorisation des données corporatives et sectorielles (entrepôts, comptoirs, données maitresses et de référence, etc.);
Participer à des activités de nettoyage, de transformation, de conversion et de correction des données;
Réaliser des tests durant la modification des applications, pour garantir l’intégrité opérationnelle des solutions de données;
Participer à la mise en production itérative des solutions, travailler avec des équipes des différentes unités d’affaires pour établir et exécuter les tâches nécessaires, selon un ordre bien établi;
Travailler en collaboration avec les autres professionnels TI et communiquer avec les différents partenaires afin de clarifier et bien comprendre leurs besoins;
Participer à la définition des fonctions, services ou éléments techniques requis;
Réaliser, documenter et valider les analyses demandées ;
Respecter les règles fonctionnelles et techniques ainsi que les normes de conception et de livraison de solutions;
Participer ou réaliser des essais à différents niveaux de détails, qu’ils soient fonctionnels ou techniques ;
En contexte de livraison et de mise en production, soutenir les partenaires lors des essais d’acceptation ;
Participer à l’implantation des solutions retenues;
Participer au plan d’évolution des applications et systèmes technologiques.

Ce qu’on t’offre

Nous sommes avant tout une équipe de collaborateurs à taille humaine qui a à cœur le bien-être de ses employés, c’est pourquoi nous t’offrons:

Une rémunération annuelle fixe et une bonification annuelle selon l’atteinte de ta performance
Des objectifs individuels accessibles et réalistes pour garantir un environnement sans pression
Des assurances collectives Manuvie (dentaire, vision, soins paramédicaux…)
4 semaines de vacances
Remboursement des abonnements de sport et du transport
Horaires flexibles et télétravail
Plan de développement pour chaque employé et coaching avec un mentor
Environnement non hiérarchique favorisant l’intrapreneuriat
Activités mensuelles de team building
Abonnement au spa

Note : Ce poste débutera en télétravail pour s'adapter au contexte de pandémie. Il faut donc prévoir un retour progressif physique en fonction du déconfinement.

Type d'emploi : Temps Plein, Permanent

Salaire : 90 000,00$ à 115 000,00$ par an

Horaire :

Du Lundi au Vendredi
Repos la Fin de Semaine

Expérience:

Scala: 3 ans (Souhaité)
Databricks: 1 an (Souhaité)
Consultation: 2 ans (Souhaité)
Big Data: 3 ans (Souhaité)
Spark: 3 ans (Souhaité)
Python: 3 ans (Souhaité)

Langue:

Français (Souhaité)
Anglais (Souhaité)","agileDSS
4.3",Montreal
676,Senior Data Engineer,"Senior Data Engineer
My client, the largest e-commerce investor, was founded by founders for founders. They invested $2B+ in over 4k business. Looking for a Data Engineer talent to join their smart team to build the data-driven app for early-stage founders.

Contact me for details about this exciting opp!!!

100% Remote if you want; but NO NO NO outside-the-country applicants, thank you.
Responsibilities:
You will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development
Working closely with every member of the team, vendors and external partners, you will produce significant components of the code
Collaborate with all functions, ranging from core Engineering team to Data Science team to the marketing team
You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary
You will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself.
You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs
Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

What we look for:
Great communication skills, with a desire or experience to lead a small team of other devs in the near future
Desire to help founders. We take a strong founder first stance on this team
Be self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission
On this team, we maximize learning. You will fail if you're not learning fast enough
Comfort working in a high growth, constantly changing environment
Heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support
Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!
Have a strong business sense, you can foresee potential issues and solve them quickly
Demonstrated ability to collaborate effectively across multiple teams
Strong interest in building businesses, ecommerce and fintech

Technical Requirements:
Ideally, you have worked on 3 or more different stacks in your career in a professional setting. Bonus points for systems managing time-series
Able to architect and scale data integrations (shopify, paypal, plaid, etc.) from third-party API docs independently, extracting the right business value for the vision and roadmap
Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes
Comfortable working in server and database environments that are changing constantly
Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff
Comfortable with relational databases and schemas involving time-series
Skills and interest in Python, SQL, Snowflake, Kubernetes and pipeline management/orchestration tools (Eg. Airflow)
TOR123","Vaco
3.7",Midtown Toronto
677,"Research Scientist - HEOR, Evidence Synthesis","Are you a self-starter with a passion for projects involving innovative health economic concepts? If you a natural ""doer"" who enjoys collaborating, moving the ball forward and rolling up your sleeves - keep reading!

Our culture is similar to that of a start-up, but in a well-funded established global portfolio organization. Our team has a real passion and excitement for HEOR, priding ourselves on being leaders with vision in our field.

We are growing and seeking those who are passionate about Health Economics and Outcome Research; researchers who love the prospect of collaborating with a diverse team of scientists and who look to make a real difference.

We hire throughout the year at varying levels of experience and offer these opportunities out of offices in US, Vancouver BC and London.

What you can expect day-to-day:
Research Scientists collaborate across a broad portfolio of sophisticated health economic and health policy research projects as a member of a project team; and they understand how to create the data foundation needed to provide the statistical analysis framework for projects. In collaboration with the project lead, conduct statistical analysis and modeling procedures, and contribute to interpretation of the results from statistical procedures and models in order to address client's research questions.

Essential responsibilities include:
Develops client-ready deliverables in terms of protocols (systematic literature reviews of cost-effectiveness modeling), statistical analysis plans (evidence synthesis), technical reports, and slides, identifying necessary deviations from templates to ensure content aligns with objectives

Develops content for components of proposals in collaboration with senior team members

Applies alternative (known/standard) methods in terms of systematic literature reviews, evidence synthesis, and/or cost-effectiveness modeling according to best practices and identifies relevant limitations to project lead

Accountable for timely delivery and financial performance of project subcomponents; estimates required hours and identifies challenges early on; and communicates any changes and possible solutions to project lead if necessary

Drafts and reviews update slides/minutes and actions for overall study and viewed by client as independent researcher for specific study component(s)

Communicates with client frequently on calls and supports project lead in responding to emails; may also be involved in face-to-face presentations to clients

Breaks down complex project tasks or project subcomponents into manageable components and approaches them in logical and clear manner

Highlights resourcing constraints for project subcomponents to project or team lead and identifies tasks where support is needed from junior team members

Identifies new opportunities within existing projects/clients

Participates in, and occasionally leads group strategy discussions

Guides junior teams members

Leads publication independently to implement own ideas in a wide range of other project-related and infrastructure activities such as: recruiting experts for meetings, advisory groups, or panels; contributing to or reviewing proposals; assisting with problem-solving; researching potential solutions; among others.

Qualifications:
Required

Master's degree

Minimum of 1-years' experience

Other required

Excellent oral and written communication skills

Ability to work effectively individually and as part of a diverse team

Proficiency with Microsoft Office

Desired

Master's degree with a concentration in economics, health services research, epidemiology, biostatistics, public policy, health policy, or public health or related; Ph.D.

Experience in conducting literature reviews.

Experience in conducting systematic reviews, scoping reviews, rapid reviews, or critical reviews

Experience conducting and interpreting statistical analyses

Experience writing scientific or review papers

Understanding of medical terminology and/or any disease-specific expertise

Experience with statistical programs such as R, Stata or SAS

Any data provided as a part of this application will be stored in accordance with our Privacy Policy .

Precision Medicine Group is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. © 2020 Precision Medicine Group, LLC

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Precision Medicine Group at QuestionForHR@precisionmedicinegrp.com .",Precision Medicine Group,Vancouver
678,Data Engineer (Full Time Permanent Remote Work Opportunity),"Your opportunity:

Lixar, fueled by BDO Canada, is looking for a dynamic and dedicated Data Engineer to join our remote Canadian team. As a Data Engineer, you will be part of a team supporting and participating in the ongoing development of leading edge applications.


The ideal candidate will be a senior developer who has a strong background in Big Data with a mix of general programming and some exposure to data visualization.


As an experienced Data Engineer, you have:


Post-secondary education in engineering or computer science or equivalent work experience
A proven track record using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle ""big data"" problems
A master of all things SQL (and NoSQL)
5+ years of programming experience in Python
Proven experience using RESTful Web Services & JSON
Good experience using Cloud based data solutions (AWS/Azure)
Experience working with production systems
Knowledge of ELT, ELT, Lambda and Kappa data architectures


Preferably, you also have:


Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git)
Experience with DataBricks
Some Data Visualization experience in Power BI, Tableau, or similar
Exposure to data science, machine learning or statistics
Some experience using Docker


How do we define success for your role?


You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration
You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work
You identify, recommend, and are focused on effective service delivery to your clients
You share in an inclusive and engaging work environment that develops, retains & attracts talent
You actively participate in the adoption of digital tools and strategies to drive an innovative workplace
You grow your expertise through learning and professional development.


Why BDO?


Our firm is committed to providing an environment where you can be successful in the following ways:

We enable you to engage with the firm's strategic plan, and be a key contributor to the success and growth of the firm.
We help you be the best professional you can be in our services, industries and markets.
Achieve your personal goals outside of the office and make an impact on your community.


Giving back, it adds up: Where company meets community. BDO is actively involved in our communities by supporting local charity initiatives. We support staff with local and national events where you will be given the opportunity to contribute to your community.

Total rewards that matter: We pay for performance with competitive total cash compensation that recognizes and rewards your contribution. We provide flexible benefits from day one, and a market leading personal time off policy. We are committed to supporting your overall wellness beyond working hours, and provide reimbursement for wellness initiatives that fit your lifestyle.

Everyone counts: We believe every employee should have the opportunity to participate and succeed. Through leadership by our Chief Inclusion and Diversity Officer, we are committed to a workplace culture of respect, inclusion, and diversity. We recognize and celebrate the valuable differences among each of us, including race, religious beliefs, physical or mental disabilities, age, place of origin, marital status, family status, gender or gender identity and sexual orientation. If you require accommodation to complete the application process, please contact us.

Ready to make your mark at BDO? Click “Apply now” to send your up-to-date resume to one of our Talent Acquisition Specialists.

To explore other opportunities at BDO, check out our careers page.


#LI-MM1","BDO
3.7",Midtown Toronto
679,"Manager, Data Science - Research & Analytics TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Lead a team of passionate data scientists focused on understanding members’ habits, driving new advanced features in a data-driven manner, and creating member-facing metrics to track their progress and motivate them.
Review the team’s designs, algorithms, and code while also spending time developing your own
Lead the initiative to fully leverage the world's best and largest fitness dataset to derive insights about member's habits and motivations
Work closely and collaborate with a cross functional team of Product Manager, Designers, and Engineers to drive new, innovative, data-driven functionality
Create metrics to motivate members and track their progress
Analyze member behavior and engagement to inform feature roadmap and marketing
Drive direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems
Identify innovative opportunities for new data-driven features

Who You Are

Advanced degree in engineering, scientific, or mathematical field
5+ years data science experience
2+ years leading and/or managing technical teams
Knowledge of machine learning, probability, and statistics
Strong knowledge of Python and SQL
Strong data visualization
Ability and desire to explain complicated concepts simply
Team player with high integrity
Open to feedback and constantly striving to learn and improve
High degree of self-awareness

Extra Credit

Knowledge of Snowflake, DBT, Looker, and Amplitude

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
680,CT Data Engineer,"EY is a global leader in assurance, tax, transaction and advisory services. Technology is at the heart of what we do and deliver at EY. Technology solutions are integrated in the client services we deliver and are key to our innovation as an organization.




Fueled by strategic investment in technology and innovation, Client Technology seeks to drive growth opportunities and solve complex business problems for our clients through building a robust platform for business and powerful product engine that are vital to innovation at scale. As part of Client Technology, you’ll work with technologists and business experts, blending EY’s deep industry knowledge and innovative ideas with our platforms, capabilities, and technical expertise. As a catalyst for change and growth, you’ll be at the forefront of integrating emerging technologies from AI to Data Analytics into every corner of what we do at EY. That means more growth for you, exciting learning opportunities, career choices, and the chance to make a real impact.




The project




This open role is for an integrated data platform that allows different service lines to perform various data management activities including onboard data, perform data ingestion, data processing, mapping to centralized taxonomy and then consume data for their respective product offering needs to support their clients. There is also potential to collaborate on additional platforms and offerings within the Client Technology group.




The selected candidate




Leads the delivery of processes to extract, transform and load data from disparate sources into a form that is consumable by analytics processes, for projects with moderate complexity, using strong technical capabilities
Designs, develops and produces data models of relatively high complexity, leveraging a sound understanding of data modelling standards to ensure high quality
Builds networks with other departments across the business to help define and deliver business value, and may interface and communicate with program teams, management and stakeholders as required to deliver small to medium-sized projects
Applies advanced big data concepts to ingest, process and transform data and store data in variety storage technologies
Applies Graph and AI/ML to data and data components supporting business requirements



Your key responsibilities include




Leading the production of high-quality data engineering deliverables, helping to ensure project timelines are met, and providing informal mentoring / training to junior members of the team
Leading the delivery of data quality reviews including data cleansing where required to ensure integrity and quality
Leading the delivery of data models, data storage models and data migration to manage data within the organization, for a small to medium-sized project
Resolving escalated design and implementation issues with moderate to high complexity
Analyzing the latest industry trends such as cloud computing and distributed processing and beginning to infer risks and benefits of their use in business
Providing technical expertise to maximize value from current applications, solutions, infrastructure and emerging technologies and seek to continuously improve internal processes
Developing working relationships with peers across other engineering teams and beginning to collaborate to develop leading data engineering solutions
Driving adherence to the relevant data engineering and data modelling processes, procedures and standards



Skills and attributes for success




Batch and Event Processing - Capability to design an efficient way of processing high volumes of data where a group of transactions is collected over a period of time or on an event driven method
Data Integration (Sourcing, Storage and Migration) - Capability to design and implement models, capabilities and solutions to manage data within the enterprise (structured and unstructured, data archiving principles, data warehousing, data sourcing, etc.). This includes the data models, storage requirements and migration of data from one system to another
Data Quality, Profiling and Cleansing - Capability to review (profile) a data set to establish its quality against a defined set of parameters and to highlight data where corrective action (cleansing) is required to remediate the data
Data Services - Experience building data services with asynchronous calls to data sources. Using functional and reactive programming features in modern java and open source libraries



Intermediate understanding of the following tools and technologies, and how to apply them to solve business problems




Essential:




Experience with Spring Boot, Spring Cloud, Kafka, EventHub
Good knowledge of Docker / Containers and Event Driven Architectures
Expertise with Azure functions, Azure Key Vault integration, Azure blob storage configurations
Hands-on experience with Azure Databricks, Delta Lake, Azure Functions, Azure Data Factory
Hands-on experience in developing AI/ML algorithms to detect data anomalies and patterns using Python, R and similar technologies
Expertise with Graph Databases - Azure Cosmos/Gremlin, Neo4j, Spark GraphFrames
Expertise in NoSQL Databases – CosmosDB, MongoDB
Expertise in index, search and exploration using Elastic
Hands-on experience with Programming Languages – Java, Node.js, Python, R, SQL, XML
Relational SMP Databases – Azure SQL PaaS, PostgreSQL, Synapse



Nice to have:




APIGEE, AKS
Azure Cognitive Services, Databricks MLFlow is a big plus
Elasticsearch, Kibana



Education




B.S. in Actuarial, Behavior Economics, Computer Science, Data Analytics, Data Science, Econometrics, Engineering, IT, Cyber Security, or related field preferred



What we look for




Strong analytical skills and problem-solving ability
A self-starter, independent-thinker, curious and creative person with ambition and passion
Excellent inter-personal, communication, collaboration, and presentation skills
Customer focused
Excellent time management skills
Positive and constructive minded
Takes responsibility for continuous self-learning
Takes the lead and makes decisions in critical times and tough circumstances
Attention to detail
High levels of integrity and honesty



What working at EY offers




We offer a competitive remuneration package where you’ll be rewarded for your individual and team performance. Our comprehensive Total Rewards package includes support for flexible working and career development, and with FlexEY you can select benefits that suit your needs, covering holidays, health and well-being, insurance, savings and a wide range of discounts, offers and promotions. Plus, we offer:




Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you



EY is committed to being an inclusive employer and we are happy to consider flexible working arrangements. We strive to achieve the right balance for our people, enabling us to deliver excellent client service whilst allowing you to build your career without sacrificing your personal priorities.




About EY




As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime.




If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.




Make your mark.




Apply now.","Ernst & Young
3.8",Midtown Toronto
681,2-2021DA - Data Engineer,"Data Engineer

If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!

This position is available to remote workers anywhere in the world, as long as you are able to work on a schedule that aligns with our North American business hours. You can also choose to work from our headquarters in beautiful Vancouver, BC once the health situation makes this possible.

This position is open to experienced candidates with a track record in this area. We’re building up our data warehouse and analysis skills, and we’re looking for someone who knows how to analyze, recommend, deploy, and use tools and techniques to help us get the most out of our data!



What You’ll be Doing

As a Data Engineer, you’ll help foster informed decision making and innovation within ActiveState by making our data understandable, actionable, and available in the relevant contexts.

You’ll be a part of our Tools and Infrastructure team, and will work closely with our in-house Data Analyst and with most of our other teams from time to time, both inside and outside of Engineering.




Your primary work will include:

Designing, building, and managing ETL and warehousing pipelines, including recommending tools, technologies, and practices for us to adopt.
Improving data accessibility within ActiveState by developing and training other developers in the use of monitoring, analysis, and visualization tools and techniques.
Ensuring data is managed in compliance with our in-house policies.
Managing and designing the data and reporting environment, including data sources, tooling, security, and metadata.
Designing, building, deploying, and managing tools and processes to help colleagues understand data.
Testing and documenting your work.



You’ll work with others on the following tasks:

Using code and data visualization tools to collect, validate, normalize, collate, analyze, interpret and present data. Some of this work will be ad hoc, while some will be routine and automated.
Analyzing and optimizing data models, queries, and access patterns.
Building processes and systems to monitor data quality, ensuring that production data is accurate.
Updating our data collection and analysis policies.

Our team is mostly scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Zoom for video calls and screen sharing, Asana for task management, and Google Drive.




We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code.

What’s in it for You
Working for a stable and growing company that offers the environment and personal growth potential of a start-up.
The chance to work with a smart, passionate team of people.
Competitive salary and bonus plan.
Comprehensive benefits package and health/wellness credit program.
Requirements
Demonstrated experience with ETL and data management technologies (for example, Snowflake and Matillion)
Demonstrated ability to develop, customize, deploy, and maintain and develop business intelligence software.
Practical experience working with and enhancing data warehouses/data lakes.
Experience creating and optimizing data models.
Demonstrated ability to perform, validate and document both ad hoc and automated data analysis and reporting. Ability to apply statistical methods to data sets is a plus.
Curiosity, an analytical mind, and strong problem-solving skills.
Excellent written and spoken communication skills, both technical and non-technical, including the ability to make data and analysis understandable and relevant to a diverse set of audiences.
Assets

If you have experience with any of the following please make sure to highlight it in your cover letter:

Data processing, messaging, and workflow technologies such as Kafka, Map/Reduce, Hadoop, Hive, PrestoDB, Luigi, Airflow, Storm, Argo etc.
Analyzing marketing and sales data
Google Data Studio
PostgreSQL
AWS/data engineering in cloud environments
Kubernetes
Experience working with a wide variety of different data sets using one or more of the common data analysis languages (such as Pandas/Python (preferred), R, Matlab, etc.) as well as spreadsheets and visualization tools (eg. Data Studio, Power BI, etc.)
Open Source projects and culture
Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI.
Go, Perl, Python, Tcl, and Ruby



Working At ActiveState

ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all.

Our company is a team of 55+ and growing, with 2/3rds of the positions in technical roles including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events.

Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches. For more about working at ActiveState and our Glassdoor rating go to www.activestate.com/careers.




How To Apply

Please submit your contact info, resume, and a cover letter below. Submissions without a cover letter will not be considered. We look forward to hearing from you!

We are committed to creating a welcoming environment for everyone at ActiveState and we welcome applicants from all walks of life.

Even if you don’t feel you meet every exact requirement, we still would love to hear from you and why you think you would be an awesome addition to our team and we encourage you to apply.","ActiveState
4.9",Vancouver
682,Senior Optical Engineer or Optical Scientist,"Senior Optical Engineer or Optical Scientist




About Metamaterial Inc.

META delivers previously unachievable performance, across a range of applications, by inventing, designing, developing, and manufacturing sustainable, highly-functional materials. Our extensive technology platform enables leading global brands to deliver breakthrough products to their customers in consumer electronics, 5G communications, health and wellness, aerospace, automotive, and clean energy. META’s achievements have been widely recognized, including being named a Global Cleantech 100 company. Learn more at www.metamaterial.com.




About the role

We are seeking a Senior Optical Engineer or Optical Scientist for our facility in Dartmouth, Nova Scotia. You will be a key member of the Optics team that develops new technologies and products for applications in augmented reality and scientific instruments. Your role will be to develop concepts and hardware for prototyping and manufacturing new optical devices based on holographic elements. You will be working hands-on within a diverse, multi-disciplinary team to develop holographic optical elements for high performance imaging systems. The ideal candidate has extensive experience developing new concepts for optical systems matched with the practical skills to bring them to life.




Responsibilities

Provide expert level optical engineering expertise towards the development of holographic optical components and sub-systems for HMD, HUD and scientific instrument applications.
Lead hands-on assembly, testing and debugging of custom hardware systems for development and manufacturing.
Work with internal and external stakeholders to develop product concepts and designs that address market needs.
Characterize the performance of optical products relative to the design goals; design and construct the necessary metrology systems.
Identify causal relationships between observed product performance and the design parameters.
Monitor and communicate to the team industry development and trends.
Communicate results through technical reports and presentations tailored to the needs of the target stakeholders.
Supervise junior members of the engineering team.



Required Skills and Experience

Hands-on experience implementing and testing optical devices and systems, particularly holographic devices.
Extensive experience constructing and validating models of optical devices and sub-systems.
Experience in process control, data acquisition, and data analysis in Python (preferred) or Matlab, R or Julia.
Proficiency with optical design tools and modelling methods (e.g. Zemax, VL Fusion, Comsol, Lumerical).
Excellent written, verbal and presentation skills.



Qualifications

An MSc or PhD in Physics, Applied Physics, Optics, EE, or related field, is required.
Minimum 5 years of experience with optical engineering and/or applied optics, with industrial experience developing products based on new technologies.



Professional Standards and Performance Review: As an experienced professional, the Senior Optical Engineer or Optical Scientist will maintain high professional standards and act in accordance with best practice. They will support the development of the professional standards of the team and take a continuous approach to improvement and their own personal development. As a representative of the Company, the Chemistry Laboratory Manager will act in line with the Company Code of Conduct and will participate in the performance review process.","Metamaterial Inc.
4.1",Dartmouth
683,Data Engineer (Ingestion),"Data Engineer - Ingestion


Location: Toronto


Are you ready to step up and take your technology expertise to the next level?


There is never a typical day at Accenture, but that’s why we love it here! This is an extraordinary chance to begin a rewarding career at Accenture Technology. Immersed in a digitally-compassionate and innovation-led environment, here is where you can help top clients shift to the NEW using leading-edge technologies on the most ground-breaking projects imaginable. Immerse yourself in a supportive ecosystem that values your individuality and encourages you to innovate, ideate and disrupt. We recognize that it's the diversity of our people that makes us stronger, smarter and more effective as a team.


We are Accenture Cloud First


Accenture is a leader in cloud transformations working with AWS, Azure, Google, and private clouds. The formation of Accenture Cloud First, with a $3 billion investment over three years, demonstrates our commitment to deliver greater value to our clients when they need it most. Our Cloud First multi-service group of more than 70,000 cloud professionals delivers a full stack of integrated cloud capabilities across data, edge, integrated infrastructure and applications, deep ecosystem skills, culture of change along with a deep industry expertise to shape, move, build and operate our clients’ businesses in the cloud. To accelerate our clients’ transformation leveraging cloud, we combine world-class learning and talent development expertise; deep experience in cloud change management; and cloud-ready operating models with a commitment to responsible business by design — with security, data privacy, responsible use of artificial intelligence, sustainability and ethics and compliance built into the fundamental changes Accenture helps companies achieve. Our services cover the full spectrum of client needs, from strategy to service management, device-to-cloud networks, workplace solutions, and more.

Today, more than ever, companies need to operate and compete at an unprecedented speed and scale as industries are reshaping beneath them. This means innovating faster, creating new revenue streams, deriving more insights from data - and from the edge - and interacting differently with their customers, partners, and employees. Choose Accenture and make delivering this kind of innovative work part of your extraordinary career.


The Work


Accenture’s Cloud First Infrastructure Engineering professionals’ partner with our clients to advise, create, and deploy end-to-end infrastructure transformation solutions, enabling business innovation. These solutions are the backbone of driving IT-enabled differentiation. IE professionals are grounded in New-IT with an expertise in one or more of our core practice areas: Digital Workplace, Network Technology, Service Management, Hybrid Cloud, Public Cloud, and traditional Data Center.


Key Responsibilities:


Application Design, Development and Support for Azure Data and AI Data analytics Platform
Involved in designing and developing new solutions
Lead the effort to design, build and configure applications, acting as the primary point of contact.
Lead team for Azure Databricks, Azure Data Lake, ADB, PySpark and Synapse
Responsible for Application Support and lead the role with offshore & on-shore teams
Co-ordinate with the client resolving issues, implementing enhancement, and troubleshooting issues to come up with recommendations for the client



Who are we looking for?

3 year of experience in the following:

Azure Data Factory
PySpark
Azure SQL
Azure Data Lake

Preferred Skills:

Certification: Azure Data Certification

Python","Accenture
4.1",Mississauga
684,Ingénieur·e de données /Data Engineer,"Qui sommes-nous :

BusPatrouille est une entreprise spécialisée dans la technologie de sécurité. À titre de principal fournisseur international de dispositifs visant à faire respecter le bras d’arrêt des autobus scolaires, notre mission principale est d’améliorer la vie des élèves où qu’ils se trouvent.

La technologie de BusPatrouille a été déployée sur un plus grand nombre d’autobus et a été utilisée pour délivrer un plus grand nombre de contraventions relatives au bras d’arrêt des autobus scolaires que toute autre technologie des autres entreprises existantes à l’échelle mondiale. Notre technologie exclusive transforme les autobus scolaires en autobus intelligents équipés de caméras vidéo, de GPS, de télémétrie, de traitement de données et d’archivage. De cette manière, nous permettons aux comtés et aux districts scolaires d’améliorer la sécurité des enfants.

BusPatrouille est en pleine croissance. Nous sommes donc à la recherche d’un.e ingénieur.e de données d’expérience pour intégrer notre équipe de veille stratégique (BI). Si vous aimez travailler dans un environnement dynamique avec des collègues talentueux, ce poste est pour vous.

Responsabilités :

Le rôle de l’ingénieur.e de données est essentiel pour construire des données évolutives et des modèles analytiques, ainsi qu’une architecture allant de la formation à l’ingestion d’événements, puis à la production de rapports, en partant du début. Vous évaluerez et soutiendrez la mise en œuvre de systèmes robustes utilisés par chaque équipe et client de BusPatrouille. La personne idéale possède de solides connaissances en gestion des données, en développement ETL (extraire, transformer, charger), en codage et en infonuagique. Elle aime travailler avec une diversité d’outils, de langages, de systèmes et d’architectures tout en s’assurant que les systèmes de données et la stratégie respectent les meilleures pratiques en matière d’évolutivité.

Rédiger des tâches ETL (extraire, transformer, charger) et ELT (extraire, charger, transformer) à l’aide de divers outils et langages de programmation.
Créer des pipelines de données dans des environnements AWS avec AWS glue.
Écrire des requêtes SQL complexes et optimiser leur vitesse et leur précision.
Concevoir, développer, tester, corriger et déployer des pipelines de données en soutien aux produits de base, aux déploiements auprès des clients et aux rapports de performance.
Écrire des scripts pour planifier l’ingestion et la synchronisation des données.
Développer des minientrepôt de données (data marts) à partir des besoins de l’entreprise pour permettre aux parties prenantes de l’entreprise d’être autonomes.
Créer et tenir à jour une documentation claire.
Travailler avec des collègues ingénieur.e.s, des chefs de projet et des utilisateurs.
Suivre les processus et les procédures de l’entreprise, en particulier les pratiques relatives à la sécurité de l’information.

Connaissances et compétences requises :

Un baccalauréat ou un diplôme supérieur en technologie, dans un domaine quantitatif ou dans un autre domaine connexe (par exemple, informatique, statistiques, génie électrique).
Plus de cinq ans d’expérience en ingénierie des données, ingénierie des bases de données ou analyse commerciale.
Plus de cinq ans d’expérience avec SQL (MySQL, PostgreSQL, Redshift).
Plus de quatre ans d’expérience avec les principaux langages de script tels que Python.
Plus de trois ans d’expérience dans la conception de schémas, la modélisation de données dimensionnelles, la conception d’API et le développement de services Web RESTful.
Une expérience de la visualisation de données (par exemple avec Tableau) est un atout.
Une curiosité intellectuelle, une volonté constante d’apprendre, un esprit d’initiative.
De solides compétences en communication écrite et verbale.
Un esprit d’équipe.

Rémunération et avantages :

Un salaire concurrentiel.
Des avantages sociaux complets, notamment une assurance soins médicaux, soins dentaires et soins de la vue.
Un poste indispensable au sein d’une entreprise qui se développe rapidement et qui est investie d’une mission.
L’occasion de travailler avec une équipe très performante.
L’occasion de contribuer à la création d’une entreprise vouée à la sécurité des enfants.

Nous sommes à la recherche de membres essentiels de l’équipe de BusPatrouille qui nous aideront dans notre quête pour accroître la sécurité des enfants. Ce poste joue un rôle important dans notre entreprise et constitue une formidable opportunité pour les personnes qui seront retenues. Nous offrons un milieu de travail inclusif, diversifié, enthousiaste, intègre et profondément engagé. Venez nous aider à assurer la sécurité des enfants.

=========================================================================

Who We Are:

Our mission is to create a culture of responsibility and awareness on the road. We are devoted to making the journey to and from school safer. We develop partnerships, deploy safety tech and manage the entire program. We have equipped thousands of busses across North America with our innovative technology and we continue to educate tens of thousands of drivers a month on safety. BusPatrol America cares about student safety. We educate motorists every day by helping enforce the law and work with school officials to improve safety.

The Role:

The Data Engineer at BusPatrol will build scalable data and analytics models and architecture from event formation to ingestion to reporting, from scratch. You will evaluate and lead the implementation of robust systems used by every team within BusPatrol. You will shape the vision and architecture of end-to-end pipeline while following industry best practices. The right candidate will have strong data architecture, ETL, SQL, and a proven track record working with enterprise metrics to build automated data pipelines. The candidate will also have strong operational skills to drive efficiency and speed, expertise in building repeatable data engineering processes, strong project management skills, and a vision for how to deliver data products.

Responsibilities:

Create data pipelines in state-of-the-art AWS environment EC2, S3, Lambda, etc. with AWS Glue.
Manage all aspects of the data and analytics system from stream configuration to ETL to aggregate tables and cubes for reporting needs.
Identify, design, and implement internal data pipeline jobs / processes improvements using machine learning (and other modern techniques): automating manual processes, optimizing data delivery, re-designing infrastructure for scalability, etc.
Write scripts to schedule data ingestion and syncing. Evaluate, lead and form backend logic to create data marts from requirements for the purposes of self-serving stakeholders.
Assist data architects to build the working framework for data search and retrieval.
Troubleshoot data jobs / processes in production to fix data quality bugs or pipeline performance issues.
Build and assemble large, complex data sets with multi-dimensional relationships that meet both functional and non-functional requirements from business stakeholders.
Build Appropriate ML data models and data schemas for business use cases.

Requirements:

Bachelor's degree or higher in a quantitative/technical field (e.g., Computer Science, Statistics, Engineering)
5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics
5+ years of SQL knowledge for various reporting and transformation needs (MySQL, PostgreSQL, Redshift)
4+ years of experience in core languages such as Python
3+ years of experience with schema design and dimensional data modeling
Experience with Data Lake architectures, and with combining structured and unstructured data into unified representations.
Experience with API design and development of RESTful web services
Hands on experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.
Analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions.
Data visualization experience with tools like Tableau a plus
Must be an intellectually curious self-starter and motivated to continually learn.

What we will offer you

The opportunity to join a mission-driven company, dedicated to developing and deploying safety technology in support of children’s safety
The opportunity to build an IT infrastructure group in support of our mission
Dedicated, accessible and committed colleagues and leadership team
The chance to join an innovative and dedicated team, focused on leading edge technology
Competitive salary and benefits package

We’re looking for critical members of the BusPatrol team to assist us in our quest to improve children’s safety. This is an important role for us and a great opportunity for the right candidates. Our environment is inclusive, diverse, ignited, built on integrity and deeply committed. Come and help us keep our children safe.

Type d'emploi : Temps Plein","BusPatrol
3.8",Montreal
685,Big Data Engineer 9+Yr Exp Canadian Citizen or PR,"Position/Title: BigData Engineer

Location: Brampton

Rate: $/hr

Client- COGNIZANT

· BigData ( Python & Spark & AWS - 8 to 10 years)

· specializing in software products services and technology

· Developing features using serverless technologies like AWS Lambda, Glue, EMR

· Developing Big Data pipeline using AWS technologies like Kinesis, SQS, SNS and so on

· Development of batch and real time processing jobs using Apache Spark and Java/Python

· Development of complex features using BigData Technologies which includes doing impact analysis, design, and development.

· Work effectively in a fast paced and dynamic environment

· Communicate effectively with all stakeholders

Must Have:

· BigData application/data pipeline Development experience using PySpark and following

· AWS technologies: Lambda, API Gateway, Glue, EMR, ECS, Kinesis, SQS, SNS, RDS,

· DynamoDb, Cognito, Redshift

· Experience in Databricks

· Language: Core Java/Python

· Tools: Maven, GIT

· OS: Linux

Good to have:

BigData skills: Hadoop, Kafka, Apache Spark (Spark Streaming, Spark Batch), Hive, SQL, HBase/Cassandra, Kubernetes, Redshift

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Reference ID: 210010

Job Types: Contract, Permanent

Salary: $80,031.00-$100,000.00 per year

Schedule:

8 hour shift

Work remotely:

Yes","Compest solutions Inc.
4.6",Brampton
686,Data Analytics Consultant - Contractor,"Data Analytics Consultant - Contractor - Customer 360 Analytics

The TELUS Business Marketing Team is looking for a talented, driven, passionate individual with strong analytical and interpersonal skills. Our Team – TELUS Business Solutions Marketing BI - has a mandate to build solutions for our stakeholders using data from various sources, building algorithms that can predict customer loyalty, churn and stickiness. We love to turn data into stories - stories about money falling through the cracks, success stories about our products and services, but most importantly stories about our customers and how we can enhance their experience. We run like a start-up and we have embraced lean and agile methodologies. We celebrate our failures and see them as opportunities to learn. Our culture fosters collaborative learning and out-of-the-box thinking in a relaxed environment. Come help us to make something awesome!

Candidates are able to communicate with business stakeholders, gather requirements, develop, design and implement reporting solutions in an agile-type environment. They must be able to shift effortlessly between business conversations about performance analytics and technical conversations around databases, SQL and Domo with their stakeholders and peers. A successful candidate has strong business analysis, problem solving and critical thinking skills.

Candidates must be comfortable working within a dynamic, cross-functional environment and be able to explain complex concepts, performance reporting methodologies, and analysis results to a diverse stakeholder community. You must be willing to roll up your sleeves and get close to the data.

Here's the impact you'll make and what we'll accomplish together:

You will be successful because you have an optimal mix of business and technical skills honed in a high performance driven business. You would be working with Data Scientists, Engineers and Analysts to help build trigger based B2B campaigns to target the right customer at the right time with the right product.

You have a passion for growing our business, the courage to innovate and embrace change in our business intelligence capabilities and embody the spirited teamwork necessary to support stakeholders across a wide variety of teams.

Here's how

You will:

Develop new analytical solutions to provide timely insights to the business
Assemble multiple data sources across various databases to build foundational C360 data marts
Build repeatable processes and automation to create standardized datasets, reports and analysis
Implement business intelligence and rules, optimize data processes and perform data quality audits
Proactively work with business stakeholders, manage relationships and lead marketing programs from a data standpoint
Effectively communicate with leadership and stakeholders
Lead Customer 360 programs, coach and mentor junior team members

You are the missing piece of the puzzle if:

You love digging into quantitative and qualitative data; you analyze it, pivot it and distill issues to their core to provide the best possible performance reports and channel insights
You have expert knowledge and understanding of global best practices in business intelligence tools (e.g. Python, R, SAS,DOMO, SQL, Tableau)
You have advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
You are recognized for your curiosity and growth mindset
You see the bigger picture of the problem you are trying to solve, and will proactively out new data points from varied sources (external and internal) to complement your analysis
You have excellent attention to detail, a structured approach to analysis and the ability to develop logical arguments
You have minimum 4-7 years of experience in a similar role and/or related education with demonstrated performance

Great-to-haves

Prior telecommunications expertise
Python experience
Hive, Spark, NiFi experience
B2B marketing
Experience with cloud (GCP AWS or Azure)
Experience with the Salesforce tech, i.e., marketing cloud, Pardot, Einstein
Data Science / Modeling experience or working in a Data Science team

Contract would be until 31st Dec 2021,with a high possibility of extension.

Other Locations : Alberta, British Columbia, Quebec","TELUS
3.9",Midtown Toronto
687,Senior Data Analyst,"WHAT DOES IT MEAN TO WORK AT ESG?

We are East Side Games - a pillar in beautiful Vancouver’s gaming community. Our mission is to create games that are easy to pick up, hard to put down, and don’t suck! We put players at the heart of our evolution, independence, and profitability. With their help, we’ve defined the narrative idle gaming space with huge brands that reach the lives of millions globally... And we’re just getting started!

Culture rules here, and that’s what makes us unique. We put people at the core of what we do. We believe that you can steer the ship of your career, and we anchor through support, trust, and connection. Tackle your challenges, share your learnings, then share a drink with the studio in our weekly Cheers Friday Announcements. Have we piqued your curiosity? Then check out our amazing Culture and Benefits!

WHAT IMPACT CAN A LEAD DATA SCIENTIST HAVE AT ESG

At East Side Games, we all band together to deliver a world-class gameplay experience for our players around the globe. Whether that’s working on Archer: Danger Phone, or on any of our other current or upcoming titles, you’re committed to making memorable player experiences. Everyone has an impact here. As a Senior Data Analyst, you create actionable insights from the data we collect that directly leads to product improvements within our IdleKit team. Through a deep understanding of our player’s behaviour, you’ll work on building dashboards, reports, and predictive models that ultimately lead to a world-class game experience our players cherish.

What is IdleKit?

IdleKit is East Side Games core technology platform that enables our internal games and external partnership games. The IdleKit team operates as an independent business unit that productizes our platform and actively publishes new games under the East Side Games brand.

We’re a remote-first studio and encourage all applications.

WHAT YOU MIGHT DO IN YOUR DAY TO DAY

Formulate hypotheses and run a variety of A/B tests to determine the best strategies to implement into our products.
Work with external partner studios to create balance changes and features that will improve target metrics.
Evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data.
Be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data.
Build partnerships with each team member, sharing the tools and insights that predict and improve retention and monetization within our products.
Continuously improve, maintain, and develop our analytics tools and predictive models for our games.


WHAT YOU BRING TO ESG

A bachelor's degree in mathematics, statistics, computer science, economics, or a related quantitative field and/or a graduate degree in data science or business analytics.
At least four years prior experience as a data analyst/scientist, preferably in the F2P mobile gaming space.
Expert level knowledge of SQL (e.g., window functions), Tableau (or similar), and proficiency with at least one scripting language (e.g., R, Python).
Ambition to own and take ownership of the reporting and analysis functions for our games.
The ability to tell a convincing story with data.
An innate curiosity and ability to mine large complex data sets and build predictive models that lead to meaningful conclusions.
Previous experience A/B testing and calculating statistical significance within a big data context (e.g., bootstrapping, permutation testing).
Strong written and oral communication skills.
Prior management experience is a huge plus.


YOU ARE:

Hungry, humble, and smart and can use these three pillars to impact you and those around you.
A mobile game fanatic. You are on top of the latest games, trends, and what’s happening in live events.
Entrepreneurial, self-motivated, and have the attitude to get things done.
A risk-taker, and gain your biggest learnings through them.
Empathic, compassionate, and curious.
Solution-oriented and data-driven.
Comfortable in an environment where priorities and plans can change rapidly.


WE’RE BUILT ON THE FOUNDATIONS OF DIVERSITY AND INCLUSION

East Side Games are an equitable employer that values justice, equity, diversity and inclusion. We welcome and encourage people of marginalized backgrounds, particularly QTBIPOC folks, to apply, and will acknowledge and value the strengths you bring to foster yours and the studio’s growth.

If this sounds like something you hoped for and more, and you’re enthused to build genre-defining narrative idle games, click the “Apply Here” button below. If now is not the right time for you but you know someone who would be a great match for us at East Side Games, check out our referral bonus here! Let’s build great games together


We can’t wait to hear from you!




oKAdDf8gPs","Eastside Games
4.0",Remote
688,Senior Data Analyst,"WHAT DOES IT MEAN TO WORK AT ESG?

We are East Side Games - a pillar in beautiful Vancouver’s gaming community. Our mission is to create games that are easy to pick up, hard to put down, and don’t suck! We put players at the heart of our evolution, independence, and profitability. With their help, we’ve defined the narrative idle gaming space with huge brands that reach the lives of millions globally... And we’re just getting started!

Culture rules here, and that’s what makes us unique. We put people at the core of what we do. We believe that you can steer the ship of your career, and we anchor through support, trust, and connection. Tackle your challenges, share your learnings, then share a drink with the studio in our weekly Cheers Friday Announcements. Have we piqued your curiosity? Then check out our amazing Culture and Benefits!

WHAT IMPACT CAN A LEAD DATA SCIENTIST HAVE AT ESG

At East Side Games, we all band together to deliver a world-class gameplay experience for our players around the globe. Whether that’s working on Archer: Danger Phone, or on any of our other current or upcoming titles, you’re committed to making memorable player experiences. Everyone has an impact here. As a Senior Data Analyst, you create actionable insights from the data we collect that directly leads to product improvements within our IdleKit team. Through a deep understanding of our player’s behaviour, you’ll work on building dashboards, reports, and predictive models that ultimately lead to a world-class game experience our players cherish.

What is IdleKit?

IdleKit is East Side Games core technology platform that enables our internal games and external partnership games. The IdleKit team operates as an independent business unit that productizes our platform and actively publishes new games under the East Side Games brand.

We’re a remote-first studio and encourage all applications.

WHAT YOU MIGHT DO IN YOUR DAY TO DAY

Formulate hypotheses and run a variety of A/B tests to determine the best strategies to implement into our products.
Work with external partner studios to create balance changes and features that will improve target metrics.
Evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data.
Be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data.
Build partnerships with each team member, sharing the tools and insights that predict and improve retention and monetization within our products.
Continuously improve, maintain, and develop our analytics tools and predictive models for our games.


WHAT YOU BRING TO ESG

A bachelor's degree in mathematics, statistics, computer science, economics, or a related quantitative field and/or a graduate degree in data science or business analytics.
At least four years prior experience as a data analyst/scientist, preferably in the F2P mobile gaming space.
Expert level knowledge of SQL (e.g., window functions), Tableau (or similar), and proficiency with at least one scripting language (e.g., R, Python).
Ambition to own and take ownership of the reporting and analysis functions for our games.
The ability to tell a convincing story with data.
An innate curiosity and ability to mine large complex data sets and build predictive models that lead to meaningful conclusions.
Previous experience A/B testing and calculating statistical significance within a big data context (e.g., bootstrapping, permutation testing).
Strong written and oral communication skills.
Prior management experience is a huge plus.


YOU ARE:

Hungry, humble, and smart and can use these three pillars to impact you and those around you.
A mobile game fanatic. You are on top of the latest games, trends, and what’s happening in live events.
Entrepreneurial, self-motivated, and have the attitude to get things done.
A risk-taker, and gain your biggest learnings through them.
Empathic, compassionate, and curious.
Solution-oriented and data-driven.
Comfortable in an environment where priorities and plans can change rapidly.


WE’RE BUILT ON THE FOUNDATIONS OF DIVERSITY AND INCLUSION

East Side Games are an equitable employer that values justice, equity, diversity and inclusion. We welcome and encourage people of marginalized backgrounds, particularly QTBIPOC folks, to apply, and will acknowledge and value the strengths you bring to foster yours and the studio’s growth.

If this sounds like something you hoped for and more, and you’re enthused to build genre-defining narrative idle games, click the “Apply Here” button below. If now is not the right time for you but you know someone who would be a great match for us at East Side Games, check out our referral bonus here! Let’s build great games together


We can’t wait to hear from you!




oKAdDf8gPs","Eastside Games
4.0",Remote
689,ARCHITECTE DE SOLUTION BIG DATA,"CTC006039 : ARCHITECTE DE SOLUTION BIG DATA


Location : Montreal, Quebec
Field : Solutions Architect
Position Type : Contract
Starting : July 5, 2021
Ending : July 1, 2022
Resources Required : 1


Position Description





Duration: 12 months mandate with possibility of permanence.

Bilingualism: Required (French and English).

Rate open

Remote: 100% remote. An eventual presence on site will be considered. It is recommended to live in Montreal or its surroundings.

About the role:

Do you have a strong background in Big Data and would like to leverage it by designing innovative and groundbreaking solutions?
Do you want to influence the Bank's IT strategies and directions?
Do you want to put your expertise to work building the digital bank of tomorrow?

The IT - Advanced Analytics Ecosystem team is looking for a Big Data Solutions Architect to join a project at the heart of our data strategy. We need someone who is creative in designing analytical solutions, able to deliver real results while meeting commitments, and able to collaborate happily and efficiently in multidisciplinary teams.

Working on an architecture team means being at the center of the Bank's transformation and playing a key role in designing secure, forward-thinking solutions.

More details on responsibilities:

In collaboration with domain architecture, development teams and operations, design and implement complex megadata solutions.
Define the megadata and analytics strategy using relevant technologies and analytics industry trends.
Lead the implementation of the defined strategy in the design and architecture of the client analytics platform components using cloud infrastructures (Azure, AWS) as well as several software components required by data scientists.
Lead the design of reference architecture models for structured and unstructured data integration
Define technical evaluation criteria for product and technology selection and to determine preferred technical approaches for successful solutions within a coherent system design.
Participate in and execute proof of concept exercises for the adoption of new megadata management technologies, software engineering tools, and models within existing structures.
Use influence to recommend methods for improving data reliability, efficiency and quality.
Monitor the implementation of solutions through to delivery ensuring compliance with established architectures (enterprise architecture).

What you offer:

Completed Bachelor's degree, related to the industry, and 10 years of relevant experience or completed Master's degree, related to the industry and 7 years of relevant experience
Experience and knowledge of Azure, AWS cloud.
Experience building architectures related to data security, firewalls, encryption, identity and access management (IAM), networking, compliance (SOX/HIPPA/PII) and data protection
Hands-on experience with several megadata tools (Spark, Kafka, Snowflake, Databricks, Qlik)
Experience designing data pipelines and automating megadata platform applications/services using Python, PySpark, SQL and Javascript; and automating them using DevOps processes and tools
Experience with Git, Ansible, Terraform, Jenkins in mission critical production environments desirable.
Excellent knowledge of container management practice and tools ( Docker, Kubernetes).
Excellent knowledge of architecture design, data modeling, and implementation of megadata platform architectures and analytics applications.
Knowledge and experience with advanced analytics capabilities, including machine learning using supervised and unsupervised techniques",CTConsultants,Montreal
690,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
691,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
692,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
693,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
694,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
695,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
696,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
697,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
698,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
699,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
700,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
701,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
702,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
703,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
704,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
705,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
706,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
707,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
708,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
709,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
710,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
711,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
712,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
713,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
714,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
715,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
716,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
717,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
718,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
719,Data Engineer,"Do you love making sure that information is accessible and easy to use? So do we.

You are a data designer who knows how to find, store, and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.

About you:
You draw on your experience in bringing data to life to aim sometimes complex problems, and you’re able to use concepts around storing, transforming, and visualizing data along the way.

About the job:
As a Data Engineer, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.

Day-to-day you:

Use your knowledge to plan and deliver data warehouses and storage
Take part in crafting and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt, and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Build and use effective metrics and monitoring processes
Help to develop business intelligence tools
Craft and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Your skills:
You have got a great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.

Your skills and experience include:

Strong knowledge of Python, Spark, and T-SQL
Database, storage, collection and aggregation models, techniques, and technologies - and how to apply them in business
Experience in structured problem solving
Strong knowledge of Python, Spark, and T-SQL
Superb communication skills
Ability to use technology to aim business problems using one or more Microsoft Analytics services for building data pipelines, data streams, and system integration
Desirable skills:

Knowledge of Azure tools such as Azure Data Factory, Azure Data Lake, Azure SQL DW or Azure SQL
Knowledge of Big Data tools such as Hadoop / Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics
Experience preparing data for Data Science and Machine Learning
Crafting and building Data Pipelines using streams of IoT data
Knowledge of Dev-Ops processes (including CI/CD) and Infrastructure as code fundamentals
You’re likely to have a Bachelor’s degree in IT, Applied Mathematics, Statistics or another meaningful field, or an equivalent combination of education and experience. You also have several years of relevant professional experience.","Avanade
4.1",Midtown Toronto
720,"Senior Applied Scientist, Alexa Speech","Master's degree in Electrical Engineering, Computer Sciences, or Mathematics with specialization in speech recognition, natural language processing, image processing, or machine learning.
5+ years relevant industry experience
Experience with programming languages such as C/C++, Python, Java or Perl.
Amazon is looking for a passionate, talented, and inventive Scientist with a strong machine learning background to help build industry-leading Speech and Language technology. Our mission is to push the envelope in Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), and Audio Signal Processing, in order to provide the best-possible experience for our customers.

As a Scientist, you will work with talented peers to develop novel algorithms and modeling techniques to advance the state of the art in spoken language understanding. Your work will directly impact our customers in the form of products and services that make use of speech and language technology. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in spoken language understanding.

We are hiring in all areas of spoken language understanding: ASR, NLU, text-to-speech (TTS), and Dialog Management.

Position Responsibilities:

Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for machine learning (ML) and/or natural language (NL) applications.
Develop and/or apply statistical modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications in business and engineering.
Routinely build and deploy ML models on available data.
Research and implement novel ML and statistical approaches to add value to the business. Mentor junior engineers and scientists.
PhD in relevant fields + 3 years relevant industry experience
Experience in building speech recognition and natural language processing systems (e.g. commercial speech products or government speech projects)
Solid Machine Learning background and familiar with standard speech and machine learning techniques.
Proficient in neural network and/or deep learning are pluses.
Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field
Solid software development experience
Good written and spoken communication skills.
To learn more about the Digital Products team at Amazon, visithttp://www.amazon.com/careers/digitalproducts and apply now.

Amazon is committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act. If contacted for an employment opportunity, please advise Human Resources if you require accommodation.","Amazon Dev Centre Canada ULC
3.8",Midtown Toronto
721,"Cloud Data Architect, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Toronto; Calgary; Montreal; Vancouver


Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the office.


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Cloud Data Architect on our Data & Analytics Modernization team within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in modern data solutions including data ingestion/data pipeline frameworks, data warehouse & data lake architectures, cognitive computing and cloud services. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Lead, define, design and implement end-to-end modern data platforms in support of analytics and AI use cases
Collaborate with enterprise architects, data architects, ETL developers & engineers, data scientists and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities
Address aspects such as data privacy & security, data ingestion & processing, data storage & compute, analytical & operational consumption, data modeling, data virtualization, self-service data preparation & analytics, AI enablement, and API integrations
Define and develop solution architectures, lead development teams, estimate effort and mentor junior colleagues
Lead technical meetings with client staff, and advise client with technical option analyses based on leading practices
About the team


Omnia AI, Deloitte’s Artificial Intelligence (AI) practice is comprised of a collaborative team of experts who use their hands-on experience with cutting-edge information assets to facilitate successful AI transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

Enough about us, let’s talk about you


You are someone with:

5+ years experience leading engagements from design to implementation of creative data solutions leveraging the latest in Big Data frameworks, supporting on-premise, cloud (AWS, Azure, GCP) and hybrid architectures to enable use cases in analytics and AI
5+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads
3+ years experience with analytics/data management strategy formulation, architectural blueprinting, business case development and effort estimation of disruptor based analytics
Ability to simplify complex technical concepts into easy-to-understand non-technical language in order to facilitate, communicate and interact with executives and business stakeholders, working with Agile development methods in data-oriented projects
Completed Bachelor’s Degree (or higher) in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or related field is desired; certifications in architecture (TOGAF), data engineering and development on AWS, Azure, GCP and/or Hadoop distributions are an asset.

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.","Deloitte
3.9",Midtown Toronto
722,"Senior Data Analyst, Global Investments","Why join us?

Are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor? If so, we would love to tell you our story.

At OMERS we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in Toronto, London, New York, Singapore, Sydney and other major cities across North America and Europe. Our culture is truly one of a kind. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live with an ever-constant eye to the global investment markets.
The Senior Data Analyst, Global Investments Technology (GIT) will join a team that leads the delivery of the products and platforms that enable OMERS Global Investments (GI) to analyze opportunities, action investment decisions and optimize the OMERS investment portfolio. GIT works across investment teams including Capital Markets, Infrastructure, Private Equity, Growth Equity and Ventures, and in close collaboration with Finance, Risk & Compliance teams.

As a key member of the Global Investments Technology team, the Senior Data Analyst is instrumental in enhancing data & analytics capabilities by championing industry best practices and delivering high quality datasets, reports, and training to enhance business decision making.

The Senior Data Analyst will develop Power BI datasets and reports to support OMERS investment entities, maintain a healthy business relationship to assist in meeting business demands and deliver training workshops to promote a data culture. The Senior Data Analyst will also support and collaborate with data engineers, data scientists and investment professionals and engage in technical support, research and knowledge sharing through the implementation as part of 1 or more product team(s).

As a member of this team, you will be responsible for:
Technical
Organizing workshops with partners to gather requirements and develop low/high fidelity wireframes
Developing and monitoring Power BI Premium Dataflows to gather, transform and democratize structured and unstructured data assets
Developing Power BI datasets by applying best-practice semantic modeling techniques
Building visually stunning reports that clearly communicate an effective story
Leading solution build, delivery, support and troubleshooting
Provisioning and managing resources of Premium Capacity
Managing the Power BI / Power Platform infrastructure
Usage Monitoring and Auditing
Organizational
Operating in an Agile development environment
Communicating effectively with analysts and various partners across multiple teams and with various other partners such as product managers, data engineers and members of senior management
Managing change and communicating impacts to partners and fellow team members
Facilitating collaboration and sharing through best practices of delivering and sharing content
Identifying, defining and implementing opportunities for improving existing processes
Exhibiting the ability to work on multiple projects simultaneously and ensuring timely delivery
Leading the Power BI Community of Interest to review the latest features and updates
Collaborating with other teams and establishing Power Platform Governance and Support

To succeed in this role, you have:
Professional
Experience . 5+ years solving complex technical projects as a full-stack (M & DAX) Power BI developer
A Bachelor’s Degree in a scientific or engineering field of study or equivalent work experience
Microsoft certification – Data Analyst Associate
Industry Knowledge of best practices learned from MVP & Product Team articles and Investments/Finance.
Training . Excited to support new Power BI users by running various internal community initiatives such as presentations, hands-on workshops, or troubleshooting end-user obstacles.
Demonstrated success building deep technical relationships and aligning expectations across various partners.
Problem - Solving. The ability to trace data lineage and resolve technical issues with minimal direction.
Teamwork . Motivated and keen to work in a collaborative environment with a focus on team success.
Technical
A depth of Power BI experience wrangling complex data using M functions and developing sophisticated semantic logic using DAX expressions
Connect/Transform. Knows what “M” is, how to merge, append, and perform more advanced UI transforms
Model. Basic knowledge of dimension / fact tables and can identify them in a dimensional model. Comfortable with simple DAX, knows the CALCULATE function well and can explain how it works.
Visualization. Recommends appropriate visualizations to answer business questions and references examples of published materials that explain how to choose a visual. Proficient at all ways to manipulate look & feel.
Admin/Architecture . Has experience configuring Administrative features in the tenant. Knows how to install and manage a gateway. Basic levels of understanding of licensing.
Embed/Custom Visuals . Understand that Power BI can be embedded internally and knows how to add and share in Teams.
Breadth of technical experience and knowledge in the MSFT data and analytics ecosystem, with Subject Matter Expertise in two or more of the following items:
Power BI Service administration
Power BI Desktop
Tabular Editor and DAX Studio
Azure Synapse Analytics
Azure Data Factory
Azure Machine Learning
Azure Databricks

Our story:
Founded in 1962, OMERS is one of Canada’s largest defined benefit pension plans, with $105 billion in net assets as at December 31, 2020. OMERS is a jointly-sponsored pension plan, with 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. OMERS members include union and non-union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children’s aid societies across Ontario. Contributions to the Plan are funded equally by members and employers. OMERS teams work in Toronto, London, New York, Amsterdam, Luxembourg, Singapore, Sydney and other major cities across North America and Europe – serving members and employers and originating and managing a diversified portfolio of high-quality investments in public markets, private equity, infrastructure and real estate.

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","OMERS
3.5",Midtown Toronto
723,Senior Java/Data Engineer (Backend/Middleware) (VP),"Citi’s Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citi’s Capital Markets, Securities Services and Banking lines of businesses.

Our mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurial spirit.

We are looking for a Senior Data Engineer with experience in developing data pipelines to join our team, part of the Citi’s Innovation Lab, working on a trade surveillance platform used across multiple businesses within our Institutional Clients Group.

As a Senior Data Engineer on our team, you will be responsible for designing, building and integrating data pipelines. The trade surveillance platform will be looking at running various models at scale on large data sets to identify and act upon possible market abuse in the market.

You will work with our stakeholders and data consumers to ensure we are meeting their requirements. You will contribute to the team’s strategy around security, development, testing, and deployment best practices.

This is an exciting opportunity to work on a mission critical project, take a leading role in evolving our platform, and be a difference maker at Citi.

Job Background/context:

We believe the future’s here. Right here with us. Home to where we define, ideate, develop and distribute production-ready financial solutions of far-reaching impact. And right now, the door’s open to direct the future of our technology for a truly global client base. This means collaborating with the keenest minds in data science, big data, software engineering, web development, UX design and more. Doers looking to bring the next bold ideas to life for a fascinating array of clients - investing, trading and transacting at the forefront of change in markets and economies the world over.

If you have this kind of vision, capable of seeing ahead, of developing a clear path forward in a quest to try the as yet untried, here is the opportunity. In a supported, resource-rich, vibrant co-working environment, part of an ecosystem of globally interconnected labs, realizing a broader mission of enabling growth and economic progress on a scale you won’t find anywhere else.

Key Responsibilities:

Working closely with a global team building large distributed data-centric applications in the trade surveillance and compliance space.
Designing and building message and data processing/streaming services to enable seamless integration with multiple business systems.
On-boarding of new data streams from external systems.
Working closely with data scientists to ensure data is of the highest quality and is available when needed.
Act as data pipeline subject matter expert to the global application team as well as other internal and external stakeholders.
Building close relationships with clients and stakeholders to understand the use cases for the platform and prioritising work accordingly.
Working well in a multidisciplinary DevOps-focused team and building close relationships with engineers, data scientists, business analysts, and production support teams.
Holds themselves accountable for ensuring high quality results and acts as a mentor and coach to other team members.

Skills & Qualifications:

You have experience driving the technical direction on data-intensive projects.
You will have specific examples of times that you have:
Delivered value to business by getting applications into production.
Designed systems from scratch that can scale with large volumes of data.
You have expertise in multiple programming languages and building data pipelines, ideally using Spark and Java.
You have expertise working with message/event streaming services, ideally using Kafka or Solace.
You have experience working with both relational and non-relational databases, ideally Oracle, Mongo and Elastic Search
You understand the full spectrum of the data processing and integration ecosystem, including testing strategies.
You have experience working in a DevOps culture and are comfortable working with CI/CD tools (ideally IBM UrbanCode Deploy, TeamCity, and/or Jenkins.)
Ideally, you have experience working in virtualized environment, as well as container orchestration services such as Kubernetes/OpenShift.
You have experience in systems observability including monitoring and health patterns and the tools to ensure the highest production stability.
You have high development standards, especially for code quality, code reviews, unit testing, continuous integration and deployment.
You have proven capability to interact with clients and deliver results – from ideation to production.
You have experience working in fast paced development environments.
You agree that verbal and written communication skills are vital.

Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply.

-

Job Family Group:

Technology

-

Job Family:

Applications Development

-

Time Type:

-

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting","Citi
3.9",Mississauga
724,"Manager, Data Science - Machine Learning TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Lead a team of passionate data scientists focused on modeling members’ fitness performance and providing weight recommendations
Develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more.
Review the team’s designs, algorithms, and code while also spending time developing your own
Lead the initiative to fully leverage the world's largest and best fitness data set
Collaborate closely with fitness experts on training methodologies. Validate and innovate on new more effective training methodologies using a data-driven approach
Work closely and collaborate with front-end and back-end teams to take the team’s work to production
Drive the direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems
Leverage your creativity to identify innovative opportunities for new data-driven features

Who You Are

Advanced degree in engineering, scientific, or mathematical field
5+ years data science experience
2+ years leading and/or managing technical teams
Knowledge of machine learning and signal processing algorithms
Working experience with data filtering and cleansing techniques
Strong knowledge of Python and SQL
Working knowledge of software development, including RESTful APIs
Team player with high integrity
Open to feedback and constantly striving to learn and improve
High degree of self-awareness

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
725,Product Development Confectionary Scientist,"At Cronos Group, we hire talented people who thrive on solving difficult problems and give them the opportunity to hone new skills and approaches. If you want to play a part in shaping an innovative industry and help build a historically significant company, we want to meet you.

If you are an experienced confectionary scientist with a strong work ethic, enjoy collaborative multi-disciplinary projects and are a motivated self-starter, then this is the job for you! As the Confectionary Scientist you will be leading the development and commercialization of new confectionary products and enhancing existing products. You will work closely with key interdisciplinary stakeholders to drive products forward from concept to implementation. There is a key emphasis on administrative and organizational skills while managing and administrating multidisciplinary projects to take confectionary product concepts from benchtop R&D to commercialization. The ideal candidate is energetic, collaborative, and forward- thinking.

This position is based out of Stayner, Ontario Canada.

What you’ll be doing:

Lead the development of cannabis edible products (confectionary products, chocolate products, baked-goods, beverages and other food products) including product formulations, specifications, packaging, stability, nutritional fact calculations and critical production parameters.
Taking ownership for the development and commercialization of new and enhancement of existing products that meet regulatory, quality, operational, sales, marketing, and financial expectations.
Familiar with regulatory requirements of confectionary and edible products in the Cannabis Act and Canadian Food Inspection Agency (CFIA) requirements; ensuring that products comply with government regulations and certification requirements.
Maintain R&D workspace and R&D equipment for the development and design of confectionary and chocolate products. Designing experiments and leading formulation design, recipe development and standardization of final formulation specifications.
Collaborate with operations for manufacturing equipment selections, technical transfer of production manufacturing, and final product quality and integrity; ensuring critical control parameters and product attributes are successfully transferred to the operations teams.
Ensure inventory traceability and administrative documentation of all cannabis product being used for Product Development activities (all R&D and scale up activities) Collect, organize and interpret data from experiments, prepare reports and present results
Work with procurement and quality teams to select & qualify suppliers and draft raw material specifications.
Collaborate with innovation and finance team to help develop costings of product and assist in business case development.
Track and report on industry trends and competitor intelligence: track and develop subject-matter expertise regarding economic, regulatory, and marketing issues and trends including monitoring new product filings and other product development related publications.
Work with consumer insights and marketing teams to discovery new opportunities and define technically feasible products to meet novel consumer needs and existing market gaps.


You’ll need to have:

Post-secondary education in Food Science, Science, Engineering, Culinary or related field.
A minimum of 5+ years in food product development or cannabis edible product development
Experience with all types of confectionary manufacturing processes (eg, chocolate panning, chocolate enrobing, gummy manufacturing, hard-candy manufacturing, etc…)



We are committed to fostering a diverse and inclusive work environment, and we welcome and encourage applications from people with disabilities and people with diverse backgrounds, identities, and cultures. For candidates with disabilities, accommodations are available upon request in all phases of the selection process.","Cronos Group Inc.
2.7",Stayner
726,Software Development/Engineering Manager - Data Science,"Description & Requirements

Description

Data science is a crucial part of UKG. Our team builds statistical and machine learning models that support product features across the company, with the goal of empowering thousands of organizations and millions of employees to thrive. We tackle problems in the fields of machine learning, natural language processing, document processing, sociology, and statistics... and we're just getting started. We’re looking for a software engineering manager to join the team and help it grow. You will lead a team of data scientists and software engineers. The team is distributed, working across multiple time zones, in an agile environment with daily stand-ups and regular releases. This position requires excellent technical, tactical, and strategic leadership, along with a strong ability to communicate both within the team, and across the organization.

As part of the team, you will:

Support and grow a team of highly motivated people.
Focus on data-driven processes that lead to continuous improvement for the team.
Support the professional, technical, and personal growth of a diverse group of people, with a wide range of experiences.
Collaborate with the team to set the product and technical roadmaps, along with the plans for achieving them.
Work with your peers to help support and drive cultural changes across the organization.

Qualifications

Previous engineering leadership experience, preferably with a data science team
University degree in Computer Science, Statistics, Mathematics, preferably at the graduate level; or equivalent experience.
Passionate about people, processes, and technologies and with the ability to use that passion to inspire and motivate others.
Strong outcome-based work ethic with a sense of ownership, urgency, and drive and an unwavering commitment to do the right thing.
Proven leadership in facilitating complex discussions to achieve goals and solve problems.
An understanding of the importance of being data driven, and the value that KPIs can bring to continuous improvement and innovation.
A technical background in software engineering, data engineering, or data science.
Ability to build and maintain productive relationships with a diverse array of stakeholders and groups throughout the organization.
Experience in Lean-Agile development processes such as Kanban or Scrum.
Experience working in an enterprise-scale SaaS production environment.

Corporate overview

Here at UKG, Our Purpose Is People. UKG combines the strength and innovation of Ultimate Software and Kronos, uniting two award-winning, employee-centered cultures. Our employees are an extraordinary group of talented, energetic, and innovative people who care about more than just work. We strive to create a culture of belonging and an employee experience that empowers our people. UKG has more than 13,000 employees around the globe and is known for its inclusive workplace culture. Ready to be inspired? Learn more at www.ukg.com/careers

EEO Statement

Equal Opportunity Employer

Ultimate Kronos Group is proud to be an equal opportunity employer and is committed to maintaining a diverse and inclusive work environment. All qualified applicants will receive considerations for employment without regard to race, color, religion, sex, age, disability, marital status, familial status, sexual orientation, pregnancy, genetic information, gender identity, gender expression, national origin, ancestry, citizenship status, veteran status, and any other legally protected status under federal, state, or local anti-discrimination laws.","UKG (Ultimate Kronos Group)
4.2",Remote
727,Solution Architect (Big Data) - Canada,"Wavicle Data Solutions designs and delivers data and analytics solutions to reduce time, cost, and risk of companies’ data projects, improving the quality of their analytics and decisions now and into the future . As a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.
Our 250+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team’s deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.

At Wavicle, you’ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle. Wavicle has been recognized by industry leaders as follows:
Chicago Tribune’s Top Workplaces
Inc 500 Fastest Growing Private Companies in the US
Crain’s Fast 50 fastest growing companies in the Chicago area
Talend Expert Partner recognition
Microsoft Gold Data Platform competency

About the Role:
We are looking for a Solution Architect who will perform mission critical duties in our data engineering strategy, contributing to and leading the development of our Enterprise Data and Analytics Platforms. A passionate professional who can blend the ever-evolving technology landscape of Cloud and Advanced Analytics with the complex and high-impact space of E-Commerce and Direct Sales.
The Solution Architect will be responsible for leading a team of talented engineers to develop and maintain the foundation of next generation data platforms. This role will be responsible for expanding, optimizing, and monitoring our expanding data pipelines through meticulous architecting, intelligent business logic, consistent data governance, testing and continuous delivery.

Responsibilities:
Lead and provide advanced data engineering expertise for projects that enable analytics to drive optimization of decisions for client(s), within a team of engineers.
Design new methods and processes to ensure maximum effectiveness of client data.
Partner with data analysts/scientists to provide solutions enabling statistical analysis tools and data visualization applications.
Identify processes and tools that can be shifted towards automation to enable seamless development and self-service analytics workloads.
Partner with various business units and data stewards to understand the business needs.
Obtain and/or maintain technical expertise of available data manipulation and preparation tools (Talend, Informatica, Matillion etc) as well as programming languages ( Python, Spark, EMR, etc.)
Ensure data is secure, relevant, and maintains high quality standards.
Identify and implement industry best practices.
Evaluate new data sets to determine appropriate ingestion techniques.
Build, manage and optimize data pipelines through a variety of ETL tools, including custom infrastructure and 3rd-party tooling (AWS, GCP, Databricks, Snowflake).
Work with internal engineering teams and vendors to understand business logic to ensure veracity in datasets.
Generate documentation on existing production data logic and its influencing business processes in order to reconcile knowledge gaps between the business, engineering, and data collection.
Requirements
8-10 years of experience in delivering data engineering solutions that include batch and streaming capabilities.
5+ years of strategic/management consulting experience is highly preferred.
Experience building, testing, automating and optimizing data pipelines.
Experience using AWS, Databricks, Snowflake or similar products.
Strong understanding and prior use of SQL and be highly proficient in the workings of data technologies (Hadoop, Hive, Spark, Kafka, low latency data stores, Airflow, etc.).
Deep understanding of data testing techniques, and a proven record of driving sustainable change to the software development practice to improve quality and performance.
Proficiency with data querying languages (e.g. SQL), programming languages (e.g. Python, Spark, Java, etc.).
Expertise selecting context-appropriate data modeling techniques, including Kimball dimensional modeling, slowly changing dimensions, snowflake, and others.
Passion for software development and data and be highly skilled in performing data extraction, transformation and processing to optimize quantitative analyses on various business functions.
Familiarity with Scrum, DevOps, and DataOps methodologies, and supporting tools such as JIRA.
Experience with AWS technologies such as Redshift, RDS, S3, Glacier, EC2, Lambda, API Gateway, Elastic Map Reduce, Kinesis, and Glue.
Experience with managing AWS infrastructure as code, including the use of Cloud Formation, Git, and GitLab.
Excellent oral and written communication skills.
Strong presentation skills and the ability to communicate analytical and technical concepts with confidence and in an easy-to-understand fashion to technical and non-technical audiences.
Bachelor or Master Degree in Computer Science or relevant field is required.

Equal Opportunity Employer (to be included with job board posts, not Wavicle website)
Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.","Wavicle Data Solutions
4.3",Remote
728,Intermediate/Senior Data Analyst,"Driven by the mission to democratize education, Paper is the leader in personalized learning. Partnering with innovative schools and school districts, Paper helps deliver true educational equity through their category leading Educational Support System (ESS) that offers virtual access to 24/7 tutors and essay reviewers. Founded in 2014, Paper philosophically believes that all students should be given the tools and resources to reach their academic potential, independent of socio-economic status, geography, language or other barriers. Today, Paper is partnered with over 700 schools and supports over 750,000 students. We are headquartered in Montreal, Quebec with remote employees across the US and Canada. Paper is proud to have been named by GSV as one of the most transformational growth companies in digital learning .
Paper is looking for an experienced Data Analyst to join our growing R&D and analytics team. This position will be responsible for conducting full lifecycle analysis for cross functional teams. This will include requirements elicitation, domain modeling, experiment design, data reporting, and long-term reporting maintenance. The data analyst will also be expected to participate in maintaining and extending existing data transformation pipelines as well as monitoring performance and quality control plans to identify improvement opportunities. The ideal candidate is an experienced data enthusiast who enjoys acting as an enabler and gatekeeper for the company's data so stakeholders can understand and use it to make strategic business decisions. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of uncovering new insights from data to support the company's mission and growth.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.

Acquire data from primary or secondary data sources.

Participate in fulfilling data requests from multiple teams.

Design and carry-out experiments to test business assumptions or assess the impact of interventions.

Prepare reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data and suggest data-driven interventions.

Collaborate with data engineers, data scientists, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance.

Create appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary.

Work with management to prioritize business and information needs.

Requirements

Technical expertise regarding data models, database design development, data mining and segmentation techniques.

Knowledge of statistics and experience using statistical packages for analyzing datasets.

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.

Adept at queries, report writing and presenting findings.

Strong project management and organizational skills.

Experience supporting and working with cross-functional teams in a dynamic environment.

Programming experience (Python, R, Mathlab, etc).

We are looking for a candidate who has attained a degree in Mathematics, Physics, Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Having prior experience using the following software/tools is a plus:

Experience with databases (SQL),

Experience with ELT frameworks (e.g. dbt)

Experience in experiment design

Experience with reporting packages (Tableau etc)

Position can be located in any geography in the US or Canada.
About Paper

A great place to work! Paper offers a fast-paced, dynamic, inclusive work environment where all employees have an impact. You will be challenged to achieve, develop, and grow as part of a hyper-growth company.

The diverse experiences, ideas, and identities of PAPER's team members help us make better decisions and drive great results. We foster an inclusive work environment that welcomes team members of all backgrounds and perspectives. We are committed to providing a meaningful environment for every member of our team. We hire exceptional people and reward them with trust, autonomy, mentorship, and growth.

We are naturally curious and have strong attention to detail. We love working in a team environment where trust is key and we all strive to make an impact every day. If this sounds like the right fit, please apply and come work with us.",Paper,Quebec
729,Data Engineer (Only for those on the autism spectrum),"Specialisterne Canada is recruiting on behalf of CIBC!

Specialisterne Canada specializes in working with businesses to hire people on the autism spectrum or who identify as neurodivergent[1]. Presently, Specialisterne Canada is working with CIBC to recruit for a several positions in downtown Toronto.

Specialisterne Canada provides recruitment, staffing solutions and management support to businesses interested in creating a more neurodiverse workforce. Specialisterne has an expertise in developing more comfortable processes and work environments where employees can feel productive and supported. We help managers understand the strengths of their employees and implement strategies to help them thrive in the workplace.

CIBC places a high value on diversity in its workforce, recognizes the business benefits that accrue from responding to challenges from multiple perspectives, and is exercising a leadership position in the hiring of people with disabilities.

Applications should be submitted in full no later than July 2nd, 2021.

DATA ENGINEER

Full-time, Permanent

Downtown Toronto/Remote

Are you interested in using and developing your skills in software development? Do you enjoy problem solving and critical thinking? Does transforming data into technology-based solutions sound like something you would enjoy?

Here is what you will do:

Develop technology-based solutions to identify potential money laundering as part of governmental compliance
Work alongside a team of Business Systems Analysts to understand business requirements and define technical infrastructure
Design and develop various applications following an agile development process to meet business needs
Perform unit testing to identify bugs and make adjustments as needed to ensure system functionality
Work with data to construct pipelines, apply transformation and cleansing rules and assess data quality

What you will bring:

Have a degree or diploma in Computer Science, Computer Engineering, Data Science, Analytics, Information Technology or a similar discipline
Use your Scala or Spark programming skills to perform analysis and develop applications in line with business requirements
Use your knowledge of SQL or other relational databases to retrieve, manipulate and manage data
Enjoy taking an experimental approach to solving problems and challenges while leveraging your critical thinking skills

Nice to have (not requirements):

Knowledge or experience with Hadoop

[1]Neurodiversity is the concept that there is great diversity in terms of how human brains are wired and work. For the purposes of this recruitment program, this umbrella term has been defined to include but not be limited to conditions such as Autism, ADHD/ADD, PDD-NOS, Mental Health Conditions, Learning Disabilities, and similar ways of being.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Dental care
Disability insurance
Extended health care
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Work remotely:

Temporarily due to COVID-19","Specialisterne Canada
2.6",Midtown Toronto
730,Data Engineer (4-month contract),"ABOUT US

CI Global Asset Management is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.


POSITION: Data Engineer
LOCATION: Toronto (M5J 0A3)
STATUS: Contract (6 months)


JOB OVERVIEW

We are currently seeking a Data Engineer to join our Client Reporting and Data Management team. The successful candidate will work closely with our data science team on the development of our centralized predictive analytics function. In this role, you will assist with solving high-value business problems by extracting and manipulating large, complex datasets for use by data scientists. The role will be a four month contract position, with an option to extend based on performance.


WHAT YOU WILL DO

Collaborate with business analysts, data scientists, software engineers, and solution architects to develop data pipelines to feed our data marketplace
Extract, analyze & interpret large, complex datasets for use in predictive modelling
Utilize AWS tools to develop automated, productionized data pipelines
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Develop and support ETL code for data warehouse and data marts to support the reporting and data analytic systems.


WHAT YOU WILL BRING

Experience

At least 1 year of work experience in quantitative analysis
Strong CS fundamental, Data Structure and Algorithm knowledge
Strong understanding of Statistics
Experience working and preparing data for Data Science / Machine Learning models preferred
Experience with large-scale, AWS big data storage such as S3 and EBS
Experience creating ETL jobs using AWS Glue
Experience with AWS Data pipeline tools like Cloudwatch and Stepfunctions
Experience working with data preparation tools like Talend
Experience in the Financial Services Industry is an asset

Education/Training

Post-secondary degree in a quantitative discipline

Knowledge, Skills, and Abilities

Strong knowledge with programming methodologies (version control, testing, QA) and agile development methodologies.
In-depth knowledge of AWS tools required to develop automated, productionized data pipelines
In depth knowledge of and experience with relational, SQL and NoSQL databases
Fluency with SQL, R and Python (pandas, boto3, scikit-learn, sparkmagic)
Experience working with large, complex datasets
Excellent communication, writing and interpersonal skills


WHAT YOU CAN EXPECT FROM US

Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:

Recognition & Compensation
Training & Development
Health & Well-being
Communication & Feedback


If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.

Only qualified candidates selected for an interview will be contacted.

CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.


Posting Tags: IND# #LI-POST","CI Financial
3.4",Midtown Toronto
731,Data Engineer - Salentica,"SS&C is a global provider of investment and financial services and software for the financial services and healthcare industries. Named to Fortune 1000 list as top U.S. company based on revenue, SS&C is headquartered in Windsor, Connecticut and has 20,000+ employees in over 90 offices in 35 countries. Some 18,000 financial services and healthcare organizations, from the world's largest institutions to local firms, manage and account for their investments using SS&C's products and services.

Job Description

Data Engineer

Location: King Street, Toronto

SS&C Technologies Holdings, Inc. is a global provider of financial services software and software-enabled services. Founded in 1986, SS&C has built the most comprehensive powerhouse of software technology in the financial services industry – technology that complements our unrivaled expertise and professionalism in fund administration, insurance and pension funds, and asset and wealth management accounting and operations. Named by Forbes as one of America’s best midsize employers, SS&C has more than 20,000 employees and 15,000 clients worldwide, and is headquartered in Windsor, Connecticut, with offices throughout North America, Europe, Asia Pacific, Africa, and Australia.

SS&C Salentica, a subsidiary of SS&C Technologies is an industry-leading provider of software and services to the Financial Services industry. We are currently looking for an industry proven, self-motivated Product Manager to join our team of experienced professionals. The successful candidate will be a conscientious worker with a record of success, who has demonstrated they can work collaboratively and adapt to changing technologies.

Responsibilities:

Build data driven systems, architectures, and platforms to provide innovative solutions for long-term analytical outputs and cloud based application development projects.
Participate on cross-functional teams of technology, product, and business specialists to deliver best-in-class, customer-centric, big data projects by leveraging leading edge tools and technologies.
Use strong technical and quantitative knowledge and skills to identify new opportunities for business solutions within vast amounts and varieties of data, delivers compelling proposals, defines requirements, designs new projects, and guides them through successful delivery and validation to drive business growth.
Translate business problems into analytical, data-driven methodology to improve business efficiencies and make significant financial gains.
Communicate complex analysis in a clear, understandable way to non-experts.
Design and continuously improves algorithms. Mines raw, relevant data from a variety of sources to identify patterns and correlations and to generate best-in-class actionable and meaningful insights.
Manage stakeholders and guides them in unlocking the value in their data.
Influences architectures that will lead to transformation of data analytics platforms and information technology overall.

Qualifications:

Minimally requires a Master's degree, or Bachelor's degree and 2 years of related experience, or high school degree and 4 years of related experience.
Experience in the Financial Services industry
Experience with CRM applications and/or digital reporting portal applications
Technical skills with any or all of:

Java programming, AWS infrastructure, Linux, Bash scripting

Self-motivator; able to grasp concepts quickly with minimal supervision, take ownership of problems and follow them through to completion
Intermediate professional working on projects of a moderate scope or on varied tasks that require resourcefulness, self-initiative, and significant independent judgement
Outstanding communication skills; both oral and written
Demonstrates a developing functional knowledge to evaluate the implications of issues and make recommendations for solutions.
Guide less experienced team members. May recommend new procedures.

SS&C Offers:

An extensive health benefit plan
RRSP Matching Program and Bonus Potential
Generous training allowance and Tuition Reimbursement Program
Candidate Referral Program
Business casual work environment
Work/Life Balance
Close to all transit

To further explore this opportunity, please APPLY NOW through our careers page on the corporate website. No phone calls please. We thank all candidates for their interest, but only those under consideration will be contacted.

#LI-LM1

Unless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. SS&C offers excellent benefits including health, dental, 401k plan, tuition and professional development reimbursement plan. SS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.","SS&C Technologies
3.1",Midtown Toronto
732,"Data Engineer - Azure - Toronto, Canada","Join a team of passionate thought leaders in a dynamic and collaborative environment! The Cognizant Microsoft Business Group (MBG)'s Global Delivery Center is growing fast and we're looking for our next Azure Data Engineer to join us.

What impact will you have in this role?

Every role at the Cognizant Microsoft Business Group (MBG) is equally important in the grand scheme of things and everything we do is team work. Through team work, building relationships internally and at times with clients, understanding context at all times and what is important, and getting comfortable with influence and persuasion you will stand out as an expert in your field.

As we continue to scale we're looking for the market's best Azure Data & AI specialists to help us grow our business' fastest growing practice. You'll be working with the industry's biggest players, delivering innovative greenfield Data Platform builds, Data Integration programmes and implementing bespoke High-Level Data Architectural designs.

What type of experience do you need to be successful in this role?

Strong experience using the Microsoft Azure Data Stack (ADFv2, Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks, Analysis Services, Cosmos DB)

Azure data migration patterns

Knowledge of C# essential

Agile methodology experience essential

CI/CD, Azure DevOps experience, highly desirable

Customer/client-facing consulting skills

Ability and desire to mentor junior team members.

3+ years current and deep experience with implementing large engagements. Proven experience managing projects through the entire project lifecycle. This includes managing multi-phase/multi-dimensional/multi-resource projects to conclusion while maintaining high customer satisfaction

3+ years experience assessing feasibility of migrating customer solutions and/or integrating with 3 rd party systems both Microsoft and non-Microsoft platforms

2+ years of experience and advanced domain knowledge in one or more vertical industries: manufacturing, financial services, government, legal, healthcare, property management

What personality traits and other capabilities are important for this role?

Our consultants are self-motivated and pragmatic with strong problem-solving skills and a passion for crafting great solutions coming with a wealth of experience or talent that enables quality software delivery. They understand the best approach to architecture and development is through blending technologies and methodologies appropriate to the task at hand. The goal is to contribute to the clients' long lasting success to enable us to expand our business and clientele.

Security Responsibility:
All employees must act in accordance with the Cognizant Microsoft Business Group (MBG)'s corporate security standards.
ABOUT THE COGNIZANT MICROSOFT BUSINESS GROUP (MBG)

The Cognizant Microsoft Business Group (MBG) has a singular purpose—advancing your cloud modernization journey with focus, simplicity and scale. The Microsoft Business Group is an end-to-end Microsoft-centric cloud solutions and managed services provider that leverages extensive experience and IP to deliver constant innovation and business value, powered by the Microsoft Cloud platform. We are designed to reflect how you think about cloud transformation from a platform native perspective. Our dedicated experts and trusted blueprint deliver your digital difference through the Microsoft Cloud: Azure, Microsoft 365 and Dynamics 365. We turn digital potential into real business performance at speed.

Who We Are

We are the destination employer for Microsoft-committed professionals, providing depth of specialization and differentiated career paths. We have authentic conversations, build connections and grow careers while centering ourselves around our employees. We are a global team of certified consultants across all relevant technologies, coupled with cloud focused advisory consultants. With our supercharged talent, we are the world's best Microsoft partner. We prioritize investing and expanding.

EQUAL EMPLOYMENT OPPORTUNITY

As a Global Cloud Transformation Consultancy business, the Cognizant Microsoft Business Group (MBG) understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. We are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment.

The Cognizant Microsoft Business Group (MBG) prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life-cycle at Cognizant Microsoft Business Group (MBG).",Cognizant's Microsoft Business Group,Midtown Toronto
733,Data Engineer x 2 - Mississauga,"Our retail industry client is looking for 2 Data Engineers to join their team on a permanent hire basis.

You will be part of our innovation hub located in downtown Toronto where your desire for impact will only be matched by your innate ability to collaborate with other like minded individuals to come up with creative solutions to our retail data science problems

Job Description

Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.


Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.


Working with Analytics and Product Management to ensure optimal data design and efficiency.


Assisting Data Analysts and Data Scientists with pipeline and model deployment


Use an analytical, data-driven approach to drive a deep understanding of our fast changing business.


Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.
.

Advantages

work from home initially until quarantine is lifted


be part of a new department working on high profile projects




Responsibilities
Job Description

Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.
Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.
Working with Analytics and Product Management to ensure optimal data design and efficiency.
Assisting Data Analysts and Data Scientists with pipeline and model deployment
Use an analytical, data-driven approach to drive a deep understanding of our fast changing business.
Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.


Qualifications
Job Requirements

Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance or related quantitative field, or equivalent practical experience.
Experience and proficiency with SQL and SQL-like languages
More than 3 years of software engineering experience, especially working on back-end data infrastructure.
Proficiency with at least one of the following languages: Java, Python, Scala.
Proficiency with Spark and/or similar tools in Hadoop/YARN environment and comfortable with Linux operating system.
Ability to creatively solve problems in a fast paced, rapidly changing environment
Ability to navigate ambiguity, drive solutions forward and bring stakeholders along.
Strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders.
Strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs.


Summary

minimum 3 years software engineering especially working with back-end data infrastructure
Proficiency with at least one of the following languages: Java, Python, Scala
Experience and proficiency with SQL and SQL-like languages
Proficiency with Spark and/or similar tools in Hadoop/YARN environment and comfortable with Linux operating system.","Randstad
4.2",Mississauga
734,Data Solution Architect,"Summary: Onix Solution Architect helps customers transform and evolve their business through the use of Google’s global data center and software products. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of how technology is used in the workplace.
You swiftly problem-solve technical issues for customers to show how our products can make businesses more productive, collaborative, and innovative. You work closely with a cross-functional team of web developers and systems administrators, not to mention a variety of both regional and international customers. Your relationships with customers are crucial in helping Google grow its business and bringing our product portfolio into companies both big and small around the world.
You are a Solution Architect with excellent technical, communication, and organizational skills. Your previous experience with cloud platform and infrastructure products, search products, content/document management repository systems, and SQL-based relational databases will be on display as you engage with customers to understand their business and technical requirements.
As a Cloud Platform Solution Architect, you will work hand-in-hand with the Sales team to introduce Google Cloud Platform to our customers. You will help prospective customers and partners to understand the power of Google Cloud Platform, explaining technical features, and problem-solving key technical issue


Scope/Level of Decision Making: This is an exempt position operating under limited decision-making and supervision. Position performs a variety of assigned activities, referring more complex issues to the manager.

Location: Remote- Nationwide, Remote- Ontario, Remote- Quebec


Primary Responsibilities

Lead strategic cloud application development discovery session to help customers understand the value of cloud application development and how to position it within their organization.
Proactively help customers address all technical issues that may arise throughout the entire pre-sales cycle.
Create customer and partner connections to help grow Onix name recognition in the data space.
Establish strategic customer relationships and become their go-to trusted advisor for Big Data needs.
Ability to facilitate demonstrations, proof of concepts, and public-facing presentations.
Use Google Cloud Platform and Amazon Web Services tools to build Enterprise-grade Big Data solutions.
Architect new cloud-based data pipelines.
Ability to bring together multiple data sources into a unified data warehouse.
Apply analytics and visualizations to customer data sets.
Assist in strategic direction and planning for the growth of the Cloud Data Team.
Quickly architect sound cloud solutions to radically different customer environments.
Establish strategic customer relationships and become the technical go-to resource for answers as well as a trusted cloud advisor.
In-depth understanding and the ability to demonstrate expertise in designing, deploying, and maintaining custom enterprise web applications.
In-depth understanding and the ability to demonstrate expertise in using a variety of development languages.
In-depth understanding and the ability to demonstrate expertise to determine the best migration path from legacy or on-prem applications into public cloud environments.
Review and analyze customer architecture at the domain and product level and translate and evolve them into cloud-ready applications.
Staying in constant communication with customers to ensure Onix is addressing all of their needs during the pre-sales cycle.
Learning and maintaining an in-depth understanding of current and new development technologies and industry standards.
Assist account manager with technical discovery and responsible for all technical scoping activities during the creation of the Statement of Work.
Ability to frequently travel throughout the United States and Canada.

Required Skills and Experience

Degree in Computer Science or Math (or related technical major) or equivalent practical experience (math strongly preferred).
Experience with big data concepts (i.e. analysis, extraction, schema, lineage, etc.) for complex and large data sets.
Experience with REST API development.
Experience with microservice applications and cloud-based services, with data lake concepts for landing, refining, and analyzing data.
Developing canonical data models (for example conformed dimensions) for enterprises.
Migrating large data sets from on-prem to cloud environments.
Developing data pipelines for large-scale ETL transformations.
Experience with large data sets and Enterprise-grade databases (structured and unstructured).
Experience architecting and building data pipelines.
Deep understanding of the ETL (extract, transform, load) process.
Experience extracting data from multiple sources via APIs and scripting.
Experience transforming data through field mapping, programmatic rulesets, and data integrity checking.
Able to expertly convey ideas and concepts to others.
Excellent communication skills (verbal, written, and presentation)
Creative problem-solving skills and the ability to design solutions not immediately apparent.
Ability to participate in multiple projects concurrently.
Customer-oriented and shows a bias for action.
Able to function in a highly dynamic team that moves rapidly from idea to planning to implementation.
Highly adaptable with the ability to learn new technologies quickly without direct oversight.
Strong knowledge of Python Machine Learning standard libraries.
Mastery of N-dimensional NumPy arrays.
Mastery of pandas data frames
Ability to perform element-wise vector and matrix operations on NumPy arrays.
Strong knowledge of Anaconda, Virtualenv, and Jupyter Notebooks
Good functional knowledge of the Tensorflow programming model.
Strong understanding of all commonly used Machine Learning models and the main algorithms that compose the models.
Ability to rapidly prototype proofs-of-concept and technical demonstrations.
Ability to conduct technical BD/ML workshops enabling the audience ( researchers, Doctoral and postdoctoral CS PhDs, ML PhDs, Mathematicians, Scientist etc) to adopt the cloud technologies to for the development and implementation of BD/ML for scientific research.
Good knowledge of common networking concepts.
Strong customer-facing communication skills.
Experience in writing software in Java or Python.
Familiarity with web-related technologies (web applications, web services, service-oriented architectures) and network/web-related protocols.
Creative problem-solving skills and a drive to solve difficult issues.
Ability to stay positive and motivated while under pressure.
Ability to participate in multiple projects concurrently.
Excellent communication skills (verbal, written, and presentation)
Customer-oriented and shows a bias for action.
Provide on-time, well-executed work that leads to excellent customer satisfaction.
Able to expertly convey ideas and concepts to others.
Highly adaptable with the ability to learn new technologies quickly without direct oversight.
Good understanding of the built-in data types. ( lists, dictionaries, tuples sets).

Preferred Skills and Experience

Google Cloud Platform Data Engineer Certification.
Experience with Big Data, PaaS, and IaaS technologies.
Experience in and understanding of data and information management - especially as it relates to IaaS and PaaS.
Experience architecting and developing software for scalable, distributed systems.
Understanding of the public cloud market and pain points driving enterprise cloud adoption.
Education: Bachelor's Degree
Travel Expectation: 25% travel expected


It is the policy of Onix to ensure equal employment opportunity in accordance with the Ohio Revised Code 125.111 and all applicable federal regulations and guidelines. Employment discrimination against employees and applicants due to race, color, religion, sex, (including sexual harassment), national origin, disability, age (40 years old or more), military status, or veteran status is illegal.

Onix will only employ those who are legally authorized to work in the United States or Canada. This is not a position for which sponsorship will be provided. Individuals with temporary visas such as E, F-1, H-1, H-2, L, B, J, or TN or who need sponsorship for work authorization now or in the future, are not eligible for hire.","Onix Networking Corp
4.2",Quebec
735,Applied Deep Learning Scientist (Focus on Computer Vision),"Location: Montreal, Canada

Dans des marchés en rapide évolution, les clients à travers le monde font confiance à Thales. Thales est une entreprise où les personnes les plus brillantes du monde entier se regroupent pour mettre en commun leurs idées et ainsi s'inspirer mutuellement. Dans tous les secteurs où œuvre Thales, notamment l’aérospatiale, le transport, la défense, la sécurité et l'espace, nos équipes d’architectes conçoivent des solutions innovantes qui rendent demain possible dès aujourd’hui.

Carrefour mondial de l’intelligence artificielle, Montréal est le foyer du nouveau centre de recherche et de technologie spécialisé en intelligence artificielle (cortAIx) collaborant avec les principaux groupes canadiens de recherche en intelligence artificielle à Montréal et à Toronto. S’appuyant sur ses compétences dans les principaux marchés industriels, Thales donne vie à l'intelligence artificielle au profit de ses clients tout en créant de passionnants emplois pour les chercheurs et les développeurs experts en intelligence artificielle en vue de trouver des solutions qui transformeront notre monde, du fond des océans aux confins de l'univers et du cyberespace. Ayant très tôt opté pour le modèle d’innovation ouverte et collaborative, Thales procède actuellement à la création de la structure du centre de recherche et de technologie spécialisé en intelligence artificielle (cortAIx). Piloté par Thales, le centre cortAIx, en collaboration avec l'Institut québécois d'intelligence artificielle (MILA), l'Institut de valorisation des données (IVADO) et l’Institut Vector de Toronto, est situé dans le célèbre quartier Petite-Italie, au cœur de la communauté de l’innovation à Montréal.

In fast changing markets, customers worldwide rely on Thales. Thales is a business where brilliant people from all over the world come together to share ideas and inspire each other. In aerospace, transportation, defence, security and space, our architects design innovative solutions that make our tomorrow's possible.

Montreal – a world leading AI hub, is home to new Centre of Research & Technology in Artificial Intelligence eXpertise (cortAIx) collaborating with leading Canadian AI research groups in Montreal and Toronto. With competencies in major industrial markets Thales is bringing artificial intelligence to life for our customers creating exciting jobs for AI researchers and developers who will create solutions that will transform our world from the bottom of oceans to the depths of space and cyberspace. As an early adopter of open, creative and collaborative innovation model, Thales is building the Centre of Research and Technology in Artificial Intelligence eXpertise (cortAIx). Led by Thales, cortAIx, in collaboration with the MILA (Artificial Intelligence Institute of Quebec), the IVADO (Institute of Data Valorization) and the Vector Institute of Toronto, is located in Montreal’s famous Little Italy, in the heart of Montreal’s innovation community.

RAISON D’ÊTRE:

Un chercheur en intelligence artificielle (IA) appliquée en recherche et technologie (R&T) est chargé de découvrir, d'activer et d'intégrer des concepts d'IA innovants dans les solutions Thales. Il / elle prouve leur viabilité à travers la mise en œuvre de Proofs of Concept (PoC) et guide leur croissance de maturité à travers des prototypes et des démonstrateurs qui à leur tour illustreront et permettront leur plein potentiel commercial.

MISSIONS PRINCIPALES

En tant que chercheur en IA appliquée à la recherche et à la technologie, vous dirigerez les activités clés tout au long de nos projets au rythme rapide.

Pour réussir dans ce rôle, la curiosité pour ce qui est nouveau, la volonté de remettre en question le statu quo, l'ouverture d'esprit et la pensée originale sont essentielles. L'individu doit rapidement apprendre et évaluer les nouvelles techniques et technologies afin de décider de les adopter, de les adapter ou de les abandonner. Il doit également être capable de proposer de nouvelles idées, de les présenter, de les remettre en question et de les améliorer continuellement. L'individu doit posséder des compétences techniques approfondies et pratiques et être familiarisé avec les derniers outils et environnements de développement Deep Learning, avec un fort accent sur les applications de vision par ordinateur, afin de contribuer à la mise en œuvre de ces idées.

Proposer des concepts innovants et les mettre en œuvre est rarement un processus individualiste. Le scientifique fait partie d'une équipe multidisciplinaire. Un fort esprit d'équipe et des capacités de travail d'équipe sont obligatoires. Il / elle contribuera en tant qu'expert technique à des projets de Recherche et Technologie au sein de Thales et de ses business units. Par conséquent, de bonnes compétences en communication sont nécessaires.

EXIGENCES

Maîtrise en informatique, ingénierie ou mathématiques
Expérience préalable en intelligence artificielle, apprentissage automatique
Compétences démontrées dans la conception de systèmes d’IA
Bonne base en mathématiques, statistiques et probabilités
Solide connaissance des fondations de l'apprentissage automatique avec un accent sur les applications de vision par ordinateur
Connaissance des architectures traditionnelles d'apprentissage profond (MLP, CNN, UNET, etc.) et des architectures d'apprentissage génératif profond (GAN, VAE) pour les tâches de vision par ordinateur.
Solides compétences en développement avec des frameworks d'apprentissage automatique tels que Scikit-learn, Tensorflow, Keras, PyTorch, Theano
Solides compétences en programmation Python
Connaissance pratique du système d'exploitation Linux
Volonté de contribuer dans un environnement axé sur l’équipe
Capacités de leadership démontrées dans des organisations scolaires, civiles ou commerciales
Capacité à travailler de manière créative et analytique dans un environnement de résolution de problèmes
Compétences avérées en communication verbale et écrite en anglais (conférences, présentations, publications, etc.)

QUALIFICATIONS PRÉFÉRÉES

Doctorat en informatique, ingénierie ou mathématiques
Minimum 3 ans d'expérience en machine learning en Python avec un intérêt pour le Deep Learning
Un historique de développement de logiciels d'IA (Deep Learning Focus) exceptionnel avec des preuves Github (ou similaires)
Compétences démontrées dans la conception de systèmes d’IA
Intérêt démontré pour le Deep Learning appliqué, y compris 1 / stade précoce de préparation des données, augmentation, génération, 2 / réglage systématique du modèle Deep Learning, 3 / modélisation d'expériences de Machine Learning réplicables, 4 / pipeline d'apprentissage profond pour la sélection et la validation de modèles ML.
Expérience de travail avec des langages de programmation tels que C, C ++, Java, des langages de script (Perl / Python / Ruby) ou similaires
Une expertise en apprentissage automatique embarqué (par exemple, quantification du Deep Learning) est un atout majeur
Expérience pratique de la visualisation des données, des outils / langages d'analyse
Travail d’équipe et collaboration démontrés dans des environnements professionnels
Capacité d'établir une crédibilité auprès des clients et des autres membres de l'équipe
Expérience préalable dans un environnement de recherche et technologie ou d'innovation (brevets, conception de systèmes, etc.)
Historique des publications dans les grandes conférences d'Intelligence Artificielle: CVPR, NeurIPS, IJCAI, AAAI, etc.

JOB PURPOSE

A Research and Technology (R&T) Applied Artificial Intelligence (AI) Scientist is responsible for discovering, enabling and integrating innovative AI concepts into Thales solutions. He/she proves their viability through the implementation of Proofs of Concept (PoCs) and guides their maturity growth through prototypes and demonstrators that will in turn illustrate and enable their full business potential.

KEY JOB FUNCTIONS

As a Research and Technology Applied AI Scientist, you will drive the key activities throughout our fast-paced projects.

To be successful in this role, curiosity for what is new, willingness to challenge the status quo, open-mindedness and out-of-the-box thinking are crucial. The individual should quickly learn and assess new techniques and technologies in order to decide whether to adopt, adapt or discard them. He/she also needs to be able to come up with new ideas, present them, challenge them and improve them continuously. The individual must possess deep, hands-on technical skills and be familiar with latest Deep Learning development tools and environments, with a strong focus on Computer Vision applications, in order to contribute to the implementation of those ideas.

Coming up with innovative concepts and implementing them is rarely an individualistic process. The scientist is part of a multi-disciplinary team. Strong team spirit and teamwork capabilities are mandatory. He/she will contribute as a technical subject matter expert to Research and Technology projects across Thales and its business units. Therefore, good communication skills are required.

ESSENTIAL SKILLS AND QUALIFICATIONS

PhD/Masters degree in computer science, engineering or mathematics fields
Prior experience in artificial intelligence, machine learning
Minimum 3 years of machine learning experience in Python with interest in Deep Learning
A track record of outstanding AI (Deep Learning focus) software development with Github (or similar) evidence
Demonstrated abilities in designing AI systems
Demonstrated interest in applied Deep Learning, including 1/ early stage of data preparation, augmentation, generation, 2/ systematic Deep Learning model tuning, 3/ replicable Machine Learning experiments modeling, 4/ Deep Learning pipeline for ML model selection and validation.
Work experience with programming languages such as C, C++, Java, scripting languages (Perl/Python/Ruby) or similar
Expertise in Embedded Machine Learning (e.g., Deep Learning quantization) is a strong plus
Good foundation in mathematics, statistics and probability
Strong knowledge of Machine Learning foundations with a focus on Computer Vision applications
Knowledge of mainstream Deep Learning architectures (MLP, CNN, UNET, etc) and Deep Generative Learning architectures (GAN, VAE) for computer vision tasks.
Strong development skills with Machine Learning frameworks such as Scikit-learn, Tensorflow, Keras, PyTorch, Theano
Strong Python programming skills
Working knowledge of Linux OS
Eagerness to contribute in a team-oriented environment
Demonstrated leadership abilities in school, civil or business organisations
Ability to work creatively and analytically in a problem-solving environment
Proven verbal and written communication skills in English (talks, presentations, publications, etc.)

Chez Thales, nous proposons des CARRIÈRES passionnantes, pas de simples emplois. Fort de ses 80 000 collaborateurs dans 68 pays, Thales a mis en place une politique de mobilité permettant, chaque année, à des milliers d'employés de faire progresser leur carrière tant dans leur domaine d’expertise que dans de nouveaux domaines de compétences, cela aussi bien dans leur pays d’origine qu’à l'étranger. Ensemble, nous pensons qu’adopter une politique de flexibilité est une manière plus actuelle de travailler. C’est ici que commence votre parcours exceptionnel, postulez sans tarder!

At Thales we provide CAREERS and not only jobs. With Thales employing 80,000 employees in 68 countries our mobility policy enables thousands of employees each year to develop their careers at home and abroad, in their existing areas of expertise or by branching out into new fields. Together we believe that embracing flexibility is a smarter way of working. Great journeys start here, apply now!

Thales s’engage à promouvoir un lieu de travail diversifié et inclusif pour tous. Thales s’engage à fournir des accommodements à toute les étapes du processus de recrutement. Les candidats retenus pour une entrevue qui ont besoin d’accommodement sont priés d’en informer à la suite de l’invitation pour une entrevue. Nous travaillerons avec vous pour répondre à vos besoins. Toutes les informations relatives à l'accommodement fourni seront traitées de manière confidentielle et utilisées uniquement dans le but de fournir une expérience de candidat accessible.

Thales is committed to a diverse and inclusive workplace for all. Thales is committed to providing accommodations in all parts of the interview process. Applicants selected for an interview who require accommodation are asked to advise accordingly upon the invitation for an interview. We will work with you to meet your needs. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.","Thales Group
3.7",Montreal
736,Software Developer – Data Science,"Join our team

The Data Strategy & Enablement team is on a continuous journey towards helping TELUS become a world-class leader in data solutions, doing so by delivering data analytics capabilities built upon unified scalable platforms, advanced AI tooling, high quality data, and a data-product and data platform oriented culture while always keeping an eye on the horizon, preparing for the next big thing.

We are entrepreneurial and passionate, believers that so much more is possible and can be achieved by creating value and great outcomes for our customers, team members, communities, and environment and that through meaningful transformation we can integrate dynamic change in our professional lives.

Together, we will develop and execute strategic programs that will enhance the experience for TELUS subscribers and internal stakeholders across TELUS.

Always wanted to work with a team of innovators and be part of a culture that embraces creativity and collaboration? If so, we’d love to talk with you!
Here’s the impact you’ll make and what we’ll accomplish together

As a Software Developer - Data Science, you’ll be a part of the team and journey that will transform the way we do business across various domains. You will provide vision and strategic guidance to evolve from common static analysis to dynamic machine learning deployment.

You will combine your expert knowledge of data science with your strong software development skills to automate and facilitate machine learning model development, training and deployment and will leverage your experience in building reusable algorithms, functions and libraries.

You will be working in an environment defined by continuous integration on multiple solutions that will exchange information. You will have to understand a complex architecture and guide its evolution.

You’ll collaborate with teams across the company to help identify new business opportunities while championing data driven decision making and the accelerated adoption of AI.
Here's how
Lead the software development and implementation of ML & AI and Big Data solutions
Support and evolve the Advanced Analytics and Data Management roadmap by leveraging industry research, best practices and emerging tools/technology on Software Development
Focus on code quality and timely delivery of AI products and solutions with a focus on performance, maintainability and scalability
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities
Identify opportunities for code optimization and refine to improve effectiveness/accuracy and enhance ROI
Collaborate with Data Scientists and Data Engineers within TELUS as well as external business stakeholders
Influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset

Qualifications
You're the missing piece of the puzzle
You are recognized for addressing business needs via your application of software development, data mining and analysis, predictive modeling, statistics and other advanced analytical techniques in which you have previous hands-on work experience
3+ years of experience working in a software engineering role with a track record of building highly scalable and robust systems
You are sought out when it comes to analyzing and translating technicalities into business implications
You have solid development experience with consuming and designing RESTful APIs in Python
You are comfortable using various front end frameworks like React
You are familiar with at least one of the cloud computing platforms - GCP, AWS, Azure
Strong understanding of application level and system level software design patterns
Great-to-haves
BS/MS degree in Computer Science, Engineering, or relevant field
Machine learning and data science knowledge
Experience with agile methodology and work in a start-up environment
GCP or other cloud certifications
A bit about us
Our business is connecting Canadians. Our social impact is using our world-leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. When you join our team, you’re helping us make the future friendly. We’re committed to diversity and equitable access to employment opportunities based on ability —your unique contributions and talents will be valued and respected here.

Primary Location: CA-ON-Toronto
Other Locations: CA-BC-Victoria, CA-QC-Montreal, CA-QC-Quebec City, CA-BC-Vancouver, CA-ON-Toronto, CA-AB-Edmonton, CA-ON-Ottawa, CA-BC-Burnaby, CA-AB-Calgary

Schedule: Full-time","TELUS
3.9",Midtown Toronto
737,"Senior Actuarial Manager, Data Science","What you will do

Join a leadership team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. The insurance industry is undergoing a data-driven, technology revolution and you will be in the driver’s seat.

Insurance pricing, underwriting, claims and other core insurance functions are all looking for actionable insights that can be coaxed out of our data. You and your team will work with these business areas to realize this value & further embed data science in our operations.

Our leadership team collectively seeks to expand our very strong and diverse talent base. You will take shared ownership for continuing this successful growth.

What you need to succeed

As a senior manager, you will need the following skills and experience to succeed in the role:

7+ years of experience in the general insurance industry.

Expert knowledge in at least one insurance discipline eg: Pricing, claims, underwriting, marketing, fraud or other. Ideal candidates have experience leading teams in multiple disciplines.

The capacity to oversee, develop and mentor a highly productive team of data scientists, actuaries & insurance professionals

Cross-functional skills that allow you to straddle the worlds of data scientists, actuaries, engineers & core insurance functions.

The ability to establish a vision with stakeholders and create a culture that treats data as an essential asset

The drive to advance our department’s capability to evolve the business by leading the development and deployment of long-term tools.

What sets you apart

Amazing people skills . You are able to translate and communicate complex algorithms to non-technical experts. You are someone who understands that it is not enough to just have a great algorithm but critical to generate buy-in for the solution.

Excellent leadership skills . You constantly seek to improve the engagement, innovation and empowerment of our team members

Subject matter expert. You are recognized as an expert in one or more areas of; pricing, underwriting, claims, predictive modeling, data science, marketing or other specializations.

A can-do team player. You are willing to roll-up your sleeves and do whatever is needed to move projects forward. That means you will take opportunities be a project manager, developer, modeler and chief communicator of solutions.

Customer focused. You prioritize building relationships with business partners to identify their needs and develop innovative solutions.

Additional Information

A viva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.","Aviva
3.7",Montreal
738,"Senior Data Engineer, R&D","BenchSci's vision is to help scientists bring novel medicine to patients 50% faster by 2025. We do this by empowering scientists to run more successful experiments with the world's most advanced, easy to use biomedical artificial intelligence software platform, thereby avoiding delays that slow the progress of medicine to clinical trials. Backed by F-Prime, Inovia, Golden Ventures, and Google's AI fund, Gradient Ventures, we provide an indispensable tool for more than 41,000 scientists that accelerates research at 15 top 20 pharmaceutical companies and over 4,300 leading academic centers. We're a CIX Top 10 Growth company, certified Great Place to Work®, and top-ranked company on Glassdoor.

We are currently seeking a Senior Data Engineer, R&D to join our Machine Learning team. Reporting to the Engineering Manager, you will work on creating the data infrastructure that supports BenchSci’s supervised learning pipeline for the R&D problems that we are solving. In this role, you will work closely with domain experts and ML engineers in the earliest stages of building a new feature through domain modelling, data preparation, feature engineering, and rapid prototyping of heuristics or baseline models. Success will be measured by the continuous improvement of our model quality through a data-centric approach to model training, as well as the velocity with which we can ship new R&D features.

This position is open to candidates who would like to work remotely (outside of the GTA) or in-person at our Toronto office (post-COVID). For candidates who will be working within the GTA once we return to the office, we will continue to have ongoing remote flexibility of up to 4 days per week (department dependent).
You will:
Collaborate closely with ML and domain experts to solve interesting and challenging problems with respect to extracting ground truth data to train high-quality models
Employ best practices in modern machine learning workflows within a cloud-based environment
Set the baseline performance to beat by the rapid development of specialized heuristics or baseline models
Analyze and evaluate our data sets across the ML lifecycle to ensure they are fit for purpose for both labeling and model training
Work on projects involving some of the largest pharmaceutical companies in the world
Provide troubleshooting analysis and resolution in a timely manner
Have opportunities to work both independently and in pair-programming settings
Be given an unmatched opportunity for growth and development, and to learn from a team of outstanding engineers
You have:
4+ years of experience working as a professional developer
Expertise in Python and programming fundamentals
Expertise in intermediate/advanced SQL and BigQuery or similar serverless data warehousing solutions
Experience with statistical analysis of datasets
Experience with cloud reference architectures for common patterns in data pipelines
Strong cross-team communication and collaboration skills
Nice to haves, but not mandatory qualifications:
A background in Life Science
Working knowledge of data versioning tools such as DVC for machine learning
Working knowledge of distributed systems and data processing fundamentals
Knowledge of distributed data processing abstractions like Beam or Spark
Working knowledge of machine learning data fundamentals such as data splits, training-serving skew, common data representations such as embeddings or multi-hot encodings, sampling strategies for active learning
Working knowledge of how to evaluate classification model quality, such as precision, recall, F1, PR/ROC curves
Our benefits and perks:
A compensation package that includes equity options in the company
An annual Executive Health Assessment at Medcan: All employees get the “executive treatment”
Effectiveness coaching for managers: Onsite, personalized coaching from an executive coach with a doctorate in clinical psychology
Mental health tools and support: Optional mindfulness sessions and a free Headspace account
Complimentary genome sequencing from 23andMe: Find out what your DNA says about your health, traits, and ancestry
Three weeks of vacation, plus another week: Get 15 days to use anytime, and we’re closed Dec 25-Jan 1
Additional days off: Company summer day, your birthday, and earn +1 vacation day annually
Work from anywhere flexibility: Every day right now, and up to 4 days per week once we return to the office
An onsite gym: Keep fit, conveniently, with a Peloton and other great equipment
A great benefits package: Including health and dental

Our Culture:
We believe culture is critical to success and invest accordingly. We live and promote our FASTT values of focused, advancement with speed, tenacity, and transparency. We work hard to maintain an engaging, supportive environment where everyone can do their best work. To learn more, read our culture deck.

Diversity, Equity and Inclusion:
We're committed to creating an inclusive environment where people from all backgrounds can thrive. We believe that improving diversity, equity and inclusion is our collective responsibility, and this belief guides our DEI journey. To learn more, read about our DEI initiatives.

Accessibility Accommodations:
BenchSci provides accessibility accommodations during the recruitment process. Should you require any accommodation, we will work with you to meet your needs.","BenchSci
4.5",Midtown Toronto
739,Data Engineer - Toronto Hub,"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster.

We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.

Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or in our Toronto office - it’s up to you.

Veeva is looking for a data engineer to create ETL pipelines for our Veeva Data Cloud product. We’re building a system to provide our customers with access to billions of records a day with insightful analysis along with aggregations and transformations.

For this role, we need someone who can design flexible data processes and leverage their Python and Scala skillsets to implement them in an AWS cloud environment.

You’ll be responsible for creating and owning the implementation of numerous data analysis features as well as the pipelines that process those features in a multi-tenant, highly parallel system.
What You'll Do
Design and build scripts and tools that perform data analysis, transformations, aggregations, and other augmentations on large sets of in a spark-based AWS environment (EMR, Glue, S3, Redshift, Athena)
Evaluate various pipeline models, tools, and environments and implement these to push data from our sources through your transformations and finally to our customers
Work with product management and data research teams to prototype and test new ideas then take those to production
Work in a fast-paced, test-driven environment
Requirements
BS degree in Computer Science, Engineering or related subject
3 years+ experience working on Apache Spark applications in either Python (PySpark) and/or Scala
Experience creating spark jobs that work on at least 1 billion records.
Intermediate or greater SQL knowledge
Experience creating data pipelines in a production system
Experience working on AWS environments (S3, EMR, Glue, Redshift)
Nice to Have
Experience working with Data Quality techniques
Java development experience
Experience working with Machine Learning/AI models
Experience with AWS glue
Familiarity with agile methodologies
Experience with the following tools: Jira, Git, Terraform
Perks & Benefits
Allocations for continuous learning & development
Annual budget to donate to the non-profit of your choice
Health & wellness programs
#LI-Remote

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances.","Veeva Systems
4.1",Midtown Toronto
740,Machine Learning Scientist - Senior,"Machine Learning Scientist

Since Ron Glozman founded Chisel AI in 2016 (see his full story here) we’ve evolved to be the machine learning leader in the insurance industry. Our software reads insurance forms and extracts key policy data hundreds of times faster than a human. Our advanced AI platform and intelligent workflows automate high volume, repetitive manual underwriting and brokering processes, enabling insurance carriers and brokers to double their business, reduce operating costs, and deliver a better digital customer experience without adding staff. Our customers include some of the world’s largest commercial lines insurance carriers and brokers.

The Opportunity:

We have a rare opportunity for a Senior Machine Learning Scientist who wants to take the latest advances in ML and NLP and build out technology for delivery in production. This is a chance to take your passion for solving complex problems, and apply your findings tactically not just theoretically, as you create solutions to solve a major industry challenge faced by large global customers.

You will lead the collaboration within our team between machine learning and software development, implement best practices, and further iterate on our core AI information extraction competency. You will be a mentor and technical lead to Machine Learning Scientists at Chisel AI who are still in the early stages of their machine learning careers. This is a unique opportunity to get in at the ground level as we scale; to influence the AI roadmap for our entire organization and to revolutionize an industry with data that’s actionable.

Our new Machine Learning Scientist will:

Develop. In this role, you’ll hit the ground running creating production-level code for our core AI capability within your first month. You’ll work closely with the Product Development Manager, Software Developers and Machine Learning Scientists to create new ML algorithms and models, to execute on our product roadmap, and will push the envelope forward in document information extraction.
Research. You will spend 10% of your time researching the latest trends and breakthroughs in NLP and related fields in ML, especially document information extraction. Whether you find this information on Reddit, StackExchange, HackerNews, or in academic journals is up to you, but you’ll be expected to share key takeaways with us.
Collaborate. You will work with our various Product Development teams to iterate, develop and mature best in market product solutions.
Mentor. You will lead and guide the work of Chiselers, suggesting the right approach and tools, quality assuring their work, and helping them grow increasingly knowledgeable and autonomous in using Machine Learning to develop our products.

Our new Machine Learning Scientist has:

The experience. You have 5+ years of experience developing production-level code, preferably in a machine learning or SaaS software environment. You have a strong understanding of machine learning development in Python and have an understanding of information extraction problems and related areas in ML.
The coaching. You have exposure guiding the work of individuals or a small team. You are comfortable working side-by-side with team members and providing technical leadership and best practices for a B2B environment.
The education. Ideally, you hold a master’s degree or Ph.D. in machine learning, computer science, physics, mathematics, statistics, or a related analytical field. We do, however, recognize that not everyone gains their skills this way. If you have a bachelor’s degree in software engineering or computer science and the technical work experience to match, we’d still like to see your profile.
The technical skillset. You have a deep knowledge of Python ML tools, including scikit-learn, and Pandas or similar frameworks. You’ve successfully applied these technologies in the past and are eager to learn new ways to leverage these frameworks.
The intellectual curiosity. You are a solutions-oriented individual who wants to dig deep into and apply the latest research to solve real business problems. You are known for keeping on top of best practices and industry breakthroughs; you are eager to share your expertise with our team.

What do you need to know about Chisel AI?

We are technology enthusiasts and experts pushing the limits on how AI will shape the future of insurance. Having successfully raised one of the largest seed rounds in Canadian history and with partners like Venrock, a leading Silicon Valley venture firm, by our side very little stands in the way of our success.

Chisel AI was named a Digital Disruptor to Watch in 2021 by NEXT Canada, named to the 2020 INSURTECH100 list of the world’s most innovative insurtech companies, won Gold at the 2019 Zurich Innovation World Championship and made the CIX Top 20 Early Companies list celebrating the most innovative technology companies in Canada.

Venture backed and well-funded, Chisel AI has been named as an ""Analytics Arms Dealer"" by Novarica, an IDC Innovator for Insurance Sales Automation Solutions, featured in CB Insights research on Insurtech Startups Modernizing the P&C Value Chain, and included in the recent Strategy Meets Action (SMA) report, “The Top 50 InsurTechs in P&C.”

Why join Chisel AI?

We’re a company with heavy traction, big clients, and a plan to expand rapidly. We’ve assembled a strong and diverse leadership team and are poised to scale and develop talented people of all levels. This is a place where failures turn into opportunities, where we learn from each other and where everyone’s voice is heard. We’re at a unique and rare stage of growth that will give our team and those who join us a chance to put their mark on everything we build.

What you can expect when you apply to Chisel AI

We know that diversity and belonging makes for the best problem solving and creative thinking. Chisel AI is committed to fostering an inclusive and accessible environment where employees feel valued and respected, and where every employee has the opportunity to realize their potential. We want to know what motivates you and we don’t believe that everyone follows the same career path. We are dedicated to adding new perspectives to our team and encourage you to apply if your experience is close to what we are looking for.

We are committed to providing reasonable accommodations, if required, and will work with you to meet your needs.

Due to COVID-19 please expect changes to our standard recruitment process. In all instances, the safety of our team and our candidates is of our utmost concern so we will be conducting interviews virtually and online. We will keep you informed on these changes and ensure that you are prepared in advance with the necessary instructions to conduct the next steps in the recruitment process.

KhGahqDjn3","Chisel AI
5.0",Vancouver
741,"Senior Data Analyst, Growth","We make small businesses more successful through better banking.

Our company is looking for a Senior Data Analyst, Growth to join our growing team as we enter a new phase of expansion We are a Toronto, New York and San Francisco-based, venture-backed startup at the heart of the FinTech movement that is shaping the way financial services are delivered. We are backed by some of the best VCs in the world (Battery, Redpoint, Tom Williams and more) and are growing fast.

Our story

Our company's purpose is to eliminate the pain that small business owners face through their financial management and banking. To achieve this, we're rebuilding business banking from the ground up. Imagine you could start with a clean slate and think of a different way to deliver banking to small businesses. What would you change? What would you keep? These are the decisions that we make every day.

Our product

NorthOne is a mobile, tech-powered bank account built for startups, freelancers, and small/medium-sized businesses (SMBs). Poor financial literacy has an outsized impact on the costs and failure rates amongst SMBs, and we are on a mission to eliminate these problems. We are more than a banking platform, we are the world-class Finance Department that SMBs could never afford.

Our team

We ❤ growth. As a Senior Data Analyst, Growth, you'll partner with our world-class Growth team on generating insights to identify the best areas of opportunity. This is the first hire of its kind at NorthOne - the potential for growth is big! Reporting to our Senior Product Manager, Growth, you'll also benefit from our experienced management team, who have already created and exited startups and come from leadership roles at brands like Square, McKinsey, Google, Frank and Oak, Strava, Instacart, Prodigy, eBay and more.

We're building a product that solves real pain vs the imagined kind. Small businesses are the bedrock of every community and of the American economy. Their storytelling potential is endless, they have been underserved by banking and fintech for far too long, and you'll be their champion. Ready to start?

WHAT YOU'LL BE DOING

Analyzing data to derive insights which identify new opportunities for growth and help us to solve customer problems
Building predictive growth models and dashboards to measure ongoing performance
Partnering with engineering, data science, and other analytics teams to build long-term solutions that allow the business and our customer base to grow effectively
Sharing your findings with the team to make sure stakeholders have all the information they need to make the best strategic decisions
Contributing growth ideas to the team based off insights derived from your own analysis and research

REQUIREMENTS

Today you might be a Data Analyst, Senior Data Analyst, Data Scientist, Product Analyst or the equivalent in your company...or something that we haven't heard of yet - we keep an open mind.

The most important characteristic for our Senior Data Analyst, Growth is your attitude. We want you to join because you don't see roadblocks, you see opportunities to be at your best. You know that somehow, you can figure anything out.

The skills required for this role:
You have experience working with digital products and/or SaaS
You get giddy about building awesome quantitative models using Python/SQL/Excel/Looker
You're a natural communicator and you love diagnosing and solving problems
You're a pro at making complex technology and business processes simple
You know how to connect the dots between departments and stakeholders

Bonus points

You've supported teams that work on quick release and testing cycles
You've worked with Atlassian tools before (JIRA, Confluence, Bitbucket, etc.)
You geek out over technology and/or FinTech

If you are this close to what we've described but aren't sure, apply. Let's figure out together if this is where you could shine.

BENEFITS

Our mission is big and audacious, but we're assembling a team to take the challenge head on.

As a Senior Data Analyst, Growth, you'll be joining a team that prioritizes:

People : Our company is more than just a business. We're a band of brothers and sisters supporting each other on our mission to rebuild business banking. We're really serious about mission, fit, and the people we work with. You'll be part of a rapidly scaling team that reflects these values and keeps this place special.
Diversity : You'll find yourself in an environment that values diversity and inclusivity. We believe that a broad array of lived experiences and backgrounds are essential for creating the best possible product and company culture.
Leadership : You're right in the thick of it, making critical decisions that will clear our path forward.

You'll receive:
Top-tier health/dental benefits: We care about the people we work with and put their health first. NorthOne is proud to offer inclusive health and dental coverage.
Flexible working hours: We don't clock in and out at set times. You know when you do your best work. We celebrate accomplishments, not how many hours are spent at the office.
Unlimited paid time off: We hire talented people and know that they need time off to be at their best. Take as much time off as you need to recharge and make sure you're working sustainably.
The latest computer equipment: We make sure you have the best equipment so you can produce great work.
Professional development budget: We support lifelong learners by covering the cost of classes, workshops and conferences. You'll also get access to our ever-growing library of industry-related books.
Remote get-togethers: Bond with your teammates over shared interests at regular get-togethers. Find like-minded people who are passionate about everything from sport and music to gaming and cooking.
One hell of an adventure!

If you recognize yourself in this job description, let's talk.

NorthOne is proud to be an equal opportunity employer and celebrates diversity. We welcome all applicants regardless of race, colour, gender, age, religion, sexual orientation, disability status or national origin.","NorthOne
4.7",Midtown Toronto
742,Data Management Specialist - Immunogenicity,"For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, we’ll help you build a career that you can feel passionate about.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Support the Scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with Good Laboratory Practices (GLP), Standard Operating Procedures (SOP), Analytical Procedures (AP), and study plans. We are currently looking for a Data management Specialist for our Immunogenicity team located in Senneville, Quebec.




The following are the responsibilities related to the position:

Contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. Follow and ensure the application of GLP, SOPs, special procedures and health and safety rules on their assigned studies.
Perform and review tabulation of results and participate in writing the study report.
Collaborate with the Scientist to compile and assemble study deliverables in an audit ready state for submission to the Quality Assurance department (QA) and answer QA findings.
Preparing or revision of the study summary (e.g. MQS, MVS) when required.
Perform all other related duties as assigned.



The following are minimum qualifications related to the position:

DEC in sciences or AEC
Laboratory experience
An equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above.
Be able to work as part of a team. Have a positive attitude, good interpersonal relationships and professionalism. Adapt to changes. Actively participate in departmental meetings to improve performance and quality. Good understanding of Microsoft Office software and data generating software used in the department relevant to their role.



IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Safety Assessment
Charles River is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state-of-the-art facilities and expert regulatory guidance. From individual specialty toxicology and IND enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. Each year approximately 120 investigational new drug (IND) programs are conducted in our Safety Assessment facilities.","Charles River Laboratories
3.4",Senneville
743,Data Management Specialist - Immunogenicity,"For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, we’ll help you build a career that you can feel passionate about.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Support the Scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with Good Laboratory Practices (GLP), Standard Operating Procedures (SOP), Analytical Procedures (AP), and study plans. We are currently looking for a Data management Specialist for our Immunogenicity team located in Senneville, Quebec.




The following are the responsibilities related to the position:

Contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. Follow and ensure the application of GLP, SOPs, special procedures and health and safety rules on their assigned studies.
Perform and review tabulation of results and participate in writing the study report.
Collaborate with the Scientist to compile and assemble study deliverables in an audit ready state for submission to the Quality Assurance department (QA) and answer QA findings.
Preparing or revision of the study summary (e.g. MQS, MVS) when required.
Perform all other related duties as assigned.



The following are minimum qualifications related to the position:

DEC in sciences or AEC
Laboratory experience
An equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above.
Be able to work as part of a team. Have a positive attitude, good interpersonal relationships and professionalism. Adapt to changes. Actively participate in departmental meetings to improve performance and quality. Good understanding of Microsoft Office software and data generating software used in the department relevant to their role.



IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Safety Assessment
Charles River is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state-of-the-art facilities and expert regulatory guidance. From individual specialty toxicology and IND enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. Each year approximately 120 investigational new drug (IND) programs are conducted in our Safety Assessment facilities.","Charles River Laboratories
3.4",Senneville
744,Java - Software Developer (Data Services),"The ""Senior Java Developer - Cloud"" will work in collaboration with Java Developers and Data Scientists on the Data Services team in supporting three major projects: a surfacing engine that serves millions of users per day, crawlers that scour the web and use computer vision, and an infrastructure that processes, aggregates and filters billions of events per day. You will make a difference: your work will be used by more than a hundred million users per day.

What you'll be doing:
Work in close collaboration with the Product Owner to understand the requirements

Work closely with the software development team to maintain a high level of product quality

Propose solutions to our unique challenges (high throughput, low latency)

Work with existing DevOps teams to implement requirements

Work with Data Science team to architect their solutions following best practices

Innovate and communicate new practices, technologies and methodologies

What you'll need to be successful:
Must haves:
A minimum of 3 years in a similar role

Experience with leading cloud providers such as AWS, Azure and Google Cloud Engine and their offerings

Working knowledge of Python, Java, Docker, Kubernetes, Mesos, etc.

Experience using CI/CD tools (ex.: GitLab, Bitbucket, Terraform, etc.)

Ability to setup monitoring (cost, performance, etc.) of cloud-based solutions

Excellent communication and presentation skills in English. French is an asset.

Nice to Have:
Experience with distributed solutions (ElasticSearch, Kafka, Spark, Cassandra, etc.)

Experience with High availability and High throughput architecture

Experience with Big Data solutions (Hive, Spark, Kafka, BigQuery, Databricks, etc.)

Experience with leading on-premises cloud solutions such as Mesos and Kubernetes

Can build POC to demonstrate new tools, versions or opportunities.

An obsession with security and vulnerability testing

As an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees

IN this role, you may be exposed to adult content","MindGeek Careers
3.6",Quebec
745,Data Management Specialist - Immunotoxicology,"For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, we’ll help you build a career that you can feel passionate about.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Support the Scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with Good Laboratory Practices (GLP), Standard Operating Procedures (SOP), Analytical Procedures (AP), and study plans. We are currently looking for a Data Management Specialist for our Immunotoxicology group located in Senneville, Qc.




The following are responsibilities related to the position:

Contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. Follow and ensure the application of GLP, SOPs, special procedures and health and safety rules on their assigned studies.
Perform and review tabulation of results and participate in writing the study report.
Collaborate with the Scientist to compile and assemble study deliverables in an audit ready state for submission to the Quality Assurance department (QA) and answer QA findings.
Preparing or revision of the study summary (e.g. MQS, MVS) when required.
Perform all other related duties as assigned.



The following are minimum qualifications related to the Senior Analyst position:

DEC in sciences or AEC
An equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above.
Be able to work as part of a team.
Have a positive attitude, good interpersonal relationships and professionalism.
Adapt to changes.
Actively participate in departmental meetings to improve performance and quality.
Good understanding of Microsoft Office software and data generating software used in the department relevant to their role.



IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Safety Assessment
Charles River is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state-of-the-art facilities and expert regulatory guidance. From individual specialty toxicology and IND enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. Each year approximately 120 investigational new drug (IND) programs are conducted in our Safety Assessment facilities.","Charles River Laboratories
3.4",Senneville
746,SAS Data Engineering Consultant,"We Are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.

You Are:
As a SAS Engineer, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in modern data solutions including designing and delivering performant Business Intelligence SAS applications to our clients by supporting our engagement teams in collaboration with the project manager. You are enthusiastic about all things data, statistics, data mining, customer intelligence and advanced analytics. If you have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development, then this role may be for you.
In this role, you will:

Deliver proof on concepts using appropriate SAS technology
Support analysis, design, development and testing phases
Document business processes, business requirements and system requirements
Provide specifications for ETL or any service oriented dataflow
Support SAS cloud strategy
Database design for the following solutions: Customer Intelligence, In-Memory Analytics, Customer Intelligence and Marketing Intelligence
Support Integrated and UAT testing
Performance tuning
Support the project manager and the scrum master
Define good development practices and methodology for the team
Guide developers throughout the development phases
Deploy solutions in regards to our client’s DevOps approach
Participate in project proposals and RFI
Participate in business development activities


Here’s What You Need:

Bachelor's Degree in Computer Science
Strong working experience in an environment with SAS, with 3+ years of experience delivering various projects involving SAS Cloud Analytics technologies
Experience in Agile Methodology
Proven design and development experience as a SAS Programmer in complex environments
Experience in developing using version control tools
Knowledge of MS Project, any Agile platforms and Visio
Demonstrate experience in performing gap analysis and impact analysis
Experience supporting business users working on projects or programs involving multiple highly inter-dependent applications and/or data sources
Demonstrated capacity to work collaboratively with client organizations
Ability to work with diverse remote teams
Ability to develop and present new ideas and conceptualize new approaches and solution
Proven analytical skills and systematic problem solving

We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world what’s possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality.

To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn

It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients our employees must be available to travel when needed.

Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces.

We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply.

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.","Accenture
4.1",Montreal
747,Intermediate Data Engineer,"About Clir:

We are on a mission to minimize humankind’s impact on the climate. We do this by turning renewable energy data into action. We have global growth across 15 countries and 4 continents, with growth of 300% per year. Founded in Canada we are continuously expanding with team members located in North America, Europe, and South America. Guided by our core values, we are passionate, excited, and determined to fulfill our mission!




About the role:

We are focused on changing the renewable energy industry and as an Intermediate Data Engineer you will have an opportunity to be part of this mission. We are looking for a candidate who wants to do work that has an impact, not just in the industry but also on the environment. Your ability to ask questions, solve problems, and be an integral part of an open and collaborative team will be a catalyst for your success.




Who you are:

Passionate about our core values (communication, sustainability, inclusion, impact, and innovation)
Excited about the opportunity to join the new and growing Data team and champion data-driven decision making throughout the company
Team-focused, collaborative, and eager to learn
Motivated to work in an environment where everyone is focused on creating value for our customers
Comfortable with focusing among multiple competing priorities and approaching hard questions through a lens of curiosity



What you’ll be doing:

Design, develop, implement and test new data pipelines and data infrastructure as part of your team
Maintain and improve the performance of existing data pipelines and data infrastructure
Communicate with management and colleagues on a regular basis
Recommend and implement improvements to existing data pipelines, data infrastructure, and team processes
Mentor and support developers on your team and across the company



What you’ll need:

2+ years of hands-on development experience implementing successful, robust, and secure features and systems, preferably in the data domain
Strong, applied knowledge of at least one modern programming language
Experience in delivering written and verbal technical feedback in form of code reviews to peers
Familiarity with effective agile and software development practices such as scrum/kanban, CI/CD, test automation, infrastructure as code



Bonus:

Experience with any of: Python, Go, AWS systems, Relational Databases (Postgres, MySql, SQL Server)
Experience with data engineering tools: Airflow, Docker, Database Build Tool (dbt), Spark, Kafka
Experience with a Data Warehouse: BigQuery, Redhsift, Snowflake.
Experience working in a startup environment
Experience with Data Analysis and interest in Machine Learning
Familiarity with data visualization and charting tools



What’s in it for you:

Opportunity to work in an inclusive and diverse workplace
Be part of a team who are focused on reducing our impact on the environment
A chance to grow your skills and career alongside a supportive team of mentorship-focused developers
Medical insurance & dental care
Professional development benefits
Flexible schedule
Work from home friendly



At Clir Renewables, diversity and inclusion are not words we take lightly. These are words we take to heart, we drive to better understand our biases, and recognize that we have more work to do to create a workforce that truly represents those who our product serves. We strongly encourage applicants of all genders, ages, ethnicities, cultures, abilities, sexual orientations, and life experiences to apply.


As a partially remote organization, Clir works hard to ensure the safety of all clients and employees through the authentication of prospective employees and their backgrounds. Successful candidates may be subject to a background check conducted by Clir, and will need to demonstrate the legal right to work in Canada, the UK, or any area in which they wish to conduct work by showing proof of a valid work permit, visa, residency, or citizenship.","Clir
5.0",Vancouver
748,Cloud Data Platform Senior Delivery Lead,"Cloud Data Platform Senior Delivery Lead and Architect

About Capco

Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking, Capital Markets, Finance Risk & Compliance, Insurance, and Wealth and Investment Management. Experience Capco for yourself at capco.com

Let’s Talk About You

You want to Own Your Career. You’re serious about rising as far and as fast as your work and achievements can take you. And you’re ready to write the next chapter of your career story: a challenging and rewarding role as a Capco Cloud Data Platform Senior Delivery Lead and Architect.

Let’s Get Down To Business

Capco is seeking talented, innovative, and creative individuals to join our Cloud Practice, to help our customers become successful in their Cloud journey.

About the Role

Capco is seeking talented, innovative, and creative individuals to join our Data Practice, to help our customers become successful in their Data Transformation and Cloud journeys. As a Cloud Data Platform Senior Delivery Lead and Architect, you will be an integral part of the data and cloud practices, working with other like-minded individuals. You will get involved in projects ranging from cloud data strategy, architecture, and migration. Our Solution Leads are talented, innovative, and creative individuals who bring with them diverse experience and skillsets related to Data, Cloud and and DevSecOps practices.

About You

Experience

As a Capco Cloud Data Platform Senior Delivery Lead and Architect:

You lead the strategy, design and implementation of cloud-based data platforms running on AWS, GCP or Azure.
You have 8-10 years of experience delivering data solutions including 4-5 years in Big Data and cloud-based technologies.
You take ownership of data solution architecture, in conjunction with other associated teams.
You are comfortable in your ability to consult on the administration, monitoring, and deployment of large-scale data systems and services on the Cloud.
You can collaborate closely with our clients and facilitate across both the business and technology on solution requirements and delivery.
You can provide support and leadership to Capco’s data practice community.
You can lead Capco data analysts, data engineers, and data scientists to create and operationalize dynamic data & model pipelines with automated provisioning of workloads.
You can collaborate closely with business on consumption requirements (e.g. use cases) and interpret these into data platform strategy, design and execution.
You have successfully conquered processing and transformation of massive data through machine learning models and have familiarity using Spark-based solutions like Databricks.
You are familiar and have hands-on knowledge in setting up data related solutions (warehouses, lakes, science, app dev) using platforms like Snowflake.
You have extensive experience with data processing and engineering tools, such as Kafka, Informatica, and Talend.
You have experience with employing automated testing solutions for data migrations to the cloud.
You have deep experience implementing data governance and data quality solutions.
You have a solid understanding of DevOps & Automaton principles to automate repetitive tasks and requests.
You bring with you experience working with CI/CD pipelines (e.g., AWS CodePipeline, Gitlab, CircleCI, Jenkins) related to data applications, scripts and service/tools instantiation and configurations.
You are well-versed in various monitoring communication channels, tools, and related systems to ensure stability, health, and performance of the cloud data solution and infrastructure.
You have a good awareness and application of various data security standards, including PCI-DSS, FIPS 140-2, NIST 800-171, GDPR and others.
You have a good understanding and know-how to leverage tools, such as Tableau for data visualization.



As a leader in the Capco Data Practice:

You are self-motivated, pro-active and have a team-player attitude.
You can understand and communicate complex solutions to both business and technology stakeholders.
You can effectively organize and prioritize your workload.
You possess excellent oral, listening, and written communication skills.
You operate with an automation first mind-set and are obsessed with continuous growth and improvement.
You deliver on your commitments and are a great collaborator while also confident in your individual abilities.
You bring new ideas to the team, are known to be a good problem solver, take time to validate your own ideas and help shape other’s.
You continue to build your awareness, understanding and experiment with new technologies in the Data, Cloud and Financial Services industries.
You have excellent people skills with ability to lead by example and motivate team members.
You are quick, but methodical, and able to function in a fast paced environment while following best practices and organizational processes.

Professional experience is important. But it’s paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From Day One, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage.

Now Take the Next Step

If you’re looking forward to progressing your career with us, then we’re looking forward to receiving your application.

Capco is well known for its thought leadership and client-centric model that distinguishes it from other consulting firms. Capco’s strong technology and digital knowledge base, it’s global experience of the Financial Service enables us to deliver projects from strategy through to delivery. We are committed to providing new areas of expertise from which our clients will greatly benefit.

We have:

Access to industry-focused talent globally
Ability to leverage best-of-breed, innovative products and solutions for complex architecture and large-scale transformation
Extended global geographic market reach
Ability to capitalize on our client footprint and deep domain expertise within financial services

For more information about Capco, visit www.Capco.com.

Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.","CAPCO
3.9",Midtown Toronto
749,Senior AI Research Scientist – Machine Learning & eXplainable Artificial Intelligence (XAI) (Principal level position also available),"Company Description


The Bosch Research and Technology Center North America with offices in Sunnyvale, California, Pittsburgh, Pennsylvania and Cambridge, Massachusetts is part of the global Bosch Group (www.bosch.com), a company with over 70 billion euro revenue, 400,000 people worldwide, a very diverse product portfolio, and a history of over 125 years. The Research and Technology Center North America (RTC-NA) is committed to providing technologies and system solutions for various Bosch business fields primarily in the areas of Human-Machine Collaboration (HMC), Robotics, Energy Technologies, Internet Technologies, Circuit Design, Semiconductors and Wireless, and MEMS Advanced Design.

The focus of our global research on Human Machine Collaboration includes Big Data Visual Analytics, Explainable AI, Audio Analytics, NLP, Conversational AI, Mixed Reality and Smart Wearables, etc. We develop intuitive, interactive and intelligent solutions to enable inspiring UX for Bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems (ADAS), Industry 4.0 and Internet of Things (IoT), security systems, smart home and building solutions, health care, and robotics.

As a part of the global research unit, our Visual Analytics & eXplainable AI group is responsible for shaping the future industrial AI experience for Bosch products and services by combining cutting-edge technologies of machine learning, data analysis and interactive visualization. We research and develop scalable, transparent, and intelligent big data analytic solutions (e.g. audio, images, sensor logs) for various domains including Industry 4.0 (I4.0), IoT, autonomous driving, connected vehicles, etc. With our award-winning talents (IEEE VIS best paper & best paper runner-ups), we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, ICML, ICASSP, Interspeech, and IEEE Signal Processing Magazine.



Job Description

Conduct research and engineering in eXplainable AI (XAI) and machine learning for related business domains of autonomous driving, connected vehicles, Industry 4.0, IoT, car multimedia etc.
Work with an international team of experts to transfer the results of advanced research to Bosch business units. When necessary, build prototypes to verify research ideas.
Apply research results to real-world use cases with high quality implementation. Integrate the resulting systems/software into existing Bosch platforms.
Actively scout for the latest technology and predict market trends by monitoring news, technical events and seminars.
Provide expert opinions on relevant technology areas to management team to facilitate strategic planning, R&D roadmap development, and business investment.
Summarize research findings in high-quality paper and/or patent submissions.


Qualifications


Basic Qualifications:

Ph.D in Computer Science or related fields
3+ years of research experience or equivalent graduate research experience for eXplainable Artificial Intelligence (XAI), machine learning and deep learning
2+ years of industry experience in R&D for deep learning, eXplainable Artificial Intelligence (XAI) algorithms & systems
Experience with one or more programming languages for machine learning applications (e.g. Python, C++)

Preferred Qualifications:

Strong publication records in top venues of machine learning, deep learning and computer vision (e.g., NeurIPS, ICML, ICRL, CVPR, IJCV, AAAI, and TVCG)
Deep knowledge in machine learning and deep learning, with applications to eXplainable AI, computer vision, high-dimensional data analysis, and event sequence mining
Familiar with one or more main-stream machine learning platforms (e.g., TensorFlow, PyTorch, and scikit-learn)
Knowledge in full stack web development on both frontend (e.g., React, Vue.js, and D3.js) and backend (e.g., Flask, Django)
Good communication and teamwork skills
Strong leadership skills to drive research topics

Additional Information


BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives

FIRST Robotics (For Inspiration and Recognition of Science and Technology)
AWIM (A World In Motion)

By choice, we are committed to a diverse workforce – EOE/Protected Veteran/Disabled.","Bosch Group
4.1",Waterloo
750,Data Science Manager - (Spendscape),"The Data Science Manager oversees all data, analytics, experimentations and insights across Spendscape Inc. Identify future product opportunities and drive efforts to determine and implement new ideas, consulting service, and key metrics and the levers to influence them. The incumbent applies and integrates statistical, mathematical, predictive modeling and business analysis skills to manage and manipulate complex, high volume data from a variety of sources. Analyzes large quantities of data and presents insights and predictions (e.g., on client behaviors and preferences, new products and consulting services) to support management planning, execution and monitoring of business decisions.

This role will collaborate with various groups across Moneris and Spendscape to build accurate and effective data analytics products. The incumbent will be a creator and leader of external analytics and data products to support commercialization of data.


Key accountabilities include:

Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.

Deliver better predictions and/or intelligent automation that enables smarter business decisions, and drive productivity

Applies strong communication and story-telling skills to summarize findings, draw business conclusions, and present actionable insight in a way that resonates with business/groups.

Applying new and cutting edge methodologies in order to create new data products.

Lead and leverage analytics and insights to advance the commercialization and monetization of data. Identify industry insights and business trends to provide business opportunity for Spendscape to expand consumption, commercialization and monetization of data.

Partner with engineers to ensure that data is appropriately identified, recorded, transformed, and furnished for consumption

Collaborate with developers, sales, and other data scientists to embed data science findings within analysis and reporting.

Evangelize the power of analytics to improve the business and its operation.

Additionally, the information collected is used to comply and facilitate all legal and regulatory requirements.

Data Science Manager

Applies expertise and thinks creatively to address unique or ambiguous situations and to find solutions to problems that can be complex and non-routine.

Lead the development of statistical models to extract trends, measure results, and predict future performance of our product.

Comply with corporate policies established by Moneris Corporation including but not limited to Code of Conduct, Technology Policy & Privacy Policy.

Designation:

Post-Secondary education in Data Science, Computer Science, Mathematics, Statistics, or Engineering, ideally with a Masters in one of these fields preferred, PhD considered an asset

5-7 years of experience in a programming role involving statistical modelling and machine learning

Minimum Experience, Technical Skills:

Ability to understand complex business problems and break down analytics projects into a structured approach. Explaining complex terms in simple language

Programming; preferably with R, Python, and SQL

Experience in deployment of models in a production environment such as Azure and DataBricks

Proficient with Microsoft Windows/ MS Office Applications

Fluent in English (reading, writing, and verbal) though Bilingualism in French considered an asset.

Develops and fosters exceptional relationships across various stakeholders, including senior management.

Dedicated and committed to our customers.

Highly developed and proven consulting, change management, project management and strategic thinking capability

Soft Skills:

Passionate with a deeply analytical mindset

Strong written and verbal communication skills.

Excellent time management ability to manage multiple priorities in an agile environment with ability to meet time compressed deadlines.

A team player that can support the team to accomplish our mission to be a world-class company driven by data.",Spendscape Inc,Etobicoke
751,SAS Data Engineering Consultant,"We Are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.

You Are:
As a SAS Engineer, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in modern data solutions including designing and delivering performant Business Intelligence SAS applications to our clients by supporting our engagement teams in collaboration with the project manager. You are enthusiastic about all things data, statistics, data mining, customer intelligence and advanced analytics. If you have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development, then this role may be for you.
In this role, you will:

Deliver proof on concepts using appropriate SAS technology
Support analysis, design, development and testing phases
Document business processes, business requirements and system requirements
Provide specifications for ETL or any service oriented dataflow
Support SAS cloud strategy
Database design for the following solutions: Customer Intelligence, In-Memory Analytics, Customer Intelligence and Marketing Intelligence
Support Integrated and UAT testing
Performance tuning
Support the project manager and the scrum master
Define good development practices and methodology for the team
Guide developers throughout the development phases
Deploy solutions in regards to our client’s DevOps approach
Participate in project proposals and RFI
Participate in business development activities


Here’s What You Need:

Bachelor's Degree in Computer Science
Strong working experience in an environment with SAS, with 3+ years of experience delivering various projects involving SAS Cloud Analytics technologies
Experience in Agile Methodology
Proven design and development experience as a SAS Programmer in complex environments
Experience in developing using version control tools
Knowledge of MS Project, any Agile platforms and Visio
Demonstrate experience in performing gap analysis and impact analysis
Experience supporting business users working on projects or programs involving multiple highly inter-dependent applications and/or data sources
Demonstrated capacity to work collaboratively with client organizations
Ability to work with diverse remote teams
Ability to develop and present new ideas and conceptualize new approaches and solution
Proven analytical skills and systematic problem solving

We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world what’s possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality.

To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn

It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients our employees must be available to travel when needed.

Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces.

We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply.

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.","Accenture
4.1",Montreal
752,Data Management Specialist - Immunotoxicology,"For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, we’ll help you build a career that you can feel passionate about.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Support the Scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with Good Laboratory Practices (GLP), Standard Operating Procedures (SOP), Analytical Procedures (AP), and study plans. We are currently looking for a Data Management Specialist for our Immunotoxicology group located in Senneville, Qc.




The following are responsibilities related to the position:

Contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. Follow and ensure the application of GLP, SOPs, special procedures and health and safety rules on their assigned studies.
Perform and review tabulation of results and participate in writing the study report.
Collaborate with the Scientist to compile and assemble study deliverables in an audit ready state for submission to the Quality Assurance department (QA) and answer QA findings.
Preparing or revision of the study summary (e.g. MQS, MVS) when required.
Perform all other related duties as assigned.



The following are minimum qualifications related to the Senior Analyst position:

DEC in sciences or AEC
An equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above.
Be able to work as part of a team.
Have a positive attitude, good interpersonal relationships and professionalism.
Adapt to changes.
Actively participate in departmental meetings to improve performance and quality.
Good understanding of Microsoft Office software and data generating software used in the department relevant to their role.



IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Safety Assessment
Charles River is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state-of-the-art facilities and expert regulatory guidance. From individual specialty toxicology and IND enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. Each year approximately 120 investigational new drug (IND) programs are conducted in our Safety Assessment facilities.","Charles River Laboratories
3.4",Senneville
753,Data Management Specialist - Immunogenicity,"For 70 years, Charles River employees have worked together to assist in the discovery, development and safe manufacture of new drug therapies. When you join our family, you will have a significant impact on the health and well-being of people across the globe. Whether your background is in life sciences, finance, IT, sales or another area, your skills will play an important role in the work we perform. In return, we’ll help you build a career that you can feel passionate about.




IMPORTANT: In order to be considered for this position, a resume/CV must be uploaded and submitted during the application process. Please make sure work history and education are added correctly.




Job Summary

Support the Scientists in maintaining study deliverables while respecting timelines and preserving a quality of work compliant with Good Laboratory Practices (GLP), Standard Operating Procedures (SOP), Analytical Procedures (AP), and study plans. We are currently looking for a Data management Specialist for our Immunogenicity team located in Senneville, Quebec.




The following are the responsibilities related to the position:

Contribute to quality control by reviewing analytical procedures, procedure forms, or other related documentation to assigned studies. Follow and ensure the application of GLP, SOPs, special procedures and health and safety rules on their assigned studies.
Perform and review tabulation of results and participate in writing the study report.
Collaborate with the Scientist to compile and assemble study deliverables in an audit ready state for submission to the Quality Assurance department (QA) and answer QA findings.
Preparing or revision of the study summary (e.g. MQS, MVS) when required.
Perform all other related duties as assigned.



The following are minimum qualifications related to the position:

DEC in sciences or AEC
Laboratory experience
An equivalent combination of education and experience may be considered an acceptable substitute for the specific education and experience listed above.
Be able to work as part of a team. Have a positive attitude, good interpersonal relationships and professionalism. Adapt to changes. Actively participate in departmental meetings to improve performance and quality. Good understanding of Microsoft Office software and data generating software used in the department relevant to their role.



IMPORTANT: A resume is required to be considered for this position. If you have not uploaded your resume in your candidate profile, please return to upload field and attach your resume/CV.


About Safety Assessment
Charles River is committed to helping our partners expedite their preclinical drug development with exceptional safety assessment services, state-of-the-art facilities and expert regulatory guidance. From individual specialty toxicology and IND enabling studies to tailored packages and total laboratory support, our deeply experienced team can design and execute programs that anticipate challenges and avoid roadblocks for a smooth, efficient journey to market. Each year approximately 120 investigational new drug (IND) programs are conducted in our Safety Assessment facilities.","Charles River Laboratories
3.4",Senneville
754,Intermediate Data Engineer,"About Clir:

We are on a mission to minimize humankind’s impact on the climate. We do this by turning renewable energy data into action. We have global growth across 15 countries and 4 continents, with growth of 300% per year. Founded in Canada we are continuously expanding with team members located in North America, Europe, and South America. Guided by our core values, we are passionate, excited, and determined to fulfill our mission!




About the role:

We are focused on changing the renewable energy industry and as an Intermediate Data Engineer you will have an opportunity to be part of this mission. We are looking for a candidate who wants to do work that has an impact, not just in the industry but also on the environment. Your ability to ask questions, solve problems, and be an integral part of an open and collaborative team will be a catalyst for your success.




Who you are:

Passionate about our core values (communication, sustainability, inclusion, impact, and innovation)
Excited about the opportunity to join the new and growing Data team and champion data-driven decision making throughout the company
Team-focused, collaborative, and eager to learn
Motivated to work in an environment where everyone is focused on creating value for our customers
Comfortable with focusing among multiple competing priorities and approaching hard questions through a lens of curiosity



What you’ll be doing:

Design, develop, implement and test new data pipelines and data infrastructure as part of your team
Maintain and improve the performance of existing data pipelines and data infrastructure
Communicate with management and colleagues on a regular basis
Recommend and implement improvements to existing data pipelines, data infrastructure, and team processes
Mentor and support developers on your team and across the company



What you’ll need:

2+ years of hands-on development experience implementing successful, robust, and secure features and systems, preferably in the data domain
Strong, applied knowledge of at least one modern programming language
Experience in delivering written and verbal technical feedback in form of code reviews to peers
Familiarity with effective agile and software development practices such as scrum/kanban, CI/CD, test automation, infrastructure as code



Bonus:

Experience with any of: Python, Go, AWS systems, Relational Databases (Postgres, MySql, SQL Server)
Experience with data engineering tools: Airflow, Docker, Database Build Tool (dbt), Spark, Kafka
Experience with a Data Warehouse: BigQuery, Redhsift, Snowflake.
Experience working in a startup environment
Experience with Data Analysis and interest in Machine Learning
Familiarity with data visualization and charting tools



What’s in it for you:

Opportunity to work in an inclusive and diverse workplace
Be part of a team who are focused on reducing our impact on the environment
A chance to grow your skills and career alongside a supportive team of mentorship-focused developers
Medical insurance & dental care
Professional development benefits
Flexible schedule
Work from home friendly



At Clir Renewables, diversity and inclusion are not words we take lightly. These are words we take to heart, we drive to better understand our biases, and recognize that we have more work to do to create a workforce that truly represents those who our product serves. We strongly encourage applicants of all genders, ages, ethnicities, cultures, abilities, sexual orientations, and life experiences to apply.


As a partially remote organization, Clir works hard to ensure the safety of all clients and employees through the authentication of prospective employees and their backgrounds. Successful candidates may be subject to a background check conducted by Clir, and will need to demonstrate the legal right to work in Canada, the UK, or any area in which they wish to conduct work by showing proof of a valid work permit, visa, residency, or citizenship.","Clir
5.0",Vancouver
755,Java - Software Developer (Data Services),"The ""Senior Java Developer - Cloud"" will work in collaboration with Java Developers and Data Scientists on the Data Services team in supporting three major projects: a surfacing engine that serves millions of users per day, crawlers that scour the web and use computer vision, and an infrastructure that processes, aggregates and filters billions of events per day. You will make a difference: your work will be used by more than a hundred million users per day.

What you'll be doing:
Work in close collaboration with the Product Owner to understand the requirements

Work closely with the software development team to maintain a high level of product quality

Propose solutions to our unique challenges (high throughput, low latency)

Work with existing DevOps teams to implement requirements

Work with Data Science team to architect their solutions following best practices

Innovate and communicate new practices, technologies and methodologies

What you'll need to be successful:
Must haves:
A minimum of 3 years in a similar role

Experience with leading cloud providers such as AWS, Azure and Google Cloud Engine and their offerings

Working knowledge of Python, Java, Docker, Kubernetes, Mesos, etc.

Experience using CI/CD tools (ex.: GitLab, Bitbucket, Terraform, etc.)

Ability to setup monitoring (cost, performance, etc.) of cloud-based solutions

Excellent communication and presentation skills in English. French is an asset.

Nice to Have:
Experience with distributed solutions (ElasticSearch, Kafka, Spark, Cassandra, etc.)

Experience with High availability and High throughput architecture

Experience with Big Data solutions (Hive, Spark, Kafka, BigQuery, Databricks, etc.)

Experience with leading on-premises cloud solutions such as Mesos and Kubernetes

Can build POC to demonstrate new tools, versions or opportunities.

An obsession with security and vulnerability testing

As an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees

IN this role, you may be exposed to adult content","MindGeek Careers
3.6",Quebec
756,"Senior Manager, Data Science (DOE)","About JUDI.AI – Smart Analytics that Grow Customer Relationships

There has never been a better time to redefine small business lending. JUDI.AI is at the forefront of the SMB lending space, providing a software platform that makes it easy for credit unions and community banks to digitally transform lending processes, become smarter lenders and build deeper relationships with their small business customers. At JUDI.AI, we:

Find ways to supplement traditional credit data sources to make better informed credit decisions.
Apply AI and machine learning to risk detection logic, enabling loan providers to lend more with less risk.
Continuously assess the financial health of small business loan recipients to provide valuable post-lending advice and business growth insights - when they are needed the most.

The result is small business lending redefined as fast, less risky and more profitable for everyone.

JUDI.AI pledges 1% of our equity, revenue, time and product to not-for-profits of our customers' choice.

About Our Team – Unique Thinkers. Game Changing Attitudes.

JUDI.AI is home to entrepreneurs, rainmakers and data wizards – a family of financial analysts, software developers, data scientists, marketers and salespeople. We are also home to a collaborative group of musicians, skiers, acrobats, runners, kite boarders, sailors and yogis. We are a small company of about 15 employees in downtown Vancouver (Coal Harbour) with team members also located in Toronto. Our management team comes from a range of high growth and blue-chip technology companies like Nokia, PayPal, VisionCritical, BlastRadius and Diply.

About the Role – A Key Piece of Our Puzzle

The Senior Manager, Data Science (DOE) will be the senior leadership role on the data science team. The role will report to the Head of Product Engineering and will manage the data and analytics team. The successful candidate will lead all analytics initiatives at JUDI.AI, and will work closely with the product and development teams to implement and apply state-of-the-art technologies and methodologies to credit decisioning.

Additionally, this person will:

Plan

Conceive and prioritize data projects across the organization.
Identify new data sources and evaluate emerging technologies and analytic trends for data discovery and visualization.
Conduct Proof of Concept studies for new functionality

Build, Manage & Execute

Provide hands-on leadership and oversight of Data Science and Analytics.
Support recruitment and training of a team specialized in advance analytics and data science.
Lead projects connecting business needs to analytics and development applying best practices for artificial intelligence and machine learning.
Establish analytical standards and best practices across the enterprise.
Support model governance programs, from designing to testing, validation and monitoring.
Oversee documentation to outline data sources, transformations, models and implementation.

Coordinate, Communicate & Lead

Partner across teams and coordinate stakeholder expectations to support interpreting and analyzing data challenges.
Work closely with JUDI’s executive team to support the long-term vision of the company and manage resources.
Act as a thought leader on the subject both externally and internally
Communicate Analytics and Data Science findings to executives, clients and internal teams.
About You - A Resilient Company Builder

You are looking to join on a journey with a team dedicated to building something amazing from the ground floor. You enjoy and can envision the rewards from an early-stage company and overcoming the struggles inherent in our position – you see opportunity early and are relentless in the face of obstacles. You get up quickly when knocked down, because getting knocked down is part of company building. If it were easy everyone would be doing it. You are entrepreneurial, agile, and nimble – a “get your hands dirty” team player.

Key Capabilities

Have demonstrated business acumen and a proven track record of achieving commercial value through the application of advanced analytics;
Are a leader, communicator, and collaborator; and
You're entrepreneurial, agile and nimble – a “get your hands dirty” team player.

Your Qualifications

M.S. or Ph.D. in a quantitative discipline (e.g., Math, Statistics, Econometrics, Engineering, Physical Sciences).
2-5 years of professional experience in data analytics and related projects.
Preferred prior experience in the Financial Services Experience (risk, fraud, underwriting, or banking transaction analysis)
Strong quantitative/statistical modelling and programming skills.
Hands-on coding skills with Python, R, UNIX scripting.
Familiarity with query languages like SQL
Experience building and leading Data Science teams.
Deep knowledge of supervised and unsupervised regression and classification techniques, such as Neural Networks, Decision Trees, Clustering, Boosting, SVM, and NLP.
Experience working in an agile environment with frequent, incremental coding, testing and deployment.",Judi.ai,Midtown Toronto
757,Cloud Data Platform Senior Delivery Lead,"Cloud Data Platform Senior Delivery Lead and Architect

About Capco

Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking, Capital Markets, Finance Risk & Compliance, Insurance, and Wealth and Investment Management. Experience Capco for yourself at capco.com

Let’s Talk About You

You want to Own Your Career. You’re serious about rising as far and as fast as your work and achievements can take you. And you’re ready to write the next chapter of your career story: a challenging and rewarding role as a Capco Cloud Data Platform Senior Delivery Lead and Architect.

Let’s Get Down To Business

Capco is seeking talented, innovative, and creative individuals to join our Cloud Practice, to help our customers become successful in their Cloud journey.

About the Role

Capco is seeking talented, innovative, and creative individuals to join our Data Practice, to help our customers become successful in their Data Transformation and Cloud journeys. As a Cloud Data Platform Senior Delivery Lead and Architect, you will be an integral part of the data and cloud practices, working with other like-minded individuals. You will get involved in projects ranging from cloud data strategy, architecture, and migration. Our Solution Leads are talented, innovative, and creative individuals who bring with them diverse experience and skillsets related to Data, Cloud and and DevSecOps practices.

About You

Experience

As a Capco Cloud Data Platform Senior Delivery Lead and Architect:

You lead the strategy, design and implementation of cloud-based data platforms running on AWS, GCP or Azure.
You have 8-10 years of experience delivering data solutions including 4-5 years in Big Data and cloud-based technologies.
You take ownership of data solution architecture, in conjunction with other associated teams.
You are comfortable in your ability to consult on the administration, monitoring, and deployment of large-scale data systems and services on the Cloud.
You can collaborate closely with our clients and facilitate across both the business and technology on solution requirements and delivery.
You can provide support and leadership to Capco’s data practice community.
You can lead Capco data analysts, data engineers, and data scientists to create and operationalize dynamic data & model pipelines with automated provisioning of workloads.
You can collaborate closely with business on consumption requirements (e.g. use cases) and interpret these into data platform strategy, design and execution.
You have successfully conquered processing and transformation of massive data through machine learning models and have familiarity using Spark-based solutions like Databricks.
You are familiar and have hands-on knowledge in setting up data related solutions (warehouses, lakes, science, app dev) using platforms like Snowflake.
You have extensive experience with data processing and engineering tools, such as Kafka, Informatica, and Talend.
You have experience with employing automated testing solutions for data migrations to the cloud.
You have deep experience implementing data governance and data quality solutions.
You have a solid understanding of DevOps & Automaton principles to automate repetitive tasks and requests.
You bring with you experience working with CI/CD pipelines (e.g., AWS CodePipeline, Gitlab, CircleCI, Jenkins) related to data applications, scripts and service/tools instantiation and configurations.
You are well-versed in various monitoring communication channels, tools, and related systems to ensure stability, health, and performance of the cloud data solution and infrastructure.
You have a good awareness and application of various data security standards, including PCI-DSS, FIPS 140-2, NIST 800-171, GDPR and others.
You have a good understanding and know-how to leverage tools, such as Tableau for data visualization.



As a leader in the Capco Data Practice:

You are self-motivated, pro-active and have a team-player attitude.
You can understand and communicate complex solutions to both business and technology stakeholders.
You can effectively organize and prioritize your workload.
You possess excellent oral, listening, and written communication skills.
You operate with an automation first mind-set and are obsessed with continuous growth and improvement.
You deliver on your commitments and are a great collaborator while also confident in your individual abilities.
You bring new ideas to the team, are known to be a good problem solver, take time to validate your own ideas and help shape other’s.
You continue to build your awareness, understanding and experiment with new technologies in the Data, Cloud and Financial Services industries.
You have excellent people skills with ability to lead by example and motivate team members.
You are quick, but methodical, and able to function in a fast paced environment while following best practices and organizational processes.

Professional experience is important. But it’s paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From Day One, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage.

Now Take the Next Step

If you’re looking forward to progressing your career with us, then we’re looking forward to receiving your application.

Capco is well known for its thought leadership and client-centric model that distinguishes it from other consulting firms. Capco’s strong technology and digital knowledge base, it’s global experience of the Financial Service enables us to deliver projects from strategy through to delivery. We are committed to providing new areas of expertise from which our clients will greatly benefit.

We have:

Access to industry-focused talent globally
Ability to leverage best-of-breed, innovative products and solutions for complex architecture and large-scale transformation
Extended global geographic market reach
Ability to capitalize on our client footprint and deep domain expertise within financial services

For more information about Capco, visit www.Capco.com.

Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.","CAPCO
3.9",Midtown Toronto
758,Cloud Data Consulting Sr Manager,"Cloud Data Consulting Sr Manager


Location: Toronto/Montreal/Ottawa

WE ARE
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.

YOU ARE
A Big Data and Cloud leader—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.

WORK YOU’LL DO
Cloud Data Consulting Architects at the Senior Manager level will be responsible for providing solutions to digital age data challenges in multiple industries through architecture, design and implementation of an ecosystem of big data, NoSQL, Self-Service Data Preparation, AI, Machine Learning and other modern data technologies on cloud and also on prem. The solutions typically will include re-engineering the data acquisition, storage, processing, security, data management, governance and analysis using these technologies leading to the implementation of a modern data platform. A solid experience and understanding of considerations for planning, scaling, deployment and operations that are unique to big data, NoSQL and other emerging modern data technologies is required. We are looking for candidates who have a broad set of skills across these areas and who can demonstrate an ability to identify and apply modern data and cloud technologies to architect and implement innovative and differentiated data solutions. Our architects are expected to work with our clients in defining the future state architectures of their data platforms enabling analytical intelligence and then play a lead role to implement a roadmap to reach that state




Basic Qualifications

Bachelor's degree in Computer Science, Engineering, Technical Science or 8 years of IT/Programming experience

Minimum 5+ years of architecting, implementing and successfully operationalizing large scale data solutions in production environments using big data and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Databricks, Azure Data Lake etc.

Minimum 5+ years of architecting data and building performant data models at scale for Hadoop/NoSQL ecosystem of data stores to support different business consumption patterns off a centralized data platform

Minimum 5+ years of Spark/Pyspark processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applications

Minimum 5+ years of architecting and industrializing data lakes or real-time platforms for an enterprise enabling business applications and usage at scale

Minimum 5+ years designing and implementing relational data models working with RDBMS and understanding of the challenges in these environments

Bilingual french an asset

Bonus Points

Minimum 4+ years of experience implementing large scale secure cloud data solutions using AWS data and analytics services e.g. S3, EMR, Redshift; or

Minimum 4+ years of experience implementing large scale secure cloud data solutions using Google data and analytics services e.g. BigQuery, DataProc; or

Minimum 4+ years of experience implementing large scale secure cloud data solutions using Azure data and analytics services e.g. Databricks, ADLS; or

Minimum 4+ years of experience building data management (metadata, lineage, tracking etc.) and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on Azure, AWS, Google and Azure cloud

Minimum 4+ years of experience securing modern data platforms on-premise or on AWS, Google, Azure cloud","Accenture
4.1",Montreal
759,Senior AI Research Scientist – Machine Learning & eXplainable Artificial Intelligence (XAI) (Principal level position also available),"Company Description


The Bosch Research and Technology Center North America with offices in Sunnyvale, California, Pittsburgh, Pennsylvania and Cambridge, Massachusetts is part of the global Bosch Group (www.bosch.com), a company with over 70 billion euro revenue, 400,000 people worldwide, a very diverse product portfolio, and a history of over 125 years. The Research and Technology Center North America (RTC-NA) is committed to providing technologies and system solutions for various Bosch business fields primarily in the areas of Human-Machine Collaboration (HMC), Robotics, Energy Technologies, Internet Technologies, Circuit Design, Semiconductors and Wireless, and MEMS Advanced Design.

The focus of our global research on Human Machine Collaboration includes Big Data Visual Analytics, Explainable AI, Audio Analytics, NLP, Conversational AI, Mixed Reality and Smart Wearables, etc. We develop intuitive, interactive and intelligent solutions to enable inspiring UX for Bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems (ADAS), Industry 4.0 and Internet of Things (IoT), security systems, smart home and building solutions, health care, and robotics.

As a part of the global research unit, our Visual Analytics & eXplainable AI group is responsible for shaping the future industrial AI experience for Bosch products and services by combining cutting-edge technologies of machine learning, data analysis and interactive visualization. We research and develop scalable, transparent, and intelligent big data analytic solutions (e.g. audio, images, sensor logs) for various domains including Industry 4.0 (I4.0), IoT, autonomous driving, connected vehicles, etc. With our award-winning talents (IEEE VIS best paper & best paper runner-ups), we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, ICML, ICASSP, Interspeech, and IEEE Signal Processing Magazine.



Job Description

Conduct research and engineering in eXplainable AI (XAI) and machine learning for related business domains of autonomous driving, connected vehicles, Industry 4.0, IoT, car multimedia etc.
Work with an international team of experts to transfer the results of advanced research to Bosch business units. When necessary, build prototypes to verify research ideas.
Apply research results to real-world use cases with high quality implementation. Integrate the resulting systems/software into existing Bosch platforms.
Actively scout for the latest technology and predict market trends by monitoring news, technical events and seminars.
Provide expert opinions on relevant technology areas to management team to facilitate strategic planning, R&D roadmap development, and business investment.
Summarize research findings in high-quality paper and/or patent submissions.


Qualifications


Basic Qualifications:

Ph.D in Computer Science or related fields
3+ years of research experience or equivalent graduate research experience for eXplainable Artificial Intelligence (XAI), machine learning and deep learning
2+ years of industry experience in R&D for deep learning, eXplainable Artificial Intelligence (XAI) algorithms & systems
Experience with one or more programming languages for machine learning applications (e.g. Python, C++)

Preferred Qualifications:

Strong publication records in top venues of machine learning, deep learning and computer vision (e.g., NeurIPS, ICML, ICRL, CVPR, IJCV, AAAI, and TVCG)
Deep knowledge in machine learning and deep learning, with applications to eXplainable AI, computer vision, high-dimensional data analysis, and event sequence mining
Familiar with one or more main-stream machine learning platforms (e.g., TensorFlow, PyTorch, and scikit-learn)
Knowledge in full stack web development on both frontend (e.g., React, Vue.js, and D3.js) and backend (e.g., Flask, Django)
Good communication and teamwork skills
Strong leadership skills to drive research topics

Additional Information


BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives

FIRST Robotics (For Inspiration and Recognition of Science and Technology)
AWIM (A World In Motion)

By choice, we are committed to a diverse workforce – EOE/Protected Veteran/Disabled.","Bosch Group
4.1",Waterloo
760,Machine Learning Data Engineer,"Join our Vancouver area Sports Tech venture bringing the worlds most advanced player / puck tracking system to hockey leagues across the globe. We’re looking for a proven Machine Learning Data Engineer to join our talented team in building ETL data pipelines, stat identification models and real-time analytics apps.

If you have passion for building quality systems, who likes to mix their passion of data with sports and the upside of owning equity in a high potential startup Sports Tech company, we would like to hear from you. We are offering a starting salary plus a healthy share options grant to own part of the venture as an early employee, and cash in on a future valuation. Join us on our path as a key team member to becoming a world hockey data leader with our patent pending sensor based hockey tracking .

Job Type: Permanent

Salary: $60,000.00-$70,000.00 per year

Benefits:

Dental care
Extended health care
Flexible schedule
Stock options

Schedule:

Monday to Friday

COVID-19 considerations:
Work from home during COVID is ok, future work is in our R&D lab.

Application question(s):

What interests you about working within the Sports Tech industry?

Experience:

Machine Learning: 2 years (preferred)

Work remotely:

Temporarily due to COVID-19","Drive Hockey Analytics, Inc.",Burnaby
761,"Senior Data Engineer (Marketing, Sales & Finance)","Since being founded in 2011, Prodigy Education has grown from 3,000 local users to more than 100 million registered users worldwide. As one of the fastest-growing EdTech startups in North America, Prodigy connects students, parents, teachers, and school districts with resources with the goal of promoting a lifelong love of learning. Anyone with an internet connection is welcome to create a free account for Prodigy’s popular Math Game for grades 1 to 8. Prodigy Education also provides online math tutoring via certified teachers who adapt their style and lessons to teach students in the way they learn best. For more information visit www.prodigygame.com.

Our passion is our mission - to help every student in the world love learning!

Here at Prodigy, we are working hard to achieve our mission of helping every child in the world to LOVE learning. Our data team is responsible for all aspects of data ingestion, storage, transformation, and analysis using modern tools and environments such as Spark, Databricks, dbt, Airflow, Snowflake, Periscope, Kafka, and AWS. You will be working alongside our data engineering, data science, and data analysis teams to help build and manage all of our data pipelines and high-quality datasets, focusing on our Financial and Payments domains.
Your Impact:
Create and manage key business data pipelines and high-quality datasets
Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data acquisition and data-related technical issues, and other analytics needs.
Work cross-functionally to explore and propose solutions to business problems that can be addressed using insights from data
Create and optimize data tools for analytics and data scientist team members that assist them in building our product into an innovative industry leader.
Support the development of new solutions for batch, real-time data, and analytics use cases that align with business requirements
Maintain and troubleshoot the infrastructure built for optimal extraction, transformation, and loading of data from a wide variety of data sources
Identify, design, and implement process improvements: automate manual processes, optimize data delivery, improve data reliability, efficiency, and quality, etc.
Build analytics tools that utilize the data pipeline to provide actionable insights into student learning, customer acquisition, operational efficiency, and other key metrics.
Aid in improving our data architecture and keeping our current architecture up to modern standards and best practices
Who You Are:
At least 3 years of experience in data engineering.
Working familiarity with a variety of different storage mechanisms including SQL & NoSQL databases, Data Warehouses, and Data Lakes.
Experience working with AWS Cloud platforms and related systems
Experience building and optimizing data pipelines, architectures, and data sets.
Experience with big data tools: Databricks, Spark, dbt, etc - and how they fit into an overall data architecture.
Experience with data pipeline and workflow management tools, such as Airflow
Experience with real-time data processing and stream-processing systems: Kafka, Spark-Streaming, etc.
Experience in requirements analysis, design, implementation, and testing of software solutions, especially data related, using Python, Scala, and/or other programming languages
A successful history of manipulating, processing, and extracting value from large disconnected datasets, especially related to Financial, Marketing, and Sales data.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience implementing backend Data APIs using NodeJS, Python, or other programming languages
Strong project management, organizational, and communication skills.
University degree in Engineering, Computer Science, Stats, Mathematics. A graduate degree in Data Science related discipline is a strong asset
Our Core Technologies:
Data tools: Kinesis, Lambda, Kubernetes, ECS, dbt
Storage: S3, Snowflake, Delta, Postgres Aurora, DynamoDB
Coding World & Libs: Python, Javascript (NodeJS), Spark
Platforms: AWS, Persicope, Databricks, Snowflake
What We Offer:
A culture of transparency, where team members are involved in important conversations
Full health benefits from day one (1) for you and your family, fully covered!
We are a profitable company, with eligibility to participate in stock options for all full-time permanent employees
Learning and development budget for all full-time employees to use towards career growth and development opportunities
We recognize 9-5 is not for everyone! We offer flexible working hours that will allow you to schedule your workday with a bit more freedom!

While we operate 100% remotely, for the time being, we understand the importance of togetherness. We offer frequent and fun team and company events, to stay connected and in the know.

Please note: During the Covid-19 pandemic, in order to keep all our candidates and team members safe, Prodigy is operating, hiring and onboarding 100% remotely for the time being.

Come as you are. We believe the power of our collective potential will transform education. We are building towards a diverse, inclusive, and equitable workplace to empower and create access and opportunity for all. We welcome applications from people from all underrepresented groups, including (but not limited to) people of any gender, age, or religion, members of the LGBTQIA2+ community, BIPOC and other underrepresented races and nationalities, people with disabilities, veterans, and anyone who may contribute to the further diversification of Prodigy Education. If you feel like you don’t have all the qualifications for this position, and are willing to use your initiative to learn the rest, we’d still love for you to apply!

We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Education will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require accommodation, please notify us and we will work with you to meet your needs.","Prodigy Game
4.8",Oakville
762,Senior Data Analyst,"Job Requisition ID #

21WD48199

Position Overview

Autodesk is seeking an experienced data analyst to join the Data Science team in our Data Platform and Insights group. The Data Platform and Insights group is chartered with building innovative data products and analytics solutions for Autodesk’s strategy, marketing, sales and customer support teams. Data Analysts will play a critical role in discovering and communicating data-driven insights to inspire product improvements.

Responsibilities

Leverage Data Mining techniques to find key business insights

Partner with Data Scientists to improve Data Science models

Collaborate with Product Managers to explore new product ideas or enhancements

Build reporting to measure progress in key initiatives

Become an expert in Autodesk data

Work as an individual contributor with opportunities for management as we grow the team

Minimum Qualifications

4+ years in an Analyst role

Strong SQL coding skills and comfortable using it every day

Experience working with unstructured data

Experience working in Python or R

Experience building Data Visualizations via Python/R or a Business Intelligence tool

Preferred Qualifications

Familiarity with Data Science concepts

Experience working in Git

Experience using big data platforms (Hadoop, Spark, Hive)

A/B Testing Experience Ideal Candidate

User Design/Front-end Development Experience

Have interest in learning about Data Science

Have a strong attention to detail and care deeply about data quality

Proactively reach out to stakeholders to understand data better

Enjoy collaborating with team members to drive impact

Are a strong communicator; you can adjust communication for technical

Stakeholders and non-technical stakeholders

At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.

Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers .","Autodesk
3.9",Montreal
763,Intermediate Software Engineer - Data Applications,"Xero is a beautiful, easy-to-use platform that helps small businesses and their accounting and bookkeeping advisors grow and thrive.

At Xero, our purpose is to make life better for people in small business, their advisors, and communities around the world. This purpose sits at the centre of everything we do. We support our people to do the best work of their lives so that they can help small businesses succeed through better tools, information and connections. Because when they succeed they make a difference, and when millions of small businesses are making a difference, the world is a more beautiful place.

About the team:

The Data team is responsible for driving the adoption of data driven decision making across Xero - for both our internal users and our global audience of small business owners, bookkeepers and accountants. We create, manage and deliver a wide range of data services including machine learning toolsets, frameworks API prediction services, core reporting, key data dimensions, extensible and scalable analytical data processing and storage facilities. We are the centre of expertise for data architecture, data modeling, machine learning, ethical data usage and artificial intelligence service design. We also lead the work to raise the data and AI literacy levels across Xero with a particular focus on the product management and engineering cohorts globally.
About the role
As an Intermediate Software Engineer in the Data team you will work closely with Applied Scientists, and Data Engineers to design and build the data pipelines and applications that will enable Xero to bring intelligent, insightful products and beautiful experiences to millions of customers around the world. You will have a strong interest in building Machine Learning applications that can run and evolve at scale leveraging microservices and the latest technologies.
What you'll do
Collaborate with colleagues from the Science, Evaluation & Measurement and Data Enrichment teams to build end-to-end machine learning pipelines for training and inference at scale.
Monitor, maintain and support the solutions you build including being part of an on-call roster should an urgent issue come up.
Work with colleagues to maintain and operate the Data team’s pipelines, with an emphasis on monitoring for changes in data quality
From ideation to production enable the development of easy-to-use infrastructure, tooling and monitoring for data applications and reproducible data science workflows
Stay current with emerging practices, techniques and frameworks in the fields of applied machine learning and artificial intelligence at scale.
Mentor and develop members of your team, increasing our capability to build and operate intelligent, data-driven, products and services in our core customer offerings
Champion the ethical development of data processing systems which include ML/AI components and ensure your teams are always working with the best interests of our users in mind.
What you'll bring with you
Proven experience in operating at an intermediate technical level.
Track record of solving customers' problems through software.
Excellent written and verbal communication skills
Appreciation of best practices for building production-grade maintainable web services
Experience coding in production and knowledge of application architecture
Experience working within commercial software development teams.
Understanding of SQL and designing data models.Working with infrastructure as code eg: CloudFormation, Terraform, Kubernetes.

Ideally you will also have:
Demonstrable experience in developing both training and inference systems for machine learning pipelines at scale.
Why Xero?

At Xero, we are empowered to bring our ‘whole self’ to work. Our collaborative and inclusive culture is one we’re immensely proud of. We know that a diverse workforce is a strength that enables businesses, including ours, to better understand and serve customers, attract top talent and innovate. We care about learning together and celebrate our teams’ continuous improvement and career development.

We offer a great remuneration package, including compelling benefits and perks, like Xero shares. We also support flexible working arrangements that allow you to balance your work, your life and your passions. Our Canadian Xero family includes Hubdoc, an automated data capture platform and we have offices in Toronto, Calgary, and Vancouver. From the moment you step through our doors, you’ll feel welcome and supported to do the best work of your life.","Xero
4.3",Midtown Toronto
764,Senior Engineer / Scientist - Remediation Practitioner,"If you are looking for a home for the best years of your career, where you can contribute to a dynamic employee-owned firm, tackle challenging project work, and collaborate with industry recognized professionals, Geosyntec is the place for you! We are seeking an exceptional Senior Remediation Practitioner with site investigation and remediation experience to grow our remediation and mining practices in our Saskatoon, SK office and to help us lead, manage, and grow our practice in Western Canada. This individual should be interested in being a leader and contributing to innovative and challenging projects, including the financial and technical evaluation, design, permitting, and construction stages. Our client base includes a diverse mix of industrial, institutional, and governmental clients.

As a firm, we offer a breadth of services. In the mining sector our focus includes source evaluation, mine permitting, geotechnical engineering, tailings and mine waste engineering, water resource management, water treatment and complementary treatability testing, closure and reclamation, and corporate social responsibility/environmental social governance. Our regional focus is on environmental services including geochemistry characterization and modelling, site-wide water quality and water balance models, innovative water treatment and source control solutions, treatability and leachate testing (through our in-house laboratory SiREM), integrated closure planning and mine closure requirements.

In the industrial sector, we focus on developing and implementing leading edge remedial solutions for soil and groundwater impacted sites. We collaborate with industry and academia to ensure that our clients get the best value possible. Petroleum, chlorinated solvent, nitrate, pesticide, fertilizers, metals and emerging contaminants such as fluorinated organics are driving our practice.

Our clients ask us to address their new ventures and most challenging problems involving the environment, natural resources, and civil infrastructure. Geosyntec is internationally known for its technical leadership, broad experience, and exceptional client service. Learn more by visiting us at www.geosyntec.com

ESSENTIAL DUTIES AND RESPONSIBILITIES

Task and project management, including planning and implementing investigation and remediation projects, budgeting and budget management, adherence to schedule, quality, client satisfaction, and profitability.
Business development; including bringing in new clients and obtaining repeat business from existing clients, leading proposal preparation, and developing and implementing a business development plan.
Management and mentoring of junior staff and managing subcontractors.
Work plan development, data evaluation, and report writing.
Preparing technical reports, letters, memoranda, plans, specifications, and proposals.
Reviewing and managing written document production.
Preparing for and participating in meetings with clients, regulatory personnel, and other parties.

Collaboration and mentoring are cornerstones of Geosyntec’s culture. We operate under a sell-manage-do culture, and so we expect that you’d work on challenging technical projects while leveraging your existing knowledge and experience to help Geosyntec expand its current practices and capabilities through business development and client management. You may also be asked to take on project management responsibilities, along with staff management and mentoring tasks.

Here are some other things you should know about this position:

Training: This position requires OSHA/MSHA health and safety, first aid, and CPR training and medical monitoring, paid for by the firm. We also offer professional development opportunities including technical conferences, in-house seminars, webinars, and mentoring, that allow our professionals to build the technical and business skills necessary to become successful consultants.
Fieldwork and overnight travel: Up to 20%

Your success is our success. We encourage our professionals to continually develop their interests and skills. Advancement is based on an individual’s own performance and initiative.

EDUCATION AND LICENSURE

Bachelor's degree in Engineering, Environmental, Civil, Chemical, Water Resource, Hydrogeology or Geochemistry. (required)
Advanced degree in the same. (preferred)
Professional Geoscientist or Engineer registration in the province of Saskatchewan, British Columbia, Alberta or Ontario. (required)
Project management certification, business development training, and leadership training. (preferred)
Regional visibility through involvement in professional associations or trade organizations. (preferred)

SKILLS, EXPERIENCE AND QUALIFICATIONS

At least 8 years of direct environmental consulting experience in the Canadian and / or U.S. marketplace, or equivalent combination of education and experience. (required)
8 years of experience in contaminated site assessment and remediation. (preferred)
Mining experience. (preferred)
An entrepreneurial attitude and enthusiasm for supporting business development and technical efforts to expand Geosyntec’s market share are valued assets. (required)
Thorough knowledge and experience with local regulations, and good relationships with regulators and indigenous groups. (preferred)
Experience with multi-disciplinary project teams. (required)
Demonstrated success in the development and management of clients. (required)
Excellent leadership skills. (required)
Ability to succeed in a fast-paced consulting environment, handling multiple project assignments, meeting strict deadlines, and traveling to client facilities as needed. (required)
Current OSHA 4-hr HAZWOPER training and refreshers. (preferred)
Valid Canadian driver’s license and a satisfactory driving record for business travel. (required)

CULTURE/EEO STATEMENT

Geosyntec strives to hire and retain the best and brightest people in their fields. We look for exceptional interpersonal skills, communication skills, and problem-solving abilities, plus the passion for technical excellence and quality. We seek individuals with leadership potential, a commitment to lifelong learning and growth, and the desire to build a long and rewarding career with a growing Firm.

Geosyntec is a great place to build a career. If you're looking for an exciting place to work, a place with challenging and rewarding projects, and a place that has been nationally recognized for its employees' quality of life, technical expertise, and business success, then Geosyntec may be the place for you. You can learn more about careers and employment at Geosyntec by visiting http://www.geosyntec.com/careers/

Geosyntec offers excellent compensation packages commensurate with experience, along with a comprehensive employee benefits package.","Geosyntec Consultants, Inc.
3.6",Saskatoon
765,"Manager, Data Science Engineering","This role will start off as work from home, gradually you will be required to work in the Markham office location.

Join an exciting team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat during this data-driven, technology revolution.

You will be part of a dynamic small team with exposure to different business stakeholders and direct influence on future products and innovative solutions. You will help build the foundation that enables our team to bring insights to the business and impact millions of customers. The team has already developed algorithms that are used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!

Your responsibilities:

As an engineering manager, you will:

Provide technical leadership to build, develop and scale engineering teams

Influence and guide strategy, execution and innovation for key engineering projects.

Champion top software engineering practices such as continuous integration, testing, and deployment.

Use your expertise in software development, python, data science or data engineering to propose new and innovative solutions to the many interesting problems we work on.

Provide engineering and architecture oversight for new-build infrastructure.

Drive projects forward, manage priorities with senior leadership and keep all stakeholders updated.

Recruit and hire top talent to support one or more engineering missions

What you need to succeed:

You will need the following skills and experience to succeed in the role:

5+ years of experience managing engineering teams

10+ years of relevant engineering experience

Great leadership skills coupled with technical expertise. The ideal candidate has a strong understanding of technical systems and is also able to jump in to help with coding or implementation tasks

Experience leading full stack engineering teams through the full software life-cycle.

A proven track record in successfully delivering moderate to complex Agile projects

Excellent interpersonal relations and demonstrated ability to work with others effectively

Excellent interpersonal and communication skills (written, verbal and presentation)

Ability to encourage and motivate team members

What sets you apart:

Strong Background in software development with a good understanding of Machine Learning and AI.

Experience with Python, Hadoop, Spark, AWS, PostgreSQL, Kuberneties and Docker are an asset.

You understand the relationship between analytics and business outcomes and can focus on long-term strategies for our team.

Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.﻿

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status","Aviva
3.7",Markham
766,Data Engineer(AWS / Pyspark),"Job Details:


Job Title:: Data Engineer(AWS / Pyspark)
Job Location:: Mississauga ,ON


Experience in building large scale batch and data pipelines with data processing frameworks in AWS cloud platform using PySpark Glue
Deep experience in developing data processing data manipulation tasks using PySpark such as reading data from external sources merge data perform data enrichment and load in to target data destinations
Proficiency with Big Data processing technologies Hadoop Hive or Databricks
Experience in deployment and operationalizing the code using CI CD tools Bitbucket and Bamboo
Experience with SQL and relational databases
Strong AWS cloud computing experience Extensive experience in Lambda S3 EMR Redshift

About Capgemini:


Capgemini is a global leader in consulting, digital transformation, technology and engineering services. The Group is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year+ heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. Today, it is a multicultural company of 270,000 team members in almost 50 countries. With Altran, the Group reported 2019 combined revenues of €17billion

What we offer:


Your career matters to you and is important to us too. Because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. This approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our University innovative and business-focused learning curriculums.
We promote a culture of diversity. We believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. Diversity enriches our creative solutions and adds value for our clients.
With the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve.
Our Shared values have been at the heart of the group since our formation. They are honesty, boldness, trust, freedom, team spirit, modesty and fun. These values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within Capgemini and in our partnerships.
Capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. We strongly encourage women, veterans and active military service personnel to apply.


Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law","Capgemini
3.9",Midtown Toronto
767,Data Engineer(AWS / Pyspark),"Job Details:


Job Title:: Data Engineer(AWS / Pyspark)
Job Location:: Mississauga ,ON


Experience in building large scale batch and data pipelines with data processing frameworks in AWS cloud platform using PySpark Glue
Deep experience in developing data processing data manipulation tasks using PySpark such as reading data from external sources merge data perform data enrichment and load in to target data destinations
Proficiency with Big Data processing technologies Hadoop Hive or Databricks
Experience in deployment and operationalizing the code using CI CD tools Bitbucket and Bamboo
Experience with SQL and relational databases
Strong AWS cloud computing experience Extensive experience in Lambda S3 EMR Redshift

About Capgemini:


Capgemini is a global leader in consulting, digital transformation, technology and engineering services. The Group is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year+ heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. Today, it is a multicultural company of 270,000 team members in almost 50 countries. With Altran, the Group reported 2019 combined revenues of €17billion

What we offer:


Your career matters to you and is important to us too. Because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. This approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our University innovative and business-focused learning curriculums.
We promote a culture of diversity. We believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. Diversity enriches our creative solutions and adds value for our clients.
With the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve.
Our Shared values have been at the heart of the group since our formation. They are honesty, boldness, trust, freedom, team spirit, modesty and fun. These values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within Capgemini and in our partnerships.
Capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. We strongly encourage women, veterans and active military service personnel to apply.


Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law","Capgemini
3.9",Midtown Toronto
768,Data Engineer(AWS / Pyspark),"Job Details:


Job Title:: Data Engineer(AWS / Pyspark)
Job Location:: Mississauga ,ON


Experience in building large scale batch and data pipelines with data processing frameworks in AWS cloud platform using PySpark Glue
Deep experience in developing data processing data manipulation tasks using PySpark such as reading data from external sources merge data perform data enrichment and load in to target data destinations
Proficiency with Big Data processing technologies Hadoop Hive or Databricks
Experience in deployment and operationalizing the code using CI CD tools Bitbucket and Bamboo
Experience with SQL and relational databases
Strong AWS cloud computing experience Extensive experience in Lambda S3 EMR Redshift

About Capgemini:


Capgemini is a global leader in consulting, digital transformation, technology and engineering services. The Group is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year+ heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. Today, it is a multicultural company of 270,000 team members in almost 50 countries. With Altran, the Group reported 2019 combined revenues of €17billion

What we offer:


Your career matters to you and is important to us too. Because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. This approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our University innovative and business-focused learning curriculums.
We promote a culture of diversity. We believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. Diversity enriches our creative solutions and adds value for our clients.
With the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve.
Our Shared values have been at the heart of the group since our formation. They are honesty, boldness, trust, freedom, team spirit, modesty and fun. These values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within Capgemini and in our partnerships.
Capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. We strongly encourage women, veterans and active military service personnel to apply.


Disclaimer

Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law","Capgemini
3.9",Midtown Toronto
769,Senior Scientist / Study Director,"BRI, A Frontage Laboratories Company, is a Contract Research Organization (CRO) located in Vancouver, British Columbia, Canada with head office located in Exton, Pennsylvania, USA.

BRI is recruiting a Study Director level senior scientist to lead a team of experienced vivarium staff operating within a 3000 sf rodent vivarium in the design and conduct of the following oncology, pharmacology and immunology studies:

Cell line-derived or patient-derived tumor xenograft efficacy, pharmacology, and immunology studies
In vitro and in vivo pharmacological assays supporting preclinical development of oncology cytotoxic small molecules, nucleic acids and monoclonal antibodies

In a separate facility led by BRI’s bioanalytical LC/MS/MS and ELISA team, BRI offers in vitro and in vivo drug metabolism / pharmacokinetics studies supporting preclinical and clinical development in a range of therapeutic areas for submissions in Canada, USA, Europe and Japan.

Qualification:

M.Sc. or Ph.D. in pharmacology or a related discipline
7+ years hands-on experience with pharmacology, immunology or oncology
5+ years supervisory experience within a research environment
Hands on experience in the conduct of animal models and in vitro / ex vivo assays
Demonstrated abilities in problem-solving and troubleshooting
Strong written and verbal communication skills
Strong planning and organization abilities
Competent, self-motivated and ability to work independently
Highly motivated, team player, and who enjoys a leadership role within a team of technically competent virvarium staff

Duties:

Serve as a Study Director, functionally responsible for the overall conduct of a study including design, delivery and reporting to clients and BRI management
Formulate and communicate project timelines, status, and data to clients
Provide resourceful input towards troubleshooting and resolving technical issues
Practice an attitude of continuous learning within a research environment to implement and expand assays and animal models capabilities
Manage the conduct, delivery quality and timeline of multiple projects
Train and mentor junior scientists within the vivarium and oncology team
Collaborate with the vivarium manager to ensure compliance of regulatory, health and safety operating standards of the vivarium

Please visit career page of our website to apply at www.frontagelab.com","Frontage Laboratories
3.1",Vancouver
770,Snowflake Data Engineer,"Duration: 8+ months

Requirement:


Years of experience: 4+

Minimum 4 years recent experience in web development
Minimum 3 years recent experience in Ecommerce projects.
Minimum 2 years recent experience in the Demandware platform etc.)
Expert in developing web applications for Front-End Developmet
Proficient in managing the administration of the Demandware platform in Business Manager
Current developer certification in Salesforce Commerce Cloud B2C / Demandware


Role Description:

Front-End Developer works more on the browser interaction side using Javascript frameworks, advanced HTML,

and CSS techniques to implement the layout and user experience specified in wireframes and PSDs delivered by our Information Architects

and Creative Designers. This also includes the ecommerce platform technologies for static content management and server-side dynamic

content generation.


The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.


A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.","Capgemini
3.9",Brampton
771,Data Engineer - Toronto,"Are you passionate about development?

We are looking for a passionate data engineer who will help us build the future for embedded analytics platform. This is a highly technical position in an exciting new development area we will be introducing into our retail analytics business platform. We are looking for you to help implement our web platform. You will be a key team player and an integral part of our excellent team.

Supported by a solid understanding of business, software architecture, software engineering and industry best practices, as well as strong hands-on technical skills – the Data Engineer is accountable to provide expert technical advice and recommend solutions to the development resources in the planning, strategizing, and the execution of high profile and complex data processing initiatives.

Who you are…


You bring positive energy to the team and thrive on strong collaboration.
Some others look to solve complex problems, bounce ideas off, and provide an alternate viewpoint.
You are self-motivated and thrive on developing solutions to open-ended business problems.
Have 5+ years of experience leading complex data architecture projects
Have a bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or other related disciplines

Why we need you…


Lead the design, development and implementation of new and existing complex data processing solutions; enabling teams to be more efficient and effective in analyzing data and getting to insights faster
Provide technical expertise and recommend data integration and management solutions to a diverse group of data analysts and data scientists as they develop best-in-class analytics solutions
Provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project
Reviews and approves specialized work products produced by the developer(s)
Work alongside the Technology team to put data processing solutions into the production environment
Sets standards and champions the agile process.

What you’ll do…


Excellent SQL coding and experience with a broad array of development tools and platforms, including a strong Linux background and data integration, processing and transformation tools, such as SQL, R, SAS, Python, etc.
Apply strong programming skills (Python, SQL …)
Expertise in relational database design and data models
Experience with big data technologies like Spark and Hadoop
Experience with various analytical data platforms and technologies
Experience with using REST API, Cloud
Experience in custom or structured data integration design, implementation, and maintenance
Understanding of machine learning
Experience with business intelligence tools such as SiSense (nice to have) and Microstrategy


Advantages
Lead the design, development and implementation of new and existing complex data processing solutions; enabling teams to be more efficient and effective in analyzing data and getting to insights faster
Provide technical expertise and recommend data integration and management solutions to a diverse group of data analysts and data scientists as they develop best-in-class analytics solutions
Provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project

Responsibilities
Excellent SQL coding and experience with a broad array of development tools and platforms, including a strong Linux background and data integration, processing and transformation tools, such as SQL, R, SAS, Python, etc.
Apply strong programming skills (Python, SQL …)
Expertise in relational database design and data models
Experience with big data technologies like Spark and Hadoop
Experience with various analytical data platforms and technologies
Experience with using REST API, Cloud
Experience in custom or structured data integration design, implementation, and maintenance
Understanding of machine learning
Experience with business intelligence tools such as SiSense (nice to have) and Microstrategy


Qualifications
You are self-motivated and thrive on developing solutions to open-ended business problems.
Have 5+ years of experience leading complex data architecture projects
Have a bachelor’s degree in Computer Science, Computer Engineering, Electrical Engineering or other related disciplines

Summary
Provide expert advice to development resources in reviewing and understanding the design and architecture of the technical solution of a specific project
Reviews and approves specialized work products produced by the developer(s)
Work alongside the Technology team to put data processing solutions into the production environment
Sets standards and champions the agile process.","Randstad
4.2",Midtown Toronto
772,Postdoctoral Research Scientist - Machine Learning for Audio Analytics,"Company Description


The Bosch Research and Technology Center North America with offices in Sunnyvale, California, Pittsburgh, Pennsylvania and Cambridge, Massachusetts is part of the global Bosch Group (www.bosch.com), a company with over 70 billion euro revenue, 400,000 people worldwide, a very diverse product portfolio, and a history of over 125 years. The Research and Technology Center North America (RTC-NA) is committed to providing technologies and system solutions for various Bosch business fields primarily in the areas of Human-Machine Collaboration (HMC), Robotics, Energy Technologies, Internet Technologies, Circuit Design, Semiconductors and Wireless, and MEMS Advanced Design.

The focus of our global research on Human Machine Collaboration includes Big Data Visual Analytics, Explainable AI, Audio Analytics, NLP, Conversational AI, Mixed Reality and Smart Wearables, etc. We develop intuitive, interactive and intelligent solutions to enable inspiring UX for Bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems (ADAS), Industry 4.0 and Internet of Things (IoT), security systems, smart home and building solutions, health care, and robotics.

As a part of the global research unit, our Visual Analytics & eXplainable AI group is responsible for shaping the future industrial AI experience for Bosch products and services by combining cutting-edge technologies of machine learning, data analysis and interactive visualization. We research and develop scalable, transparent, and intelligent big data analytic solutions (e.g. audio, images, sensor logs) for various domains including Industry 4.0 (I4.0), IoT, autonomous driving, connected vehicles, etc. With our award-winning talents (IEEE VIS best paper & best paper runner-ups), we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, ICML, ICASSP, Interspeech, and IEEE Signal Processing Magazine.



Job Description

Develop state-of-the-art machine learning based audio signal processing and analysis technologies and modules
Collaborate with other colleagues to integrate audio signal processing and analysis modules into the prototype systems for Bosch Audio Event Detection applications and improve the performance with various technologies
Summarize research findings in high-quality paper and/or patent submissions


Qualifications


Basic Qualification:

Ph.D. in Computer Science, Electrical Engineering or related fields
Experience in audio signal processing, machine learning and related fields
Hands-on experience of audio event detection or audio scene classification technologies
Hands-on experience of deep learning technologies and familiar with state-of-the-art deep learning toolkits
Programming experience with C/C++ and/or Python
Programming experience with Matlab

Preferred Qualification:

Publication record in top machine learning and audio analytics venues (e.g. ICASSP, Interspeech, AAAI, ICML).
Experience on noise cancellation or source separation
Experience on audio signal localization
Good communication and team-working skills
Good leadership skills to drive research topics

Additional Information


BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives

FIRST Robotics (For Inspiration and Recognition of Science and Technology)
AWIM (A World In Motion)

By choice, we are committed to a diverse workforce – EOE/Protected Veteran/Disabled.","Bosch Group
4.1",Waterloo
773,Postdoctoral Research Scientist - Machine Learning for Audio Analytics,"Company Description


The Bosch Research and Technology Center North America with offices in Sunnyvale, California, Pittsburgh, Pennsylvania and Cambridge, Massachusetts is part of the global Bosch Group (www.bosch.com), a company with over 70 billion euro revenue, 400,000 people worldwide, a very diverse product portfolio, and a history of over 125 years. The Research and Technology Center North America (RTC-NA) is committed to providing technologies and system solutions for various Bosch business fields primarily in the areas of Human-Machine Collaboration (HMC), Robotics, Energy Technologies, Internet Technologies, Circuit Design, Semiconductors and Wireless, and MEMS Advanced Design.

The focus of our global research on Human Machine Collaboration includes Big Data Visual Analytics, Explainable AI, Audio Analytics, NLP, Conversational AI, Mixed Reality and Smart Wearables, etc. We develop intuitive, interactive and intelligent solutions to enable inspiring UX for Bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems (ADAS), Industry 4.0 and Internet of Things (IoT), security systems, smart home and building solutions, health care, and robotics.

As a part of the global research unit, our Visual Analytics & eXplainable AI group is responsible for shaping the future industrial AI experience for Bosch products and services by combining cutting-edge technologies of machine learning, data analysis and interactive visualization. We research and develop scalable, transparent, and intelligent big data analytic solutions (e.g. audio, images, sensor logs) for various domains including Industry 4.0 (I4.0), IoT, autonomous driving, connected vehicles, etc. With our award-winning talents (IEEE VIS best paper & best paper runner-ups), we also actively collaborate with leading groups in academia and industry to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, ICML, ICASSP, Interspeech, and IEEE Signal Processing Magazine.



Job Description

Develop state-of-the-art machine learning based audio signal processing and analysis technologies and modules
Collaborate with other colleagues to integrate audio signal processing and analysis modules into the prototype systems for Bosch Audio Event Detection applications and improve the performance with various technologies
Summarize research findings in high-quality paper and/or patent submissions


Qualifications


Basic Qualification:

Ph.D. in Computer Science, Electrical Engineering or related fields
Experience in audio signal processing, machine learning and related fields
Hands-on experience of audio event detection or audio scene classification technologies
Hands-on experience of deep learning technologies and familiar with state-of-the-art deep learning toolkits
Programming experience with C/C++ and/or Python
Programming experience with Matlab

Preferred Qualification:

Publication record in top machine learning and audio analytics venues (e.g. ICASSP, Interspeech, AAAI, ICML).
Experience on noise cancellation or source separation
Experience on audio signal localization
Good communication and team-working skills
Good leadership skills to drive research topics

Additional Information


BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives

FIRST Robotics (For Inspiration and Recognition of Science and Technology)
AWIM (A World In Motion)

By choice, we are committed to a diverse workforce – EOE/Protected Veteran/Disabled.","Bosch Group
4.1",Waterloo
774,Data Arch Strategy Manager,"Data Strategy Manager
Location: Toronto, ON
We Are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.
You Are:
A curious leader who can connect and advise senior clients with storytelling and strong data driven mindset. As a manager, you will be a coach to develop our up and coming leaders in their careers, and a day to day leader of our diverse multi-disciplinary workforces to solve our client’s data challenges.
As a Data Strategy Manager, you will apply deep strategy development, architecting value, and operating model architecture skills to influence client agendas through business insight in a data driven reinvention and culture. You will partner with our clients to make bold decisions on priority C-Suite issues at the intersection of business, technology, and operations within a complex data management landscape.
You will provide deep understanding of our clients' industry landscape and options to mature data management practice from people, process and technology in the context of global, economic, technology and social trends.
The Work:

Stream lead on short high impact data strategies (why, how, value, and approach) for our client’s senior leadership in their data organization (SVP to C-suite); leading small teams of motivated generalists and deep specialists
Day to day leader and client relationship management of diverse delivery teams working with mid-level clients
Knowledgeable expert in data management and engineering to advise clients and Accenture teams as a subject matter advisor
Support new sales opportunities in partnership with our diverse workforce
Fortify Accenture’s Data & Analytics Strategy practice and role as a thought leader by creating content
Active coach and mentor to our up and coming leaders in the practice
Racking up those air miles will have to wait, as weekly non-essential travel to client sites is currently suspended. For now, all Accenture business travel, international and domestic, is currently restricted to client-essential sales/delivery activity only.


Here’s What You Need:

Minimum 7 years of Strategy consulting experience.
Minimum 7 years of experience in Journey to Cloud Transformation from Data Strategy and Data Driven Consulting standpoint, Data Driven Technology ROI/Cost Take Out, Data Driven Organization Operating Model, Modern Data Engineering Architecture, Data-Driven Enterprise, Applied Intelligence, Modern Data Management and Governance
Minimum 7 years of experience working with the interception of Business and Technology from the standpoint of various Data Management Facets such as Operating Models, Governance, Veracity and Trust, Privacy etc.
Minimum 7 years of experience in build in trusted relationships with senior leaders at client organizations who own, steward, consume, manage and implement data management solution from both business and IT.
Clear view on Data led elements of an Intelligent Enterprise comprises and the business benefits therefrom
Practical knowledge and understanding of data and analytics role in the digital space and end-to-end strategy-through-execution cycle
Experience leading small high impact teams
Strong communication skills, an ability to write business cases, and structure solutions
Desire to coach and mentor others
Ability to travel and work in Canada
Bonus Points if:

You perform as a long-term trusted advisor and partner by providing Thought Leadership for Data Driven consulting and profound knowledge of market trends in modern Data Engineering practice.
You can manage budgeting and forecasting activities and build financial proposals.
You have managed end-to-end projects and have reported and escalated to top levels.","Accenture
4.1",Midtown Toronto
775,Machine (deep) learning scientist for information retrieval/ Scientifique en apprentissage machine (profond) pour extraction d'information,"Until SARS-CoV-2, the fastest vaccine ever developed took about 4 years. SARS-CoV-2 vaccines were developed in less than 12 months. Imagine a world where every vaccine was developed at the speed of SARS-CoV-2 vaccines. Help GenAIz make this a reality. Join us.


GenAIz, a division of Uni3T, is a young and dynamic software development company that is active in the life science and pharmaceutical industry. Our mission is to increase collective well-being by accelerating the creation of better products, processes and treatments, through a state-of-the-art innovator’s assistant.


We are currently looking for a search engine researcher with building systems retrieving unstructured documents in response to a natural language queries to work on our GenAIz search engine (information retrieval). As a GenAIz AI researcher, you must enjoy documenting your research, sharing this knowledge and writing excellent code, while following typical agile development processes.




Responsibilities:

Create knowledge and technology by owning research projects: plan, propose, execute and analyze results;
Act independently, completing each research step without significant supervision;
Communicate and document research for technical and non-technical audiences;
Report and present research analysis/findings clearly and effectively to peers and management;
Be a team player by participating in peer review, sharing ideas and helping everyone succeed;
Work with the development teams to move research technology into production;



Qualifications:

A master's or PhD degree;
5+ years of industry experience on multidisciplinary research projects in either engineering or science disciplines;
Theoretical and empirical research experience in machine learning, AI, computer science, applied mathematics, data science, or related technical fields. ML and AI is strongly preferred;
Capable of completing research and analyzing results;
Some experience with business team requirements;
Experience implementation and evaluating machine learning models that meet the predefined metrics and product requirements;
History of working with large text, image or other datasets.
Experience manipulating and analyzing data from different sources;
Able to write clean, re-usable, and production-ready code;
Knowledge of statistics, linear algebra and data structures;
Some knowledge of computational syntax, pragmatics or semantics;
Experience building systems retrieving unstructured documents in response to a natural language query;
Familiar with neural ranking models such as DRMM, DeepMatch, DSSM, NRM-F;
Experience with search ranking metrics such as MAP, NDCG, CTR, dwell time;
Knowledge of vector space models (BoW, B-ngrams, tf-idf weighting, BM25);
Exposure to unsupervised document representation methods (n-gram embeddings, Sen2Vec, doc2vec, skip-thought vectors, SBERT);
Experience working with modern deep learning architectures such as LSTM and Transformers;
Familiar with Python, deep learning frameworks such as Caffe, Keras, TensorFlow, Pytorch, numpy and sklearn;
Excellent written, verbal and interpersonal communication;



Preferred Qualifications:

PhD degree;
Experience with MongoDB, git, GCP, Docker, AWS, K8s and micro-services;
A background in information retrieval;
Experience in the life sciences domain;
Knowledge of classical NLP and information retrieval techniques such as LSA and LDA;



Benefits:

Permanent Full-time position;
Competitive base salary + bonus;
Comprehensive insurance coverage;
Dynamic company culture with career development opportunities;
Flexible working hours;
Located between Griffintown and the Old Montreal, in the Cité du Multimédia neighborhood, now part of Montreal’s holistic hub for innovation, education, and entrepreneurship: the Quartier de l’Innovation.



GenAIz Group is an equal opportunity employer. All applicants will receive consideration for employment without regard to age, color, family or medical care leave, gender identity or expression, marital status, medical condition, national origin, physical or mental disability, political affiliation, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.


We thank all applicants for their interest, however only those candidates selected for interviews will be contacted.


Avant le SRAS-CoV-2, un vaccin qui était développé rapidement prenait environ 4 ans. En comparaison, les vaccins contre le SRAS-CoV-2 ont été développés en moins de 12 mois. Imaginez un monde où chaque vaccin serait développé à la vitesse des vaccins contre le SRAS-CoV-2... Aidez GenAIz à faire de ce rêve une réalité. Rejoignez-nous maintenant !


GenAIz, une division d'Uni3T, est une entreprise jeune et dynamique de développement de logiciels, active dans l'industrie pharmaceutique et des sciences de la vie. Notre mission est d'accroître le bien-être collectif en accélérant la création de meilleurs produits, processus et traitements grâce à un assistant à l'innovateur à la pointe de la technologie.


Nous recherchons actuellement un chercheur en moteur de recherche, sachant construire des systèmes qui récupèrent des documents non structurés suite à des requêtes en langage naturel, afin de travailler sur notre moteur de recherche GenAIz (information retrieval). En tant que chercheur en IA de GenAIz, vous devez aimer documenter vos recherches, partager vos connaissances et écrire un excellent code, tout en suivant des processus de développement agiles.


Responsabilités :

Générer des connaissances et créer des technologies en vous appropriant des projets de recherche : planifier, proposer, exécuter et analyser les résultats ;
Réaliser de manière indépendante et proactive chaque étape de votre recherche avec un minimum de supervision ;
Communiquer facilement vos recherches/résultats à l’aide de documentation pertinente devant différents publics (techniques et non-techniques) ;
Avoir un bon esprit d’équipe en participant activement à des examens par les pairs, en partageant vos idées et en aidant vos collègues à atteindre leurs objectifs ;
Travailler de pair avec les équipes de développement pour pousser la technologie de recherche en production.



Qualifications :

Un diplôme de maîtrise ou de doctorat ;
Plus de 5 ans d'expérience dans l'industrie sur des projets de recherche multidisciplinaires, dans des disciplines scientifiques ou d'ingénierie ;
Expérience de recherche théorique et empirique en apprentissage automatique, IA, informatique, mathématiques appliquées, science des données ou domaines techniques connexes. Une expérience en apprentissage automatique et en IA est fortement souhaitée ;
Capable de mener à bien des recherches et d'analyser les résultats ;
Une certaine expérience des exigences d’équipes commerciales ;
Expérience dans la mise en œuvre et de l'évaluation de modèles d'apprentissage automatique qui répondent aux métriques prédéfinies et aux exigences du produit ;
Expérience de travail avec de grands ensembles de textes, d'images ou d'autres données ;
Expérience en manipulation et analyse de données provenant de différentes sources ;
Capacité à écrire un code propre, réutilisable et prêt pour la production ;
Connaissance des statistiques, de l'algèbre linéaire et des structures de données ;
Quelques connaissances en syntaxe, pragmatique ou sémantique informatique ;
Expérience dans la construction de systèmes permettant de récupérer des documents non structurés en réponse à une requête en langage naturel ;
Familiarité avec les modèles de classement neuronaux tels que DRMM, DeepMatch, DSSM, NRM-F ;
Expérience avec les métriques de classement de recherche telles que MAP, NDCG, CTR, dwell time ;
Connaissance des modèles d'espace vectoriel (BoW, B-ngrams, pondération tf-idf, BM25) ;
Familiarité avec les méthodes non supervisées de représentation de documents (n-gram embeddings, Sen2Vec, doc2vec, skip-thought vectors, SBERT) ;
Expérience de travail avec des architectures modernes d'apprentissage profond telles que LSTM et Transformers ;
Familiarité avec Python et cadres d'apprentissage profond tels que Caffe, Keras, TensorFlow, Pytorch, numpy et sklearn ;
Excellentes compétences en communication verbale, écrite et interpersonnelle ;



Qualifications préférées:

Diplôme de doctorat ;
Expérience avec MongoDB, git, GCP, Docker, AWS, K8s et micro-services ;
Une expérience professionnelle en recherche d'informations (information retrieval) ;
Expérience dans le domaine des sciences de la vie ;
Connaissance du NLP/TAL et des techniques de recherche d'information telles que LSA et LDA ;



Avantages :

Poste permanent à temps plein ;
Salaire de base compétitif + prime ;
Couverture d'assurance complète ;
Culture d'entreprise dynamique avec des possibilités de développement de carrière ;
Horaires de travail flexibles ;
Situé entre Griffintown et le Vieux-Montréal, dans le quartier de la Cité du Multimédia, qui fait maintenant partie du pôle holistique d'innovation, d'éducation et d'entrepreneuriat de Montréal : le Quartier de l'Innovation.



Le Groupe GenAIz est un employeur offrant l'égalité des chances. Tous les candidats seront considérés pour un emploi sans égard à l'âge, à la couleur, aux congés pour raisons familiales ou médicales, à l'identité ou à l'expression sexuelle, à l'état civil, à la condition médicale, à l'origine nationale, à un handicap physique ou mental, à l'affiliation politique, à la race, à la religion, au sexe (y compris la grossesse), à l'orientation sexuelle ou à toute autre caractéristique protégée par les lois, règlements et ordonnances applicables.


Nous remercions tous les candidats de leur intérêt, mais seuls les candidats sélectionnés pour un entretien seront contactés.","GenAIz
5.0",Montreal
776,"Data Science Manager, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Toronto; Ottawa; Vancouver

Partner with clients to solve their most complex business problems
Be encouraged to deepen your technical skills…whatever those may be
Lead projects and teams to make an impact that matters


Are you passionate about solving complex analytical problems, learning about the latest in cutting-edge AI, developing and nurturing client relationships and leading project teams? If you answered yes, then we have an opportunity waiting for you!

What will your typical day look like?


As a Data Science Manager you will assume full life cycle responsibility to lead and manage client engagements, with a focus on the Consumer & Retail industry and lead and oversee the development of machine learning models to deliver best-of-breed solutions for clients’ business problems. You will drive growth and market eminence for the Omnia AI data science practice through thought leadership and business development in the Consumer & Retail industry. The Data Science Manager will take a hands-on role in delivering consulting services to high growth organizations with a diverse team consisting of data scientists, data architects, software developers, information designers, business/industry leaders, design analytical plans and communicate insights on client projects. You will also be providing mentorship to team of data scientists in project planning, data collection, modelling, insights development and lead development of pitches and proposal bids

About the team


Deloitte Omnia, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Enough about us, let’s talk about you


You are someone with:

5+ years of relevant work experience with applying analytics, data science and machine learning and working with data in the Consumer & Retail industry.
Strong experience with Machine Learning agile project management end-to-end including planning & budgeting, resourcing and delivery
Data science experience using (one or more): Python, Could ML (AWS, GCP, Azure), or similar tools
Strong experience with other statistical analytical techniques, data mining, and predictive models
Database and programming languages experience and data manipulation and integration skills using (one or more) SQL, Oracle, Hadoop, NoSQL Databases, or similar tools
Superior oral and written communication skills, with demonstrated ability to communicate insights to executive business audiences
BA/BSc degree in Computer Science, Applied Mathematics, Statistics, or related field is preferred. Advanced degree (MA/MSc, equivalent or higher) is preferred

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! Deloitte encourages applications from all qualified candidates that represents the full diversity of communities across Canada. This includes candidates from Indigenous communities in support of living our values and our commitments to our Reconciliation Action Plan . We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.


Deloitte Canada has 30 offices with representation across most of the country. We acknowledge our offices reside on traditional, treaty and unceded territories as part of Turtle Island and is still home to many First Nations, Métis, and Inuit peoples. We are all Treaty people.","Deloitte
3.9",Midtown Toronto
777,AWS Data Engineer,"Senior AWS Data Engineer, Atlanta – remote – United States


Syntax is a leading Managed Cloud Provider for Mission Critical Enterprise Applications and has been providing comprehensive technology solutions to businesses of all sizes since 1972. Syntax has undisputed strength to implement and manage ERP deployments (Oracle, SAP) in a secure, resilient, private, public or hybrid cloud. With strong technical and functional consulting services, and World Class Monitoring & Automation, they serve some of North America’s largest corporations across a diverse range of industries. Syntax has offices worldwide, and partners with Oracle, SAP, AWS, Microsoft, IBM and other global technology leaders.

Position Summary


We’re looking for a passionate data engineer who is well versed in AWS cloud technologies for ETL modeling, data warehouse and data lake design/building and data movement to join our expanding BI and Data Analytics team! This individual will be responsible for supporting existing data warehouse customers, as well as performing a senior lead role for new projects to implement various data solutions in AWS. The position can be remote or in the Atlanta, GA area. Someday in a post-Covid future, a minimal amount travel may be required for this position.

Applicants for this role must be proficient data engineering experts already experienced in AWS cloud technologies such as: Python, Spark/PySpark, Glue, Redshift, S3, RDS and data movement (DMS/Kinesis). Data visualization skills in Tableau or AWS QuickSight are a plus, but not required. This team members works primarily with AWS data analytics technologies for existing projects and support customers, but also will need to regularly keep up with the ever emerging and evolving landscape of AWS data offerings.

Responsibilities

Resource on various client engagement projects to implement and deliver custom data warehousing solutions
Help desk, trouble ticket support for our existing data warehouse Managed Services customers

Qualifications

Minimum two years of hands-on AWS data technology experience
Python, Spark/PySpark, Glue, Redshift, S3, RDS and data movement (DMS/Kinesis)
Is well versed with the best practices of creating an AWS Well-Architected Environment with the Analytics Lens
AWS Certified Cloud Practitioner (Preferred, not required)
AWS Data Analytics Specialty Certification (Preferred, not required)
Possesses fantastic troubleshooting skills and ability to systematically break down problems to resolve issues and reach solutions
Prolific documentation author
Accountable to drive deliverables towards completion
Possesses an ethos of always striving for improvement and growth
Exposure to cloud-based and SaaS data warehouse solutions
Experience with JD Edwards and SAP as a data source is a plus, but not required
Must possess an ethos of always striving for improvement and growth, and desire to flourish in an engaging, creative, hard-working, fun-loving corporate culture environment!
Needs to be willing to constantly reinvent who they are to learn new technologies and approaches. Must push beyond their current skillset and limitations. Must love to learn and experiment. And not be afraid to make mistakes.
The most successful candidates will regularly employ the RTFM, GIYF and JFGI approaches to learning and problem solving. Willingness to teach colleagues and knowledge sharing are mandatory in our work environment.

You must be legally entitled to work in Canada and/or in the U.S. We are unable to sponsor at this time.","Syntax Systems Ltd.
3.9",Mont-Royal
778,Data Engineer/Consultant,"Company Description


Cardinal Path, part of dentsu, is a leading digital analytics and digital marketing firm focused on delivering insight, understanding and outcomes that create competitive advantage for our clients. We engage at the strategic, business, and technical levels to generate tangible and quantifiable value for our partners. Our clients include brands such as Bridgestone, Johnson and Johnson, Pfizer, Asics and hundreds of others. Cardinal Path’s mission is: To know. To Share. To be our Partners’ competitive advantage. And our company culture reflects the importance of our people’s’ expertise, wellness and happiness in everything we do.



Job Description


The Data Science Consultant (Data Engineer) will have proven expertise in system architecture, database design, data integrations, and be an expert in SQL and Python. Experience with delivering in big data platforms such as Google BigQuery, Microsoft Azure SQL DB/Synapse, or Amazon Redshift is essential. Expertise with traditional RDBMS platforms such as SQL Server or Oracle and NoSQL and Hadoop environments would complement. Data integration experience using ETL platforms such as AirFlow, Talend, Alteryx, or Fivetran is important.

Experience in the digital data and analytic ecosystem and intermediate knowledge in Web Analytic tools (Google Analytics or the Adobe Marketing Cloud), and API expertise is a major plus!!

Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles
Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts
Participate in product roadmap discussions and identifying key areas for improvement of products and services
Collect client project requirements, focusing on needs & impacts and necessary technical outcomes
Create solution designs to solve for clients business and technical needs while keeping within budget
Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following Cardinal Path's documentation standards
Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards
Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security
Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models
Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps.


Qualifications

Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development
Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required
Experience with relational database systems including SQL Server, Oracle, MySql, Postgres
Advanced skills in data scripting and database development technologies (SQL, Python, R)
Deep knowledge of ETL tools and how they can be applied to a big data environment
Familiarity with analyzing digital marketing, advertising and ecommerce data
API expertise for Google Analytics, Facebook, Twitter, etc. is a plus
Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics
Experience with building and maintaining DevOps workflows
Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI
Experience with cloud platforms such as AWS, Azure, and Google Cloud
Familiar with NoSql database technologies such as MongoDB
Knowledge of technologies such as Spark, Hadoop, and Airflow
3+ years experience in marketing technology/data/analytics roles



Additional Information


We know through experience that different ideas, perspectives and backgrounds foster a stronger and more creative work environment that delivers better business results. We strive to create workplaces that reflect the clients we serve and where everyone feels empowered to bring their full, authentic selves to work. We are committed to working with our candidates from all ability levels throughout the recruitment process to ensure that they have what they need to be at their best.

If you need accommodation during the application or interview process, please contact Canada.Recruitment@dentsuaegis.com or to begin a conversation about your individual accessibility needs throughout the hiring process.","Cardinal Path
3.4",Vancouver
779,Data Engineer/Consultant,"Company Description


Cardinal Path, part of dentsu, is a leading digital analytics and digital marketing firm focused on delivering insight, understanding and outcomes that create competitive advantage for our clients. We engage at the strategic, business, and technical levels to generate tangible and quantifiable value for our partners. Our clients include brands such as Bridgestone, Johnson and Johnson, Pfizer, Asics and hundreds of others. Cardinal Path’s mission is: To know. To Share. To be our Partners’ competitive advantage. And our company culture reflects the importance of our people’s’ expertise, wellness and happiness in everything we do.



Job Description


The Data Science Consultant (Data Engineer) will have proven expertise in system architecture, database design, data integrations, and be an expert in SQL and Python. Experience with delivering in big data platforms such as Google BigQuery, Microsoft Azure SQL DB/Synapse, or Amazon Redshift is essential. Expertise with traditional RDBMS platforms such as SQL Server or Oracle and NoSQL and Hadoop environments would complement. Data integration experience using ETL platforms such as AirFlow, Talend, Alteryx, or Fivetran is important.

Experience in the digital data and analytic ecosystem and intermediate knowledge in Web Analytic tools (Google Analytics or the Adobe Marketing Cloud), and API expertise is a major plus!!

Act as primary consultant to clients for data engineering services, managing the client relationship and coordinating across other support and consultant roles
Estimate projects involving data integration, data architecture, business analysis or application development and collaborate with sales and client success teams to grow accounts
Participate in product roadmap discussions and identifying key areas for improvement of products and services
Collect client project requirements, focusing on needs & impacts and necessary technical outcomes
Create solution designs to solve for clients business and technical needs while keeping within budget
Produce documentation of data pipeline design and solution architecture for data warehousing and ETL, following Cardinal Path's documentation standards
Create datasets, extracts, or views of data that will be consumed by teams of analysts and data scientists to support data mining, analytics, reporting, and dashboards
Develop, implement, and support methodologies, standards, and tools for data management, considering innovation and data security
Create ongoing standards and process for overall data architecture team, including developing governance, support and testing models
Perform exploratory data validation with analysts to ensure quality data standards are in place and ensure data integrity during all transformation steps.


Qualifications

Bachelor’s degree in Statistics, Mathematics, Business Analytics or related field quantitative field, required with a minimum of 3-5 years experience with database development
Experience with cloud / big data technologies such as BigQuery, Azure SQL DB/Synapse, Amazon Redshift is required
Experience with relational database systems including SQL Server, Oracle, MySql, Postgres
Advanced skills in data scripting and database development technologies (SQL, Python, R)
Deep knowledge of ETL tools and how they can be applied to a big data environment
Familiarity with analyzing digital marketing, advertising and ecommerce data
API expertise for Google Analytics, Facebook, Twitter, etc. is a plus
Familiarity with web analytics tools such as Adobe Marketing Cloud or Google Analytics
Experience with building and maintaining DevOps workflows
Experience with optimizing BI or visualization tools such as Tableau, Looker, DOMO or Power BI
Experience with cloud platforms such as AWS, Azure, and Google Cloud
Familiar with NoSql database technologies such as MongoDB
Knowledge of technologies such as Spark, Hadoop, and Airflow
3+ years experience in marketing technology/data/analytics roles



Additional Information


We know through experience that different ideas, perspectives and backgrounds foster a stronger and more creative work environment that delivers better business results. We strive to create workplaces that reflect the clients we serve and where everyone feels empowered to bring their full, authentic selves to work. We are committed to working with our candidates from all ability levels throughout the recruitment process to ensure that they have what they need to be at their best.

If you need accommodation during the application or interview process, please contact Canada.Recruitment@dentsuaegis.com or to begin a conversation about your individual accessibility needs throughout the hiring process.","Cardinal Path
3.4",Vancouver
780,Intermediate Scientist/CAPA Specialist,"Our client in Ottawa West is currently looking for a CAPA Specialist, R&D to join their team. As a member of Research and Development team, the candidate will contribute to the team’s success by supporting key product development programs while gaining an understanding of the business. Main tasks will include, but are not limited to, data analysis, CAPA documentation, performing CAPA investigations, and root cause analysis/failure mode effects analysis of chemical/biochemical systems and mechanical/microfluidic systems. The ideal candidate for our team will bring the following education, experiences, knowledge, and skills to the position.

Required Education and Experience:

Bachelor’s Degree in Science, Engineering or related discipline preferred.

Proven technical, creative, teamwork and implementation skills to contribute to active investigations for product development.
Demonstrated problem-solving and analytical skills. Experienced using statistical tools, root cause analysis and knowledge of Failure Mode Effects Analysis.
Strong written and oral skills are required.
Comprehends and conveys information accurately and concisely, excellent technical documentation skills. Ensures documentation and resulting actions comply with all corporate and regulatory requirements.
Understands key technical issues and provides creative solutions while balancing relative risks and gains.
Excellent attention to detail, organization skills and proven ability to multitask.
Demonstrated initiative and ability to work with tight deadlines.
Demonstrated judgment and decision-making skills, organization, coordinating and planning skills, ability to work in a multi-task environment, ability to work under pressure and propensity to continuous learning.
Ability to work both independently and within small and large teams; strong interpersonal skills and ability to work cross-functionally.
Ability or aptitude to work on complex problems/issues.
Ability or aptitude to use various types of databases and other computer software.

Familiarity with any of the following areas would be an asset:

GMP, ISO 13485 standard, FDA Quality System Requirements and other applicable US Code of Federal Regulations for Devices.
Working knowledge of Quality Management Systems.
Risk management methods.
Working knowledge of CAPA procedures.

This position requires a solid knowledge of scientific principals and theories and the ability to implement these in a creative and effective manner. The individual must be flexible and be able to work in a fast paced environment with changing priorities. This position requires someone who can work Monday through Friday from 8:00 a.m. to 5:00 p.m. Compensation to be determined based on level of experience.

If you would like to be considered for this position, please click on ""Apply Now!""

AP1956","Adecco
3.7",Ottawa
781,Ingénieur de données I / Data Engineer I,"Role and Responsibilities


(English will follow)


Ingénieur de données


Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.


Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!

Regardez la vidéo d’un/e collègue qui partage sa passion : https://www.youtube.com/watch?v=DuWzMIEZ_9I&list=PL20BE384270BA6C02&index=2&t=0s

Travail significatif qui favorise le perfectionnement professionnel

Possibilité de travailler dans l’industrie technologique et de s’y épanouir

Environnement de travail axé sur la collaboration

Faire partie d’une équipe à haut rendement


Ce que nous avons à offrir

Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important

Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif

Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise

Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires

Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année

Plaisir au travail : Activités sociales et communautaires tout au long de l’année!


Votre mission

En tant qu’ ingénieur des données au sein de notre équipe de l’accélérateur numérique, votre mission est d’améliorer l’expérience client en faisant la transformation des données dans un format pouvant être exigeant sur un certain nombre de plans pour d’autres intervenants en analyse. Cela sera accompli principalement par l’élaboration, l’entretien et la mise à l’essai d’infrastructures destinés à la production de données. Cette équipe jouera également un rôle important dans la promotion de solutions d’architecture pour des projets de science des données et de modélisation avancée.


Votre rôle et responsabilités principales

Créer et maintenir une architecture de pipeline de données optimale et évolutive.

Assembler des ensembles de données complexes qui respectent les exigences opérationnelles fonctionnelles et non fonctionnelles.

Concevoir l’infrastructure requise pour l’extraction, la transformation et le chargement de données optimaux à partir d’une grande variété de sources de données et de technologies de « données massives ».

Définir, concevoir et mettre en œuvre des améliorations de processus internes : l’automatisation des processus manuels, l’optimisation de la transmission de données, la nouvelle conception de l’infrastructure pour une plus grande évolutivité, etc.

Mettre au point des outils d’analyse qui utilisent le pipeline de données pour fournir des perspectives applicables en matière d’acquisition de clients, d’efficacité opérationnelle et d’autres mesures clés du rendement opérationnel.

Travailler avec des intervenants, y compris les équipes de la direction, de l’expérience client et de la conception pour les assister dans la résolution de questions techniques liées aux données et le soutien de leurs besoins en infrastructure.

Maintenir les données séparées et en sécurité à travers les frontières nationales par l’entremise de plusieurs centres de données.

Travailler avec des experts en données et en analyse pour parvenir à une meilleure fonctionnalité de nos systèmes de données.

Être un agent de changement et un promoteur de la mentalité agile

Contribuer au milieu de travail collaboratif et stimulant

Se garder à l’affût des nouvelles tendances et apporter des idées d’innovation


Vos qualifications

Baccalauréat en informatique, en ingénierie ou un domaine connexe

Au moins trois (3) ans d’expérience dans l’industrie en matière de travail avec des données, de code, de création de scripts (Python/Java/Scala/SQL/JS/Bash), de conception, et de mise à l’essai

Au moins trois (3) ans d’expérience en matière d’élaboration et d’administration de gros systèmes de données

Solides connaissances des principes fondamentaux du soutien à la clientèle en matière d’algorithmes et de structures de données.

Expérience en soutien et en travail avec des équipes interfonctionnelles dans un environnement dynamique Expérience en utilisation d’outils de traitement de données massives : Hadoop, Spark, Kafka, etc.

Expérience en utilisation de bases de données relationnelles SQL et NoSQL, y compris Postgres et Cassandra.

Expérience en utilisation de pipelines de données et d’outils de gestion du flux de travail : Azkaban, Luigi, Airflow , etc.

Expérience en utilisation de services infonuagiques AWS : EC2, EMR, RDS, Redshift

Expérience en utilisation de services infonuagiques Microsoft : Azure, Databrick , etc.

Expérience en utilisation de systèmes de traitement de flux : Storm, Spark-Streaming, etc.

Expérience en utilisation de langages de script orientés objet et à fonction d’objet : Python, Java, C++, Scala, etc.

Volonté de participer à tous les niveaux de l’exécution des travaux liés à un projet, au besoin

Excellentes aptitudes pour la communication verbale et écrite, en français et en anglais


À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Camille Launay, spécialiste de l’acquisition de talents ( camille.launay@cae.com ) ou Feriel Hadjloum, Gestionnaire de produits numériques ( feriel.hadjloum@cae.com ).


Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.

#LI-CL1


******************************************************

Data Engineer


If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.


Here are few reasons why folks love working at CAE !

Watch the video of a colleague sharing his/her passion: https://www.youtube.com/watch?v=DuWzMIEZ_9I&list=PL20BE384270BA6C02&index=2&t=0s

Meaningful work that drives professional development

Ability to enter and grow within the technology industry

Work in a collaborative environment

Be part of a high-performance team


What we have to offer

Benefits: fully flexible for you to choose what is important

Retirement: Defined Benefits Retirement Plan & Group Reg istered Retirement Savings Plan (RRSP)

Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts

Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan

Work-Life Balance: Flextime & California Fridays all year

Fun at work: social and community events all-year round !


Your mission


As a Data Engineer you will be asked to transform data into a format that can be consuming for other analytics stakeholders. This should be accomplished mainly through developing, maintenance and testing infrastructure for data generation. You will also play an instrumental role enabling architecture solutions for Data Science and advance modelling projects.


Your Role & Main Responsibilities


Create and maintain optimal and scalable data pipeline architecture

Assemble large, complex data sets that meet functional / non-functional business requirements

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and ‘big data’ technologies.

Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

Work with stakeholders including the Executive, CX and Design teams to assist with data-related technical issues and support their data infrastructure needs.

Keep data separated and secure across national boundaries through multiple data centers.

Work with data and analytics experts to strive for greater functionality in our data systems.

Be a change agent & Agile mindset promoter

Contribute to the collaborative and stimulating work environment

Be connected to the industry to know tendencies and suggest innovative ideas


Your Qualifications


Bachelor's degree in Computer Science, Engineering, or related field

A minimum of 3 years industry experience working with data, coding and scripting (Python/Java/Scala/SQL/JS/Bash), design and testing

A minimum of 3 years experience developing and administering large data systems

Solid knowledge of CS fundamentals in algorithms and data structures

Experience supporting and working with cross-functional teams in a dynamic environment.

Experience with big data tools : Hadoop, Spark, Kafka, etc.

Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.

Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.

Experience with AWS cloud services: EC2, EMR, RDS, Redshift

Experience with Microsoft cloud services: Azure, Databrick, etc.

Experience with stream-processing systems: Storm, Spark-Streaming, etc.

Experience with object-oriented / object function scripting languages : Python, Java, C++, Scala, etc.

Willingness to participate in all levels of project work when necessary

Excellent English and French written and verbal communication skills.


At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Camille Launay , Talent Acquisition Specialist ( camille.launay@cae.com ) or Feriel Hadjloum, Digital Product Manager ( feriel.hadjloum @cae.com ).


Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.


Position Type


Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.","CAE Inc.
3.8",Saint-Laurent
782,"Senior Scientist, Virology (Laval)","With unrivaled expertise in immunology, and operating sites in North America (East and West Coast) and Europe, Nexelis is a leading provider of assay development and advanced laboratory testing services in the infectious diseases, metabolic diseases, and oncology fields. Our versatile team of scientists, working with our advanced technology platforms, were instrumental in the development, qualification, validation, and large-scale sample testing of assays that supported the FDA filing of almost 100 new molecular entities, including blockbuster vaccines, anti-viral drugs, and immunotherapy, gene and cell therapy products.

We are currently looking for a motivated candidate with experience to fill the Senior Scientist, Virology position. This position reports to the Associate Director, Laboratory Operations. The Scientist will have extensive expertise in virology, will be responsible to perform assay development, qualification and validation of virology assays.

Position Responsibilities

Supervise and perform the development, qualification and validation of assays to assess the immune responses to various vaccine/drug candidates;
Prepare presentations of scientific data for internal and external discussions;
Prepare qualification/validation plans and reports, procedures (analytical method) that meet standards of written scientific standards and comply with Nexelis’ quality assurance and operations standards and the client-specific requirements;
Conduct literature searches of science/medical search engines and libraries;
Troubleshoot technical issues related to the assays;
Provide mentoring/training over Research Associates and technical staff;
Be compliant to all applicable regulations (e.g., GCLP) and biosafety / EHS standards;
Ensure optimization of operational efficiency in the lab;
May interact with clients, business development, account management and operations management to support commercial proposals in terms of scientific design and lab workload assumptions.

Experience and Qualifications

Expert of cell-based assays for neutralizing antibody detection;
Proficiency in immunoassays and/or immunogenicity-based methodologies;
Knowledge and experience in method development and validation of immunogenicity assays;
Proven leadership and management skills;
Team player, client oriented and strong organizational skills;
Proficient with office tools (Excel, Word, PowerPoint).
At least 3 to 5 year’s experience in a CRO and/or a pharmaceutical company;
Excellent French and English, written and spoken.

Education

M.Sc. or Ph.D. in virology / immunology.","Pacific Biomarkers
2.9",Laval
783,Senior Scientist (Laval),"Should you consider yourself to be among the best Senior Scientist in town, here is your chance to participate in the daily life of the most successful advanced testing service provider in the immunology field. Involved in more than 15 SARS-CoV-2 vaccine developments in partnership with multinational pharmaceutical companies, innovative biotechnology companies and prestigious NGOs such as Bill and Melinda Gates Foundation or CEPI, we also proudly serve the needs of our clients in fields such as Flu (universal and seasonal), meningitis, respiratory syncytial virus, chikungunya, malaria, or HPV and are growing an immune-oncology franchise.

Position Responsibilities

Plans, organizes, and supervises and work on the execution of preclinical studies;
Performs and provides direction for establishing, designing and executing new assay in response to the needs of clients. Provides support to technical staff in executing and documentation of data in reports;
Supervises and prepares advanced data analysis, merging and transforming files and data, and identification of outliers for further study. Independently performs statistical tests as required for the assigned project, to study outliers, or to answer questions;
Writes reports and bring scientific insight on complex research questions;
Develops, writes and reviews assay methods and ensures good execution in the lab;
Facilitates internal and external working relationships and communications;
Promotes teamwork and cooperation among laboratory staff;
Provides leadership/mentoring/training over technical staff;
Serves as back-up and help to the laboratory in routine testing as designated;
Relays information in a timely manner to supervisory personnel regarding problems that may impact the laboratory’s ability to meet expected service and turn-around-time;
Works on assignments that are complex in nature where considerable judgment and initiative are required in resolving problems and making recommendations;
Supervise, coordinates and mentor on a day to day basis in the context of a project;
Coordinate and monitor projects on a daily basis to ensure that deadlines are met;
Performs scientific review;
Follow all applicable procedures and escalates any potential issue, deviation, ideas for improvement to operations management to ensure project execution efficiency;
Performs other duties related to laboratory performance and efficiency as the need arises.

Experience and Qualifications

KNOWLEDGE & SKILLS

Advanced specialized knowledge of theories and principles of immune read-out;
Well-developed skills using office productivity applications such as spreadsheets, data reduction and statistical applications, and presentation graphics;
Advanced math skills to conduct tests and analyze the significance of preclinical tests and statistical data;
Additional knowledge of statistical methods, including computer-aided statistical software;
Well-developed human relations skills to convey scientific concepts and consult with a range of internal and external contacts in formal settings for purposes of testing, conversion of data, and problem solving.

ABILITIES

Perform the functions of the position, including planning, testing, and reporting;
May analyze and interpret complex readouts from multiple assays;
Think independently and resolve complex problems without supervision or guidance;
Know how to operate the computers, operating systems, peripherals, and other equipment used by the Company for information retrieval, storage, analysis, and processing;
Work collaboratively, follow logical progressions of testing projects and to think logically, creatively, and in abstract terms;
Employ critical thinking and evaluation techniques when developing and testing significance of scientific and research-oriented data;
Analyze and solve technical problems under time pressure.

Education

Masters in a biological science or equivalent;
At least 5 years of laboratory experience in the context of CRO preclinical work.","Pacific Biomarkers
2.9",Laval
784,Big Data Engineer,"Company description

VirtueTech Inc. is an Amazon Partner Network (APN) Consulting Partner, focusing exclusively on Amazon Web Services (AWS). With a strong foot in AWS, Cloud Infrastructure and Data Analytics, we are a global technology solutions provider with a reputation for stringent quality standards.

We are a very fast growing company and a trusted analytics partner for multiple Fortune 500 companies. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. Working with us offers you an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility

Job description

Job Description-

Focus on scalability, performance, service robustness, and cost trade-offs
Continuous drive to explore, improve, enhance, automate, and optimize systems and tools to best meet evolving business and market needs
Attention to detail, coupled with ability to think abstractly
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Create prototypes and proof-of-concepts for iterative development
Keen to learn new technologies and apply the knowledge in production systems
Take complete ownership of projects and their development cycle

Contract length: 6-8 months

Application deadline: 2021-04-24

Expected start date: 2021-04-26

Job Types: Full-time, Temporary, Contract

Salary: $62,173.00-$130,000.00 per year

Additional pay:

Overtime pay

Schedule:

8 hour shift
Monday to Friday

COVID-19 considerations:
Remote job. Working from home

Work remotely:

Yes

COVID-19 precaution(s):

Remote interview process",Virtue Tech Inc.,Midtown Toronto
785,Sr. Medical Scientist (Cell Therapy) / Scientifique Médical (Thérapie cellulaire),"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.




For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.

Job Description

Kite, a Gilead Company, is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors.

The Role:

The Medical Scientist (MS) is a field-based medical-scientific expert in the assigned therapeutic area. The MS assumes responsibility for all Medical activities within the assigned territory and executes the field medical strategy. This involves gathering insights, medical education and communication, supporting clinical research, and managing projects of various scope including educational events and regional advisory boards. The role requires close national and international collaboration with colleagues from Medical Affairs and other departments.

Implements defined goals and objectives aligned with the Medical Affairs Plan of Action and other strategic initiatives within the Cell Therapy therapeutic area

Responds to clinical inquiries regarding marketed or developmental Gilead/Kite products.

Develops and presents complex scientific and clinical data related to Gilead/Kite products.

Identifies and develops regional and national opinion leaders to support Gilead/Kite products through personal contacts and on-site visits

Establishes strong relationships with opinion leaders, clinical investigators and healthcare professionals at academic and non-academic settings

Works on phase 3/phase 4 programs that include collaboration with investigators and internal personnel

Provides input into site selection for both phase 4 and other clinical trials

Anticipates obstacles and difficulties that may arise in the field and resolves them in a collaborative manner

The candidate works collaboratively with Gilead/Kite personnel in Commercial, Marketing, Market Access, Clinical Research, Global Safety and Global Medical Affairs

Utilizes scientific resources to deliver impactful presentations in a variety of settings.

The incumbent travels to appointments, meetings and conferences on a frequent and regular basis, occasionally with short notice

Must have the ability to work as a member of several teams that may overlap such as national MS team, regional team, national accounts, and others

Well-developed experience in preparing and delivering presentations is required.

Experience in the management or investigation of clinical trials is preferred

Exhibits Gilead/Kite core values: integrity, inclusion, teamwork, accountability, and excellence

Knowledge, Experience and Skills:

Advanced health sciences degree (M.D., Pharm. D., PhD are preferred) with a minimum of 3 years of experience in healthcare or pharmaceutical industry

Two to four years of experience in Oncology (specifically Hematologic Malignancy) in a clinical/research or medical affairs capacity is preferred

Excellent oral and written communication skills and interpersonal skills (including ability to network)

Bilingualism (French and English) is required

Excellent project management ability and organizational skills, including the management of multiple priorities and resources

Excellent judgment and personal initiative are required

Advanced knowledge of Microsoft Office suite (Word, PowerPoint, Excel, Access, Outlook) is required

Must have knowledge of and be willing to comply with all regulatory/compliance policies

Candidate must be based in Quebec

Ability to travel 70% of the time; domestic and international travel is required, including potential attendance at conferences which may include occasional weekend travel





Kite, une société de Gilead, se consacre à la mise au point d’immunothérapies novatrices contre le cancer dans le but d’offrir une réponse rapide, durable et à long terme et d’éliminer le fardeau que représentent les soins de longue durée. L’entreprise concentre ses énergies sur des thérapies cellulaires, à savoir les cellules T à récepteur antigénique chimérique (CAR-T) et les récepteurs de l’antigène des lymphocytes T (TCR). Ces traitements visent à renforcer la capacité du système immunitaire à détecter les tumeurs et à les éliminer.

Rôle

Le scientifique médical (SM) est un expert scientifique du domaine médical qui travaille sur le terrain, dans le domaine thérapeutique qui lui a été attribué. Le SM assume la responsabilité de toutes les activités médicales dans le territoire attribué et exécute la stratégie médicale sur le terrain. Il doit par exemple recueillir des idées, soutenir la formation et les communications médicales, appuyer la recherche clinique et gérer des projets d’importances diverses, y compris des événements éducatifs et des conseils consultatifs régionaux. Le titulaire de ce poste doit entretenir une étroite collaboration nationale et internationale avec des collègues des Affaires médicales et d’autres services.

Mettre en œuvre des objectifs définis qui cadrent avec le Plan d’action des Affaires médicales et avec les autres initiatives stratégiques du domaine thérapeutique de la thérapie cellulaire.

Répondre aux questions cliniques portant sur les produits de Gilead/Kite actuellement sur le marché ou en cours de développement.

Développer et présenter des données scientifiques et cliniques complexes liées aux produits Gilead/Kite.

Repérer des leaders d’opinion régionaux et nationaux, et les amener à appuyer les produits de Gilead/Kite par l’intermédiaire de contacts personnels et de visites sur place.

Établir de solides relations avec des leaders d’opinion, des investigateurs cliniques et des professionnels de la santé en milieu universitaire et non universitaire.

Travailler aux programmes de phase III et IV notamment en collaborant avec les investigateurs et le personnel interne.

Contribuer à la sélection des centres où seront réalisées des études cliniques de phase IV et d’autres études cliniques.

Prévoir les obstacles et les difficultés pouvant survenir sur le terrain, puis les résoudre de manière collaborative.

Travailler avec le personnel de Gilead/Kite des secteurs Affaires commerciales, Marketing, Accès au marché, Recherche clinique, Innocuité mondiale et Affaires médicales mondiales.

Employer des ressources scientifiques pour donner des présentations convaincantes dans divers milieux.

Se rendre régulièrement et fréquemment à des rendez-vous, à des réunions et à des conférences, parfois avec un court préavis.

Pouvoir travailler en tant que membre de plusieurs équipes dont les activités pourraient se chevaucher, notamment dans l’équipe nationale des scientifiques médicaux, l’équipe régionale et l’équipe des comptes nationaux.

Posséder une grande expérience en élaboration et en animation de présentations, obligatoire.

Posséder une expérience en gestion ou en investigation d’études cliniques, un atout.

Incarner les valeurs de Gilead/Kite, soit l’intégrité, l’inclusion, le travail d’équipe, la responsabilité et l’excellence.

Connaissances, expériences et compétences

Diplôme de haut niveau en sciences de la santé (préférablement M.D., Pharm D. et Ph. D) et au moins trois ans d’expérience dans le secteur pharmaceutique ou des soins de santé.

De deux à quatre ans d’expérience en oncologie (plus précisément en hémopathies malignes) dans un poste du domaine clinique, de la recherche ou des affaires médicales, un atout.

Excellentes aptitudes en communications écrites et orales, et de solides compétences en relations interpersonnelles (y compris en réseautage).

Bilinguisme, anglais et français, obligatoire.

Remarquables compétences organisationnelles et en gestion de projets, y compris la capacité de gérer plusieurs ressources et priorités.

Jugement et esprit d’initiative hors pair, obligatoire.

Connaissance avancée de la suite Microsoft Office (Word, PowerPoint, Excel, Access, Outlook), obligatoire.

Connaissance des politiques réglementaires et de conformité , et volonté de les respecter, obligatoires.

Domicile au Québec, obligatoire.

Capacité à voyager 70 % du temps, autant à l’intérieur qu’à l’extérieur du pays, ce qui inclut d’éventuelles participations à des conférences pouvant nécessiter des déplacements les fins de semaine.



Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com . Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma .



For Current Kite Pharma Employees and Contractors:

Please log onto your Internal Career Site to apply for this job.","Gilead Sciences
3.8",Quebec
786,Azure Data Engineer,"Primary skills:

In-depth project experience in Hadoop and Azure Cloud technologies(Azure Databricks, Azure Data Factory, Azure Data lake, Blob Storage, Synapse, CosmosDB )
Experience in Ingestion of batch and Streaming data with complex transformations using Apache Kafka, Apache Spark, Scala, Hive SQL, Shell Script.
Work directly with Business users and convert use cases into solutions independently.
Experience in working with very large volume of log data and building analytical insights based on user requirements
Experience in handling Semi-structured data in various data formats (Parquet, JSON, Avro, Orc) and manipulate data in complex data types.

Secondary Skills:

Knowledge on Devops tools and experience in building CI/CD pipelines on Azure.
Write programs to pull data from External Applications and Services using REST API with different authentication methods.
Knowledge on nosql database types like Document and Graph DB is a plus.
Knowledge on Machine Learning Libraries for Data science and analytics is a plus.
Has worked in Agile methodologies

Certification: Azure Data Engineer (DP-200 & Dp-201, DP-203)

Job Type: Full-time

Salary: $79,138.00-$104,618.00 per year

Application question(s):

Do you have a LinkedIn account, if so drop the link below?

Speak with the employer
+91 +19259518576",Data Patterns,Brampton
787,Big Data Engineer (Remote Optional),"WHO WE ARE

Centro delivers software and services to automate digital media operations for more than 1,000 leading agencies and brands.

Our comprehensive ad tech platform, Basis, supports the planning, reporting, and financial reconciliation of direct, programmatic, search, and social media, all in one place.

We are deeply committed to building software that will change the ad tech industry for the better and are equally dedicated to building an inclusive culture of highly motivated individuals who create a positive and supportive environment together. We invest in our culture and support our employees so they can do their best work.

Centro is headquartered in Chicago, with beautiful offices also in Toronto, Dallas, Denver, and New York to name a few. Post-COVID, many of us will be returning to one of our offices (by choice, not requirement - we believe results matter more than where they are produced). All of our employees have the flexibility to work in one of our office locations, completely remote, or a hybrid of the two. Please note, we are hiring on a remote working basis only in the U.S. and Canada.



ABOUT THE TEAM

Technology is at the core of what we do. Centro’s innovative Engineering team designs and develops new features and integrations for Basis, our industry-leading, comprehensive software solution. Our platform processes over 300 billion events per day and uses AI and machine learning to automate and simplify the entire digital campaign process.

WAYS YOU'LL CONTRIBUTE

This team is all about data—and in order to create value from the massive amount of data we collect, engineering leverages their dynamic Data Engineering, Data Science, and Business Intelligence teams to create insights that benefit the industry as a whole. You will contribute by:
Implementing scalable, fault tolerant and accurate ETL pipelines that work in a distributed Hadoop environment.
Developing platform services to operate the big data applications at scale.
Gathering and processing raw data at scale from diversified sources into Hadoop.
Building enterprise business analytics and reporting applications on Hadoop.
WHAT YOU BRING TO THE TABLE
Proven experience working with various components of Hadoop ecosystem: Spark, Hive, Impala, Kafka, Oozie
Strong understanding of computer science fundamentals
Proficiency with relational databases and SQL queries (MySQL, Oracle or similar)
Understanding of how to handle high velocity, high volume data events.
Understanding of factors affecting performance of ETL processes and SQL queries, ability to work on performance tuning.
Experience implementing data pipelines moving large volumes of data a day.
Experience in implementing application in Scala on SPARK.
Experience coding in Python
BONUS POINTS
Skills in real-time streaming applications.
Knowledge of Scala.
A development workflow using Docker containers.
Compulsion for automating your day-to-day processes.
OUR TECH STACK
Ruby, Java, Python, and React.js
Hadoop, Scala, Spark, Hive
Kubernetes, Docker, Kafka
PostgreSQL, NoSQL
AWS

ANYTHING ELSE?

Don't think you have all the skills required for this role? That's okay, we recognize that experience can be built in many ways. If you have relevant skills that are not reflected in your resume, we welcome your candidacy and encourage you to share more in an optional cover letter, even if your experience doesn’t match our exact requirements.

LIFE WITH CENTRO

We take care of our people and believe that Centro’s success depends on the growth and well-being of each one of our team members.

We provide a thoughtful perks and benefits package including competitive 401k/RRSP matching, mental health support, a funded health savings account, paid sabbatical, generous parental leave, a work from home stipend for employees in closed offices, and more.

We are proud to be an equal opportunity employer are committed to building teams of Centrons that are diverse in thought, perspective, and culture. We celebrate all team members regardless of gender identity, sexual orientation, race or cultural background, religion, disability, and age. Our employee-led communities enrich our culture of uniqueness, inclusivity, and empowerment.","Centro
4.1",Ontario
788,Lead Data Engineer / Director,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Are you a go-getter who has a passion in building next generation data solutions for business problems? Are you a big fan of simplification and automation? Are you a leader who paves the path for others within and outside your team?

Manulife is seeking a Director / Lead Data Engineer , to join our rapidly expanding IT Organization and assist us as we work to be a digital leader in our industry!

As a Lead Data Engineer and Director, you will:

Lead team of strong data engineers building and maintaining Customer C360 platform
Lead the team from both technology and value perspective
Lead the team to deliver on prioritized roadmap that consists off both technology and business features
Lead the team to build innovative solutions and reduce reliance on expensive vendor products
Lead the team to modernize the platform, adopt cloud, simplify solutions and adopt automation
Lead the team to support MDM platform
Mentor and grow people in the team

Skills and Experience

You will have the following skills and experience:

Expert in building and operationalizing Data platforms in cloud using one of the public clouds, preferably MS Azure.
Hands on experience in automating data pipelines, DevOps and CICD. Experience with Terraform/Ansible or similar automation technology and IaC.
Hands on experience in Canary deployments, 0-downtime (High Availability), 0-dataloss, hot-hot DR
Hands on excellent with MS Azure services (SQL warehouse, ADLS gen 2, ADF) to design a data ecosystem.
Hands on experience in Apache Data Projects – NiFi, Spark, Map reduce, Kafka, Zookeeper, etc.
Hands on experience with Big Data streaming frameworks and tools (e.g. Spark Streaming, Kafka, etc.)
Experience in building Open APIs and microservices along with loosely coupled architecture.
Expert in developing Data set processes for data modeling, mining and production
Hands on experience of using Git flow
Understand different file formats and processing. (Parquet, ORC, Avro)
Excellent communication and interpersonal skills
Excellent analytical, problem solving and solutioning skills
A capacity for constant learning from both success and failure, remaining open to change and continuous improvement

Nice to Haves

Experience in Exploratory data analysis; Query and process Big Data, provide reports, summarize and visualize the data
Experience programming in both compiled languages (Java, Scala) and scripting languages (Python or R)
Exposure to and an understanding of Agile scrum methodologies and experience of working in an Agile team
Experience in Data processing, performance analysis, tuning and capacity planning
Experience with Databricks
Experience with in-Memory datastores such as Redis, used in streaming pipelines
Experience with Implementing ML Models in the stream producing alerts and enabling AI functionality.
Experience with Traditional batch based ETL processes and tools such as Informatica, Azure Data Factory, Talend, Pentaho or SSIS.

Basic understanding of following will be useful but not required:

Exposure to and basic understanding of business intelligence systems, dashboard reporting, and analytical reporting
Exposure to and basic understanding of collaboration tools like Teams and JIRA

What about Perks?

Manulife has lots of perks including, but not limited to:

Competitive compensation
Retirement Savings Accounts including a RPP (Pension Plan), RRSP (Retirement Savings Plan), and TFSA (Tax Free Savings account)
Manulife Share Ownership Program with employer matching
Customizable Benefits Package including Health, Dental, Vision, and 100% of Mental Health expenses
Financial support for ongoing training, learning, and education
Monthly Innovation Days (Hackathons)
Wearing jeans to work every day
An abundance of career paths and opportunities to advance
A flexible work environment with flex hours, work from home arrangements, distributed teams, and condensed work week arrangements.

This is a full time permanent role that can work from our Toronto Or Waterloo Office.



If you are ready to unleash your potential, it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2020, we had more than 37,000 employees, over 98,000 agents, and thousands of distribution partners, serving over 30 million customers. As of December 31, 2020, we had $1.3 trillion (US$1.0 trillion) in assets under management and administration, and in the previous 12 months we made $31.6 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an Equal Opportunity Employer

At Manulife /John Hancock , we embrace our diversity. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention, advancement and compensation, and we administer all of our practices and programs without discrimination on the basis of race, ancestry, place of origin, colour , ethnic origin, citizenship, religion or religious beliefs, creed, sex (including pregnancy and pregnancy-related conditions), sexual orientation, genetic characteristics, veteran status, gender identity, gender expression, age, marital status, family status, disability, or any other ground protected by applicable law.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will work with applicants who request a reasonable accommodation during the application process . All information shared during the accommodation request process will be stored and used in a manner that is consistent with applicable laws and Manulife/John Hancock policies . To request a reasonable accommodation in the application process, contact recruitment@manulife.com .","Manulife
4.0",Midtown Toronto
789,Development Engineer / Development Scientist (Synthetic Biology),"About Precision NanoSystems Inc. (PNI)




Precision NanoSystems Inc. (“PNI”) is a manufacturer of instruments, kits and reagents in the global nanomedicine market providing tools for drug development and cell-specific delivery to study, diagnose and treat disease. PNI’s NanoAssemblr family of instruments allow scientists to rapidly develop novel nanomedicine drug candidates for pre-clinical testing. PNI’s NanoAssemblr Scale-up platform enables the translation of these drug candidates to clinical testing and eventually to commercial use. PNI’s NanoAssemblr™ Transfection Reagents use nanomedicine technology to deliver genetic materials in primary cells vitro and in vivo, enabling disease researchers to easily study gene function in high-value models of disease. PNI sells its products to leading pharmaceutical and biotechnology companies, and leading academic institutions in over 20 countries worldwide. Please find more information at http://www.precisionnanosystems.com/.




Position Summary


Precision NanoSystems Inc. has an opening for Development Engineer/Scientist, Synthetic Biology to join our growing Pharmaceutical Development department in Vancouver, BC. The successful candidate will contribute to a wide range of product development projects including the development and commercialization of novel nanoparticle reagents, microfluidics and instrumentation to enable the field of genetic medicine. The individual will have a diverse set of molecular biology and genetic engineering skills with significant experience in Vector library development, Recombinant DNA technology including PCR based molecular cloning, PCR based recombination techniques, nucleic acid recombinant DNA technologies, analytical method development, next-generation sequencing (NGS) techniques, site-directed mutagenesis, RNA or protein synthesis, Genetic engineering. The individual must have worked in the yeast or bacterial cloning, manipulating primary & immortalized mammalian cell-lines, genetic modification of cells and a wide range of cell-based assays. The successful candidate must be adaptable, work well with people from a diverse interdisciplinary background, and able to multi-task with excellent critical thinking with attention to detail and a track record of successful research contribution or significant industrial R&D research experience will be an asset.


Areas of Responsibility



Contribute to a wide range of product development projects, including establishing a nucleic acid-based platform technology for regenerative medicine and vaccine applications, that support the existing proprietary NanoAssemblr™ technology developed by Precision Nanosystems Inc.
Contribute to establishing new techniques in-house, perform routine iterative testing and supporting both internal projects and external collaborations
Responsible for designing and conducting experiments with input from the assigned supervisor
Design and perform experiments pertaining to recombinant DNA technology to generate vector library.
Collect and analyze experimental data, present data at meetings, provide conclusions and outline future work plans
Troubleshoot experiments and identify abnormal or unexpected trends in data
Support all technical documentation related to projects and product development
Collaborate with internal teams to ensure successful project completion including providing support to Contract Research, R&D, Product development, Manufacturing, and Operations when required
Provide technical support to staff and customers (product use, protocols) as needed
Provide training on laboratory/product protocols to lab personnel as needed
Set up, calibrate and perform routine maintenance on specialized laboratory equipment
Ensure that the necessary laboratory supplies are available and perform tasks related to supporting the operation of the laboratory
May be required to perform other related duties as needed or assigned



Qualifications and Experience



PhD graduates in Biochemical Engineering, Molecular Biology, Biochemistry, Genetic Engineering or Biotechnology with recent postdoctoral training/experience in RNA biology, RNA Biochemistry or recombinant DNA technology considered.
MSc in the Life Sciences (e.g., Molecular biology, Biochemistry, Biotechnology, Genetic Engineering and Pharmaceutical Sciences) with recent 6-8 years of academic or industrial experience.
Knowledge of Pharmacopeial guidance considered asset
Recent 3 years of hands-on lab-based experience in Molecular Biology laboratory focusing on mRNA biology or mRNA biochemistry
Significant experience in PCR based cloning and Cell-free nucleic acid synthesis is a considered asset
Experience working in pharma or biotech industry would be advantageous
Ability to independently design, conduct, analyze and troubleshoot experiments
Experience in developing DNA based expression vectors for mRNA and protein synthesis
Experience in working with both prokaryotic and eukaryotic cells
Experience with a wide-range of laboratory techniques including PCR, qPCR, RT-PCR, Plasmid preparation, DNA, RNA & Protein gel electrophoresis, Northern blotting, Western blotting, ELISA, chemical transfection, electroporation, expression vector library construction etc.
Experience in working with nucleic acids (e.g., plasmid DNA, mRNA, siRNA), recombinant DNA technology, and nucleic acid purification methods
Sound knowledge of genetic & epigenetic mechanism of prokaryotic and/or eukaryotic gene expression
Experience with bioinformatic software tools as well as statistical analyses of experimental data is an asset
An understanding and interest in the use of nanoparticle technology for non-viral gene delivery would be an asset
Excellent communication skills (verbal and written) both in one-on-one and in a group setting with the ability to organize and present technical summaries of scientific data
The individual must be a team player who thrives in a dynamic environment with multiple tasks and aggressive deadlines
Proven ability to apply critical and analytical thinking
Must be a resourceful, proactive, detail-oriented individual who is able to work with minimum supervision
Project management skills will be considered as an asset.



PNI provides a competitive compensation and benefits package with excellent opportunities for personal growth.




Only candidates selected for an interview will be contacted. Posting valid until filled. No solicitors please.




Precision NanoSystems, Inc. is an equal opportunity employer.","Precision NanoSystems
4.4",Vancouver
790,Data Engineer (contract),"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:

Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done

Here's what you'll be doing:

Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery

Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!

A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI

Why Join Us?

You can see the code getting to production faster than you used to; you will try your Big Data skills, where precise and robust code really matters; you will work with the 3.5 Billion-record tables; you will learn how difference between European and Australian privacy laws can affect your design decisions.

Bond Brand Loyalty is proud to be recognized as one of Canada’s Best Managed Companies.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

Bond Brand Loyalty welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Bond Brand Loyalty Inc
3.5",Mississauga
791,Principal Data Infrastructure Engineer,"Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science and engineering to radically improve the lives of patients and industrialize drug discovery. Our team is working to solve some of the hardest, most meaningful problems facing human health today. Come join us in our mission to decode biology to radically improve lives, while doing the most impactful work of your life.
Recursion recently announced its intention to launch its first major multidisciplinary expansion beyond its Utah headquarters, with plans to hire up to 50 people in Toronto by the end of 2021.

The Impact You'll Make

Create a world-class research platform. You'll work across teams and functions with Software Engineers, Data Scientists, ML Engineers, Biologists, and Automation Scientists in building a platform for generating and storing petabytes of data, iterating quickly on novel analyses, and rapidly prototyping new deep learning models.
Build, scale, and operate a data platform . You'll be on a team responsible for building, operating, and tuning a data platform that allows users to discover and query across the breadth of our data at Recursion, which includes a chemistry library of 3 billion compounds, nearly 8 PB of cellular microscopy images taken in 10s of millions of different experimental contexts involving 1 million different reagents, sparse bioassay data across approximately 50 drug discovery programs, and more.
Build relatability into a heterogeneous dataset. At Recursion, we generate datasets based on a wide swath of diverse biological models and treatment approaches. You'll work with Data Scientists to build relatability and queryability into these datasets so they can be used in five years to answer the sorts of questions we haven't even thought of asking yet.
Act as a mentor, coach, and sponsor. You will share your technical knowledge and experiences, delivering impact, learning, and growth across teams at Recursion.

The Team You'll Join

You will lead a new team as they plan and implement a data platform that solves the problem of making our diverse data discoverable, queryable, and relatable across datasets while we continue to add new data modalities as we grow. This will require collaboration with many different groups including teams building out reports, dashboards, and applications, teams finding and generating the required data for the machine learning problems, and teams building and iterating on new data processing pipelines.
As an early leader in the new Toronto office you will have an important impact by shaping how new technical teams embrace the Recursion Values as they deliver challenging data platform problems while effectively collaborating across physical locations, business domains, and technical functions.

The Experience You'll Need

Experience working on data platforms that enable the discovery, query, and processing of large datasets.

Be up to date on industry trends and tools. You understand the tradeoffs between different data platform architectures and technologies like a data lake, a data warehouse, a data lakehouse, or a data mesh, and can draw on this knowledge to lead the design of the data infrastructure for Recursion.

Experience working collaboratively on projects with significant ambiguity and technical complexity, ideally spanning multiple systems and involving diverse technologies.

A people-first mindset. Despite the deadlines, we always prioritize supporting our coworkers in their growth and experience.

A drive to deliver technical solutions that are easily monitored and understood as they run in production and the effects of change can be readily quantified.

Excitement to learn parts of our tech stack that you might not already know. Our current tech stack includes Python, Clojure, Kafka, Docker, Kubernetes, PostgreSQL, JavaScript, ClojureScript, and Go. Our cloud services are provided by Google Cloud Platform.

Biology or chemistry background is not necessary, but intellectual curiosity is a must!

The Benefits/Perks You'll Enjoy

100% Coverage of health, vision, and dental insurance premiums
401(k) with generous matching (immediate vesting)
Stock option, restricted stock unit (RSUs) and employee stock purchase plan (ESPP) programs**
Two one-week paid company closures (summer and winter)
Flexible vacation/sick leave
Generous paid parental leave (including adoptive)
Onsite daycare facility **
Commuter benefit and vehicle parking to ease your commute**
Complimentary chef-prepared lunches and well-stocked snack bars**
Monthly fitness/wellness stipend
One-of-a-kind 100,000 square foot headquarters complete with a 70-foot climbing wall, showers, lockers, and bike parking**


Subject to change for remote-based employees during the COVID-19 pandemic
**United States based employees

More About Us

Recursion is a clinical-stage biotechnology company decoding biology by integrating technological innovations across biology, chemistry, automation, data science, and engineering, with the goal of radically improving the lives of patients and industrializing drug discovery. Central to our mission is the Recursion Operating System, or Recursion OS, that combines an advanced infrastructure layer to generate what we believe is one of the world's largest and fastest-growing proprietary biological and chemical datasets and the Recursion Map, a suite of custom software, algorithms, and machine learning tools that we use to explore foundational biology unconstrained by human bias and navigate to new biological insights which may accelerate our programs. We are a biotechnology company scaling more like a technology company. Recursion is proudly headquartered in Salt Lake City.

Learn more at www.recursion.com , or connect on Twitter and LinkedIn .

Recursion is an Equal Opportunity Employer that values diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected under applicable federal, state, local, or provincial human rights legislation.",Recursion,Midtown Toronto
792,Principal Scientist – Ligand Binding Assay Department,"Principal Scientist – Ligand Binding Assay Department
Laval, QC, Canada Req #1503

Wednesday, April 14, 2021

Altasciences is a mid-size contract research organization with a unique focus on supporting drug development from lead candidate selection to proof of concept. With over 25 years of industry experience, we provide preclinical and clinical solutions to an international customer base of biopharmaceutical companies. Our full-service offering in this critical stage of drug development includes program management, preclinical safety testing, clinical pharmacology services, manufacturing and analytical services, medical writing, biostatistics, data management, and bioanalysis services tailored to specific research requirements. Altasciences has facilities in Montreal, QC; Kansas City, KS, Seattle, WA, and Philadelphia, PA.

Our team is made up of over 1,300 professionals from the medical and scientific fields who work together to
achieve a common goal: to contribute to the advancement of life sciences. Bring your talents and forward-thinking approach to Altasciences and help us develop medicines for those who need them, faster.

The Principal Scientist, LBA will supervise a team of scientists in the Ligand binding assay department to ensure the scientific and regulatory excellence, client service, performance, productivity and efficiency of the group’s operations and logistics. The Principal Scientist is an the expert in the field of Oligonucleotides Bioanalysis by hybridization ELISA. He or she stays appraised of the status of all projects and recommends resource adjustment based on deliverable schedules. Provides scientific and operational guidance within their area of expertise and promote efficiency initiatives that have impact on improving productivity and profitability. He or she may be assigned to projects based on scientific competency and training.


Main Responsibilities:

Responsible for personnel management activities of assigned staff such as: scheduling, personnel actions, training and development, providing regular direction and feedback on performance, disciplinary actions and preparing and delivering annual performance and salary reviews;
Manage direct reports to ensure project timelines are respected and communicates any delays in a prompt fashion;
Provide Scientific support to assigned Bioanalytical Principle Investigator in the area of Hybridization ELISA for ASO quantitation in various matrices to support both nonclinical and clinical studies;
Responsible for set up and implementation of training for technical and scientific LBA staff;
Responsible for improved efficiency initiatives in the laboratory, including scheduling assays, operations and improving workflows;
Review costing assessments and scheduling projects with business development and operation coordinator;
Review forecast and identifying critical projects to maximize for revenue recognition;
Support Senior Director as needed with client interactions, scientific troubleshooting and support of scientific staff;
Contributes to the growth and development of Altasciences ligand binding assay services, as well as participate in strategic planning;
Responsible for working closely with other MD management members and serve as back-up when any of them is out of office;

Can be assigned as Bioanalytical Principal Investigator and will manage and conduct hybridization ELISA method development, qualification, validation and production studies for clinical and non-clinical studies in compliance with the protocol/study plan, amendments, GCP, GLPs, SOPs and Best Practices;
Respecting Health and Safety standards in terms of personal protection, laboratory maintenance, and work procedures;
Other related tasks.

Desired Profile:

Master’s or Bachelor’s degree in Biochemistry, Immunology or relevant field;
Preferred experience in regulated clinical and/or preclinical studies within the area of expertise (immunogenicity, PK or Biomarker, Oligonucleotide) with 5-10 years of experience in CRO or pharmaceutical company or equivalent;
Good organizational skills;
Highly flexible and sense of urgency;
Excellent troubleshooting skills and attentive to details;
Client oriented and ability to coach/mentor people;
Be able to easily read and understand study plans and protocols,
Good communication both written and verbal in French & English.;
Must understand general SOPs and have an excellent knowledge of GCP/GLP regulations.



Altasciences is an equal opportunity employer committed to diversity and inclusion. Our goal is to attract, develop and retain highly talented employees from diverse backgrounds, allowing us to benefit from a wide variety of experiences and perspectives. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability or any other protected grounds under applicable legislation. Reasonable accommodations for persons with disabilities during the recruitment process are available upon request. Join us at Altasciences!

Other details

Job Family

Valide Positions

Pay Type

Salary","Altasciences
3.2",Laval
793,"Senior Analyst, Enterprise Data Management","Senior Analyst, Enterprise Data Management
Equitable Bank, 30 St. Clair Ave West, Suite 700, Toronto, Ontario, Canada Req #1346

Wednesday, March 24, 2021

Canada's Challenger Bank™

Equitable Bank manages over $35 billion in assets and is a wholly-owned subsidiary of Equitable Group Inc. It was founded in 1970 as The Equitable Trust Company and has become Canada’s ninth largest Schedule I bank. Equitable Bank offers a diverse suite of residential lending, commercial lending, and savings solutions, including high-interest savings products and GICs.

At Equitable, we have no doubt that financial services are changing. Consumers increasingly prefer to interact remotely through digital channels and are less likely to visit brick and mortar locations. That’s why we launched EQ Bank in 2016. Its approach to simple and convenient banking makes it a strong contender in the industry. We believe there’s an opportunity for something different, to provide better service and a better deal for our customers through digital banking.

Job Title: Senior Analyst, Enterprise Data Management
Department: Data Management and Governance
Reports To: Senior Manager, Enterprise Data Management


Purpose of Job

Senior Analyst of Enterprise Data Management will have the responsibility for the design and maintenance of enterprise data warehouse for various projects, as well as providing on-going support for activities impacting all enterprise databases. The incumbent will be accountable for the integrity of data, allowing for effective, accurate and timely generation of all enterprise reports. They will liaise with various development groups, business groups and customers to ensure the project related data requirements are satisfied.
In addition, the incumbent will be accountable for ensuring the integrity of data, allowing for effective, accurate and timely generation of all enterprise reports.

Main Activities:

Business Analysis (40%)
Participate in Joint Application Development sessions with Business Units to gather and understand their data and reporting requirements
Play the role of Data SME for initiatives
Liaise with the technical team to document the non-functional requirements and understand system constraints
Document data interface requirements including but not limited to source to target mapping
Create test plan and execute test cases as needed
Develop reports based on requirements
Building of Data Models and Supporting Data Operations (40%)
Design and update data models for initiatives
Document models and create technical documents that can be leveraged by various teams
Create Entity Relation Diagrams (ERD), DFDs and other data modelling diagrams as required
Work closely with Enterprise Data Governance to help implement Data Governance policies
Responsible for identifying and implementing key Data Quality controls to support Data Management
Data Strategy (10%)
Identify and provide recommendations for revising existing data structure as appropriate and needed
Assist in enablement of Cloud based data and analytics
Support and Maintenance of Enterprise Data Warehouse (10%)
Support existing Enterprise Data Warehouse objects
Provide data related technical support for downstream applications
Responsible for enhancing/creating documents for existing Enterprise Data Warehouse objects

Skills/Knowledge Requirements:

3 - 4 years of experience of working with data and database systems
Post-Secondary education, preferably in the areas of Technology or Commerce/Business Administration
Experience in integrating multiple sources into a centralized data platform or Enterprise Data Warehouse
Experience in working with traditional structured row store data, semi-structured and dynamic schemas such as XML, JSON
Experience with BI tools and their data needs (i.e. Power BI, Tableau as examples)
Experience in creating scalable data models supporting a wide variety of end user audience (Visual Analysts, BI Developers, and Data Scientists etc.)
Experience in writing Data Quality routines for cleansing of data and capturing confidence score
Experience identifying and defining data gaps and challenges during data migration efforts of system implementations
Excellent written and verbal communication skills
Excellent multi-tasking and organizational skills
Excellent problem solving and analytical thinking skills
Excellent interpersonal skills
Nice-to-have
Experience with Azure Big data technologies (Azure Data Lake, Azure Data Factory, Azure Data Bricks, Azure Synapse)
Experience working in financial industry
Experience in implementation of Advanced Internal Ratings Based (AIRB) approach
Experience in writing Stored Procedures, Secure coding with safeguards against SQL injection attacks
DAMA Certified Data Management Professional (CDMP)
ISACA Certified Enterprise Data Management Associate
Microsoft Certified: Data Analyst Associate
Experience with CMMI Data Maturity Model
Experience with Agile and Waterfall SDLC methodologies
Project/Program/Portfolio management experience
Familiarity with ITIL and IT service management best practices
Experience with Atlassian (Confluence and JIRA)

Equitable Bank is an equal opportunity employer and encourages applications from all qualified candidates. Accommodations are available on request for candidates taking part in all aspects of the selection process. All candidates considered for hire must successfully pass a criminal background check and credit check to qualify for hire. While we appreciate your interest in applying, an Equitable recruiter will only contact leading candidates whose skills and qualifications closely match the requirements of the position

Other details

Job Family

Equitable Bank

Pay Type

Salary","Equitable Bank
3.9",Midtown Toronto
794,Cloud Data Engineer,"Who is DigitalOnUs?

At DigitalOnUs, we not only provide Agile and DevOps methodologies to our customers, but we have also adopted the same within the company as well. Our nimble processes are not mired in red tape, yet robust, flexible and results oriented. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators, and challengers. Each day, we strive to make great come alive. Our lemma: ""work smart and play hard""

Our technology partners are Hashicorp, Cloudbees, Chef, Pagerduty, Docker and SAP .

We are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family !

We are looking for a data engineer responsible for expanding and optimizing data and data pipeline architecture, as well as optimizing data flow.

Will support software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

Location: Canada

Qualifications we are looking for:
Azure data engineers collaborate with business stakeholders to identify and meet data requirements. They design and implement solutions. They also manage, monitor, and ensure the security and privacy of data to satisfy business needs. The role of a data engineer is different from the role of a database administrator.

+5 years of experience in data Engineering

Familiarity with eClinical Works (ECW) data, HL7 or FHIR

Experience with machine learning algorithms, including deep neural networks, natural language processing, kernel methods, dimensionality reduction, ensemble methods, hidden Markov models and graph algorithms.

Data Warehousing Experience with SQL Server, Oracle, Redshift, Teradata, etc.

Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch, Databricks etc.)

Experience with real-time data processing and API platforms.

Experience in using Python, Java and/or other data engineering languages.

Experience with data visualization and presentation, turning complex analysis into insight.

Healthcare domain and data experience

IDEAL BACKGROUND: Healthcare data background, especially provider data (versus payer data), including clinical data. Experience with FHIR is highly desirable. Experience and deep background in various methods of ETL is required. Programming and full-stack development experience would be a great addition.

Key Activities- Maintain, improve, clean, and manipulate data in the business operational and analytics databases Design and deploy data platforms across multiple domains ensuring operability Transform data for meaningful analyses Improve data efficiency, reliability and quality Create data enrichment Build high performance Ensure data integrity Create and manage data stores at scale Ensure data governance - security, quality, access and compliance

Why you will love this job?

We look for people who are thoughtful, can break down problems, work individually sometimes, and in pairs or teams at other times.

You are trusted to work on your own but ask for help when you are blocked

We will work with you to find the balance of what you want to do, what you are good at, and how that fits in with the company goals.

What you can expect from us

At DigitalOnUs, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness lead to quality, innovation, commitment to deliverables, efficiency, and cost-effectiveness for all our customers.

Empathy for your coworkers and our customers is an important part of success here. As an early-stage startup, most people wear many hats.

We are growing at a phenomenal pace! We have lots of opportunities to grow and learn

Hear your voice, nurture your talent, and help you strengthen your footprint!

Health, Life, Dental, and Vision Insurance

Flexible Work Hours

Work-from-Home Options

Company-wide retreats

If you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the ""Company""). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and / or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https://www.digitalonus.com/privacy-policy/","Digital On Us
4.5",Midtown Toronto
795,Data Science Instructor,"About the role::
Journey is looking for an experienced, energetic, data scientist with an interest in teaching. As a data science instructor you will be responsible for leading lectures on various topics, assigning course work, grading, and mentoring students on a 1-1 basis. You will work closely with other instructors and members of our education team, and follow along with our pre-built curriculum and teacher guide. You will work as an instructor for our Concordia Bootcamps program (a partnership between us and Concordia University) and have a direct impact on changing peoples lives through education.

This is a full-time contractual position which will last 14-weeks. Hours will be from 9:30am to 5:30pm (EST) Monday through Friday. This course will be taught remotely.

You can review the program and upcoming course dates here: https://concordiabootcamps.ca/courses/data-science-remote/ (https://concordiabootcamps.ca/courses/data-science-remote/)

Responsibilities::

Teach a class of beginners (in collaboration with 1-2 other instructors) with the goal of ensuring they graduate ready for junior level roles in Data Science
Act as coach/mentor to students as they work their way through the course
Care profoundly about every student's success
Present lectures on Math, Stats, Python, Pandas, SQL, Data Visualization, and more
Work with the Director of Education to learn and adjust to the pre-established curriculum and course content
Follow each student independently and ensure that they develop a mastery of the subject matter
Qualifications::

You have experience teaching (as a TA), coaching, managing or supporting junior staff or managing projects
You have a minimum of 2 years of professional experience in the field of Data Science
You are an outstanding presenter. You're easy to follow when you explain difficult concepts because of your ability to dissect and disseminate them into bite-sized, understandable ideas
You're energetic and have a strong ability to motivate others
Who you are::

You love the idea of helping people lead better lives through education
You're a lifelong learner, constantly learning new things in your field
You love to share your learnings and experiences with others
You don't let a bad minute ruin a good day
You're an active listener
You're empathetic
Salary and benefits::

This is a 14-week contractual position (40 hours per week)
Salary range from $10,000-$15,000 CAD for the duration of the contract - dependant on experience
Fully remote work
Work with an amazing and fun team
Possibility to extend your contract and teach more courses
About Journey Education:
Journey provides digital skills training with courses, workshops, and events all offered online. Our product lineup currently includes courses in Web Development and Data Science, with new products on the way. Founded in 2014 and headquartered in Montreal, Canada, Journey works with highly experienced instructors to develop cutting-edge, real-world training and meaningful educational products that help people unlock their potential.

At Journey, we are building an environment where our employees feel included and heard. Diversity and inclusion are important to us and we strongly encourage applications from minorities, people with disabilities, people from gender and sexually diverse communities and/or people with intersectional identities.",Journey Education,Canada
796,"Full Stack Developer, Data Visualization (English Services)","Job Family Media Production
Primary Location Toronto
Position Language Requirement English Only
Language Skill Level (Reading) -
Language Skill Level (Writing) -
Language Skill Level (Speaking) -
Status of Employment Contract
Work schedule(s) Full-time


Please note that this is a 6-month contract opportunity.

What it’s like working at CBC

At the CBC, we all have a story to tell. What’s yours?

If you share our passion for Canadian storytelling and you wish to help us engage with individuals and communities across our various digital platforms, this is where you’ll want to be!

Every day, you will have an opportunity to shape the way in which Canadians see themselves reflected in our digital services. Your work will have a direct impact on how millions of Canadians from various communities connect with our products, with one another, and with the diverse voices that make our country so unique.

You will have the opportunity to play a part in enlightening and entertaining Canadians through our innovative work in building the mediums that deliver our content. We are an innovative hub, where the talented professionals we work with are respected and valued for their contributions. Our product teams are vibrant and our work culture strives to achieve the highest standards of diversity and inclusion. We believe that hiring people with different career paths and backgrounds is fundamental in our shared success and in building healthy and highly performant teams. When you join our mission, you are not only shaping the vision of the CBC, but the future of our country.

Why is this role important?

As Canada’s public broadcaster, our mandate is to create content that resonates with communities across the nation. The Machine Intelligence - Retention’s vision is to enable better decisions through data. Our end goal is to build a product that provides information to CBC content producers about their specific audiences and the potential audiences they may reach as it relates to content creation.

This is a unique opportunity that will combine your creative full stack development skills with data science. We are seeking a Full Stack Developer to join our team as we build a data analytics platform from the ground up. This data platform will generate insights that will inform strategic content decisions across many of the CBC content areas (news, sports, locals, etc).

Working in collaboration with full-stack developers, product designers, data scientists and engineers, and a team of content producers, you will be fully involved in all stages of the software development lifecycle.

We are looking for a team member who can bring UI/UX wireframes to life in a working application, creating an inventory of components and interfaces. This person will also be able to work though ambiguity and will show a passion for researching innovative solutions for sophisticated data displays and solving modelling challenges.





Here’s why we should work together:

Our digital teams’ values - collaboration, learning, and continuous improvement - embody who we are as a people-focused, digital-forward employer. We follow lean startup principles and use an Agile approach. Our dedicated people managers work closely with every individual to ensure we are leveraging their strengths, championing their ideas and supporting their pursuit of new skills and their desired career progression.

Here at CBC Digital Strategy & Products, we want you to be happy and feel good at work. It is essential that work be a safe space where our employees are able to share their authentic selves with one another and to push each other to challenge conventions.





Perks you can look forward to:

Flexible work schedules, allowing you to prioritize yourself, your family and your work;

Work from home opportunities;

Competitive total rewards package;

20% of time for innovation, learning and development; wherever your interests lie;

Opportunities to work with cutting edge technology;

Opportunities for continued learning and professional development;

Opportunities to become a member of our Employee Resource Groups;

Pair programming and mentorship opportunities, where you can learn from the best in the industry and help coach new talent;

A creative and dynamic work environment, where your ideas and contributions can be heard, valued and respected;

A supportive management team committed to upholding the highest standards of diversity and inclusivity;

An environment which favours experimentation and an iterative approach in order to achieve the highest form of technical innovation.




How you will make an impact:

You will design, validate and develop our platform presentation layer optimized for user experience using your knowledge of data visualization and service design principles.

You will drive the data to our platform by ingesting, storing, processing and analyzing big datasets.

You will translate algorithmic models and analysis into visualizations that are easily understandable by non-technical members of the organization

You will collaborate with individuals, teams and communities of practice to ensure the highest quality product is developed and best practices are followed.

You will continuously pursue knowledge through build, measure, learn processes in an Agile environment and stay on top of the latest technology developments.

What you could bring to our team:

The passion for Data Visualization. An understanding of front end design principles. You can implement business requirements through multiple phases of front end focused design to intuitive usage and optimal visualization. You like to experiment and explore bleeding edge technologies and techniques, and validate their effectiveness. You are comfortable with the level of ambiguity these new technologies and projects might bring.

The experience. You have strong software development principles and apply them rigorously. You have worked with Big Data in the past and have tackled its challenges. You have extensive experience selecting and using modern tools to define and build an interface that can effectively gather, structure and process data from multiple sources, at scale. Familiarity with end-to-end data science application development is a plus. To that end, we will be asking you to complete a timed technical assessment. We want to respect your time, evaluate your skills and ensure you have the knowledge that will enable you to thrive and grow in our environment.

The education. A degree in Computer Science, Engineering, Math, or equivalent is preferred, but we know not everyone gains their programming skills this way.

The technical skills. You have strong front-end software development skills with at least two years experience in React and at least one year of experience integrating API endpoints and GraphQL. You are familiar with Python and cloud services such as GCP.

The bonus skills. Ideally, You have an in-depth understanding of the entire application flow, from the data layer to the UI. You are highly proficient with visualization libraries such as D3.js and Material-UI and have knowledge of Data Visualization/UX best practices and data modeling.





To Apply:

At the CBC, we recognize that not everyone takes the same path when it comes to building their skills. We value diversity of thought and of experience, and we are excited to hear from you! Hands-on experience, intelligence, innovation, a passion for learning, and a team-focused approach can combine to form the best set of qualifications. If you feel you meet most of the qualifications and you are excited by the possibility of adding to the rich culture of the CBC, take a chance and express your interest by applying now!

If you’re interested in reading more about the various backgrounds of the talented people that make up our teams, our exciting new projects, and what we’re currently working on, check out our Digital Labs blog on Medium!

CBC/Radio-Canada is committed to being a leader in reflecting our country’s diversity. That’s because we can only create and tell the stories that connect Canadians, by having a workforce that mirrors the ever-changing makeup of our country. That’s why we, as an employer, value equal opportunity and nurture an inclusive workplace where our individual differences are not only recognized and valued, but also extend to and pervade all the services we provide as Canada’s public broadcaster. For more information, visit the Diversity and Inclusion section of our website. If you have accommodation needs at this stage of the recruitment process, please inform us as soon as possible by sending an e-mail to recruitment@cbc.ca.

You are invited to consult and familiarize yourself with our Code of Conduct, which can be found on our corporate website. All employees must adhere to the Code as a condition of employment. We also invite you to take a look at our policy on conflicts of interest. In the event that you become an employee, it will be important to inform us, as quickly as possible, of any situation that, because of your hiring, constitutes or could appear to constitute a conflict of interest.

If you require any type of accommodation during the hiring and interviewing process, please connect with us at medeea.leonte@cbc.ca.



Job Posting Date Jun 15, 2021, 1:50:43 PM
Unposting Date Jun 30, 2021, 1:59:00 AM","CBC/Radio-Canada
3.4",Midtown Toronto
797,Exhaust Dispersion Scientist/Engineer/EIT,"Do you want to be part of a team that works in a Wind Tunnel? Are you interested in Air Quality? RWDI is seeking a motivated and dynamic individual to join our Exhaust Dispersion & Design team as a Scientist/Engineer/EIT in the Guelph office.


As a member of the Exhaust Dispersion & Design team, you will:





Solve challenging air quality design problems aimed at helping our clients design their buildings in a way that enhances safety and comfort.
Use, design, and maintain specialized desktop and physical (wind tunnel) dispersion modelling tools, conduct data analysis, and produce documentation that supports our clients’ design goals.
Lead technical development initiatives to advance our tools and knowledge.
Have an opportunity to contribute to industry via conferences and technical committees.
Work under the general supervision of senior staff with considerable latitude for the exercise of independent judgment.



The ideal candidate will have the following qualifications:





Keen interest in air quality issues and building design.
Combination of a post-graduate education and experience in a science or engineering discipline with an environmental, mechanical, chemical, or meteorological focus.
Understanding of boundary layer fluid mechanics (theory and application of principles).
Knowledge of building science and building mechanical systems.
Experience with physical and/or numerical exhaust dispersion modeling are significant assets.
Strong Excel skills, including VBA.
Demonstrated initiative with ability to practically apply engineering principles.
Proven accountability and ownership mindset with a team-focused attitude.
An ability to adapt and work in a flexible, fast-paced environment with minimal supervision.
Excellent written and verbal communication skills.
Creative problem-solving skills and a high level of self-motivation.

Please submit your cover letter and resume at the following link:

http://rwdi.com/en_ca/people/careers

Salary: Commensurate with experience

Thank you in advance for your application. Only candidates selected for an interview will be contacted.

RWDI endorses and practices the principles of equal opportunity employment.
We are committed to diversity and inclusion.

Accommodations are available during all stages of the recruitment process in accordance with AODA and the Human Rights Code.","RWDI
3.4",Guelph
798,Employment Equity INVENTORY - Aquatic Biologist/Physical Scientist & Team Leader Opportunities @ DFO,"Fisheries and Oceans Canada - Aquatic Ecosystems
Dartmouth (Nova Scotia)
BI-03, BI-04, PC-03, PC-04
BI-03 Salary Range - $81,359 to $104,748 BI-04 Salary Range - $100,920 to $119,915 PC-03 Salary Range $88,533 to $105,353 PC-04 Salary Range $102,577 to $120,520

For further information on the organization, please visit Fisheries and Oceans Canada

Read about Fisheries and Oceans Canada’s mandate and role, departmental priorities and commitments, and the key legislation that supports our work.
Learn more about the Aquatic Ecosystems Branch
Understanding the job advertisement
Video: How to navigate the application process

Closing date: 13 October 2021 - 23:59, Pacific Time

Who can apply: **RESTRICTED TO EMPLOYMENT EQUITY MEMBERS AS FOLLOWS ** Open to Canadian citizens who are members of the following Employment Equity groups: Aboriginal persons, Visible Minorities, and Persons with Disabilities.



Apply online

Important messages

************************************************************************************
WHAT YOU NEED TO KNOW ABOUT APPLYING TO THIS INVENTORY
************************************************************************************ This inventory is open to individuals who self-declare as a visible minority, a person with a disability, or an Aboriginal person. Therefore, only those applicants who indicate in their application that they are members of the requisite Employment Equity (EE) group(s) will be considered.

In order to self-declare, please ensure to indicate this by checking off the appropriate box within the online application as part of the Employment Equity section.

The term “Aboriginal” is used within this job advertisement as it relates to the Employment Equity Act and other legislative frameworks. The term “Indigenous” is used, where feasible, in support of the United Nations Declaration on the Rights of Indigenous Peoples.

********************************************************

When you apply to this selection process, you are not applying for a specific job, but to an inventory for future vacancies. As positions become available, applicants who meet the qualifications may be contacted for further assessment.

===================================
HOW TO APPLY:
===================================
We are requesting that all job applications be submitted through the GC JOBS SYSTEM BY CLICKING ON THE “APPLY ONLINE” LINK BELOW. The benefit of applying online is that candidates are guided through a series of questions which helps them submit a complete application and therefore contains all of the information that hiring managers are looking for.

Work environment
Now is your chance to gain experience in the federal public service. Here are some reasons to apply:

Did you know that Fisheries and Oceans Canada and the Canadian Coast Guard have been recognized as top employers? We’ve been recognized as Forbes Canada’s Best Employers (2018) and, one of Canada’s Top Employers for Young People in 2017, 2018, 2019, and 2020!

The workplace, the Bedford Institute of Oceanography (BIO) Campus in Dartmouth, offers free parking and bus accessibility (Metro Transit’s route #51). BIO is next to Shannon Park's Canada 150 Trail and offers many workplace wellness initiatives. Check out www.bio.gc.ca to learn more about our Campus.

Additionally, we offer:

learning and training opportunities to support you in your current and future career
competitive salaries and benefits, such as supplemental health insurance, dental care, and vacation allowances
flexible work arrangements, volunteer days, and family-related leave
access to an Employee Assistance Program to support you through all stages of your career
an opportunity to serve Canadians by helping to protect our aquatic resources

Come join DFO / CCG for the opportunity to be a part of something bigger!

=================================================================
Have we sparked your interest? APPLY TODAY!
=================================================================
Intent of the process

Please Note: This process has been designed to have two (2) different job streams in one advertisement. There are merit criteria specific to each stream; please review them carefully.

Stream 1 – Aquatic Biologist/Physical Scientist (BI-03 and PC-03) Salary Range - $81,359 to $105,353
Stream 2 – Section Head /Team Leader (BI-04 and PC-04) Salary Range - $100,920 to $120,520

Candidates will not be required to indicate in their application the stream(s) for which they wish to be considered. Candidates who meet the essential qualifications will automatically be considered for the streams in which they are found qualified. Please note, the above two streams may be utilized for other positions with the same requirements. If no stream information is listed after a merit criterion, it will apply to both streams on this poster.

Two pools will be created as a result of this process; the results achieved in the process will determine if the candidate is placed in the BI-03/PC-03 pool only or both the BI-03/PC-03 and BI-04/PC-04 pools. Candidates may be offered positions of various tenures (permanent and temporary appointments), and will be required to meet conditions of employment depending on the position being staffed. As a result of the potential and possible use of this selection process, and subsequent pools which may be accessed by a variety of hiring managers across the region, we encourage all interested persons seeking these types of opportunities to apply.


Positions to be filled: 1

Information you must provide

Your résumé.

A response to a text question addressing the following:

Employment with the Federal Government
Interest in temporary opportunities
In order to be considered, your application must clearly explain how you meet the following (essential qualifications)

EDUCATION

For BI-03/BI-04 positions:
Graduation with a degree from a recognized post-secondary institution in a natural, physical or applied science with specialization in a field relevant to the duties of the position.

For PC-03/PC-04 positions:
Graduation with a degree from a recognized post-secondary institution, with acceptable specialization in physics, geology, chemistry or some other science relevant to the position.

Degree equivalency

Required EXPERIENCE for all positions (BI-03/PC-03 & BI-04/PC-04)

1. Experience working on projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species.
2. Experience providing information and advice to management on topics or issues related to the management or conservation of natural resources.
3. Experience assessing, synthesizing or analyzing information from a variety of sources on issues related to the management or conservation of natural resources.

………………………………………………………………………………………….

Additional Required EXPERIENCE for BI-04/PC-04 positions

1. Experience collaborating with internal teams or external stakeholders, partners or clients* .


stakeholders, partners or clients may include (but not limited to): federal, provincial and municipal departments and agencies, Indigenous partners, private sector organizations, NGOs, etc..

2. Experience leading complex** projects or initiatives that contribute to the management or conservation of aquatic habitat or aquatic species.

**Complex is defined as two or more of the following characteristics: high profile (i.e. attracting public or media attention); involving multiple stakeholders; multi-jurisdictional/multi-disciplinary in nature; involving third-party interests; requiring multiple consultations; or having a significant impact

3. Significant*** experience providing information and advice to senior management**** on topics or issues related to the management or conservation of natural resources.

***Significant experience is understood to mean the depth and breadth of the experience normally associated with having performed a broad range of complex related activities.

**** Senior Management means the Director level and above.

4. Experience in assigning and supervising the work of others.
If you possess any of the following, your application must also clearly explain how you meet it (other qualifications)

EDUCATION:
Post-graduate degree from a recognized university in a natural, physical or applied science with a specialization in a field relevant to the position.

Degree equivalency

The following qualifications are specific to the work in one or more of our Directorates/Programs. **Note: While these qualifications are not under the heading of essential qualifications, depending on the position being staffed, any of the following “Asset” or “other” qualifications may be deemed as essential qualifications and only those candidates and persons with a priority or preference entitlement who possess those qualifications will be considered for that specific vacancy.**

ASSET/ESSENTIAL QUALIFICATIONS: BI-03/PC-03 (but may also be invoked for certain BI-04/PC-04 positions):

Experience supervising staff.
Experience planning and participating in public consultation process.
Experience in the process for listing or recovery of species under the Species at Risk Act.
Experience implementing laws, regulations, policies or programs with respect to the Fisheries Act, Oceans Act, or Species at Risk Act (or other federal environmental regulations).
Experience establishing relationships, consulting, engaging, or negotiating with at least two (2) of the following: Indigenous community, academic institution, government departments/organizations, public, industry or non-governmental organization.
Experience in managing , regulating or assessing marine aquaculture.
Experience in the establishment, planning, or monitoring of protected areas.
Experience working with Geographic Information Systems (GIS) or other spatial data programs.
ASSET QUALIFICATIONS: BI-04/PC-04 (but may also be invoked for certain BI-03/PC-03 positions):

Significant experience in human resources management (as a sub-delegated manager).
Experience in evaluating the effects of human activity on the aquatic environment.
Experience in coordinating work teams including several representatives from various organizations.
Experience in collaborating with partner or stakeholder groups to carry out marine planning or conservation initiatives.
Experience managing financial resources (ie a budget).
The following will be applied / assessed at a later date (essential for the job)

Various language requirements

Information on language requirements

KEY LEADERSHIP COMPETENCIES:

For more information about these competencies, please visit the following link:

www.canada.ca/en/treasury-board-secretariat/services/professional-development/key-leadership-competency-profile/examples-effective-ineffective-behaviours.html


Create Vision and Strategy
Mobilize People
Uphold Integrity and Respect
Collaborate with Partners and Stakeholders
Promote Innovation and Guide Change
Achieve Results
ABILITIES:

Ability to communicate orally.
Ability to communicate in writing.
Other information

The Public Service of Canada is committed to building a skilled and diverse workforce that reflects the Canadians we serve. We promote employment equity and encourage you to indicate if you belong to one of the designated groups when you apply.

Information on employment equity

****************************************************
APPLICATION/ASSESSMENT PROCESS
****************************************************


Step 1: Application

When applying to this selection process, you will be asked if you have any of the experience listed above and must answer a screening questions demonstrating how you meet the qualifications . For some of the qualifications only a “Yes” or “No” response is required at this time.
Step 2: Job Matching

As positions become available, the hiring manager will establish the experience requirements a candidate would require for the particular role being staffed.

Upon identifying the requirements of the position, Human Resources will review your responses to the experience questions. Should you indicate you have the experience factors the hiring manager is looking for, Human Resources will contact you to:

1. Confirm you are available and interested in the position
2. Ask you to elaborate on how you meet the experience required (for the “Yes” or “No” questions in the application) .

This communication will be sent to you using the GC Jobs communication platform and/or as well to your e-mail. Please ensure that you check your e-mail and GC Jobs account frequently as there is often a deadline for your response. Please note that we will have to consider that you are no longer interested in participating in the selection process and that you have withdrawn your candidacy should you not provide us with an up-to-date email address or respond to our communication.

Step 3: Online Interview

You will be asked to complete a video interview using an online platform which will be recorded and made available to the hiring manager. The online interview is designed to assess your verbal communication skills and assess you against the Key Leadership Competencies.

Please note: You may be asked to complete an online interview before you’ve been matched to a position.
Step 4: Additional Assessment

Depending on the position being staffed, the hiring manager may establish additional criteria that are essential qualifications which candidates must meet. These criteria may include additional abilities and/or knowledge factors for their vacancy. Therefore, in addition to reference checks, a knowledge test or additional interview may be required.
Step 5: Appointment

If the hiring manager has determined that you meet the requirements for the position, you will receive an official notification from Human Resources. Should you be selected for the position, the hiring manager will contact you directly. You will be required to meet any conditions of employment for the position, such as a valid security clearance which will be reflected in your employment letter of offer.

************************************
ASSESSMENT
************************************
Please note that your overall conduct and communications, including email correspondence, throughout the entire process may be used in the assessment of qualifications and competencies.

You will be asked to provide proof (original documentation will be required) of your education credentials. If you were educated outside of Canada, you must have your certificates and/or diplomas assessed against Canadian education standards. For more information please click on “Degree Equivalency” in the Education section above.

****************************************
OFFICIAL LANGUAGES
****************************************
Persons are entitled to participate in the selection process in the official language of their choice. Applicants are asked to indicate their preferred official language in their application.
Preference

Preference will be given to veterans and to Canadian citizens, in that order, with the exception of a job located in Nunavut, where Nunavut Inuit will be appointed first.

Information on the preference to veterans

We thank all those who apply. Only those selected for further consideration will be contacted.","Fisheries and Oceans Canada
4.0",Dartmouth
799,Data Analyst (Research),"ABOUT HRI

Homewood Research Institute (HRI) invites applicants for the position of Data Analyst (Permanent, Full-time).

HRI is an ambitious and growing national charity dedicated to research that transforms mental health and addiction services in Canada and around the world. Through strategic partnerships with Homewood Health and a vital growing network including some of the world’s most influential scientists, clinicians and researchers, we are uniquely positioned to innovate, test new discoveries, and accelerate the process that brings research into solutions for the real world. For more information, visit hriresearch.com.

POSITION OVERVIEW

The HRI Data Analyst works closely with Research Associates, Research Scientists, and Investigators to ensure accurate collection, organization, documentation, analysis and sharing of data. The Data Analyst is responsible for the statistical analysis required for knowledge translation and exchange activities and for peer-reviewed publications. The Data Analyst is an integral member of the research and evaluation team.

KEY RESPONSIBILITIES

1. Data Analysis and Planning

Plans and conducts relevant analyses for internal/external collaborators involving a range of statistical methods, including multivariate analyses, structural equation modeling with cross-sectional and longitudinal data using data from a rolling cohort
Applies methods of handling missing data, such as multiple imputations
Uses external data from a variety of sources (e.g. Statistics Canada, Resident Assessment Instrument-Mental Health), in combination with internal project data
Prioritizes and responds to ad hoc and routine data inquiries

2. Development and Maintenance of Datasets

Leads the development and maintenance of datasets including the creation of standard operating procedures for creating, organizing, storing, documenting, extracting/exporting, converting, merging and manipulating large and small data files
Ensures that data are accurate, consistent, properly maintained, and shared in compliance with relevant privacy protection, confidentiality, and other ethical principles
Uses SAS or R to process and prepare datasets for HRI investigators including merging multiple data sets (different sources), deriving project-specific variables in consultation with HRI investigators, and applying appropriate de-identification techniques tailored to each unique data request
Writes documentation reports to accompany the release of datasets, including relevant procedural notes and data codebooks

3. Knowledge Translation and Communication

Contributes to the writing of peer-reviewed scientific publications and technical reports
Provides data outputs and creates reports for stakeholders including visually intuitive graphs and depictions on complex study results
Presents findings at scientific meetings when appropriate
Communicates clearly with research team members, external stakeholders, and funders

4. Consultation and Training

Provides data analysis and data management consultation/ support to researchers, graduate students, post-doctoral fellows and to affiliated scientists as needed

POSITION REQUIREMENTS

Education

Master’s degree in quantitative research (i.e., biostatistics, health sciences, psychology)

Skills and Experience

Demonstrated ability to interact effectively and build rapport with a wide range of individuals
Strong organizational skills and initiative; work well independently
Proficiency in statistical analysis software such as SAS, R, Mplus, STATA, and/or SPSS; Advanced proficiency in Microsoft Excel
Ability to perform data management and formatting for standard statistical software
Strong verbal and written communication skills with statisticians and non-statisticians including technical report writing and writing for peer-reviewed scientific publications
Ability to work on multiple analytical projects concurrently with attention to detail
Initiative to acquire new skills and remain current with new developments as required
Commitment to HRI values of Anti-Oppression Equity and Inclusion and supports related organizational goals and research activities
Knowledge of mental health and addictions research would be an asset
English/French bilingual capacity would be considered an asset

Anti-Oppression, Diversity and Inclusion Focus

At HRI, we strive to foster Anti-Oppression, Equity, and Inclusion (AOEI), because we believe living these values is the most powerful platform for social change. We believe that people and organizations thrive when we embrace the richness of the human experience and invite all voices to contribute to a shared goal.

We are passionate about our vision: “No life held back or cut short by mental illness or addiction.” This vision encompasses everyone, including (but not limited to) First Nations, Métis, and Inuit, people with disabilities, people of all cultural, religious, racial, and ethnic backgrounds, people of all income and education levels, people of all ages, non-binary and gender-nonconforming people, women, and two-spirit, lesbian, gay, bisexual, trans, queer, questioning, intersex, and asexual (2SLGBTQQIA) people.

As a research organization, we are working continuously to move AOEI values into action through our organizational culture, policies, and research activities.

JOB LOCATION

This position offers remote work arrangements due to the ongoing pandemic, however regular in-person meetings and events will be required when work returns to normal.

HOW TO APPLY

Please submit a resume and cover letter and inform us if you require accommodations during the interview process. We thank all applicants for their interest, however, only those selected to interview will be contacted.

Reference ID: HRI - 2021-03

Application deadline: 2021-06-25

Job Types: Full-time, Permanent

Pay: $29.88-$38.15 per hour

Benefits:

Dental care
Disability insurance
Employee assistance program
Extended health care
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Education:

Master's Degree (preferred)

Work remotely:

Temporarily due to COVID-19",Homewood Research Institute,Guelph
800,"Senior Data Engineer, Remote","Introduction

As a Senior Data Engineer, you will be a member of a fast-paced software engineering team consisting of open-minded and highly skilled individuals, that designs and continuously delivers a wide range of data analytics services for both clients and business partners.

Company

Infostrux is a Select Snowflake Services Partner building and operating reliable ‘as code’ data cloud solutions for business intelligence, data analytics, and data product use cases.

Position Overview

Participate in analysis, design and implementation of data analytics solutions
Suggest reusable patterns and process improvements to be implemented across the whole organization
Follow the trends and newest technologies in data architecture and data methodologies and bring them to practice where appropriate

Qualifications

Passion for data and engineering excellence
Experience building solutions based on formal (traditional, modern) and less formal data architectures, methodologies, designs and processes
7+ years of hands-on experience building data solutions using a variety of traditional and big data technologies
2+ years of hands-on experience building data solutions in AWS, Azure and/or GCP
Software engineering experience
Desired:
Snowflake, Fivetran, DBT
Python, JavaScript, Kotlin or Java
AWS Redshift, Kinesis, S3, Azure Synapse, SQL, Databricks, Data Lake Gen2, Stream Analytics, Apache Spark, Kafka, Presto, Airflow
ML/AI
DevOps, Cloud Infrastructure",Infostrux Solutions,Quebec
801,Big Data Engineer,"Cubert is the name and innovation is our game. As the creators behind FitTrack (https://getfittrack.com/) we know what it takes to develop new consumer hardware products and mobile applications for e-commerce/retail to a loyal customer base across the world.


But we take no credit. Cubert’s success comes down to one factor: Good people. Every person matters, so investing in hiring, developing and retaining sharp minds is our top priority.


We keep our team close knit, sharp and agile, which gives us the flexibility to constantly adapt to every situation. Why? A smaller team means high impact, strong communication and adaptability as a unit.

We are tied together by our values:


We strive to be the best in what we do
We obsess over customer experience
We challenge convention
Our foundation is built on trust
We take ownership in everything we do
We value learning and personal mastery

So if you’re tired of getting caught in red tape, or having the glass ceiling stop you from making magic, you’ve come to the right place.

Welcome to Cubert.







Role Responsibilities:



Use Big Data technologies to design and develop scalable and fault-tolerant big data ETL systems and Data Lakes in a non-Hadoop environment.
Providing leadership within enterprise data strategies and providing the framework of foundation Big Data Analytics.
Engaging stakeholders to understand their objectives for Big Data and utilizing information gathered to plan the computing framework with data sources, analytical tools and data storage.
Evaluating and recommending new and emerging data management and storage technologies and standards.
Ensuring consistency between data management, enterprise storage and all other technical system components.
Create and maintain a corporate repository of all data architecture artifacts.
Adhere to Agile principles and philosophies (Scrum or Kanban, as applicable) in fulfillment of the role.
Work as a cross-functional team member in an Agile setting to help complete and deliver the team commitments.



What you bring to the table:



Bachelor’s degree in Information Technology, Software Engineering, Computer Science, or related field.
1+ year of data architecture experience in Big Data with advanced understanding of Data architecture concepts, patterns and standards.
Experience in designing and implementing Big Data Lakes and ETL ingestion facilities.
Strong understanding of relational data structures, theories, principles, and practices.
Experience with enterprise data management technologies, including database platforms, ETL tools, and SQL.
Experience with data modelling tools.
Experience on GCP data technologies, dataflow, bigquery, pubsub, google cloud storage, dataproc, cloud function.



How we help you become successful




Flat hierarchy and co-operative international working environment
Learning support per company policy (approved courses etc.)
Health Benefits with Health Spending Accounts
Competitive compensation
Dog Friendly Office
Stocked Kitchen with healthy (and some unhealthy!) snacks




Cubert Inc. is an equal opportunity employer and encourages applications from qualified individuals. We thank all applicants for their interest: However, only those selected for an interview will be contacted. If chosen to participate in the selection process, accommodations are available upon request. We will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicant’s accessibility needs.","Cubert Inc.
4.2",Toronto
802,Big Data Engineer,"Cubert is the name and innovation is our game. As the creators behind FitTrack (https://getfittrack.com/) we know what it takes to develop new consumer hardware products and mobile applications for e-commerce/retail to a loyal customer base across the world.


But we take no credit. Cubert’s success comes down to one factor: Good people. Every person matters, so investing in hiring, developing and retaining sharp minds is our top priority.


We keep our team close knit, sharp and agile, which gives us the flexibility to constantly adapt to every situation. Why? A smaller team means high impact, strong communication and adaptability as a unit.

We are tied together by our values:


We strive to be the best in what we do
We obsess over customer experience
We challenge convention
Our foundation is built on trust
We take ownership in everything we do
We value learning and personal mastery

So if you’re tired of getting caught in red tape, or having the glass ceiling stop you from making magic, you’ve come to the right place.

Welcome to Cubert.







Role Responsibilities:



Use Big Data technologies to design and develop scalable and fault-tolerant big data ETL systems and Data Lakes in a non-Hadoop environment.
Providing leadership within enterprise data strategies and providing the framework of foundation Big Data Analytics.
Engaging stakeholders to understand their objectives for Big Data and utilizing information gathered to plan the computing framework with data sources, analytical tools and data storage.
Evaluating and recommending new and emerging data management and storage technologies and standards.
Ensuring consistency between data management, enterprise storage and all other technical system components.
Create and maintain a corporate repository of all data architecture artifacts.
Adhere to Agile principles and philosophies (Scrum or Kanban, as applicable) in fulfillment of the role.
Work as a cross-functional team member in an Agile setting to help complete and deliver the team commitments.



What you bring to the table:



Bachelor’s degree in Information Technology, Software Engineering, Computer Science, or related field.
1+ year of data architecture experience in Big Data with advanced understanding of Data architecture concepts, patterns and standards.
Experience in designing and implementing Big Data Lakes and ETL ingestion facilities.
Strong understanding of relational data structures, theories, principles, and practices.
Experience with enterprise data management technologies, including database platforms, ETL tools, and SQL.
Experience with data modelling tools.
Experience on GCP data technologies, dataflow, bigquery, pubsub, google cloud storage, dataproc, cloud function.



How we help you become successful




Flat hierarchy and co-operative international working environment
Learning support per company policy (approved courses etc.)
Health Benefits with Health Spending Accounts
Competitive compensation
Dog Friendly Office
Stocked Kitchen with healthy (and some unhealthy!) snacks




Cubert Inc. is an equal opportunity employer and encourages applications from qualified individuals. We thank all applicants for their interest: However, only those selected for an interview will be contacted. If chosen to participate in the selection process, accommodations are available upon request. We will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicant’s accessibility needs.","Cubert Inc.
4.2",Toronto
803,Cloud Solution Architect - Data,"Microsoft is on a mission to empower every person and every organization on the planet to achieve more. Our culture is centered on embracing a growth mindset, a theme of inspiring excellence, and encouraging teams and leaders to bring their best each day. In doing so, we create life-changing innovations that impact billions of lives around the world. You can help us to achieve our mission.
Microsoft aspires to help our customers achieve their own digital transformation, leveraging the power of Microsoft Cloud solutions and support offerings. To this end, Microsoft invests in a dedicated Customer Success team that will help Microsoft customers successfully realize their business outcomes.

Azure is the most comprehensive, innovative and flexible cloud platform today and Microsoft is hiring professionals that will drive customer cloud adoption within the most important companies in the market.

We are always learning. Insatiably curious. We lean into uncertainty, take risks, and learn quickly from our mistakes. We build on each other’s ideas because we are better together. We stand in awe of what humans dare to achieve and are motivated every day to empower others to do more and achieve more through our technology and innovation. Together we make a difference.

To learn more about Microsoft’s mission, please visit: https://careers.microsoft.com/mission-culture

Check out all of our products at: http://www.microsoft.com/en-us

We are looking for a highly motivated and passionate Data Platform & Advanced Analytics/Artificial Intelligence Cloud Solution Architect to drive high priority customer initiatives on the Microsoft Azure Platform in collaboration with customers and the Microsoft field in Enterprise accounts segment of our business. This is a customer facing role, owning overall technical relationship between customer and Microsoft Data, Advanced Analytics and Artificial Intelligence Platform.

You will own the Data Platform & Advanced Analytics technical customer engagements including architectural design sessions, specific implementation projects and/or MVPs. The ideal candidate will have experience in customer-facing roles and success leading deep technical architecture discussions with senior customer executives, Enterprise Architects, IT Management and Developers to drive Data Platform and Advanced Analytics solutions to productions.
Responsibilities
Key responsibilities include
Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.
Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, Analytics and AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. SQL Server, Azure Synapse, Azure ML, Azure Cognitive Services, Azure Data Factory, Big Data, Data Lake, Azure Databricks, Power BI, etc.)
Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment
Develop deep relationships with key customer IT decision makers and relevant business decision makers (like AI or Analytics), who drive long-term cloud adoption within their company to enable them to be cloud advocates
Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.
Collaborate with other Cloud Solution Architects and MS stakeholders in developing complex end-to-end Enterprise solutions on Microsoft Cloud platforms.
Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform
Be an Azure Platform evangelist with customers, partners and external communities.
Qualifications
Knowledge and Skills: Professional Experience
5+ years of success in consultative/complex technical sales and deployment Data Platform and Analytics projects, architecture, design, implementation, and/or support of highly distributed applications required
Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. Required
Good business acumen to quickly understand the customer’s industry and business to have relevant discussions with business decision makers.
Problem Solving. Ability to solve customer problems through cloud technologies Required
Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) Required
Technical
Enterprise-scale technical experience with cloud and hybrid Data and Analytics architecture designs, database migrations, and technology management. required
The technical aptitude and experience to learn new technologies and understand relevant cloud trend especially in Data Platforms and Analytics
Competitive Landscape: Knowledge of cloud development platforms
Partners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred
Breadth of technical experience and knowledge, with depth / Subject Matter Expertise in two or more of the following Data Analytics and AI Platform Cloud solutions required
SQL including OSS (postgres, MySQL etc), Azure SQL
NoSQL Databases including OSS (Maria, Mongo etc), Cosmos DB
Big Data including SQL DW, Snowflake, Big Query, Redshift
Advanced Analytics including Azure Data Bricks, visualization tools as PowerBI, Tableau
Data Governance
Data Engineering
Data Science
Machine Learning including Azure ML, ML Server
Artificial Intelligence including BOT framework, Cognitive Services, Cognitive Search
Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python
Education
Bachelor's degree in Computer Science, Information Technology, Engineer, or related field preferred
Certification in one or more of the following technologies preferred: Cloud, mobile, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence
Experience
Prior work experience in a Consulting/Architecture position within a software and/or services company such as Amazon, VMware, Google, IBM, Oracle desired
Prior solution delivery experience in Analytic and AI specialized solution providers

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.","Microsoft
4.4",Vancouver
804,Senior Data Engineer,"Senior Data Engineer
My client, the largest e-commerce investor, was founded by founders for founders. They invested $2B+ in over 4k business. Looking for a Data Engineer talent to join their smart team to build the data-driven app for early-stage founders.

Contact me for details about this exciting opp!!!

100% Remote if you want; but NO NO NO outside-the-country applicants, thank you.
Responsibilities:
You will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development
Working closely with every member of the team, vendors and external partners, you will produce significant components of the code
Collaborate with all functions, ranging from core Engineering team to Data Science team to the marketing team
You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary
You will scope out business needs and action them with speed and accuracy and then lead and execute on it yourself.
You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs
Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

What we look for:
Great communication skills, with a desire or experience to lead a small team of other devs in the near future
Desire to help founders. We take a strong founder first stance on this team
Be self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission
On this team, we maximize learning. You will fail if you're not learning fast enough
Comfort working in a high growth, constantly changing environment
Heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support
Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!
Have a strong business sense, you can foresee potential issues and solve them quickly
Demonstrated ability to collaborate effectively across multiple teams
Strong interest in building businesses, ecommerce and fintech

Technical Requirements:
Ideally, you have worked on 3 or more different stacks in your career in a professional setting. Bonus points for systems managing time-series
Able to architect and scale data integrations (shopify, paypal, plaid, etc.) from third-party API docs independently, extracting the right business value for the vision and roadmap
Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes
Comfortable working in server and database environments that are changing constantly
Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff
Comfortable with relational databases and schemas involving time-series
Skills and interest in Python, SQL, Snowflake, Kubernetes and pipeline management/orchestration tools (Eg. Airflow)
TOR123","Vaco
3.7",Midtown Toronto
805,Ingénieur de données / Data Engineer,"Nous sommes à la recherche d’un(e) Ingénieur de données / Data Engineer pour rejoindre notre équipe de conseillers en analytique avancé et travailler sur des projets innovants avec nos clients. Nos conseillers travaillent pour les plus grandes entreprises québécoises sur des projets à moyen ou long terme et chez nous hors de question de travailler en silo: on partage nos projets, nos compétences et notre savoir-faire au quotidien.

agileDSS, c’est quoi/qui ?

agileDSS est une entreprise de service-conseil spécialisée en analytique avancé. Depuis 15 ans, nous accompagnons les grandes entreprises québécoises à tirer le meilleur parti de leurs données par le biais d’une expertise de pointe en analytique avancé (Big Data, Intelligence d’Affaires, Visualisation de Données et Data Science).

Ce poste est pour toi si tu as :

Un minimum de 5 années d’expérience pertinente en Big Data
Forte expérience de travail avec les systèmes de base de données dans le cloud comme Google Big Query, Snowflake, Redshift ou équivalent;
Une solide expérience de travail de conception et d’optimisation de pipelines de données sur de grands volumes de données structurées et semi-structurées;
Expérience en matière de développement d'entrepôts de données, de modélisation et/ou d'analyse de données;
Expérience pertinente avec les plateformes de sciences de données tel que Azure Databricks, Spark, Hortonworks, etc. ;
Maitrise du Java, SQL, Scala et Python
Bonne connaissance de la gestion des données, de l'intégration des données et des techniques de développement des bases de données;
Expérience des technologies de base de données (par exemple, SQL, NoSQL, Oracle, Hadoop, Snowflake, Teradata);
Fait preuve de rigueur et d’objectivité dans son travail d’analyse;
Flexibilité dans la gestion de son quotidien et de ses relations professionnelles;
Excellente capacité d’identification et de résolution de problèmes;
Bon communicateur, sachant travailler efficacement en équipe;
Bonnes aptitudes au développement de relations efficaces avec les fournisseurs et prestataires de services externes;

Atout :

Expérience avec les langages de programmation et de gestion de base de données traditionnels, y compris SQL, PL/SQL, avec les langages de manipulation de données propres aux sciences des données tels que Python et R.
Anglais ""fonctionnel"" demandé

Mais les hard skills c’est pas tout !
Avant toute chose on cherche un nouveau collègue qui va s’épanouir dans notre environnement! Si tu es une personne qui aime partager ses connaissances, qui prône le self-management, qui est bienveillant, fun et gourmande, tu as de grandes chances de te plaire chez nous !

À quoi tu peux t’attendre dans ton rôle ?

Participer, en collaboration avec les concepteurs, à l’élaboration et à la réalisation, des solutions de données corporatives;
Coordonner la collecte, la formalisation et la documentation des besoins de l’organisation en ce qui a trait aux solutions de données corporatives ou sectorielles;
Mettre en œuvre des règles d’affaires de traitement et de valorisation des données corporatives et sectorielles (entrepôts, comptoirs, données maitresses et de référence, etc.);
Participer à des activités de nettoyage, de transformation, de conversion et de correction des données;
Réaliser des tests durant la modification des applications, pour garantir l’intégrité opérationnelle des solutions de données;
Participer à la mise en production itérative des solutions, travailler avec des équipes des différentes unités d’affaires pour établir et exécuter les tâches nécessaires, selon un ordre bien établi;
Travailler en collaboration avec les autres professionnels TI et communiquer avec les différents partenaires afin de clarifier et bien comprendre leurs besoins;
Participer à la définition des fonctions, services ou éléments techniques requis;
Réaliser, documenter et valider les analyses demandées ;
Respecter les règles fonctionnelles et techniques ainsi que les normes de conception et de livraison de solutions;
Participer ou réaliser des essais à différents niveaux de détails, qu’ils soient fonctionnels ou techniques ;
En contexte de livraison et de mise en production, soutenir les partenaires lors des essais d’acceptation ;
Participer à l’implantation des solutions retenues;
Participer au plan d’évolution des applications et systèmes technologiques.

Ce qu’on t’offre

Nous sommes avant tout une équipe de collaborateurs à taille humaine qui a à cœur le bien-être de ses employés, c’est pourquoi nous t’offrons:

Une rémunération annuelle fixe et une bonification annuelle selon l’atteinte de ta performance
Des objectifs individuels accessibles et réalistes pour garantir un environnement sans pression
Des assurances collectives Manuvie (dentaire, vision, soins paramédicaux…)
4 semaines de vacances
Remboursement des abonnements de sport et du transport
Horaires flexibles et télétravail
Plan de développement pour chaque employé et coaching avec un mentor
Environnement non hiérarchique favorisant l’intrapreneuriat
Activités mensuelles de team building
Abonnement au spa

Note : Ce poste débutera en télétravail pour s'adapter au contexte de pandémie. Il faut donc prévoir un retour progressif physique en fonction du déconfinement.

Type d'emploi : Temps Plein, Permanent

Salaire : 90 000,00$ à 115 000,00$ par an

Horaire :

Du Lundi au Vendredi
Repos la Fin de Semaine

Expérience:

Scala: 3 ans (Souhaité)
Databricks: 1 an (Souhaité)
Consultation: 2 ans (Souhaité)
Big Data: 3 ans (Souhaité)
Spark: 3 ans (Souhaité)
Python: 3 ans (Souhaité)

Langue:

Français (Souhaité)
Anglais (Souhaité)","agileDSS
4.3",Montreal
806,Senior Food Scientist,"The Senior Food Scientist is responsible for researching and conducting experiments, gathering data, developing preliminary findings and preparing written reports for the development of new products and reformulating of existing products to improve quality and/or margins. This position is designed with an emphasis on developing and demonstrating technical expertise in food product development.

Assists in keeping Nature’s Path on the leading edge of new product development:

Leads product development projects steps from concept through commercialization.
Researches new and current raw materials and applications.
Develop new product prototypes for presentation to management and marketing.
Organizes and participates in project presentations to brand management.
Independently designs, plans, and executes experiments.
Independently conducts plant trials and oversees new product start-ups.
Interprets experimental results, provides recommendations, and implements next steps.
Keeps informed on current developments in the food industry, new technologies, and innovative ingredients.
Works with cross-functional teams to accomplish project objectives with little or no support.
Manages multiple projects simultaneously, ensuring timely completion of project objectives in a fast-paced environment.

Ensures operational standards for quality, cost, lean manufacture, food safety and sustainability:

Improves existing products by optimizing product attributes (cost, nutritional profiles, and ingredient statements).
Assists in cost containment and quality standards of ingredients by researching vendors and alternate suppliers.
Creates new product documentation including processing parameters, ingredient specifications, nutritional information, and disposition of final product.
Works with Operations to optimize run parameters.
Participates in ongoing product shelf-life testing of all new and revised products.
Leads the submissions for third party lab testing as per protocol.
Leads operation meetings to ensure documentation and review of pre- and post- new product runs.

Assists in the assurance of customer satisfaction with quality, consistent products:

Determines optimal final product specifications for new product development.
Enters and tracks nutritional information using the Genesis program to assure accuracy of nutritional facts for new product packaging.
Maintains up-to-date knowledge of all legal requirements for packaging changes.

Education

Bachelor degree in Food Science, or related degree, from a recognized university or college with relevant food science work experience.

Experience

Respect for or experience in the whole health/natural organics industry desirable.
Brings a solution-focused approach to innovation and problem solving
Minimum 5 years of Product Development, R&D experience - From Concept to Commercialization
Able to accurately prepare specifications, label declarations and formulations
Strong business acumen and demonstrate business knowledge by leading discussion and direction on project work with the organization
Able to identify opportunities and exhibit high energy and a willingness to be involved.
Knowledge in food chemistry and statistical analysis as used in designing experiments and measuring process capabilities; cereal extrusion, baking, and tortilla chip manufacturing experience desirable.","Nature's Path Foods
3.3",Richmond
807,Senior Clinical Quantitative Scientist - Oncology Data Analytics,"Bayer is a global enterprise with core competencies in the Life Science fields of health care and agriculture. Its products and services are designed to benefit people and improve their quality of life. At Bayer you have the opportunity to be part of a culture where we value the passion of our employees to innovate and give them the power to change




Senior Clinical Quantitative Scientist - Oncology Data Analytics




YOUR TASKS AND RESPONSIBILITIES

The primary responsibilities of this role, Senior Clinical Quantitative Scientist – Oncology Data Analytics, are to:




Develop and implement sound scientific approaches (modern and innovative methods) and technology to robustly evaluate the safety and benefit-risk profile of Cancer drugs based on data from clinical trials, spontaneous reports and real world in collaboration with clinical, regulatory and other strategic functions
Analyze clinical and molecular data from cancer patients to identify new scientific insights



Key Tasks:

Define and execute analysis plans to address scientific questions using clinical trial data
Develop and implement modern and innovative quantitative methodologies including modeling and simulation to solve complex problems
Analyze clinical and molecular data from cancer patients to gain new scientific insights and assist drug development
Explore quantitative models and tools to enable data-driven decision making by testing and prototyping
Supervise development of quantitative tools to be used across the organization
Effectively communicate scientific findings to other clinical operations departments
Stay abreast of current and emerging quantitative methodologies and tools and provide assessment and recommendations
Lead programming activities to develop and validate exploratory and interactive data analysis packages needed for clinical studies and projects in collaboration with responsible statistician(s)



WHO YOU ARE

Your success will be driven by your demonstrations of our LIFE values. More specifically related to this position, Bayer seeks an incumbent who possess the following:




MS/PhD in a relevant quantitative discipline (e.g. Statistics, Bioinformatics, Computational Biology, Genomics, or Computer Science) or a degree in Cancer Biology, Immunology, or Molecular Biology combined with significant previous experience with data analysis
Min. 2 years of relevant statistical analysis experience in the Pharmaceutical, Biotechnological, Academic, or Research Institutes or similar sector
Strong knowledge of applied statistics used to analyze and interpret aggregate clinical data
Technical Skills:
High technical competency in clinical research setting is required
Previous experience creating interactive data displays using statistical and/or visualization software or tools (i.e. SAS, R, Shiny, Python, Spotfire etc.) is required
Machine learning, NLP experience and web development (HTML, JavaScript etc.) is a plus
Communication & Presentation Skills:
Fluency in English is required
Capability of working independently and collaboratively
Demonstrated ability to prepare training materials such as use-cases, user-manuals, and formal presentations
Leadership Skills:
Good knowledge of the pharmaceutical industry including the understanding of clinical drug development process and associated documents and regulations
Proven problem-solving capabilities to address complex issues independently and as a self-starter
Experience in leading teams
Preferred: Knowledge of CDISC standards and Oncology experience



#LI-CA

Bayer welcomes and encourages applications from people with disabilities. Candidates participating in our selection process requiring accommodation due to a disability or medical need are encouraged to notify the Bayer representative that they will be meeting with to ensure appropriate arrangements can be made.


Location:

Canada : Ontario : Mississauga




Division:

Pharmaceuticals




Reference Code:

384382","Bayer
4.1",Mississauga
808,"Research Scientist - HEOR, Evidence Synthesis","Are you a self-starter with a passion for projects involving innovative health economic concepts? If you a natural ""doer"" who enjoys collaborating, moving the ball forward and rolling up your sleeves - keep reading!

Our culture is similar to that of a start-up, but in a well-funded established global portfolio organization. Our team has a real passion and excitement for HEOR, priding ourselves on being leaders with vision in our field.

We are growing and seeking those who are passionate about Health Economics and Outcome Research; researchers who love the prospect of collaborating with a diverse team of scientists and who look to make a real difference.

We hire throughout the year at varying levels of experience and offer these opportunities out of offices in US, Vancouver BC and London.

What you can expect day-to-day:
Research Scientists collaborate across a broad portfolio of sophisticated health economic and health policy research projects as a member of a project team; and they understand how to create the data foundation needed to provide the statistical analysis framework for projects. In collaboration with the project lead, conduct statistical analysis and modeling procedures, and contribute to interpretation of the results from statistical procedures and models in order to address client's research questions.

Essential responsibilities include:
Develops client-ready deliverables in terms of protocols (systematic literature reviews of cost-effectiveness modeling), statistical analysis plans (evidence synthesis), technical reports, and slides, identifying necessary deviations from templates to ensure content aligns with objectives

Develops content for components of proposals in collaboration with senior team members

Applies alternative (known/standard) methods in terms of systematic literature reviews, evidence synthesis, and/or cost-effectiveness modeling according to best practices and identifies relevant limitations to project lead

Accountable for timely delivery and financial performance of project subcomponents; estimates required hours and identifies challenges early on; and communicates any changes and possible solutions to project lead if necessary

Drafts and reviews update slides/minutes and actions for overall study and viewed by client as independent researcher for specific study component(s)

Communicates with client frequently on calls and supports project lead in responding to emails; may also be involved in face-to-face presentations to clients

Breaks down complex project tasks or project subcomponents into manageable components and approaches them in logical and clear manner

Highlights resourcing constraints for project subcomponents to project or team lead and identifies tasks where support is needed from junior team members

Identifies new opportunities within existing projects/clients

Participates in, and occasionally leads group strategy discussions

Guides junior teams members

Leads publication independently to implement own ideas in a wide range of other project-related and infrastructure activities such as: recruiting experts for meetings, advisory groups, or panels; contributing to or reviewing proposals; assisting with problem-solving; researching potential solutions; among others.

Qualifications:
Required

Master's degree

Minimum of 1-years' experience

Other required

Excellent oral and written communication skills

Ability to work effectively individually and as part of a diverse team

Proficiency with Microsoft Office

Desired

Master's degree with a concentration in economics, health services research, epidemiology, biostatistics, public policy, health policy, or public health or related; Ph.D.

Experience in conducting literature reviews.

Experience in conducting systematic reviews, scoping reviews, rapid reviews, or critical reviews

Experience conducting and interpreting statistical analyses

Experience writing scientific or review papers

Understanding of medical terminology and/or any disease-specific expertise

Experience with statistical programs such as R, Stata or SAS

Any data provided as a part of this application will be stored in accordance with our Privacy Policy .

Precision Medicine Group is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. © 2020 Precision Medicine Group, LLC

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Precision Medicine Group at QuestionForHR@precisionmedicinegrp.com .",Precision Medicine Group,Vancouver
809,Data Engineer (Full Time Permanent Remote Work Opportunity),"Your opportunity:

Lixar, fueled by BDO Canada, is looking for a dynamic and dedicated Data Engineer to join our remote Canadian team. As a Data Engineer, you will be part of a team supporting and participating in the ongoing development of leading edge applications.


The ideal candidate will be a senior developer who has a strong background in Big Data with a mix of general programming and some exposure to data visualization.


As an experienced Data Engineer, you have:


Post-secondary education in engineering or computer science or equivalent work experience
A proven track record using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle ""big data"" problems
A master of all things SQL (and NoSQL)
5+ years of programming experience in Python
Proven experience using RESTful Web Services & JSON
Good experience using Cloud based data solutions (AWS/Azure)
Experience working with production systems
Knowledge of ELT, ELT, Lambda and Kappa data architectures


Preferably, you also have:


Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git)
Experience with DataBricks
Some Data Visualization experience in Power BI, Tableau, or similar
Exposure to data science, machine learning or statistics
Some experience using Docker


How do we define success for your role?


You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration
You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work
You identify, recommend, and are focused on effective service delivery to your clients
You share in an inclusive and engaging work environment that develops, retains & attracts talent
You actively participate in the adoption of digital tools and strategies to drive an innovative workplace
You grow your expertise through learning and professional development.


Why BDO?


Our firm is committed to providing an environment where you can be successful in the following ways:

We enable you to engage with the firm's strategic plan, and be a key contributor to the success and growth of the firm.
We help you be the best professional you can be in our services, industries and markets.
Achieve your personal goals outside of the office and make an impact on your community.


Giving back, it adds up: Where company meets community. BDO is actively involved in our communities by supporting local charity initiatives. We support staff with local and national events where you will be given the opportunity to contribute to your community.

Total rewards that matter: We pay for performance with competitive total cash compensation that recognizes and rewards your contribution. We provide flexible benefits from day one, and a market leading personal time off policy. We are committed to supporting your overall wellness beyond working hours, and provide reimbursement for wellness initiatives that fit your lifestyle.

Everyone counts: We believe every employee should have the opportunity to participate and succeed. Through leadership by our Chief Inclusion and Diversity Officer, we are committed to a workplace culture of respect, inclusion, and diversity. We recognize and celebrate the valuable differences among each of us, including race, religious beliefs, physical or mental disabilities, age, place of origin, marital status, family status, gender or gender identity and sexual orientation. If you require accommodation to complete the application process, please contact us.

Ready to make your mark at BDO? Click “Apply now” to send your up-to-date resume to one of our Talent Acquisition Specialists.

To explore other opportunities at BDO, check out our careers page.


#LI-MM1","BDO
3.7",Midtown Toronto
810,"Research Scientist - HEOR, Evidence Synthesis","Are you a self-starter with a passion for projects involving innovative health economic concepts? If you a natural ""doer"" who enjoys collaborating, moving the ball forward and rolling up your sleeves - keep reading!

Our culture is similar to that of a start-up, but in a well-funded established global portfolio organization. Our team has a real passion and excitement for HEOR, priding ourselves on being leaders with vision in our field.

We are growing and seeking those who are passionate about Health Economics and Outcome Research; researchers who love the prospect of collaborating with a diverse team of scientists and who look to make a real difference.

We hire throughout the year at varying levels of experience and offer these opportunities out of offices in US, Vancouver BC and London.

What you can expect day-to-day:
Research Scientists collaborate across a broad portfolio of sophisticated health economic and health policy research projects as a member of a project team; and they understand how to create the data foundation needed to provide the statistical analysis framework for projects. In collaboration with the project lead, conduct statistical analysis and modeling procedures, and contribute to interpretation of the results from statistical procedures and models in order to address client's research questions.

Essential responsibilities include:
Develops client-ready deliverables in terms of protocols (systematic literature reviews of cost-effectiveness modeling), statistical analysis plans (evidence synthesis), technical reports, and slides, identifying necessary deviations from templates to ensure content aligns with objectives

Develops content for components of proposals in collaboration with senior team members

Applies alternative (known/standard) methods in terms of systematic literature reviews, evidence synthesis, and/or cost-effectiveness modeling according to best practices and identifies relevant limitations to project lead

Accountable for timely delivery and financial performance of project subcomponents; estimates required hours and identifies challenges early on; and communicates any changes and possible solutions to project lead if necessary

Drafts and reviews update slides/minutes and actions for overall study and viewed by client as independent researcher for specific study component(s)

Communicates with client frequently on calls and supports project lead in responding to emails; may also be involved in face-to-face presentations to clients

Breaks down complex project tasks or project subcomponents into manageable components and approaches them in logical and clear manner

Highlights resourcing constraints for project subcomponents to project or team lead and identifies tasks where support is needed from junior team members

Identifies new opportunities within existing projects/clients

Participates in, and occasionally leads group strategy discussions

Guides junior teams members

Leads publication independently to implement own ideas in a wide range of other project-related and infrastructure activities such as: recruiting experts for meetings, advisory groups, or panels; contributing to or reviewing proposals; assisting with problem-solving; researching potential solutions; among others.

Qualifications:
Required

Master's degree

Minimum of 1-years' experience

Other required

Excellent oral and written communication skills

Ability to work effectively individually and as part of a diverse team

Proficiency with Microsoft Office

Desired

Master's degree with a concentration in economics, health services research, epidemiology, biostatistics, public policy, health policy, or public health or related; Ph.D.

Experience in conducting literature reviews.

Experience in conducting systematic reviews, scoping reviews, rapid reviews, or critical reviews

Experience conducting and interpreting statistical analyses

Experience writing scientific or review papers

Understanding of medical terminology and/or any disease-specific expertise

Experience with statistical programs such as R, Stata or SAS

Any data provided as a part of this application will be stored in accordance with our Privacy Policy .

Precision Medicine Group is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. © 2020 Precision Medicine Group, LLC

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Precision Medicine Group at QuestionForHR@precisionmedicinegrp.com .",Precision Medicine Group,Vancouver
811,Senior Scientist – ICP Mass Spectrometry R&D,"PerkinElmer is a global technology leader driving growth and initiative in the Environmental and Human Health Science markets. The company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world.

PerkinElmer, a global leader in technology is searching for an experienced research and development scientist to help drive innovative solutions in our Inductively Coupled Plasma –Mass Spectrometry (ICP-MS) product line. The individual will become a key member of a group of senior PerkinElmer researchers and liaise closely with other scientists at PerkinElmer’s partners and collaborators.

This position is based in Woodbridge, Ontario, Canada.

Duties and Responsibilities

Initiate, direct, and execute scientific research with an emphasis on developing next generation technology, trade secrets, and intellectual property.
Act as a mass spectrometry scientific expert within the R&D team during implementation and process confirmation phases, allowing thorough conceptualization and overall design and testing of new products.
Influence the scientific community and market via patents, publications, and conference presentations.
Provide research project planning and time estimates.
Evaluate competitive products and new technologies from research institutions, aiming to enhance future products.
Work with manufacturing, sustaining, and service personnel to improve quality, cost, manufacturability, and serviceability of products.
Demonstrate independent and creative scientific thinking, ability in solving complex problems, and resilience to setbacks and changes.
Experience and ability to lead and coordinate multiple collaborative projects in a cross-functional program team environment.

Basic Qualifications:

Ph.D. in science, engineering, or related fields (Physics, Chemistry, or Engineering, with strong computer and mathematics skills) and 0 years of experience
MS in science, engineering, or related fields (Physics, Chemistry, or Engineering, with strong computer and mathematics skills) and 3 years of experience.

Preferred Qualifications:

Prior instrumentation or application experience in ICP-MS.
Knowledge of mass spectrometry theory and components is a strongly preferred (such as sample introduction, plasma sources, vacuum technology, electromagnetic fields, quadrupole-based mass analyzers, RF systems, charged particle detectors, and data acquisition hardware)
Knowledge in design of Mass Spectrometry systems.
Strong instrumentation design skills and troubleshooting ability.
Proficient programming skills in one or more computer languages or firmware.
Ability solve to complex problems and dissect projects into manageable tasks
Excellent group interaction skills and negotiating skills.
Strong written and oral communication skills.
Demonstrated organizational skills to handle multiple tasks with different priorities.
Previous successful academic or work-related experience mentoring peers.
Proven track record of publications in peer-reviewed journals.

Job Types: Full-time, Permanent

Pay: From $88,000.00 per year

Benefits:

Dental care
Extended health care
Flexible schedule
Paid time off
Vision care

Schedule:

8 hour shift

Education:

Master's Degree (required)

Experience:

ICP-MS: 3 years (preferred)

COVID-19 precaution(s):

Remote interview process","PerkinElmer
3.7",Woodbridge
812,Senior Scientist – ICP Mass Spectrometry R&D,"Data Engineer

If you know Python, Perl, or Tcl you've probably heard of ActiveState's language distros. Now we’re building an ambitious language distribution platform so that no engineer ever has to suffer dependency hell again, and we need your help to do it!

This position is available to remote workers anywhere in the world, as long as you are able to work on a schedule that aligns with our North American business hours. You can also choose to work from our headquarters in beautiful Vancouver, BC once the health situation makes this possible.

This position is open to experienced candidates with a track record in this area. We’re building up our data warehouse and analysis skills, and we’re looking for someone who knows how to analyze, recommend, deploy, and use tools and techniques to help us get the most out of our data!



What You’ll be Doing

As a Data Engineer, you’ll help foster informed decision making and innovation within ActiveState by making our data understandable, actionable, and available in the relevant contexts.

You’ll be a part of our Tools and Infrastructure team, and will work closely with our in-house Data Analyst and with most of our other teams from time to time, both inside and outside of Engineering.




Your primary work will include:

Designing, building, and managing ETL and warehousing pipelines, including recommending tools, technologies, and practices for us to adopt.
Improving data accessibility within ActiveState by developing and training other developers in the use of monitoring, analysis, and visualization tools and techniques.
Ensuring data is managed in compliance with our in-house policies.
Managing and designing the data and reporting environment, including data sources, tooling, security, and metadata.
Designing, building, deploying, and managing tools and processes to help colleagues understand data.
Testing and documenting your work.



You’ll work with others on the following tasks:

Using code and data visualization tools to collect, validate, normalize, collate, analyze, interpret and present data. Some of this work will be ad hoc, while some will be routine and automated.
Analyzing and optimizing data models, queries, and access patterns.
Building processes and systems to monitor data quality, ensuring that production data is accurate.
Updating our data collection and analysis policies.

Our team is mostly scattered around the US and Canada, so we coordinate with each other and the rest of the company using Slack for chat, Zoom for video calls and screen sharing, Asana for task management, and Google Drive.




We like to use open source software whenever possible, and we also like to contribute back to the open source ecosystem. We embrace open sourcing both libraries and tools developed in-house as long as those are not mission-critical code.

What’s in it for You
Working for a stable and growing company that offers the environment and personal growth potential of a start-up.
The chance to work with a smart, passionate team of people.
Competitive salary and bonus plan.
Comprehensive benefits package and health/wellness credit program.
Requirements
Demonstrated experience with ETL and data management technologies (for example, Snowflake and Matillion)
Demonstrated ability to develop, customize, deploy, and maintain and develop business intelligence software.
Practical experience working with and enhancing data warehouses/data lakes.
Experience creating and optimizing data models.
Demonstrated ability to perform, validate and document both ad hoc and automated data analysis and reporting. Ability to apply statistical methods to data sets is a plus.
Curiosity, an analytical mind, and strong problem-solving skills.
Excellent written and spoken communication skills, both technical and non-technical, including the ability to make data and analysis understandable and relevant to a diverse set of audiences.
Assets

If you have experience with any of the following please make sure to highlight it in your cover letter:

Data processing, messaging, and workflow technologies such as Kafka, Map/Reduce, Hadoop, Hive, PrestoDB, Luigi, Airflow, Storm, Argo etc.
Analyzing marketing and sales data
Google Data Studio
PostgreSQL
AWS/data engineering in cloud environments
Kubernetes
Experience working with a wide variety of different data sets using one or more of the common data analysis languages (such as Pandas/Python (preferred), R, Matlab, etc.) as well as spreadsheets and visualization tools (eg. Data Studio, Power BI, etc.)
Open Source projects and culture
Agile processes, including breaking large projects up into smaller stories, estimation, working in branches (GitHub Flow), code review, and CI.
Go, Perl, Python, Tcl, and Ruby



Working At ActiveState

ActiveState has a collaborative, respectful, and professional culture. We’re all about working together to find the best solutions, and making sure that the experience of doing so is positive for everyone involved. There is a commitment from the CEO on down to making work at ActiveState a great experience for all.

Our company is a team of 55+ and growing, with 2/3rds of the positions in technical roles including software development and QA. We maintain a set of core, overlapping hours, but we’re flexible with specific start and end times and are understanding about appointments and life events.

Our vision is to have an ActiveState solution on every device on every planet, so we certainly don’t lack for ambition! But even though we’re ambitious we don’t expect work to become your life. We know you will do your best work in a positive environment free from death marches. For more about working at ActiveState and our Glassdoor rating go to www.activestate.com/careers.




How To Apply

Please submit your contact info, resume, and a cover letter below. Submissions without a cover letter will not be considered. We look forward to hearing from you!

We are committed to creating a welcoming environment for everyone at ActiveState and we welcome applicants from all walks of life.

Even if you don’t feel you meet every exact requirement, we still would love to hear from you and why you think you would be an awesome addition to our team and we encourage you to apply.","PerkinElmer
3.7",Woodbridge
813,"Manager, Data Science - Research & Analytics TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Lead a team of passionate data scientists focused on understanding members’ habits, driving new advanced features in a data-driven manner, and creating member-facing metrics to track their progress and motivate them.
Review the team’s designs, algorithms, and code while also spending time developing your own
Lead the initiative to fully leverage the world's best and largest fitness dataset to derive insights about member's habits and motivations
Work closely and collaborate with a cross functional team of Product Manager, Designers, and Engineers to drive new, innovative, data-driven functionality
Create metrics to motivate members and track their progress
Analyze member behavior and engagement to inform feature roadmap and marketing
Drive direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems
Identify innovative opportunities for new data-driven features

Who You Are

Advanced degree in engineering, scientific, or mathematical field
5+ years data science experience
2+ years leading and/or managing technical teams
Knowledge of machine learning, probability, and statistics
Strong knowledge of Python and SQL
Strong data visualization
Ability and desire to explain complicated concepts simply
Team player with high integrity
Open to feedback and constantly striving to learn and improve
High degree of self-awareness

Extra Credit

Knowledge of Snowflake, DBT, Looker, and Amplitude

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
814,"Director, Data Science Health R&D","Les candidats référés ne doivent pas postuler directement pour ce poste.
Toutes les références de candidats doivent d’abord être soumises dans Workday par un collègue de Loblaw actuel.

Lieu:

1 Presidents Choice Circle, Brampton, Ontario, L6Y 5S5

C’est toute une décision que de se joindre à une entreprise. Nous offrons des perspectives d’emploi à des personnes qui, comme vous, sont travaillantes, dynamiques et fiables.

Pourquoi ce role est-il important?

Are you at the top of your game? Bring your expertise and knowledge to Canada’s largest retailer. We are looking for smart, nice and curious team members to help bring our Data & Analytics game to the next level. This is an exciting time to join our team – we are changing the game in a big way!

If you are looking to join a company that offers unlimited opportunity, excellent leadership, world-class training and makes a big impact on the community – this is the role you’ve been waiting for!

The Data Science Health team is hiring a Director of Research & Development (R&D). The R&D team pursues longer term projects that seek to improve health and wellness of our customers. The team aims to achieve this by developing health-related data products or components that will be eventually integrated into customer or business facing solutions. This role is accountable for establishing a technical program management track and managing partnerships with health business teams and related external partnerships.



The successful candidate must be a proven people lead who is also able to effectively communicate across domain boundaries and build trust with a variety of stakeholders including health business partners, data scientists, engineers and developers.

Refine high level intake and development processes in collaboration with Sr. Director of R&D for delivery of data projects.
Mentor team members on adoption of the above processes and best practices.
Oversea distribution of resources across all active projects.
Foster the development and sustaining of a top performing R&D team through weekly one-on-one sessions with direct reports.
Help team members thrive in their roles by mentoring them and help establish & track their respective development goals.
Establish a Technical Program Management stream within R&D and develop this sub-group by promoting and/or hiring into this role.
Mentor the adoption of project management and reporting practices across the R&D team.
Manage interaction with health partners and ensure all projects are initiated with appropriate problem and scope definition.
Act as a communication bridge between health teams and data science pods to ensure constant alignment of projects with business needs.
Work closely with Sr. Director of R&D to regularly review R&D strategy and maintain alignment with overall business direction.
Work in collaboration Sr. Director of R&D and Data Science Lead to maintain competitive intelligence and identify IP value creation opportunities.

Requirements:

5 or more years of experience leading teams developing health or medical solutions.
Excellent written and oral communication skills.
Design thinking evangelist.
Track record of supporting establishment and leading execution of R&D processes.
Proven track record of transferring technology from research to production.
Passion for the health businesses within Loblaw.
Strong organizational and leadership skills.
Able to build and maintain strong working relationships with internal and external partners using their prior appreciation for the value of “bedside manner.”
Background in data science, machine learning would be considered an asset.
Good financial and business acumen is considered an asset.

#LI-BT

Comment R é ussir:

Chez Loblaw, nous recherchons toujours des personnes formidables pour continuellement renforcer notre culture. Nous croyons que les gens formidables façonnent nos valeurs, sont authentiques, bâtissent la confiance et créent des liens.

Si cela vous ressemble et que vous êtes ouvert d’esprit, que vous avez une bonne attitude face aux changements et que vous aimez les défis d’un environnement de travail aux détails dynamiques, postulez aujourd’hui.

En outre, nous croyons que la conformité aux lois consiste à faire ce qu'il faut. Le respect de la loi fait partie de notre Code de conduite; il renforce ce que nos clients et nos parties prenantes attendent de nous.

Type d'emploi:

Temps plein

Role:

Poste régulier

Loblaw considère que la diversité culturelle du Canada est une source de fierté nationale et un symbole de force. Nous nous sommes donné comme priorité de refléter la diversité croissante du Canada dans les produits que nous vendons, les gens que nous embauchons et notre culture d’entreprise. Des accommodements sont disponibles sur demande pour les postulants et collègues atteints d’un handicap.

Remarque : Si vous avez accès à Libre-service de l’employé (ESS) dans Workday, veuillez postuler à cet emploi en utilisant l’application Workday.","Loblaw Companies Limited
3.6",Brampton
815,"Assistant Scientist II, Bioanalytics","Those who join Emergent BioSolutions feel a sense of ownership about their future. You will excel in an environment characterized by respect, innovation and growth opportunities. Here, you will join passionate professionals who advance their scientific, technical and professional skills to develop products designed-to protect life.

ASSISTANT SCIENTIST II, BIOANALYTICS
12 Month Term

Emergent BioSolutions is currently seeking an Assistant Scientist II, Bioanalytics for our Bioanalytical Sciences Department. The successful candidate will have a university degree or technical diploma in chemistry, biology or in another related field of study, and a minimum of two years of directly related experience. Must have competence in laboratory and scientific practices, the ability to operate common scientific equipment and instrumentation and an understanding of immunology, immunochemistry and molecular biology concepts, statistics, sources of error and reporting of data. In addition, this individual will possess a strong work ethic and a commitment to excellence and innovation.

THE COMPANY

Emergent BioSolutions is dedicated to one simple mission—to protect and enhance life.
As a global specialty pharmaceutical company, Emergent offers specialized products to healthcare providers and governments to address medical needs and emerging health threats.

We value the diversity that each employee brings, and while we look for people who share our Core Values, we thrive on difference as well. With hundreds of talented employees working around the globe, Emergent is a growing organization with a wide variety of scientific, technical and professional career opportunities worldwide.

THE OPPORTUNITY

Develop and qualify/verify/validate/transfer bioanalytical assays to support various functions, such as routine manufacturing, product discovery, proof of concept studies and candidate selection.
Characterize products and impurities to support process/product development, formulation development, licensure, and product investigations.
Support QC labs by: supporting developed assays throughout their lifecycle, trending assay data, and supporting continuous improvement initiatives (where applicable)
Perform GxP compliant testing as required to support manufacturing, product release & stability or nonclinical/ clinical studies.

DUTIES & RESPONSIBILITIES

Participate in the development and/or optimization of bioanalytical methods to support R&D and quality laboratories
Participate in bioanalytical method validations/verifications and transfers, including assisting with authoring of associated protocols and reports
Support quality control laboratories by assisting with assay troubleshooting where required and trending assay data
Support Emergent’s quality culture by: adhering to all effective SOPs and safety requirements, documenting laboratory work consistent with GxP requirements, taking action where deficiencies are found and identifying continuous improvement opportunities
Utilize scientific knowledge to contribute to development projects
Work productively with other team members as well as on independent assignments
Receive and test samples; perform routine laboratory procedures
Make detailed observations, analyze data using appropriate statistical techniques (where applicable), report data as appropriate and interpret results
Maintain laboratory records and inventory for supplies and reagents
Perform preventative maintenance on laboratory equipment
Maintain up-to-date knowledge on bioanalytical / laboratory / scientific methodologies and techniques
Maintain a clean and sanitary work area in accordance with standard laboratory practice and procedures

The above statements are intended to describe the general nature of work performed by those in this job. It is not an exhaustive list of all duties, and other duties may be assigned.

EDUCATION, EXPERIENCE & SKILLS:
EDUCATION:
University degree or technical diploma in chemistry, biology or related field of study

EXPERIENCE:
Minimum of two years directly related experience in a recognized professional or technical/scientific field. Experience in a pharmaceutical cGMP environment is an asset, but is not required.

KNOWLEDGE, SKILLS & ABILITIES:
Competence in laboratory and scientific practices, including maintaining sufficiently detailed and compliant laboratory records.
Ability to operate common scientific equipment and instrumentation (e.g. spectrophotometer, centrifuge, biological safety cabinet)
Understanding of immunology, immunochemistry and molecular biology concepts, statistics, sources of error and reporting of data
Basic knowledge of analytical method validation
Skill in interpretation of data to support research and development work
Skill in communication of information in both written and verbal forms.
Strong organizational and interpersonal skills; can work collaboratively with others.
Basic knowledge of Microsoft Office - Word, Excel
Basic knowledge of pharmaceutical GLPs and GMPs
Knowledge of general laboratory techniques and chemical and biological safety practices
Working knowledge of how to interpret/use information derived from hazardous product regulations that include WHMIS 2015 (GHS) and Canadian BioSafety Standard(s)

ADDITIONAL REQUIREMENTS:
Citizenship/Permanent Resident or Valid Work Permit.
Successful Completion of a Criminal Record Check.
Medical assessment required for this position.

Interested? Please visit www.emergentbiosolutions .com under the career section to apply today!

As part of our team, you'll join talented and inspiring colleagues whose sense of purpose complements your own. We offer highly diverse career opportunities, a supportive culture, competitive salaries, flexible work arrangements and an extensive benefits package. Information submitted will be used by Emergent BioSolutions for activities related to your prospective employment. Emergent BioSolutions respects your privacy and any use of the information submitted will be subject to the terms of our Privacy Policy .","Emergent Biosolutions
3.3",Winnipeg
816,Data Engineer (Ingestion),"Data Engineer - Ingestion


Location: Toronto


Are you ready to step up and take your technology expertise to the next level?


There is never a typical day at Accenture, but that’s why we love it here! This is an extraordinary chance to begin a rewarding career at Accenture Technology. Immersed in a digitally-compassionate and innovation-led environment, here is where you can help top clients shift to the NEW using leading-edge technologies on the most ground-breaking projects imaginable. Immerse yourself in a supportive ecosystem that values your individuality and encourages you to innovate, ideate and disrupt. We recognize that it's the diversity of our people that makes us stronger, smarter and more effective as a team.


We are Accenture Cloud First


Accenture is a leader in cloud transformations working with AWS, Azure, Google, and private clouds. The formation of Accenture Cloud First, with a $3 billion investment over three years, demonstrates our commitment to deliver greater value to our clients when they need it most. Our Cloud First multi-service group of more than 70,000 cloud professionals delivers a full stack of integrated cloud capabilities across data, edge, integrated infrastructure and applications, deep ecosystem skills, culture of change along with a deep industry expertise to shape, move, build and operate our clients’ businesses in the cloud. To accelerate our clients’ transformation leveraging cloud, we combine world-class learning and talent development expertise; deep experience in cloud change management; and cloud-ready operating models with a commitment to responsible business by design — with security, data privacy, responsible use of artificial intelligence, sustainability and ethics and compliance built into the fundamental changes Accenture helps companies achieve. Our services cover the full spectrum of client needs, from strategy to service management, device-to-cloud networks, workplace solutions, and more.

Today, more than ever, companies need to operate and compete at an unprecedented speed and scale as industries are reshaping beneath them. This means innovating faster, creating new revenue streams, deriving more insights from data - and from the edge - and interacting differently with their customers, partners, and employees. Choose Accenture and make delivering this kind of innovative work part of your extraordinary career.


The Work


Accenture’s Cloud First Infrastructure Engineering professionals’ partner with our clients to advise, create, and deploy end-to-end infrastructure transformation solutions, enabling business innovation. These solutions are the backbone of driving IT-enabled differentiation. IE professionals are grounded in New-IT with an expertise in one or more of our core practice areas: Digital Workplace, Network Technology, Service Management, Hybrid Cloud, Public Cloud, and traditional Data Center.


Key Responsibilities:


Application Design, Development and Support for Azure Data and AI Data analytics Platform
Involved in designing and developing new solutions
Lead the effort to design, build and configure applications, acting as the primary point of contact.
Lead team for Azure Databricks, Azure Data Lake, ADB, PySpark and Synapse
Responsible for Application Support and lead the role with offshore & on-shore teams
Co-ordinate with the client resolving issues, implementing enhancement, and troubleshooting issues to come up with recommendations for the client



Who are we looking for?

3 year of experience in the following:

Azure Data Factory
PySpark
Azure SQL
Azure Data Lake

Preferred Skills:

Certification: Azure Data Certification

Python","Accenture
4.1",Mississauga
817,CT Data Engineer,"EY is a global leader in assurance, tax, transaction and advisory services. Technology is at the heart of what we do and deliver at EY. Technology solutions are integrated in the client services we deliver and are key to our innovation as an organization.




Fueled by strategic investment in technology and innovation, Client Technology seeks to drive growth opportunities and solve complex business problems for our clients through building a robust platform for business and powerful product engine that are vital to innovation at scale. As part of Client Technology, you’ll work with technologists and business experts, blending EY’s deep industry knowledge and innovative ideas with our platforms, capabilities, and technical expertise. As a catalyst for change and growth, you’ll be at the forefront of integrating emerging technologies from AI to Data Analytics into every corner of what we do at EY. That means more growth for you, exciting learning opportunities, career choices, and the chance to make a real impact.




The project




This open role is for an integrated data platform that allows different service lines to perform various data management activities including onboard data, perform data ingestion, data processing, mapping to centralized taxonomy and then consume data for their respective product offering needs to support their clients. There is also potential to collaborate on additional platforms and offerings within the Client Technology group.




The selected candidate




Leads the delivery of processes to extract, transform and load data from disparate sources into a form that is consumable by analytics processes, for projects with moderate complexity, using strong technical capabilities
Designs, develops and produces data models of relatively high complexity, leveraging a sound understanding of data modelling standards to ensure high quality
Builds networks with other departments across the business to help define and deliver business value, and may interface and communicate with program teams, management and stakeholders as required to deliver small to medium-sized projects
Applies advanced big data concepts to ingest, process and transform data and store data in variety storage technologies
Applies Graph and AI/ML to data and data components supporting business requirements



Your key responsibilities include




Leading the production of high-quality data engineering deliverables, helping to ensure project timelines are met, and providing informal mentoring / training to junior members of the team
Leading the delivery of data quality reviews including data cleansing where required to ensure integrity and quality
Leading the delivery of data models, data storage models and data migration to manage data within the organization, for a small to medium-sized project
Resolving escalated design and implementation issues with moderate to high complexity
Analyzing the latest industry trends such as cloud computing and distributed processing and beginning to infer risks and benefits of their use in business
Providing technical expertise to maximize value from current applications, solutions, infrastructure and emerging technologies and seek to continuously improve internal processes
Developing working relationships with peers across other engineering teams and beginning to collaborate to develop leading data engineering solutions
Driving adherence to the relevant data engineering and data modelling processes, procedures and standards



Skills and attributes for success




Batch and Event Processing - Capability to design an efficient way of processing high volumes of data where a group of transactions is collected over a period of time or on an event driven method
Data Integration (Sourcing, Storage and Migration) - Capability to design and implement models, capabilities and solutions to manage data within the enterprise (structured and unstructured, data archiving principles, data warehousing, data sourcing, etc.). This includes the data models, storage requirements and migration of data from one system to another
Data Quality, Profiling and Cleansing - Capability to review (profile) a data set to establish its quality against a defined set of parameters and to highlight data where corrective action (cleansing) is required to remediate the data
Data Services - Experience building data services with asynchronous calls to data sources. Using functional and reactive programming features in modern java and open source libraries



Intermediate understanding of the following tools and technologies, and how to apply them to solve business problems




Essential:




Experience with Spring Boot, Spring Cloud, Kafka, EventHub
Good knowledge of Docker / Containers and Event Driven Architectures
Expertise with Azure functions, Azure Key Vault integration, Azure blob storage configurations
Hands-on experience with Azure Databricks, Delta Lake, Azure Functions, Azure Data Factory
Hands-on experience in developing AI/ML algorithms to detect data anomalies and patterns using Python, R and similar technologies
Expertise with Graph Databases - Azure Cosmos/Gremlin, Neo4j, Spark GraphFrames
Expertise in NoSQL Databases – CosmosDB, MongoDB
Expertise in index, search and exploration using Elastic
Hands-on experience with Programming Languages – Java, Node.js, Python, R, SQL, XML
Relational SMP Databases – Azure SQL PaaS, PostgreSQL, Synapse



Nice to have:




APIGEE, AKS
Azure Cognitive Services, Databricks MLFlow is a big plus
Elasticsearch, Kibana



Education




B.S. in Actuarial, Behavior Economics, Computer Science, Data Analytics, Data Science, Econometrics, Engineering, IT, Cyber Security, or related field preferred



What we look for




Strong analytical skills and problem-solving ability
A self-starter, independent-thinker, curious and creative person with ambition and passion
Excellent inter-personal, communication, collaboration, and presentation skills
Customer focused
Excellent time management skills
Positive and constructive minded
Takes responsibility for continuous self-learning
Takes the lead and makes decisions in critical times and tough circumstances
Attention to detail
High levels of integrity and honesty



What working at EY offers




We offer a competitive remuneration package where you’ll be rewarded for your individual and team performance. Our comprehensive Total Rewards package includes support for flexible working and career development, and with FlexEY you can select benefits that suit your needs, covering holidays, health and well-being, insurance, savings and a wide range of discounts, offers and promotions. Plus, we offer:




Support, coaching and feedback from some of the most engaging colleagues around
Opportunities to develop new skills and progress your career
The freedom and flexibility to handle your role in a way that’s right for you



EY is committed to being an inclusive employer and we are happy to consider flexible working arrangements. We strive to achieve the right balance for our people, enabling us to deliver excellent client service whilst allowing you to build your career without sacrificing your personal priorities.




About EY




As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime.




If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible.




Make your mark.




Apply now.","Ernst & Young
3.8",Midtown Toronto
818,Senior Applied Scientist,"PhD degree with 4 years of applied research experience or a Masters degree and 6+ years of experience of applied research experience
3+ years of experience of building machine learning models for business application
Experience programming in Java, C++, Python or related language
Amazon's Sponsored Products advertising business is one of the fastest growing areas in the company. Have you ever wondered what happens behind that “Sponsored” label you see on Amazon? The Sponsored Products Marketplace team creates and optimizes the systems that match advertiser demand (ads) with page supply (placements) using a combination of data-driven product innovation, machine learning, big data analytics, and low latency/high-volume engineering. By the time organic search results are ready, we've processed all of the candidate ads and determined which ones are delivered to the page. We do that billions of times per day, resulting in millions of engagements with products that otherwise might not have been seen by shoppers. The business and technical challenges are significant. Fortunately, we have a broad mandate to experiment and innovate, and a seemingly endless range of new opportunities to build a big, sustainable business that helps Amazon continuously delight all of our customers.

We're looking for an innovative and customer-obsessed Sr. Applied Scientist who can help us take our products to the next level of quality and performance by creating state-of-the-art models to improve our ability to predict entity relationships, forecast the impact of advertiser actions, and optimize ad selection for different contexts. We embrace leaders with a startup mentality -- those who have a disruptive yet clear mission and purpose, an unambiguous owner's mindset, and a relentless obsession for delivering amazing products.

As Sr. Applied Scientist on the Product Targeting team, you will work alongside business leaders, other scientists, and software engineers to deliver recommenders and forecasters based on ML, DL, and RL from idea to production. You will be responsible for bridging the experimental domain with the production domain by building robust and efficient computational pipelines to scale up models, keeping the models fresh, and ensuring that real-world corner cases are handled correctly. You'll own significant products and features from inception through launch, and will work with Product Managers, other Scientists, and Engineers to make your efforts wildly successful. You will lead the science program for our team, providing input to strategic decision making on topics such as program direction/vision, roadmap, and staffing. If this sounds like your sort of challenge, read on.

Characteristics indicative of success in this role:

Highly analytical: You solve problems in ways that can be backed up with verifiable data. You focus on driving processes, tools, and statistical methods which support rational decision-making.
Technically fearless: You aren't satisfied by performing 'as expected' and push the limits past conventional boundaries. Your dial goes to '11'.
Engaged by ambiguity: You're able to explore new problem spaces with unique constraints and non-obvious solutions.
Team obsessed individual contributor: You help grow your team members to achieve outstanding results. You've learned that big plans generally involve collaboration and great communications.
Quality obsessed: You recognize that professional scientists build high quality model development and evaluation frameworks to ensure that their models can provably meet launch criteria, or efficiently iterate in the framework until they do.
Humbitious: You’re ambitious, yet humble. You recognize that there’s always opportunity for improvement. You use introspection and feedback from teammates and peers to raise the bar.
Primary Responsibilities:

Apply machine learning and analytical techniques to create scalable solutions for business problems
Work closely with software engineering and product teams across the organization to drive model implementations and new feature creations
Work closely with business stakeholders to identify opportunities for current model improvements and new models to significantly benefit the business bottom-line
Collaborate with scientists within the Ads organization as well as other parts of Amazon to share learnings move the state-of-the-art forward
Establish scalable, efficient, automated processes for data analyses, model development, model validation and model implementation
Research and implement novel machine learning and statistical approach
Impact and Career Growth
You will invent new shopper and advertiser experiences, and accelerate the pace of Machine Learning and Optimization.
Influence customer facing shopping experiences to helping suppliers grow their retail business and the auction dynamics that leverage native advertising, this role will be powering the engine of one the fastest growing businesses at Amazon.
Define a long-term science vision for our ad marketplace, driven fundamentally from the needs of our customers, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams.
This is a role that combines science leadership, organizational ability, technical strength, product focus and business understanding.

Why you love this opportunity
Amazon is investing heavily in building a world class advertising business and we are responsible for defining and delivering a collection of self-service performance advertising products that drive discovery and sales. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative and fun-loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities.

Team video ~ https://youtu.be/zD_6Lzw8raE


Strong publication record with novel research contributions
Proven success in applying ML/DL/RL models to practical problems
Experience with with any of: NLP, transfer learning, BERT, pair modeling, topic modeling, similarity, relevance.
Expertise in working with big-data in map/reduce setting using Spark, EMR, Pig, etc.
Experience with AWS and data-oriented tools such as Sagemaker, Airflow, ElasticSearch, Airflow, etc.
Experience in online advertising domain (particularly, ad targeting and serving) is a big plus.
Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/ontario

#sspajobs #spmpjobs #sptargjobs","Amazon Dev Centre Canada ULC
3.8",Midtown Toronto
819,Data & AI Strategy Senior Manager,"We are:

Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Accenture Applied Intelligence

Join Accenture Digital and leave your digital mark on the world, enhancing millions of lives through digital transformation. Where you can create the best customer experiences and be a catalyst for first-to-market digital products and solutions using machine-learning, AI, big data and analytics, cloud, mobility, robotics and the industrial internet of things. Your work will redefine the way entire industries work in every corner of the globe.

You are:

As a Senior Manager in our practice you will help shape and sell industry specific programs, including definition of the analytics/AI vision and strategies, redefine operating model and talent strategy, and help guide clients through their data and analytics journeys to deliver sustainable business value. You will act as the architect for our most transformative opportunities, enabling an end-to-end analytics journey by bringing the best of our Accenture Applied Intelligence organization. You will also play a key role on the leadership team – building a practice, assets, and thought leadership.

The work:

1. Support Applied Intelligence Consulting activities:

Lead complex analytics transformation projects from defining the strategy, operating model, value targeting, proof of value and change management to enable data, analytics and AI capabilities and outcomes
Work with our Canadian Innovation Hub to plan and define immersion sessions in core analytic and digital capabilities specific to client needs

2. Sales Origination & Business Development

Educate internal Accenture stakeholders about our Analytics offerings and applicability to their industry/clients
Facilitate the development of “request for proposals” responses and contract development
Lead the development of businesses cases for further project sales as determined by the practice

3. Practice & Offering Management

Shape assets to accelerate sales and delivery
Drive the analytics innovation agenda, including publishable thought leadership
Play an active role building a practice including capability development and recruiting
Identify and help bring into the practice talented individuals both internally from Accenture as well as externally



Qualifications:

Here’s what you need:

A Bachelor’s degree in a quantitative field like statistics/econometrics/mathematics/engineering/computer science
10+ years of consulting experience or relevant industry experience with proven track record of making significant client impact and value creation
Industry and/or industry domain specific experience delivering data-driven capabilities and solutions
Experience in designing and utilizing analytic solutions in enterprise-wide organizations
Superior understanding of how to manage client relationship, deliver analytics value, and influence senior clients to define and expand data-driven strategies into new applications and markets
Relevant experience could include one or more of the following:
Marketing and Customer Experience analytics
Pricing and Revenue Management / Optimization
Personalization and Loyalty
Selling Strategies and Merchandising
Distribution & Channels
Operational Effectiveness (workforce, crew, fuel, supply chain, etc.)
Compliance, Risk and Fraud prevention
Ability to travel and work in Canada

Bonus points if:

Fluency in French language is a great to have.
Strong Data Management and Data Governance background
Strong cloud background in delivering data-driven solutions on Azure, AWS and/or GCP
Exceptional presentation skills – ability to convey technology and business value propositions
Proven industry knowledge and experience delivering data, analytics and AI solutions driving business outcomes
Experience interacting with clients or executives of all levels to review expected outputs, applicability to business challenges, and value measurement
Well versed with leading analytics techniques and confident about how to apply them to generate insights and recommendations
Experience guiding the data formulation process and exploratory data analysis
Experience guiding and managing a team of practitioners to execute data and analytics solutions, preferably both onshore and offshore
Evidence of thought leadership in defining innovative analytics within multiple complex applications spanning marketing, risk, and cost reduction","Accenture
4.1",Montreal
820,Senior Optical Engineer or Optical Scientist,"Senior Optical Engineer or Optical Scientist




About Metamaterial Inc.

META delivers previously unachievable performance, across a range of applications, by inventing, designing, developing, and manufacturing sustainable, highly-functional materials. Our extensive technology platform enables leading global brands to deliver breakthrough products to their customers in consumer electronics, 5G communications, health and wellness, aerospace, automotive, and clean energy. META’s achievements have been widely recognized, including being named a Global Cleantech 100 company. Learn more at www.metamaterial.com.




About the role

We are seeking a Senior Optical Engineer or Optical Scientist for our facility in Dartmouth, Nova Scotia. You will be a key member of the Optics team that develops new technologies and products for applications in augmented reality and scientific instruments. Your role will be to develop concepts and hardware for prototyping and manufacturing new optical devices based on holographic elements. You will be working hands-on within a diverse, multi-disciplinary team to develop holographic optical elements for high performance imaging systems. The ideal candidate has extensive experience developing new concepts for optical systems matched with the practical skills to bring them to life.




Responsibilities

Provide expert level optical engineering expertise towards the development of holographic optical components and sub-systems for HMD, HUD and scientific instrument applications.
Lead hands-on assembly, testing and debugging of custom hardware systems for development and manufacturing.
Work with internal and external stakeholders to develop product concepts and designs that address market needs.
Characterize the performance of optical products relative to the design goals; design and construct the necessary metrology systems.
Identify causal relationships between observed product performance and the design parameters.
Monitor and communicate to the team industry development and trends.
Communicate results through technical reports and presentations tailored to the needs of the target stakeholders.
Supervise junior members of the engineering team.



Required Skills and Experience

Hands-on experience implementing and testing optical devices and systems, particularly holographic devices.
Extensive experience constructing and validating models of optical devices and sub-systems.
Experience in process control, data acquisition, and data analysis in Python (preferred) or Matlab, R or Julia.
Proficiency with optical design tools and modelling methods (e.g. Zemax, VL Fusion, Comsol, Lumerical).
Excellent written, verbal and presentation skills.



Qualifications

An MSc or PhD in Physics, Applied Physics, Optics, EE, or related field, is required.
Minimum 5 years of experience with optical engineering and/or applied optics, with industrial experience developing products based on new technologies.



Professional Standards and Performance Review: As an experienced professional, the Senior Optical Engineer or Optical Scientist will maintain high professional standards and act in accordance with best practice. They will support the development of the professional standards of the team and take a continuous approach to improvement and their own personal development. As a representative of the Company, the Chemistry Laboratory Manager will act in line with the Company Code of Conduct and will participate in the performance review process.","Metamaterial Inc.
4.1",Dartmouth
821,Big Data Engineer 9+Yr Exp Canadian Citizen or PR,"Position/Title: BigData Engineer

Location: Brampton

Rate: $/hr

Client- COGNIZANT

· BigData ( Python & Spark & AWS - 8 to 10 years)

· specializing in software products services and technology

· Developing features using serverless technologies like AWS Lambda, Glue, EMR

· Developing Big Data pipeline using AWS technologies like Kinesis, SQS, SNS and so on

· Development of batch and real time processing jobs using Apache Spark and Java/Python

· Development of complex features using BigData Technologies which includes doing impact analysis, design, and development.

· Work effectively in a fast paced and dynamic environment

· Communicate effectively with all stakeholders

Must Have:

· BigData application/data pipeline Development experience using PySpark and following

· AWS technologies: Lambda, API Gateway, Glue, EMR, ECS, Kinesis, SQS, SNS, RDS,

· DynamoDb, Cognito, Redshift

· Experience in Databricks

· Language: Core Java/Python

· Tools: Maven, GIT

· OS: Linux

Good to have:

BigData skills: Hadoop, Kafka, Apache Spark (Spark Streaming, Spark Batch), Hive, SQL, HBase/Cassandra, Kubernetes, Redshift

Regards,
Sayyad Ashraf Parvez
Email: ashrafatcompestsolutions.com
D: 647-660-7562 ext 412
Web Site : www.compestsolutions.com

Reference ID: 210010

Job Types: Contract, Permanent

Salary: $80,031.00-$100,000.00 per year

Schedule:

8 hour shift

Work remotely:

Yes","Compest solutions Inc.
4.6",Brampton
822,Ingénieur·e de données /Data Engineer,"Qui sommes-nous :

BusPatrouille est une entreprise spécialisée dans la technologie de sécurité. À titre de principal fournisseur international de dispositifs visant à faire respecter le bras d’arrêt des autobus scolaires, notre mission principale est d’améliorer la vie des élèves où qu’ils se trouvent.

La technologie de BusPatrouille a été déployée sur un plus grand nombre d’autobus et a été utilisée pour délivrer un plus grand nombre de contraventions relatives au bras d’arrêt des autobus scolaires que toute autre technologie des autres entreprises existantes à l’échelle mondiale. Notre technologie exclusive transforme les autobus scolaires en autobus intelligents équipés de caméras vidéo, de GPS, de télémétrie, de traitement de données et d’archivage. De cette manière, nous permettons aux comtés et aux districts scolaires d’améliorer la sécurité des enfants.

BusPatrouille est en pleine croissance. Nous sommes donc à la recherche d’un.e ingénieur.e de données d’expérience pour intégrer notre équipe de veille stratégique (BI). Si vous aimez travailler dans un environnement dynamique avec des collègues talentueux, ce poste est pour vous.

Responsabilités :

Le rôle de l’ingénieur.e de données est essentiel pour construire des données évolutives et des modèles analytiques, ainsi qu’une architecture allant de la formation à l’ingestion d’événements, puis à la production de rapports, en partant du début. Vous évaluerez et soutiendrez la mise en œuvre de systèmes robustes utilisés par chaque équipe et client de BusPatrouille. La personne idéale possède de solides connaissances en gestion des données, en développement ETL (extraire, transformer, charger), en codage et en infonuagique. Elle aime travailler avec une diversité d’outils, de langages, de systèmes et d’architectures tout en s’assurant que les systèmes de données et la stratégie respectent les meilleures pratiques en matière d’évolutivité.

Rédiger des tâches ETL (extraire, transformer, charger) et ELT (extraire, charger, transformer) à l’aide de divers outils et langages de programmation.
Créer des pipelines de données dans des environnements AWS avec AWS glue.
Écrire des requêtes SQL complexes et optimiser leur vitesse et leur précision.
Concevoir, développer, tester, corriger et déployer des pipelines de données en soutien aux produits de base, aux déploiements auprès des clients et aux rapports de performance.
Écrire des scripts pour planifier l’ingestion et la synchronisation des données.
Développer des minientrepôt de données (data marts) à partir des besoins de l’entreprise pour permettre aux parties prenantes de l’entreprise d’être autonomes.
Créer et tenir à jour une documentation claire.
Travailler avec des collègues ingénieur.e.s, des chefs de projet et des utilisateurs.
Suivre les processus et les procédures de l’entreprise, en particulier les pratiques relatives à la sécurité de l’information.

Connaissances et compétences requises :

Un baccalauréat ou un diplôme supérieur en technologie, dans un domaine quantitatif ou dans un autre domaine connexe (par exemple, informatique, statistiques, génie électrique).
Plus de cinq ans d’expérience en ingénierie des données, ingénierie des bases de données ou analyse commerciale.
Plus de cinq ans d’expérience avec SQL (MySQL, PostgreSQL, Redshift).
Plus de quatre ans d’expérience avec les principaux langages de script tels que Python.
Plus de trois ans d’expérience dans la conception de schémas, la modélisation de données dimensionnelles, la conception d’API et le développement de services Web RESTful.
Une expérience de la visualisation de données (par exemple avec Tableau) est un atout.
Une curiosité intellectuelle, une volonté constante d’apprendre, un esprit d’initiative.
De solides compétences en communication écrite et verbale.
Un esprit d’équipe.

Rémunération et avantages :

Un salaire concurrentiel.
Des avantages sociaux complets, notamment une assurance soins médicaux, soins dentaires et soins de la vue.
Un poste indispensable au sein d’une entreprise qui se développe rapidement et qui est investie d’une mission.
L’occasion de travailler avec une équipe très performante.
L’occasion de contribuer à la création d’une entreprise vouée à la sécurité des enfants.

Nous sommes à la recherche de membres essentiels de l’équipe de BusPatrouille qui nous aideront dans notre quête pour accroître la sécurité des enfants. Ce poste joue un rôle important dans notre entreprise et constitue une formidable opportunité pour les personnes qui seront retenues. Nous offrons un milieu de travail inclusif, diversifié, enthousiaste, intègre et profondément engagé. Venez nous aider à assurer la sécurité des enfants.

=========================================================================

Who We Are:

Our mission is to create a culture of responsibility and awareness on the road. We are devoted to making the journey to and from school safer. We develop partnerships, deploy safety tech and manage the entire program. We have equipped thousands of busses across North America with our innovative technology and we continue to educate tens of thousands of drivers a month on safety. BusPatrol America cares about student safety. We educate motorists every day by helping enforce the law and work with school officials to improve safety.

The Role:

The Data Engineer at BusPatrol will build scalable data and analytics models and architecture from event formation to ingestion to reporting, from scratch. You will evaluate and lead the implementation of robust systems used by every team within BusPatrol. You will shape the vision and architecture of end-to-end pipeline while following industry best practices. The right candidate will have strong data architecture, ETL, SQL, and a proven track record working with enterprise metrics to build automated data pipelines. The candidate will also have strong operational skills to drive efficiency and speed, expertise in building repeatable data engineering processes, strong project management skills, and a vision for how to deliver data products.

Responsibilities:

Create data pipelines in state-of-the-art AWS environment EC2, S3, Lambda, etc. with AWS Glue.
Manage all aspects of the data and analytics system from stream configuration to ETL to aggregate tables and cubes for reporting needs.
Identify, design, and implement internal data pipeline jobs / processes improvements using machine learning (and other modern techniques): automating manual processes, optimizing data delivery, re-designing infrastructure for scalability, etc.
Write scripts to schedule data ingestion and syncing. Evaluate, lead and form backend logic to create data marts from requirements for the purposes of self-serving stakeholders.
Assist data architects to build the working framework for data search and retrieval.
Troubleshoot data jobs / processes in production to fix data quality bugs or pipeline performance issues.
Build and assemble large, complex data sets with multi-dimensional relationships that meet both functional and non-functional requirements from business stakeholders.
Build Appropriate ML data models and data schemas for business use cases.

Requirements:

Bachelor's degree or higher in a quantitative/technical field (e.g., Computer Science, Statistics, Engineering)
5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics
5+ years of SQL knowledge for various reporting and transformation needs (MySQL, PostgreSQL, Redshift)
4+ years of experience in core languages such as Python
3+ years of experience with schema design and dimensional data modeling
Experience with Data Lake architectures, and with combining structured and unstructured data into unified representations.
Experience with API design and development of RESTful web services
Hands on experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.
Analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions.
Data visualization experience with tools like Tableau a plus
Must be an intellectually curious self-starter and motivated to continually learn.

What we will offer you

The opportunity to join a mission-driven company, dedicated to developing and deploying safety technology in support of children’s safety
The opportunity to build an IT infrastructure group in support of our mission
Dedicated, accessible and committed colleagues and leadership team
The chance to join an innovative and dedicated team, focused on leading edge technology
Competitive salary and benefits package

We’re looking for critical members of the BusPatrol team to assist us in our quest to improve children’s safety. This is an important role for us and a great opportunity for the right candidates. Our environment is inclusive, diverse, ignited, built on integrity and deeply committed. Come and help us keep our children safe.

Type d'emploi : Temps Plein","BusPatrol
3.8",Montreal
823,Data Analytics Consultant - Contractor,"Data Analytics Consultant - Contractor - Customer 360 Analytics

The TELUS Business Marketing Team is looking for a talented, driven, passionate individual with strong analytical and interpersonal skills. Our Team – TELUS Business Solutions Marketing BI - has a mandate to build solutions for our stakeholders using data from various sources, building algorithms that can predict customer loyalty, churn and stickiness. We love to turn data into stories - stories about money falling through the cracks, success stories about our products and services, but most importantly stories about our customers and how we can enhance their experience. We run like a start-up and we have embraced lean and agile methodologies. We celebrate our failures and see them as opportunities to learn. Our culture fosters collaborative learning and out-of-the-box thinking in a relaxed environment. Come help us to make something awesome!

Candidates are able to communicate with business stakeholders, gather requirements, develop, design and implement reporting solutions in an agile-type environment. They must be able to shift effortlessly between business conversations about performance analytics and technical conversations around databases, SQL and Domo with their stakeholders and peers. A successful candidate has strong business analysis, problem solving and critical thinking skills.

Candidates must be comfortable working within a dynamic, cross-functional environment and be able to explain complex concepts, performance reporting methodologies, and analysis results to a diverse stakeholder community. You must be willing to roll up your sleeves and get close to the data.

Here's the impact you'll make and what we'll accomplish together:

You will be successful because you have an optimal mix of business and technical skills honed in a high performance driven business. You would be working with Data Scientists, Engineers and Analysts to help build trigger based B2B campaigns to target the right customer at the right time with the right product.

You have a passion for growing our business, the courage to innovate and embrace change in our business intelligence capabilities and embody the spirited teamwork necessary to support stakeholders across a wide variety of teams.

Here's how

You will:

Develop new analytical solutions to provide timely insights to the business
Assemble multiple data sources across various databases to build foundational C360 data marts
Build repeatable processes and automation to create standardized datasets, reports and analysis
Implement business intelligence and rules, optimize data processes and perform data quality audits
Proactively work with business stakeholders, manage relationships and lead marketing programs from a data standpoint
Effectively communicate with leadership and stakeholders
Lead Customer 360 programs, coach and mentor junior team members

You are the missing piece of the puzzle if:

You love digging into quantitative and qualitative data; you analyze it, pivot it and distill issues to their core to provide the best possible performance reports and channel insights
You have expert knowledge and understanding of global best practices in business intelligence tools (e.g. Python, R, SAS,DOMO, SQL, Tableau)
You have advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
You are recognized for your curiosity and growth mindset
You see the bigger picture of the problem you are trying to solve, and will proactively out new data points from varied sources (external and internal) to complement your analysis
You have excellent attention to detail, a structured approach to analysis and the ability to develop logical arguments
You have minimum 4-7 years of experience in a similar role and/or related education with demonstrated performance

Great-to-haves

Prior telecommunications expertise
Python experience
Hive, Spark, NiFi experience
B2B marketing
Experience with cloud (GCP AWS or Azure)
Experience with the Salesforce tech, i.e., marketing cloud, Pardot, Einstein
Data Science / Modeling experience or working in a Data Science team

Contract would be until 31st Dec 2021,with a high possibility of extension.

Other Locations : Alberta, British Columbia, Quebec","TELUS
3.9",Midtown Toronto
824,Senior Data Analyst,"WHAT DOES IT MEAN TO WORK AT ESG?

We are East Side Games - a pillar in beautiful Vancouver’s gaming community. Our mission is to create games that are easy to pick up, hard to put down, and don’t suck! We put players at the heart of our evolution, independence, and profitability. With their help, we’ve defined the narrative idle gaming space with huge brands that reach the lives of millions globally... And we’re just getting started!

Culture rules here, and that’s what makes us unique. We put people at the core of what we do. We believe that you can steer the ship of your career, and we anchor through support, trust, and connection. Tackle your challenges, share your learnings, then share a drink with the studio in our weekly Cheers Friday Announcements. Have we piqued your curiosity? Then check out our amazing Culture and Benefits!

WHAT IMPACT CAN A LEAD DATA SCIENTIST HAVE AT ESG

At East Side Games, we all band together to deliver a world-class gameplay experience for our players around the globe. Whether that’s working on Archer: Danger Phone, or on any of our other current or upcoming titles, you’re committed to making memorable player experiences. Everyone has an impact here. As a Senior Data Analyst, you create actionable insights from the data we collect that directly leads to product improvements within our IdleKit team. Through a deep understanding of our player’s behaviour, you’ll work on building dashboards, reports, and predictive models that ultimately lead to a world-class game experience our players cherish.

What is IdleKit?

IdleKit is East Side Games core technology platform that enables our internal games and external partnership games. The IdleKit team operates as an independent business unit that productizes our platform and actively publishes new games under the East Side Games brand.

We’re a remote-first studio and encourage all applications.

WHAT YOU MIGHT DO IN YOUR DAY TO DAY

Formulate hypotheses and run a variety of A/B tests to determine the best strategies to implement into our products.
Work with external partner studios to create balance changes and features that will improve target metrics.
Evaluate and explore opportunities in our games and operations, through detailed querying and analysis of our data.
Be a key bridge between data, game design, and the business through the creation of reports and dashboards, helping to illustrate the ongoing story told by our data.
Build partnerships with each team member, sharing the tools and insights that predict and improve retention and monetization within our products.
Continuously improve, maintain, and develop our analytics tools and predictive models for our games.


WHAT YOU BRING TO ESG

A bachelor's degree in mathematics, statistics, computer science, economics, or a related quantitative field and/or a graduate degree in data science or business analytics.
At least four years prior experience as a data analyst/scientist, preferably in the F2P mobile gaming space.
Expert level knowledge of SQL (e.g., window functions), Tableau (or similar), and proficiency with at least one scripting language (e.g., R, Python).
Ambition to own and take ownership of the reporting and analysis functions for our games.
The ability to tell a convincing story with data.
An innate curiosity and ability to mine large complex data sets and build predictive models that lead to meaningful conclusions.
Previous experience A/B testing and calculating statistical significance within a big data context (e.g., bootstrapping, permutation testing).
Strong written and oral communication skills.
Prior management experience is a huge plus.


YOU ARE:

Hungry, humble, and smart and can use these three pillars to impact you and those around you.
A mobile game fanatic. You are on top of the latest games, trends, and what’s happening in live events.
Entrepreneurial, self-motivated, and have the attitude to get things done.
A risk-taker, and gain your biggest learnings through them.
Empathic, compassionate, and curious.
Solution-oriented and data-driven.
Comfortable in an environment where priorities and plans can change rapidly.


WE’RE BUILT ON THE FOUNDATIONS OF DIVERSITY AND INCLUSION

East Side Games are an equitable employer that values justice, equity, diversity and inclusion. We welcome and encourage people of marginalized backgrounds, particularly QTBIPOC folks, to apply, and will acknowledge and value the strengths you bring to foster yours and the studio’s growth.

If this sounds like something you hoped for and more, and you’re enthused to build genre-defining narrative idle games, click the “Apply Here” button below. If now is not the right time for you but you know someone who would be a great match for us at East Side Games, check out our referral bonus here! Let’s build great games together


We can’t wait to hear from you!




oKAdDf8gPs","Eastside Games
4.0",Remote
825,Senior Data Engineer (Azure),"About antuit.ai

Antuit.ai is the leader in AI-powered SaaS solutions, empowering world-class Consumer Products and Retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. Antuit.ai's executives, comprised of industry leaders from SAP, SAS, IBM, and Accenture, and our team of Ph.Ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. Antuit is funded by Goldman Sachs and Zodius Capital.

The Role:

Antuit.ai is interested in hiring a Senior Data Integration Engineer to work closely with clients and the product engineering and AI teams to create data pipelines to support data-driven AI-based cloud applications.

A Senior Data Integration Engineer will be responsible for understanding the client's technical requirements, design and build data pipelines to support the requirements. In this role, the Sr. Data Integration Engineer, besides developing the solution, will also oversee other Engineers' development.

The successful candidate will have strong verbal and written communication skills and effectively communicate with the client and internal team. A strong understanding of databases, SQL, cloud technologies, and modern data integration and orchestration tools like Azure Data Factory (ADF), Informatica, and Airflow are required to succeed in this role.

Responsibilities:

Responsibilities include, but are not limited to the following:

Lead design sessions to develop ETL logic that meets business and product requirements.
Implement data pipelines that meet the design and are efficient, scalable, and maintainable.
Provide technical guidance and meet best practices during the data pipeline development.
Work with clients to understand and document their data, technology, and how it would integrate with Antuit's cloud solutions.
Act as a technical escalation lead for customer and development team issues.

Qualifications and Skills:

7-10 years as a data integration engineer (or equivalent) with at least 3 years as a senior data integration engineer
Strong understanding of data models that feed advanced AI-driven applications.
At least 3 years of experience with Azure Data Factory (ADF), Informatica and similar, is critical.
At least 1 year of Spark experience (preferably PySpark)
Experience with relational databases, SQL, and Python is preferred.
Experience working with Retail, Consumer Goods, and Manufacturing data models is a plus.

Information Security Responsibilities

Understand and adhere to Information Security policies, guidelines, and procedures and practice them to protect organizational data and Information systems.

Take part in Information Security training and act accordingly while handling information.

Report all suspected security and policy breaches to the Infosec team or appropriate authority (CISO).

EEOC

Antuit.ai is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age, marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.ai

“Antuit.ai thanks all applicants; however, only those selected for an interview will be contacted. “","Antuit
4.1",Remote
826,Senior Data Engineer ( 100 % remote work ),"Fed IT, a recruitment firm specializing in IT job recruitment,
We work on two types of recruitment: temporary and permanent.
All our consultants are IT experts who speak your language and evolve in your universe.
Do not hesitate to follow our company page to discover all our open positions in the IT, development, decision-making and infrastructure fields.

We are currently looking for a Senior Data Engineer to work for our client, a technology driven company.

RESPONSIBILITIES


Complete data processing so that reports are understood, analyzed and used wisely by the end user
Be proactive and efficient in developing the road map
Be proactive and constantly push code into production
Writing viable and reusable programs
Revision of UML diagrams and documentation
Be accountable for code quality by conducting adequate testing
Responsible of the performance, reliability, scalability and resilience of at least one technical component owned by the squad
Solve complex technical problems and mentor/support other technical staff on data modeling and ETL related issues
Knowledge sharing and coaching
Participate in the integration of new Data Engineers
Share knowledge of technical design with junior developers so that they can participate in document writing
Qualifications

Bachelor’s degree in Computer Science, Engineering, Master’s degree an asset
At least 5 years in Functional Programming and/or Object-Oriented
At least 3 years writing SQL queries as well as using Apache Spark
Excellent knowledge of Python programming and its libraries
Wide knowledge in data modeling and an advanced comprehension of its architecture
Extremely comfortable with relational databases and NoSQL databases
Ability to use DevOps tools
Proficiency with cloud resources like Amazon Web Service, Google Cloud etc. Certification would be an asset.
Knowledge of big data technology an asset
Familiarity with continuous integration
Proeficient in Git
Bilingual written and spoken English and French
SKILLS

Highly analytical and detail oriented
Ability to lead and mentor junior
Team player with a high sense of accountability and ownership
Actor of change
Solution-oriented
Ability to thrive in a high pressured and being on point with technology",FED IT Canada,Midtown Toronto
827,Senior Data Engineer ( 100 % remote work ),"Fed IT, a recruitment firm specializing in IT job recruitment,
We work on two types of recruitment: temporary and permanent.
All our consultants are IT experts who speak your language and evolve in your universe.
Do not hesitate to follow our company page to discover all our open positions in the IT, development, decision-making and infrastructure fields.

We are currently looking for a Senior Data Engineer to work for our client, a technology driven company.

RESPONSIBILITIES


Complete data processing so that reports are understood, analyzed and used wisely by the end user
Be proactive and efficient in developing the road map
Be proactive and constantly push code into production
Writing viable and reusable programs
Revision of UML diagrams and documentation
Be accountable for code quality by conducting adequate testing
Responsible of the performance, reliability, scalability and resilience of at least one technical component owned by the squad
Solve complex technical problems and mentor/support other technical staff on data modeling and ETL related issues
Knowledge sharing and coaching
Participate in the integration of new Data Engineers
Share knowledge of technical design with junior developers so that they can participate in document writing
Qualifications

Bachelor’s degree in Computer Science, Engineering, Master’s degree an asset
At least 5 years in Functional Programming and/or Object-Oriented
At least 3 years writing SQL queries as well as using Apache Spark
Excellent knowledge of Python programming and its libraries
Wide knowledge in data modeling and an advanced comprehension of its architecture
Extremely comfortable with relational databases and NoSQL databases
Ability to use DevOps tools
Proficiency with cloud resources like Amazon Web Service, Google Cloud etc. Certification would be an asset.
Knowledge of big data technology an asset
Familiarity with continuous integration
Proeficient in Git
Bilingual written and spoken English and French
SKILLS

Highly analytical and detail oriented
Ability to lead and mentor junior
Team player with a high sense of accountability and ownership
Actor of change
Solution-oriented
Ability to thrive in a high pressured and being on point with technology",FED IT Canada,Midtown Toronto
828,"Sr. Research Scientist, Evidence Synthesis","Do you consider yourself a highly organized, self starter with a real passion for projects involving innovative health economic concepts? Are you passionate about putting in the hard work to conduct high quality research and programming? If you're a born problem-solver and enjoy when no day is the same - keep reading!

We are looking for a Sr. Research Scientist to join our dynamic HEOR practice!

Senior Research Scientists have a thorough understanding of how to create the data foundation needed to provide the statistical analysis framework for projects. May conduct statistical analysis and modeling procedures, and interpret the results from statistical procedures and models in order to address client's research questions.

What you can expect day to day:
Leads projects with little oversight and supervises others on project team

Displays leadership capabilities and client management skills

Independently and logically identifies issues and problems across all tasks, whether directly or indirectly involved and carries out solutions or seeks additional input for particularly challenging problems

Creatively develops fact base where data are hard to access and tailors analysis to meet future tasks goals and align with big picture project objectives

Applies analytic tools & techniques creatively to solve complex problems

Prepares initial strategies for implementation, obtains insight from others to address gaps or complexities, and assumes role of final decision maker when appropriate while taking accountability for outcomes

Develops written materials with little direction and reviewing/editing by others

Delivers effective presentations and is in command of the audience

Proactively identifies potential challenges and adjusts plans to accommodate unexpected problems or opportunities

Anticipates the key risks and proactively develops and executes mitigating strategies while mentors others in execution

Demonstrates valued contributions to internal and client discussions

Draws team together and motivates others to achieve common goal

Delegates effectively by assessing availability, skill, and interest and leads by example, particularly during challenging situations

Proactively manages client expectations and works with others to resolve any issues within reason when client needs are not met

Builds client relationships and is perceived as scientific partner

Anticipates potential opportunities for future work

Qualifications:Required:
Ph.D. in a discipline related to health services research; economics, public policy, health policy, epidemiology, biostatistics, or public health, with a minimum 5 years of relevant research experience

MS/MA plus 7 years of relevant research experience

Other required:
Thorough understanding of statistical programs (e.g. SAS, R, Stata)

Excellent oral and written communication skills

Ability to work effectively individually and as part of a diverse team

Exceptional organizational and time management skills

Proficiency with Microsoft Office

Preferred:
Experience conducting meta-analysis; experience in conducting network meta-analysis

Experience overseeing the work of others

Experience crafting health technology submissions

Experience working in statistical programs (e.g. SAS, R, Stata)

Who We Are:
PRECISIONheor is an award-winning global healthcare market access consultancy within Precision Medicine Group. We provide our clients with unified health economics and outcomes research, global pricing, access strategy and analytics, payer and physician pull-through, and data management.

We provide powerful research skills to positively impact payer and purchaser decision-making, which allows organizations to assess appropriate populations for therapies and potential expand access for life-saving and altering medical interventions.

With offices in New York, Boston, LA, Vancouver and London, our team has experienced rapid growth and includes a collection of professionals from around the globe with experience across multiple disciplines: former payer executives, academics, pharma marketers, and consultants—all passionate about generating solutions to our customers' value and access needs.
Any data provided as a part of this application will be stored in accordance with our Privacy Policy .

Precision Medicine Group is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, age, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status or other characteristics protected by law. © 2020 Precision Medicine Group, LLC

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact Precision Medicine Group at QuestionForHR@precisionmedicinegrp.com .",PRECISIONheor,British Columbia
829,Ingénieur de données / Data Engineer - 312613,"Ingénieur de données

Dans le cadre de ses ententes avec ses différents clients, Procom est actuellement à la recherche d’un Ingénieur de données. Notre client est situé à Montréal.





Description des tâches et responsabilités – Ingénieur de données

Les responsabilités du poste incluent :

Contribuer directement à la conception et au code des pipelines de données fonctionnant sur les données de production;
Améliorer les approches pour traiter efficacement un volume de données en constante augmentation;
Diriger la conception et la mise en œuvre de bout en bout des composants communs qui accélèrent et améliorent notre capacité à écrire des pipelines de données efficaces et fiables;
Maintenir l'efficacité et la fiabilité de la production des ensembles de données critiques;
Évaluer et proposer les meilleurs outils et processus pour l'accès aux données et leur analyse;
Fournir une aide à la conception et à la révision aux équipes d'ingénieurs travaillant sur le traitement des données;
Évaluer continuellement les processus de l'équipe afin de maintenir une culture d'ingénierie positive et efficace.




Exigences du poste – Ingénieur de données

Connaissances des langues et outils que nous utilisons : Scala, Scalding, Python, Airflow;
Vous avez de l'expérience dans un environnement qui soutient l'analyse des données, l'expérimentation et la modélisation du Machine Learning ou son intégration dans un produit;
Vous possédez une compréhension avérée des systèmes backend et distribués et une forte expérience de travail avec des architectures basées sur MapReduce;
Vous avez une large connaissance de l'écosystème de l'infrastructure de données et une expérience de travail avec des données à grande échelle;
Vous êtes familier avec la méthodologie standard d'ingénierie logicielle, par exemple les tests unitaires, les revues de code, la documentation de conception;
Vous aimez travailler dans un environnement collaboratif et interagir efficacement avec les autres;
Vous fondez vos décisions sur des données et un raisonnement et pouvez vous adapter à de nouvelles informations pour faire des choix éclairés;
Vous apportez des perspectives réfléchies, de l'empathie, de la créativité et une attitude positive pour résoudre des problèmes à grande échelle.




Type de poste
Contractuel 6 mois avec de fortes possibilités de renouvellement.

Date de début
Immédiatement

Numéro de référence
BH312613




____________ENGLISH VERSION___________

Data Engineer

As a part of its agreements with its various clients, Procom is currently seeking a Data Engineer. Our client is located in Montréal.





Job details – Data Engineer

Key responsibilities for this position include:

Directly contribute to the design and code of data pipelines operating on production data;
Improve approaches to efficiently handle ever-increasing volume of data;
Lead end-to-end design and implementation of common components that accelerate and improve our ability to write efficient and reliable data pipelines;
Maintain efficiency and reliability of production of the critical datasets;
Evaluate and propose the best tooling and processes for data access and analysis;
Provide design and review support to the engineering teams working on data processing;
Continuously evaluate team’s processes to maintain a positive and efficient engineering culture.




Mandatory Skills – Data Engineer

Knowledge of languages and tools we use: Scala, Scalding, Python, Airflow;
Who You Are You have experience working in an environment that supports data analysis, experimentation, and Machine Learning modeling or its integration into a product;
You possess a proven understanding of backend and distributed systems and strong experience working with MapReduce-based architectures;
You have a broad knowledge of the data infrastructure ecosystem and experience in working with large scale data;
You are familiar with standard software engineering methodology, e.g. unit testing, code reviews, design documentation;
You enjoy working in a collaborative environment and interact effectively with others;
You ground your decisions with data and reasoning and can adapt to new information to make informed choices;
You bring thoughtful perspectives, empathy, creativity, and a positive attitude to solve problems at scale.




Assignment Length
6-month contract – renewable

Start date
Immediately

Reference number
BH312613","Procom
4.3",Montreal
830,Scientist - Analytical & Synthetic Chemistry,"Olds Softgels Inc. is an established Pharmaceutical and Nutraceutical softgel manufacturer with a developing portfolio in cannabis products located in Olds, Alberta. We are looking for an enthusiastic, passionate Scientist with experience in Analytical and Synthetic Chemistry to fill a temporary role in new drug development. The focus will be on the effect of catalyst structure on reaction kinetics of polyphenols and the analysis of secondary metabolites content in plants.

Duties and responsibilities:

· Chemical modelling of reaction paths

· Development and validation of analytical methods for pharmaceutical testing

· Troubleshooting issues related to analytical methods/data

· Management of synthesis and characterization of reference standards for APIs and impurities

Candidates should have the following experience:

· PhD in chemistry with minimum 5 years of experience

· Experience in synthesis and analysis of esterified monophenols and polyphenols

· Evaluation of polyphenolic acid esters

· Knowledge and understanding of analytical chemistry methodologies for drug substance and drug product development

· Ability to work independently on projects

Job Types: Full-time, Temporary

Schedule:

8 hour shift

Work remotely:

No","Olds Softgels Inc.
2.0",Olds
831,Digital Sr Data Engineer,"Digital Sr Data Engineer-MON17877

Description

BOMBARDIER

Bombardier is a global leader, creating innovative and game-changing planes. Our products and services provide world-class transportation experiences that set new standards in passenger comfort, energy efficeincy, reliability and safety. We are a global organization focused on working together with a team spirit.

In your role, you will:

Manage the End to end process of designing, developing, testing and deploying data integration workflows (ingest, transformation, storage, consumption).

Plan and Execute secure, best practice data strategies and approaches.

Collaborate with stakeholders (business analysts, data scientists, marketing, engineering, developers, architects) to develop and improve the current data architecture, data quality, monitoring and data availability schemas.

Design and building robust data ingest & transformation pipelines and solutions needed to acquire, ingest, and process data from multiple sources and systems into modern data platforms.

Restructure and wrangling data into forms suitable and valuable for a variety of downstream usage including business analytics, machine/ deep learning model development, as well as in systems and applications for operational, business and commercial purposes.

Create and maintaining underlying cloud data infrastructure responsible for managing data flow from ingestion to storage, and to consumption.

Work cross-functionally with our consultants and tech leads to ensure solutions developed aligns comfortably within the organizational preferences on basis of technology and methodology.

Keep up to date with advancements in data technologies and leveraging the initiatives to improve and scale existing data architectures leading to improved Bombardier Aviation customers’ experience.

Qualifications

As our ideal candidate,

You possess a bachelor's/ Master’s degree in Computer Science, Engineering, Mathematics, or a related technical discipline.

You have a minimum of 7 to 10 years of industry experience in data engineering, software development, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.

You have experience with different ETL techniques & data modeling approaches.

You have industry experience using Java, Scala, Python, SQL, or similar for data manipulation.

You have expertise with data technologies such as S3, Parquet, Athena, Redshift, RDS, as well as with integrating with REST APIs using JSON/XML.

You possess effective interpersonal, communication and leadership skills, and have the ability to work under pressure and meet strict deadlines


You have strong analytic skills related to working with structured/unstructured datasets.

You have the ability to effectively articulate recommendations/conclusions verbally and in writing

You have an expertise in data engineering or architecture role in a company with large, complex data sources, and have experience working with AWS data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda, Athena).

You have expertise building/operating highly available, distributed systems of data extraction, ingestion, and processing of large datasets, as well as ETL, data modeling, data injection, transformation and processing.

Bombardier is an equal opportunity employer and encourages persons of any race, religion, ethnicity, gender identity, sexual orientation, age immigation status, disability or other applicable legally protected Characteristics to apply.

Whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone.

Join us at https://bombardier.com/en/careers/career-opportunities

Your ideas move people.

Job: Project/Program Management
Primary Location: CA-QC-Montreal Dorval
Organization: Aerospace
Schedule: Full-time
Employee Status: Regular

Job Posting: 01.06.2021, 12:57:54 PM

Unposting Date: Ongoing","Bombardier
3.4",Dorval
832,"Senior Data Engineer, KPMG Lighthouse","Overview:
You’ve got big plans. We have opportunities to match, and we’re committed to empowering you to become a better you, no matter what you do.

When you join KPMG you’ll be one of over 219,000 professionals providing audit, tax, advisory and business enablement services across 147 countries.

With the support to do things differently, grow personally and professionally and bring your whole self to work, there’s no limit to the impact you can make. Let’s do this.

The opportunity:


Innovate. Collaborate. Shine. Lighthouse — KPMG Canada’s Center of Excellence for Data Valorization, Advanced Analytics— applies data science to solve real-word business problems, operationalize AI and optimize emerging technologies for its mission. Join a diverse team which is always curious and learning, thinking independently, working collaboratively, has a passion to solve difficult problems, and has fun doing it.


KPMG Lighthouse Quebec has an exciting opportunity for a Data Analytics senior engineer, to join our team! This role will be a rewarding experience for you if you:

Thrive on challenges and work best in a fast-paced environment where each day is different
Work well in a project team environment and have strong collaboration and interpersonal skills
Have a permanent “figure it out” mindset
What you will do:
Use Advanced Analytics to enable greater insight into business drivers and outlook to proactively inform business decisions using supervised and unsupervised techniques.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Lead the planning and implementation of data collection and management tools.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Enforce data security best practices for on premises and cloud environments, including HIPAA / GDPR / Client Requirements.
Build your technical and analytical expertise by delivering high quality results on time and proactively identifying and resolving project issues.
Analyze and translate project and user needs into data, analytics and technology requirements.
Develop, implement, monitor and efficiently deliver of multiple projects in advanced analytics via, among others, cloud technologies.
Coach and mentor more junior staff on the team and engage in skill development conversations.
What you bring to this role:
5 years of professional experience in a related field
Bachelor's or graduate degree in computer engineering, mathematics, data science or related disciplines
Experience using the following software/tools is a must:
Experience with relational SQL and NoSQL databases, including MS SQL Server, PostgreSQL and Cosmos DB
Experience with cloud environment: Azure, GCP, IBM Cloud Pak and AWS cloud data services and solutions like Docker, etc.
Experience with API
Experience using the following software/tools is a plus:
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with Data Warehousing Solutions such as Azure Synapse.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience with stream-processing systems: Spark-Streaming, DataBricks, Azure Event Hubs, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Experience deploying and maintaining high performance computing VMs in on-premise and cloud environment.
Strong experience working in teams to perform ETL (extract, transform and load) of data from a variety of databases
Experience working in a multi-disciplinary team to tack structured and unstructured data processing problems across a diverse range of industries
Experience in developing, implementing and identifying opportunities for data valuation projects including; machine learning (regression techniques, classification, time series, natural language processing and others), deep learning or the field of data engineering, etc.
Keys to your success:
An insatiable curiosity to learn, an aptitude to figure it out and a hunger to make a difference
Strong communication in English and French and interpersonal skills
Ability to think critically and laterally – problem solve and innovate within a team environment
High level of attention to detail, excellent time management skills using agile methodology and ability to perform under pressure
Learn more about where a career at KPMG can take you.
Our Values, The KPMG Way:
Integrity, we do what is right | Excellence, we never stop learning and improving | Courage, we think and act boldly | Together, we respect each other and draw strength from our differences | For Better, we do what matters

KPMG in Canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier-free workplace that allows all of our people to reach their full potential. A diverse workforce is key to our success and we believe in bringing your whole self to work. We welcome all qualified candidates to apply and hope you will choose KPMG in Canada as your employer of choice.

If you have a question about accessible employment at KPMG, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact KPMG’s Employee Relations Service team for support at email: cdnersteam@kpmg.ca or phone: 416-777-8002 or toll free 1-888-466-4778 Option 3.

For general recruitment-related inquiries, please contact the HR Delivery Centre at cafmcdnhrsthotline@kpmg.ca.","KPMG
3.9",Montreal
833,Data Modeler,"FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an extraordinary online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity - Data Modeler

FreshBooks is seeking a Data Modeller to join our team. You will help design and organize new features and update existing ones in our current data and analytics infrastructure. If you're committed to great work and are constantly looking for ways to improve the systems you're responsible for, we'd love to chat with you!

What you'll do:
Collaborate with data engineers, data analysts, data scientists, and product teams working on data and analytics features for our stakeholders.
Apply Data Modelling methodologies and best practices in designing solutions.
Focus on data management functional areas of Data Quality, Data Lineage, Data Cataloging and Data Security.
Provide designs and documentation that fit into the data engineering team's Agile framework.
Participate and share your ideas in technical design and architecture discussions.
Develop your craft and build your expertise in data and analytics systems.
Champion the cause of data literacy.

What you bring:
Enthusiasm for data and analytics!
Strong data modeling fundamentals including experience with dimensional modeling, 3NF, star and snowflake schemas, etc., and strong application knowledge concepts like normalization, referential integrity, data domains, etc.
Experience building and maintaining conceptual, logical and physical data models for reporting and analytics use cases.
Experience with analytics platforms and methodologies (data lake, data warehouse, data marts, ETL, data modelling, data governance, etc.)
Strong SQL skills and experience with RDBMS and MPP relational databases.
Experience with GCP data storage products BigQuery CloudSQL, or similar technologies: e.g. Snowflake, Redshift, Azure SQL Database
Experience enabling Data governance practices as part of solution implementation.
Experience with semi-structured and unstructured data.
Experience working in an Agile environment.
The ability to balance a desire to build data and analytics features quickly for internal customers, with the responsibility of making good technical decisions.

What you might bring:
A passion for keeping up to date in current technologies and future trends.
Experience with BI tools like Looker, Tableau, Microstrategy, Periscope, etc.
Experience with Pub/Sub, Spark, Kafka, Kinesis or other streaming technologies.
Experience using GitHub, reviewing code, receiving and providing feedback.
A limitless imagination for where data could go and what we can do with it to make our customers and our people awesome!

Why Join Us?

We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. In this role, you will be working at the forefront of marketing analytics surrounded by talented team members who share a common vision for building an amazing software company right west of downtown Toronto. If this sounds like something you would be interested in, we'd like to meet you.

Apply Now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer that embraces the differences in all of our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position.

Here at FreshBooks, we welcome and encourage applications from people with disabilities. Should you require any accommodations during the recruitment process, please advise your recruiter on how we can meet your needs to ensure a fair and equitable selection process in a confidential manner.","FreshBooks
4.0",Ontario
834,MDM Data Engineer,"As an Informatica Master Data Management (MDM) Engineer, you will be responsible for designing, building and running the data driven applications which enable innovative, customer centric digital experiences.
You will be working as part of a friendly, cross-discipline agile team who helps each other solve problems across all functions. As a custodian of customer trust, you will employ best practice in development, security, accessibility and design to achieve the highest quality of service for our customers.

Our development team uses a range of technologies to get the job done: Informatica MDM, Informatica IDQ, NiFi . Node.js

You will be part of the team implementing Informatica Master Data Management (MDM) hosted on Amazon Web Services (AWS).

You are a fast learner, highly technical, passionate person looking to work within a team of multidisciplinary experts to improve your craft and contribute to the data development practice.

Here’s how
Learn new skills & advance your data development practice
Design, develop, test, deploy, maintain and improve batch and real-time data pipelines
Continuous refinement of MDM processes to deliver best version of truth
Assist with design and development of rapid prototyping of solutions
Support consumers with understanding the data outcomes and technical design
Collaborate closely with multiple teams in an agile environment

Qualifications
You're the missing piece of the puzzle
A passion for data quality
Strong data analysis skills (SQL)
Interest and ability to learn new skills and technologies as needed
Proficient in configuring and building end-to-end Informatica MDM solutions
Experience with Informatica IDQ, Apache NiFi, API Development & Testing, Node.js
Great-to-haves
3+ years of relevant applied MDM experience
Experience building MDM integrations with AWS and/or GCP services
Experience with Informatica IDQ, Informatica PowerCenter, BMC Control-M, Java, GCP, IICS
A bit about us
Our business is connecting Canadians. Our social impact is using our world-leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. When you join our team, you’re helping us make the future friendly. We’re committed to diversity and equitable access to employment opportunities based on ability —your unique contributions and talents will be valued and respected here.

Primary Location: Canada
Other Locations: CA-ON-Scarborough, CA-QC-Montreal, CA-AB-Calgary, CA-BC-Vancouver, CA-ON-Toronto

Schedule: Full-time","TELUS
3.9",Canada
835,"Data Engineer, Trust and Safety Operations","Dapper Labs is at an inflection point in our journey and it might be the perfect time for you to join us. Less than 6 months ago we launched NBA Top Shot on the new Flow blockchain and it is already on track to be the fastest-growing marketplace in history. Over $200 million in sales in the past 30 days and counting – we need to scale our systems to handle the demand!

We're looking for product-minded data engineers to build out our fraud protection team. You'll join a small team that's scaling rapidly and build sustainable foundations for the future.



Our data pipeline currently include Segment and Tableau. Most of our backend systems are in Go, frontends in React. We use vanilla postgres as well as Kafka event-driven architecture in NBA Top Shot. This is an opportunity to help define the company's data strategy, while laser focused on enabling the organization to make data-driven decisions by unlocking the distribution, collection, and tooling of data.

We believe in an open digital future: one where people own the assets they pay for and have full transparency into the software they're using. We believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they're helping create. Crypto, or blockchain, is the technology that enables this future. Blockchains are public computers that anyone can access, everyone can trust, and no-one can block or take down. Currencies and collectibles are only scratching the surface of what's possible.



Titles or years of experience don't matter to us – impact, authenticity, and values alignment do. We are now a remote-first team and open to hiring anywhere in the world.



About the role:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity
Work with Google Cloud Platform, BigQuery, Cloud Composer, etc, and drive adoption of other key technologies
Cleaning, processing, transposing data from our data lake to endpoints like Tableau
Create predictive models to understand user-level fraud risk
Consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality
Research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities
Innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the Dapper product team and our finance department
Bonus points if you have the following:
You have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made
You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply
You have a bachelor's degree in a highly quantitate field (Computer Science, Machine Learning, Statistics, Mathematics), and a master's degree preferred
You have 5+ years working experience in data science and or machine learning. Strong knowledge of SQL and python programming and graph databases
You are naturally curious and passionate about fraud prevention: if something seems off, you want to investigate what's going on and solve the true problem
You are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions

More about Dapper Labs:

Dapper Labs is the world's first blockchain entertainment company. We are the creators of industry-leading experiences including CryptoKitties and NBA Top Shot, as well as Dapper Wallet, the simplest way to manage your assets and use the blockchain. We are also the original developers behind Flow, a new decentralized blockchain designed from the ground up for scalability and ease of use.

Our mission at Dapper Labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. We have raised over $350M from leading VCs including Fred Wilson (USV) and Chris Dixon as well as Venrock, Samsung, Google Ventures, Coatue, NBA players, and global artists, among others. Dapper Labs partners include the NBA and NBPA, the NFL-PA, Ubisoft, Warner Music, Turner, Dr. Seuss, Genies, and the UFC, as well as 100+ others.

Visit our website to learn even more about Dapper Labs, including information about benefits and perks.",CryptoKitties,Vancouver
836,"Data Engineer, Trust and Safety Operations","Dapper Labs is at an inflection point in our journey and it might be the perfect time for you to join us. Less than 6 months ago we launched NBA Top Shot on the new Flow blockchain and it is already on track to be the fastest-growing marketplace in history. Over $200 million in sales in the past 30 days and counting – we need to scale our systems to handle the demand!

We're looking for product-minded data engineers to build out our fraud protection team. You'll join a small team that's scaling rapidly and build sustainable foundations for the future.



Our data pipeline currently include Segment and Tableau. Most of our backend systems are in Go, frontends in React. We use vanilla postgres as well as Kafka event-driven architecture in NBA Top Shot. This is an opportunity to help define the company's data strategy, while laser focused on enabling the organization to make data-driven decisions by unlocking the distribution, collection, and tooling of data.

We believe in an open digital future: one where people own the assets they pay for and have full transparency into the software they're using. We believe users should have the choice to leave apps without leaving the underlying network, and that the users and developers that constitute a network should benefit directly from the value they're helping create. Crypto, or blockchain, is the technology that enables this future. Blockchains are public computers that anyone can access, everyone can trust, and no-one can block or take down. Currencies and collectibles are only scratching the surface of what's possible.



Titles or years of experience don't matter to us – impact, authenticity, and values alignment do. We are now a remote-first team and open to hiring anywhere in the world.



About the role:
Work cross-functionally to analyze large amounts of behavioural and transaction data to uncover fraudulent behaviour and activity
Work with Google Cloud Platform, BigQuery, Cloud Composer, etc, and drive adoption of other key technologies
Cleaning, processing, transposing data from our data lake to endpoints like Tableau
Create predictive models to understand user-level fraud risk
Consistently consume and produce massive amounts of data while optimizing for speed, accuracy, and quality
Research and develop how advanced data science techniques and machine learning can enable and empower our fraud detection capabilities
Innovate our data methods to create a single coherent platform with sources of truth that serve many stakeholders including the Dapper product team and our finance department
Bonus points if you have the following:
You have previous experience working in fraud detection and prevention, with an understanding of the impact that has on other areas in the company where business and product decisions are made
You are capable of applying your skills across a variety of use cases; inflexible specialists need not apply
You have a bachelor's degree in a highly quantitate field (Computer Science, Machine Learning, Statistics, Mathematics), and a master's degree preferred
You have 5+ years working experience in data science and or machine learning. Strong knowledge of SQL and python programming and graph databases
You are naturally curious and passionate about fraud prevention: if something seems off, you want to investigate what's going on and solve the true problem
You are capable of tackling very loosely defined problems and thrive when given autonomy in your day to day decisions

More about Dapper Labs:

Dapper Labs is the world's first blockchain entertainment company. We are the creators of industry-leading experiences including CryptoKitties and NBA Top Shot, as well as Dapper Wallet, the simplest way to manage your assets and use the blockchain. We are also the original developers behind Flow, a new decentralized blockchain designed from the ground up for scalability and ease of use.

Our mission at Dapper Labs is to make the world a more open, empowering, and enjoyable place through consumer adoption of decentralized technologies. We have raised over $350M from leading VCs including Fred Wilson (USV) and Chris Dixon as well as Venrock, Samsung, Google Ventures, Coatue, NBA players, and global artists, among others. Dapper Labs partners include the NBA and NBPA, the NFL-PA, Ubisoft, Warner Music, Turner, Dr. Seuss, Genies, and the UFC, as well as 100+ others.

Visit our website to learn even more about Dapper Labs, including information about benefits and perks.",CryptoKitties,Vancouver
837,Data Manager (Research Institute),"Job Description
RESEARCH INSTITUTE OF THE MUHC
The Research Institute of the McGill University Health Centre (RI-MUHC) is a world-renowned biomedical and hospital research centre. Located in Montreal, Quebec, the Institute is the research arm of the McGill University Health Centre (MUHC) affiliated with the Faculty of Medicine at McGill University. The RI-MUHC is supported in part by the Fonds de recherche du Québec - Santé (FRQS).

Position summary
Stenoa is a machine-learning startup striving to make fundamental breakthroughs in real-time video analysis for guiding the diagnosis and treatment of cardiovascular disease, the leading cause of death globally. Our research and development team has access to a very large dataset of cardiac catherization videos. With all this data, the Data Science team is looking for talented engineers to help us manage the annotation and analysis of the videos and the associated medical records. If you are data curious, excited about designing data pipelines, and motivated by having impact on the clinical practice, we want to hear from you.

General Duties

Upload and organize videos on an online annotation platform. Export labels and annotations continuously following the progress of the annotations team.
Implement techniques for augmenting the database of annotations produced by trained medical specialists.
Organize the videos in a HDF5 database.
Export annotations the labelling software to the HDF5 database.
Develop technical documentation for the database. Lock a complete version of the database for descriptive quantitative analysis.
Design and implement a scalable infrastructure for expanding the HDF5 database to new sites and patients.
Website of the organization
https://rimuhc.ca/en

Education / Experience

Minimum BSc in computer science, software engineering or a related scientific discipline.
Fluency in Python and experience with HDF5 databases.
Ability to perform summary statistical analysis of texts and database object attributes.
Ability to write scripts to process json, csv and plain text files.
An inquisitive nature in diving into data inconsistencies to pinpoint issues
Ability to operate in a multidisciplinary team of physicians and computer scientists.
Capable of thriving in a collaborative environment involving different stakeholders and key opinion leaders.
Demonstrated ability of working on projects to successful completion involving a wide variety of technologies and systems.
Additional information
Status : Temporary, Full-Time (Summer worker)
Pay Scale : to be determined based on experience
Work Shift : Monday to Friday, 35hr/week
Work Site : GLEN, RI-MUHC, 1001 Decarie Blv, Montreal H4A 3J1

https://rimuhc.ca/careers

To learn more about our benefits, please visit http://rimuhc.ca/en/compensation-and-benefits

THIS IS NOT A HOSPITAL POSITION.

NOTE: The masculine gender has been used for brevity and includes the feminine gender.
Equal Opportunity Employment Program

Le CUSM applique un programme d’accès à l’égalité en emploi et invite les femmes, les Autochtones, les minorités visibles, les minorités ethniques et les personnes handicapées à présenter leur candidature. Des mesures d’adaptation peuvent être offertes aux personnes handicapées qui en font la demande en fonction de leurs besoins.","Centre universitaire de santé McGill
3.2",Montreal
838,"Director, Data Science","Director, Data Science
Montreal, Canada
(French Version follows)
At Octave Group, we believe in the power of music to inspire emotional connections in shared spaces, transforming the way people interact with each other and with their surroundings.
We are a group of passionate, diverse, and driven individuals who all share a common goal: pioneering new ways humans and music interact through technology. We continuously strive to stay ahead of the curve with our products. Our use of cutting-edge tech stack, an Agile mindset, and a strong focus on the user experience, all make for a challenging learning environment.
Octave Group is looking for a dynamic director who will provide strategic leadership to our Data Science department.
The Director, Data science will manage a team of data scientists, engineers and analysts and lead and develop our data roadmap and infrastructure, provide business insights, scope, design and implement machine-learning models. The Director, Data science, is innovative, analytical and has excellent communication skills to work cross-functionally, with engineering, marketing, finance, and operations to support all data projects.
This is a fantastic opportunity for a seasoned leader to grow this department and play a central role at Octave Group with the very strategic mandate of using data science to impact our users through smarter products and services.
What your day to day looks like:
Partner with managers, directors, and executives to identify key opportunities where the Data team’s input can play a major role.
Be very active in the Data ecosystem of the company by pairing your analytical mind with a knack for data driven storytelling to help transform our products.
Spearhead the development of our Machine Learning activities by providing experience and expertise.
Manage the compilation, analysis, cleaning, and reporting of large datasets using advanced analytics methodologies, driving business improvements.
Foster a culture of healthy collaboration and partnership within the team by acting as a functional manager, mentor, precious collaborator, and subject matter expert.
Manage the workload and level of involvement of different roles in the cross-functional team: balance scope, schedule, budget, quality, and risks.
Develop and/or review estimates for project schedule, effort, and cost using established estimating models, best practices, and past experience.
Promote a culture of data-driven decision making throughout the organization, supported by scalable processes and protocols, appropriate reporting, and modern tools.
What you bring to the table:
Natural leader and mentor, willing and ready to foster a healthy team dynamic.
Ability to adapt to a new business and comprehend its intricacies.
Education in Statistics, Applied Math, or any related field.
High attention to detail, and a keen eye for discrepancies, non-conformities, etc.…
Ability to communicate complex data insight in business terminology for executives and senior managers.
Ability to work in a global faced paced environment.
Experience managing and leading data science teams.
Knowledge of Statistical and Predictive modeling methodologies and technologies.
Knowledge of Machine Learning/Statistical Modeling.
Experience in Consumer Products environments, understanding of consumer behavior and interactions.
Expert user of Data & Statistics technologies/platforms, and data visualization tools.
Experience with SQL, Python and related libraries and technologies
Experience with big data modeling technologies (Hadoop, Hive, Spark, etc.…)
What’s in it for you:
Working alongside a team of talented individuals from diverse backgrounds, origins, and technical knowledge
An open and stimulating working environment focused on crafting performant and intuitive user experience.
Challenging and stimulating projects
Be implicated with our internal Culture Collective group to drive events, parties, social clubs, lunch & learns and more.
Working with modern techs, in a culture that drives innovation.
PC or Mac, you pick.
Free Access to a virtual health care application. Long gone are the days of waiting 8 hours at the clinic.
Conferences, training on the latest and greatest techs, weekly presentations and more.
Very competitive insurance package which is mostly covered by Octave Group
Beautiful offices right next to Jarry Park
Flexible hours and full-time work from home (little hint: post-COVID remote work >50% and up to 100% will be an option for many employees with approval)
Directeur(rice) – Science Des Données
Montréal, Canada


Octave Group est à la recherche d'un(e) directeur(rice) dynamique qui assurera un leadership stratégique au nouveau département des Sciences Des Données.
L'équipe se concentrera sur l'analyse des données actuelles et historiques, en décomposant les tendances et les schémas, ainsi qu’en présentant leurs résultats via des visualisations claires et ciblées, qui seront utilisées pour prendre des décisions commerciales clés dans toute l'entreprise.
Il s’agit d’une occasion unique pour un(e) dirigeant(e) chevronné(e) de créer ce département, de le munir de talents de première classe et de mettre en place les bases et stratégie nécessaires. Ce rôle vous permettra de combiner l’analyse, les technologies de pointe, la musique, le comportement du consommateur, tout en collaborant avec des marques de renommée mondiale. Vos efforts joueront un rôle principal dans la définition des décisions commerciales critiques dans le développement des gammes de produits d’Octave Group, partout à travers l’organisation.
Ton quotidien ressemblera à ceci:
Développer, documenter et communiquer la stratégie et la vision du département.
Agir en tant qu'expert(e) sur les technologies appliquées au sein du département.
Agir en tant que responsable fonctionnel(le) de l’équipe au quotidien.
Tirer parti des données usagers d’OG pour améliorer l’efficacité du processus décisionnel.
Présenter et expliquer les résultats aux principaux intervenants et dirigeants.
Développer et monitorer des indicateurs de performance clés pour les rapports internes et externes.
Collaborer avec les équipes produit et plate-forme pour assurer un flux de données efficace et fiable ainsi que la conformité aux processus et protocoles établis.
Étant supporté(e) par des processus et des protocoles évolutifs, des rapports appropriés et des outils modernes, encourager une culture de prise de décision basée sur les données dans l'ensemble de l'organisation.
Embaucher et développer des talents de première classe.
Collaborer avec les gestionnaires, les directeurs et les dirigeants pour identifier les principales opportunités dans lesquelles la contribution de l’équipe peut jouer un rôle majeur.
Gérer la compilation, l'analyse et la création de rapports pour de grands ensembles de données à l'aide de méthodologies d'analyse avancées, favorisant ainsi les améliorations commerciales.
Définir les meilleures pratiques pour la modélisation, l'analyse et la création de rapports de données dans l'ensemble du service et de toutes les équipes de l'organisation.
Trouver et créer de nouvelles opportunités où la science des données pourra avoir un impact sur des secteurs d'activité nouveaux et existants.
Agir en tant qu'expert(e) en ce qui concerne les statistiques et l'apprentissage automatique pour l'équipe, en assurant la formation et le mentorat.
Établir les outils et l'infrastructure de science des données, en aidant l'équipe et l’organisation à trouver les meilleures technologies pour analyser, visualiser, extraire et stocker des données.
Ce que l’on recherche:
Forte capacité d'adaptation à une nouvelle entreprise et à la compréhension de ses subtilités.
Diplôme supérieur en statistiques, mathématiques appliquées ou tout domaine connexe.
Grand souci du détail et sens aigu des divergences, des non-conformités, etc.…
Capacité à communiquer aux responsables et aux cadres supérieurs des informations complexes dans une terminologie commerciale.
Leader et mentor naturel(le)
Capacité à travailler dans un environnement multinational et très dynamique.
Expérience dans la gestion et la direction d’équipes de science des données.
Connaissance des méthodologies et des technologies de modélisation statistique et prédictive.
Solide connaissance de l’apprentissage automatique et de la modélisation statistique.
Expérience dans les environnements de produits grand public, compréhension du comportement du consommateur et de ses interactions.
Utilisateur(rice) expert(e) des technologies / plates-formes de données et statistiques, ainsi que de leurs outils de visualisation.
Une personne influente, persuasive et munie de fortes capacités oratoires.
Expérience avec l’ensemble des technologies nécessaires pour produire des résultats de science des données : collecte, analyse, visualisation, création de rapports, etc.…
Expérience avec le traitement automatique des langues et du moissonnage du Web.
Expérience avec SQL, R et Python et les bibliothèques et technologies associées (par exemple, Pandas, Numpy, Tensorflow)
Expérience avec les technologies de modélisation Big Data (Hadoop, Hive, Spark, etc.…)
Ce que l’on te propose:
Évoluer aux côtés d'un groupe de personnes super talentueuses et chaleureuses
Un environnement amusant, diversifié, ouvert et qui évolue rapidement, axé sur une atmosphère familiale et sur la création d’une expérience utilisateur optimale
Des projets stimulants et amusants
Travailler avec des technos modernes, dans une culture qui prône l'innovation constante
PC ou Mac, votre choix
50% de réduction sur votre abonnement mensuel à OPUS
Accès gratuit à une application offrant un support de santé virtuel. Fini les attentes interminables en clinique!
Conférences, budgets de formation, présentations hebdomadaires et autres…
Programme d’assurance très compétitif, principalement couvert par Octave Group
Horaires et environnement de travail flexibles
Superbes bureaux à 2 pas du parc Jarry",TouchTunes / PlayNetwork,Montreal
839,Jr. Data Engineer (ETL/SQL),"Next Pathway - The Automated Cloud Migration Company

Listed as one of Canada’s hottest start-ups by the Globe and Mail, Next Pathway is a technology services company providing clients a pathway from existing to emerging technologies. Our automation technology helps our customers accelerate the migration of complex applications and workloads to the cloud.

Next Pathway is full of bright and diverse thinkers. With deep exposure to AI, Machine Learning and Robotic Process Automation, our team members have opportunities to be trailblazers in the technology space. We encourage self-starters, transparency and team connectivity. We know diverse teams make strong teams. We welcome people of diverse backgrounds, experiences, and perspectives.

Our work environment is based on 3 core principles:

· Emphasize quality first, each and every time

· Put people in roles where they will succeed and feel challenged

· Build a team of well qualified individuals that can share ideas and learn from each other

Next Pathway rewards people for hard work, loyalty, innovation and mutual support. We aim to match people’s strengths, skills and talents to our requirements. Identifying this ideal match between attitude, skill and need, leads to success.

Next Pathway is located in the heart of the Financial District, minutes from Union Station and the Subway.

We are looking for a skilled Jr. Data Engineer (ETL/SQL) to join our team!

The candidate needs to have extensive experience as follows:

· Minimum of 3 years of proven experience in a core competency

· Proven hands-on Software Development experience

· Strong Data Warehouse knowledge and experience

· Strong SQL knowledge and experience, including developing and optimizing complex queries, creating efficient UDFs to extend the functionalities

· Experience in any RDBMS is nice to have

· Experience with Cloud Technologies (Azure, GCP, Snowflake, AWS, Yellowbrick)

· Experience with ETL tools (Informatica, DataStage, SSIS, Talend)

· Experience with major programming languages (Java, Python, Scala, C++, Java Script)

· Strong understanding and experience of relational database, include design and implementation

· Develop and maintain unit tests and integration tests, and test automation.

· Adoption of Agile and Scrum development methodology

· BA/MS/PHD degree in Computer Science, Engineering, or a related subject

Other Technologies you Might Work with Include:

· Microsoft Office Suite (Excel, Word, PowerPoint, Outlook)

· Basecamp: Project Management & Team Communication

· Slack: Messaging Platform

· Zoom: Meetings and Video Conferencing

· Confluence: Collaboration Tool

· JIRA: Project Management Software

Other Skills:

· Team Player with Excellent Interpersonal and Communication Skills (Written and Verbal)

· Strong Work Ethic with a Positive Attitude and a Passion for Data and Development

· Strong Analytical and Problem-Solving Skills

· Excellent Time Management Skills

Contract length: 6 months

Job Types: Full-time, Contract

Schedule:

Monday to Friday

Experience:

SQL: 3 years (required)
Python: 2 years (required)
PL/SQL: 2 years (required)
Scripting: 2 years (required)

Work remotely:

Yes","Next Pathway
4.5",Midtown Toronto
840,Data Integration Engineer,"Main Purpose:
We are recruiting a data integration engineer; who is knowledgeable in the full data integration lifecycle in a complex and demanding commercial environment. Based in Calgary, AB, the engineer will be part of a global team responsible for the ingestion, management, provision of both market data, and fundamental data; for the use of business analysts, data scientists, traders and applications such as dashboards and trading systems.
Knowledge Skills and Abilities, Key Responsibilities:

Knowledge Skills and Abilities, Key Responsibilities

Financial or commodity market data ingestion, data integration ETL/ELT pipeline design, data modelling, data provisioning

Data virtualization and logical data warehouse architecture

Python, SQL

AWS data stack (including S3, Redshift, EMR, Glue)

Data quality management

Experience with data related to energy and metal commodities, power generation, weather or shipping would be an asset

Abilities, Experience and Qualifications:

Bachelor’s degree in Computer Science, Information Systems or related subjects

AWS certifications are a plus

Experience with enterprise scale data systems

Competencies:

Ability to communicate effectively with a diverse set of stakeholders across business lines and technology

Understanding and experience implementing software engineering best practices

Ability to work as part of a global team utilising agile management methods

Key Relationships and Department Overview:

The Data Science and Engineering team researches, develops, and provides advanced analytics and data services to the trading business, and other commercial operations at Trafigura.

It is comprised of Data Scientists, Data Engineers, and Quantitative Finance experts. It is a commercially driven, front office aligned team that works in close partnership with the trading desks, global research and enterprise technology.","Trafigura
3.6",Calgary
841,Jr. Data Engineer (ETL/SQL),"Next Pathway - The Automated Cloud Migration Company

Listed as one of Canada’s hottest start-ups by the Globe and Mail, Next Pathway is a technology services company providing clients a pathway from existing to emerging technologies. Our automation technology helps our customers accelerate the migration of complex applications and workloads to the cloud.

Next Pathway is full of bright and diverse thinkers. With deep exposure to AI, Machine Learning and Robotic Process Automation, our team members have opportunities to be trailblazers in the technology space. We encourage self-starters, transparency and team connectivity. We know diverse teams make strong teams. We welcome people of diverse backgrounds, experiences, and perspectives.

Our work environment is based on 3 core principles:

· Emphasize quality first, each and every time

· Put people in roles where they will succeed and feel challenged

· Build a team of well qualified individuals that can share ideas and learn from each other

Next Pathway rewards people for hard work, loyalty, innovation and mutual support. We aim to match people’s strengths, skills and talents to our requirements. Identifying this ideal match between attitude, skill and need, leads to success.

Next Pathway is located in the heart of the Financial District, minutes from Union Station and the Subway.

We are looking for a skilled Jr. Data Engineer (ETL/SQL) to join our team!

The candidate needs to have extensive experience as follows:

· Minimum of 3 years of proven experience in a core competency

· Proven hands-on Software Development experience

· Strong Data Warehouse knowledge and experience

· Strong SQL knowledge and experience, including developing and optimizing complex queries, creating efficient UDFs to extend the functionalities

· Experience in any RDBMS is nice to have

· Experience with Cloud Technologies (Azure, GCP, Snowflake, AWS, Yellowbrick)

· Experience with ETL tools (Informatica, DataStage, SSIS, Talend)

· Experience with major programming languages (Java, Python, Scala, C++, Java Script)

· Strong understanding and experience of relational database, include design and implementation

· Develop and maintain unit tests and integration tests, and test automation.

· Adoption of Agile and Scrum development methodology

· BA/MS/PHD degree in Computer Science, Engineering, or a related subject

Other Technologies you Might Work with Include:

· Microsoft Office Suite (Excel, Word, PowerPoint, Outlook)

· Basecamp: Project Management & Team Communication

· Slack: Messaging Platform

· Zoom: Meetings and Video Conferencing

· Confluence: Collaboration Tool

· JIRA: Project Management Software

Other Skills:

· Team Player with Excellent Interpersonal and Communication Skills (Written and Verbal)

· Strong Work Ethic with a Positive Attitude and a Passion for Data and Development

· Strong Analytical and Problem-Solving Skills

· Excellent Time Management Skills

Contract length: 6 months

Job Types: Full-time, Contract

Schedule:

Monday to Friday

Experience:

SQL: 3 years (required)
Python: 2 years (required)
PL/SQL: 2 years (required)
Scripting: 2 years (required)

Work remotely:

Yes","Next Pathway
4.5",Midtown Toronto
842,Research Scientist - Fisheries Acoustic,"Fisheries and Oceans Canada - Fisheries and Ecosystem Sciences Division
Moncton (New Brunswick)
SE-RES-01 - SE-RES-02, SE-RES-03, SE-RES-04, SE-RES-05
$59,441 to $153,645

For further information on the organization, please visit Fisheries and Oceans Canada

Closing date: 30 June 2021 - 23:59, Pacific Time

Who can apply: Persons residing in Canada and Canadian citizens residing abroad.

Apply online

Important messages

We are committed to providing an inclusive and barrier-free work environment, starting with the hiring process. If you need to be accommodated during any phase of the evaluation process, please use the Contact information below to request specialized accommodation. All information received in relation to accommodation will be kept confidential.

Assessment accommodation

Duties

The Department of Fisheries and Oceans Canada, Gulf region is looking to hire a Scientific Researcher to develop abundance and distribution indices from hydroacoustic data, for a variety of fish species in the southern Gulf of St. Lawrence. The work consists of (1) exploring the appropriate analysis methods in the literature (multi-frequency classification), (2) developing an analysis method specific to the species targeted by the survey, (3) carrying out the analysis of a temporal series of hydroacoustic data using Echoview software, (4) using the acoustic data to develop abundance indices using statistical methods of spatial analysis, (5) writing associated publications.

Intent of the process

The intent of this process is to staff a 18-months temporary Research Scientist position in Moncton, NB. Could be extended based on funding.

The pool of qualified or partially qualified candidates may be used to staff similar positions with various language requirements and tenures.


Positions to be filled: 1

Information you must provide

Your résumé.

In order to be considered, your application must clearly explain how you meet the following (essential qualifications)

EDUCATION
Graduation with an acceptable doctoral degree within the last 3 years from a recognized post-secondary institution in a field related to the duties of the position.

Degree equivalency

EXPERIENCE
Experience in planning and conducting independent research on *fish and / or fisheries biology.
Experience in performing quantitative analyses and interpreting data using statistical methods or tools associated with biological and spatio-temporal studies.
Experience in producing briefing materials and presentations, as well as presenting research results at scientific symposia, workshops or meetings.
Experience creating scientific publications in international peer-reviewed journals with at least two articles within the past 5 years and at least one who is as a first author.
Experience working with a team of researchers and support staff.
Experience with hydroacoustic data analysis.
Experience in working with the R environment for statistical computing and graphics.

Note: The term ""fish"" includes finfish and invertebrates.

If you possess any of the following, your application must also clearly explain how you meet it (other qualifications)

The following experience qualifications could be deemed essential depending on the position.

ASSET EXPERIENCE
Experience doing independent research in a field of the natural sciences related to the duties of the position.
Experience in using fisheries acoustic technologies and methods.
Experience in analyzing fisheries acoustic data.
Experience in developing and applying acoustics classification algorithms for fish species.

The following will be applied / assessed at a later date (essential for the job)

Various language requirements
English or French essential BBB/BBB, and CBC/CBC

Information on language requirements

ABILITIES
Ability to communicate effectively orally and in writing.
Ability to work within a multidisciplinary team.

PERSONAL SUITABILITY
Initiative
Dependability
Effective interpersonal skills

The following may be applied / assessed at a later date (may be needed for the job)

Selection may be limited to members of the following Employment Equity groups: Aboriginal persons, persons with disabilities, visible minorities, women

Information on employment equity

Conditions of employment

Reliability Status security clearance

Medical suitability as required by the position

Other information

The Public Service of Canada is committed to building a skilled and diverse workforce that reflects the Canadians we serve. We promote employment equity and encourage you to indicate if you belong to one of the designated groups when you apply.

Information on employment equity

A variety of assessment tools may be used in the assessment of candidates, such as: oral interview, written test, and reference checks. Some assessment tools may be administered electronically, others, in person.

You must provide proof of your education credentials.

Persons are entitled to participate in the appointment process in the official language(s) of their choice.

Our intention is to communicate with candidates through emails and/or through the www.canada.ca/government-jobs applicant account. Candidates participating in this selection process must include in their application a valid email address and make sure that this address is functional at all times and that their system accepts messages from unknown users (some email systems block the receipt of these types of email).

Preference

Preference will be given to veterans and to Canadian citizens, in that order, with the exception of a job located in Nunavut, where Nunavut Inuit will be appointed first.

Information on the preference to veterans

We thank all those who apply. Only those selected for further consideration will be contacted.","Next Pathway
4.5",Moncton
843,"Data Engineer - SQL, Shell Scripting and Python - 312096","Data Engineer - SQL, Shell Scripting & Python

On behalf of our client in the Banking Sector, PROCOM is looking for a Data Engineer - SQL, Shell Scripting & Python.

Data Engineer - SQL, Shell Scripting & Python – Job Description

The main function of the Data Engineer is to develop, evaluate, test and maintain architectures and data solutions within our organization
The typical Data Engineer executes plans, policies, and practices that control, protect, deliver
Working closely with 40 different Data Scientist as well as Data Strategist
Opportunity to collaboratively work together, use analytical and critical thinking skills
Exposure to many different team members within bank
Identifying data sources and create data pipeline using shell script or python script
Working on the code versioning on Bit Bucket
Writing Python scripts to extract data from various sources and Ingest data from/to Google cloud

Data Engineer - SQL, Shell Scripting & Python – Mandatory Skills

4-6 years of experience with data engineering skills
4-6 years of hands-on experience with SQL, Shell Scripting and Python (TensorFlow, Pandas, Numpy, Keras)
4-6 years of hands-on experience ingesting data using APIs
4-6 years of hands-on experience with BI tools / Big data technologies like Hadoop, Spark, Scala

Data Engineer - SQL, Shell Scripting & Python – Nice to Have Skills

Knowledge of Dialogflow ES and CX APIs, BigQuery, Google Cloud Data Loss Prevention, DataFlow
Bachelors or Masters in related studies

Data Engineer - SQL, Shell Scripting & Python - Assignment Start Date

ASAP – 4 months to start

Data Engineer - SQL, Shell Scripting & Python - Assignment Location

Toronto, ON – Work Remotely","Procom
4.3",Midtown Toronto
844,Staff Application Data Engineer,"Requisition ID: 100504

Join the Global Community of Scotiabankers to help customers become better off.

The team:

Scotiabank’s Global Technology Services (GTS) Technology Operations & Site Reliability Engineering (SRE) is responsible for the operations engineering required to provide highly available and resilient systems. In GTS Enterprise Data Warehouse (EDW) & Reference Data Management (RDM) TechOps & SRE, we are responsible for providing critical data platform services, following SRE and data governance best practices, as well as consulting and coordinating with the Bank’s technology teams to meet business expectations.

The role:

You will contribute to the application and platform support of the EDW ecosystem through the solution and test strategy design, development, testing and implementation of availability, performance, security, currency, and problem remediation solutions.
You will partner with the Product Owner, Engineering teams, and Operations to deliver a high-quality product by recommending, creating, developing, and testing solutions for that are aligned with best practices within the SRE framework.
You will be a technical lead of like-minded Data Engineers, prioritizing their focus areas, reviewing their solutions and providing feedback as required.
You will maintain and recommend continuous improvements to code quality, documentation, organization, and performance meeting security, change, and release management standards ensuring SRE targets are met or improved.
You will identify opportunities, recommend, and implement solutions to improve data availability, optimize data retention, and enhance data security.
You will identify opportunities for quality improvements recommending and implementing automation to prevent problem recurrence and reduce toil.
You will create and continuously improve functional and non-functional testing ensuring tests are automated, repeatable, and benchmarked.
You will inventory, build and maintain application artifacts creating a robust repository of living documentation including application, deployment and operational guides.
You will provide knowledgeable, and skilled support for deployments and lead production incident response, striving to meet or exceed service level objectives.
You will provide after-hours support as required.

Is this role right for you?

You are a skilled application data engineer who possesses a broad set of skills and is familiar with SRE software engineering culture and practice.
You enjoy creating solutions that encompass people, process, and technology.
You enjoy looking for opportunities to be proactive, automate, and solve problems before they happen.
You want to be challenged with problem solving in time sensitive situations to reduce system downtime and customer impact, taking those learnings forward as continuous improvements.

Do you have the skills that will enable you to succeed in this role?

You have strong communication (verbal/written) and good interpersonal skills to build relationships with internal and external business partners and vendors.
You have a track record as a strong team player with a proven ability to create technical specifications, develop, and implement solutions for highly available and resilient systems.
You have at least 4+ years of hands-on technical working experience in designing solutions and authoring technical specifications.
You have at least 6+ years of hands-on technical working experience as an Application Data Engineer in and/or delivering for organization(s) that have large, complex data warehouse(s).
You have at least 6+ years of hands-on technical working experience as an Informatica developer. Technical working experience with SAS, Python, Cobol and Cognos is an asset.
You have at least 4+ years of hands-on technical working experience in designing test strategies and quality assurance testing.
You can demonstrate a technical understanding with security, firewalls, and network protocols.
You can demonstrate a solid understanding of data governance.
You possess excellent problem-solving skills, prefer to identify and resolve issues before they become a problem, and can work under pressure in a dynamic environment.
You have hands-on experience responding to production incidents that cross application and technology boundaries.
You have completed a post-secondary education in computer science, engineering or in a related technology field.

What's in it for you?

You will be a part of a Site Reliability Engineering team that will help you grow & you will have an opportunity to bring valuable and long-lasting contributions to the bank.
We are technology partners who help the business transform how our employees around the world work.
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We also foster an environment of innovation and continuous learning.
We care about our people, allowing them to design how they work to deliver amazing results.
We offer a competitive total rewards package, including a performance bonus, company matching programs (pension & Employee Share Ownership), generous vacation; health/medical/wellness benefits; employee banking privileges.
While we currently work remotely from home, when it is deemed safe to return physically to work, our primary location in downtown Toronto is:
Design focused on enabling collaboration through both environment and technology.
Located in the heart of Toronto’s financial district, the work site is located right above the TTC’s Line 1 King subway station. This location has access to The PATH & is located minutes from GO Transit/VIA Rail hub at Union Station; as well as the TTC’s King 504 streetcar line.
Minutes from the Gardiner Expressway & the DVP.
Located next door is The Commons, a dining space for employees, where breakfast & lunch are served. Also, The Bean server hot/cold beverages & snacks with plenty of room to lounge & recharge. Also, many meal/snack options + shopping & services for your everyday needs in The PATH without venturing outside.

Location(s): Canada : Ontario : Toronto

As Canada's International Bank, we are a diverse and global team. We speak more than 100 languages with backgrounds from more than 120 countries. Our employees are committed to a superior customer experience and use the Bank’s six guiding sales practice principles to ensure they act with honesty and integrity.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
845,Staff Application Data Engineer,"Requisition ID: 100504

Join the Global Community of Scotiabankers to help customers become better off.

The team:

Scotiabank’s Global Technology Services (GTS) Technology Operations & Site Reliability Engineering (SRE) is responsible for the operations engineering required to provide highly available and resilient systems. In GTS Enterprise Data Warehouse (EDW) & Reference Data Management (RDM) TechOps & SRE, we are responsible for providing critical data platform services, following SRE and data governance best practices, as well as consulting and coordinating with the Bank’s technology teams to meet business expectations.

The role:

You will contribute to the application and platform support of the EDW ecosystem through the solution and test strategy design, development, testing and implementation of availability, performance, security, currency, and problem remediation solutions.
You will partner with the Product Owner, Engineering teams, and Operations to deliver a high-quality product by recommending, creating, developing, and testing solutions for that are aligned with best practices within the SRE framework.
You will be a technical lead of like-minded Data Engineers, prioritizing their focus areas, reviewing their solutions and providing feedback as required.
You will maintain and recommend continuous improvements to code quality, documentation, organization, and performance meeting security, change, and release management standards ensuring SRE targets are met or improved.
You will identify opportunities, recommend, and implement solutions to improve data availability, optimize data retention, and enhance data security.
You will identify opportunities for quality improvements recommending and implementing automation to prevent problem recurrence and reduce toil.
You will create and continuously improve functional and non-functional testing ensuring tests are automated, repeatable, and benchmarked.
You will inventory, build and maintain application artifacts creating a robust repository of living documentation including application, deployment and operational guides.
You will provide knowledgeable, and skilled support for deployments and lead production incident response, striving to meet or exceed service level objectives.
You will provide after-hours support as required.

Is this role right for you?

You are a skilled application data engineer who possesses a broad set of skills and is familiar with SRE software engineering culture and practice.
You enjoy creating solutions that encompass people, process, and technology.
You enjoy looking for opportunities to be proactive, automate, and solve problems before they happen.
You want to be challenged with problem solving in time sensitive situations to reduce system downtime and customer impact, taking those learnings forward as continuous improvements.

Do you have the skills that will enable you to succeed in this role?

You have strong communication (verbal/written) and good interpersonal skills to build relationships with internal and external business partners and vendors.
You have a track record as a strong team player with a proven ability to create technical specifications, develop, and implement solutions for highly available and resilient systems.
You have at least 4+ years of hands-on technical working experience in designing solutions and authoring technical specifications.
You have at least 6+ years of hands-on technical working experience as an Application Data Engineer in and/or delivering for organization(s) that have large, complex data warehouse(s).
You have at least 6+ years of hands-on technical working experience as an Informatica developer. Technical working experience with SAS, Python, Cobol and Cognos is an asset.
You have at least 4+ years of hands-on technical working experience in designing test strategies and quality assurance testing.
You can demonstrate a technical understanding with security, firewalls, and network protocols.
You can demonstrate a solid understanding of data governance.
You possess excellent problem-solving skills, prefer to identify and resolve issues before they become a problem, and can work under pressure in a dynamic environment.
You have hands-on experience responding to production incidents that cross application and technology boundaries.
You have completed a post-secondary education in computer science, engineering or in a related technology field.

What's in it for you?

You will be a part of a Site Reliability Engineering team that will help you grow & you will have an opportunity to bring valuable and long-lasting contributions to the bank.
We are technology partners who help the business transform how our employees around the world work.
You'll get to work with and learn from diverse industry leaders, who have hailed from top technology companies around the world.
We have an inclusive and collaborative working environment that encourages creativity, curiosity, and celebrates success! We also foster an environment of innovation and continuous learning.
We care about our people, allowing them to design how they work to deliver amazing results.
We offer a competitive total rewards package, including a performance bonus, company matching programs (pension & Employee Share Ownership), generous vacation; health/medical/wellness benefits; employee banking privileges.
While we currently work remotely from home, when it is deemed safe to return physically to work, our primary location in downtown Toronto is:
Design focused on enabling collaboration through both environment and technology.
Located in the heart of Toronto’s financial district, the work site is located right above the TTC’s Line 1 King subway station. This location has access to The PATH & is located minutes from GO Transit/VIA Rail hub at Union Station; as well as the TTC’s King 504 streetcar line.
Minutes from the Gardiner Expressway & the DVP.
Located next door is The Commons, a dining space for employees, where breakfast & lunch are served. Also, The Bean server hot/cold beverages & snacks with plenty of room to lounge & recharge. Also, many meal/snack options + shopping & services for your everyday needs in The PATH without venturing outside.

Location(s): Canada : Ontario : Toronto

As Canada's International Bank, we are a diverse and global team. We speak more than 100 languages with backgrounds from more than 120 countries. Our employees are committed to a superior customer experience and use the Bank’s six guiding sales practice principles to ensure they act with honesty and integrity.

At Scotiabank, we value the unique skills and experiences each individual brings to the Bank, and are committed to creating and maintaining an inclusive and accessible environment for everyone. If you require accommodation (including, but not limited to, an accessible interview site, alternate format documents, ASL Interpreter, or Assistive Technology) during the recruitment and selection process, please let our Recruitment team know. If you require technical assistance, please click here. Candidates must apply directly online to be considered for this role. We thank all applicants for their interest in a career at Scotiabank; however, only those candidates who are selected for an interview will be contacted.","Scotiabank
3.9",Midtown Toronto
846,Data Engineer,"About Project X
The heart of what we do is drive for unique and innovative solutions that solve our customers problems. We are trusted advisors who create data and analytics solutions for complex client problems. We do this through collaboration, creativity and an innate need to solve tough data problems. Data runs deep in our veins and is what makes up who we are, individually and as a team, allows us to do the work we’re passionate
We think differently.
You are all about
Being that Data Engineer who receives detailed and high-level requirements & specifications from the client for implementation. You will analyze, design, develop, optimize, test, and document Data programs and solutions to meet our clients’ needs. You will work with Architects, Designers, Business Analysts, and other Developers to provide quality development deliverables.
This position does not have any direct reports.
What you need to Bring

Experience in Designing and implementing technical enhancements of Data Warehouse, Big Data or Business Intelligence as required.
A proven understanding and track record in one of AWS, Azure, GCP, or other open-source stacks.
Object oriented programming, API integration and understanding of the modern data engineering stack.
Ability to build high quality code in Python for data integration.
Strong ability and understanding of RDBMS and SQL data structures.
Utilize scripting, library and other external programming languages to complement and enhance the functionality the data integration tools provide.
Apply scheduling, automation and innovation on new and existing data platforms for those development projects aligned to the client’s business or organizational strategies.
Participate in the requirements gathering, analysis and solutions design.
Conduct unit & integration tests, assisting in test preparations to ensure data integrity, data quality, and program functional completeness & correctness.
Create detailed technical documentation for all programs and other deliverables.
Implement processes aligned to data management best practices (as defined or adopted by the client – like DevOps, Agile) and standards, ensure data quality and process performance within all system development deliverables.
Own the responsibility to meet deadlines and strive to complete work in accordance with project plans.
Participate in the development of project plans to establish appropriate workload expectations and schedules.
Demonstrate collegial teamwork internally and with clients, by communicating clearly with all project team members to identify and resolve issues for delivery success.
Contribute to lessons learned and process improvements.
Apply new technologies to improve work efforts when available through R&D and POCs.
Maintain an up-to-date knowledge of, and adopt, relevant market trends and practices.

*
Over 2 years of Required Skills, Knowledge and Experience*

Working on technical projects as a Data Pipeline Developer/Engineer providing technical solutions through the use of Big Data Tools.
Detailed, practical working knowledge in Big Data pipeline, data query/ ingestion tools like Glue, Hive, Sqoop, Spark, Kafka, Impala. Hadoop, Oozie, Etc.
Proven experience using Restful Webservices and JSON.
Working Knowledge in Scripting languages like Python, Java, Shell, Bash, SQL Programming, creating/optimize complex queries, tables, view, and procedures
Scheduling Tools – Airflow, Luigi, Oozie, Cron
Cloud and on-premise technology from infrastructure through the technology stack like AWS, GCP or Azure
General knowledge in Data modeling, Working knowledge of data modelling and data modelling concepts such as logical/physical modelling.
Data warehousing, including data mapping and transformations, data dependencies, data source analysis and profiling
Above average skills in communication, solution-based approaches to solving problems, level-headed decision making, time management, prioritizing effectively while delivering high quality work, as well as collaborating with internal teams (Project X ltd.), external teams (non-Project X 3rdparties), and client team members
Demonstrated skills in leadership and integrity and working independently
Proven ability to meet deadlines and commitments, adaptive and flexible and approach situations with a consultative mindset
Agile delivery methodology, DevOps, Continuous Integration/Continuous Deployment concepts and method.
Testing automation and Other related or emerging technologies is an asset

Education and Experience

Bachelor's degree, preferably in Software or Computer Science/Engineering Fields or have related industry experience or acumen
2+ years of proven Data Engineering experience on AWS, Azure, GCP or other Open-Source platforms.

Work Environment
We are currently a virtual working organization. In the future we may move back to where our work takes place in office environments, either at Project X HQ or on various client sites.
In our commitment to promote fair and equitable treatment of all employees and applicants, Project X Ltd. provides equal employment opportunities for all individuals regardless of age, sex, disability, race, ethnic origin, citizenship, creed, sexual orientation, marital status or any other ground as described in the Ontario Human Rights Code. In addition, accommodation will be provided during the hiring process.
Due to the current COVID-19 pandemic:

Interview will be conducted online
Project X Ltd. Staff currently work from home

M9hgcUxWGC

Job Type: Full-time",Project X,Midtown Toronto
847,"Senior Data Engineer, Corporate Systems","Company Description


Make an impact at a global and dynamic investment organization

When you invest your career in CPP Investments, you join one of the most respected and fastest growing institutional investors in the world. With current assets under management valued in excess of $400 billion, CPP Investments is a professional investment management organization that globally invests the funds of the Canada Pension Plan (CPP) to help ensure long-term sustainability. The CPP Fund is projected to exceed $450 billion by 2025. CPP Investments invests in all major asset classes, including public equity, private equity, real estate, infrastructure and fixed-income instruments, and is headquartered in Toronto with offices in Hong Kong, London, Luxembourg, Mumbai, New York City, San Francisco, São Paulo and Sydney.

CPP Investments attracts and selects high-calibre individuals from top-tier institutions around the globe. Join our team and look forward to:

Diverse and inspiring colleagues and approachable leaders
Stimulating work in a fast-paced, intellectually challenging environment
Accelerated exposure and responsibility
Global career development opportunities
Being motivated every day by CPP Investments’ important social purpose and unshakable principles
A deeply rooted culture of Integrity, Partnership and High Performance

If you share a passion for performance, value a collegial and collaborative culture, and approach everything with the highest integrity, here’s an opportunity for you to invest your career at CPP Investments.



Job Description


The Data Engineering team is looking for people who are passionate about working in agile delivery environments and resolving the engineering challenges of building robust and scalable data systems aligned to enterprise data strategy.

As Senior Data Engineer You will be responsible for developing, constructing and testing large-scale data processing systems based on AWS cloud that will help address the disparate data consumption/integration/operation challenges of a growing organization.

Through close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 20 million CPP contributors and beneficiaries. You are encouraged to bring an entrepreneurial, innovative mindset to tackle complex business requirements in the investment industry.

The opportunity:

Design solutions aligned with long-term architecture and technology strategy using Amazon Web Services (AWS) for Cloud development.
Participate in the development life cycle from start to completion - requirements analysis, development, testing, and deployment.
Work in a fast-paced environment collaborating with developers, data engineers and architects.
Develop dataset processes for data modelling, mining and production.
Ensure architecture will support the requirements of CPP Investments business.
Prepare, transform, combine and manage structured and unstructured data for use by CPP Investments business users.
Recommend ways to improve data reliability, efficiency and quality.
Define and shape CPP Investments’ future technology and research process.


Qualifications

University degree in Engineering or Computer Science preferred.
Deep experience working with big data including cleaning/transforming/cataloging/mapping/ etc.
Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.).
Experience of ETL pipelines, managing multiple datasets and providing necessary support.
Familiarity building applications in an AWS environment
Familiarity working with data lakes using S3/Redshift.
Exposure to big data workflows and analytics tools (Spark/EMR/Databricks/Cassandra).
Deep proficiency in Python with experience using Spark, Pandas or PySpark.
Familiar with one or more analytic tools such as Tableau or Qlik.
An understanding of CI/CD pipelines and experience with DevOps.
Experience building flexible solutions that can adapt quickly to changing requirements.
Ability to work in an entrepreneurial environment and be a self-starter.
Interests in the financial industry.
Exemplify CPP Investments' Guiding Principles of Integrity, Partnership and High Performance.

Additional Information


Visit our Linkedin Career Page or Follow us on Linkedin. #LI-POST

At CPP Investments, we are committed to diversity and equitable access to employment opportunities based on ability.

We thank all applicants for their interest but will only contact candidates selected to advance in the hiring process.

Our Commitment to Inclusion and Diversity:

In addition to being dedicated to building a workforce that reflects diverse talent, we are committed to fostering an inclusive and accessible experience. If you require an accommodation for any part of the recruitment process (including alternate formats of materials, accessible meeting rooms, etc.), please let us know and we will work with you to meet your needs.

Disclaimer:

CPP Investments does not accept resumes from employment placement agencies, head-hunters or recruitment suppliers that are not in a formal contractual arrangement with us. Our recruitment supplier arrangements are restricted to specific hiring needs and do not include this or other web-site job postings. Any resume or other information received from a supplier not approved by CPP Investments to provide resumes to this posting or web-site will be considered unsolicited and will not be considered. CPP Investments will not pay any referral, placement or other fee for the supply of such unsolicited resumes or information.","CPP Investments
3.7",Midtown Toronto
848,Data Engineer (AWS),"Tiger Analytics is a fast-growing advanced analytics consulting firm. Our consultants bring deep expertise in Data Science, Machine Learning and AI. We are the trusted analytics partner for multiple Fortune 500 companies, enabling them to generate business value from data. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner. We are looking for top-notch talent as we continue to build the best global analytics consulting team in the world.
The Big Data Engineer will be responsible for architecting, designing, and implementing advanced analytics capabilities. The right candidate will have broad skills in database design, be comfortable dealing with large and complex data sets, have experience building self-service dashboards, be comfortable using visualization tools, and be able to apply your skills to generate insights that help solve business challenges.We are looking for someone who can bring their vision to the table and implement positive change in taking the company's data analytics to the next level.
Requirements
Bachelor’s degree in Computer Science or similar field
5+ years of experience in a Data Engineer role
Experience with relational SQL and NoSQL databases like MySQL, Postgres
Strong analytical skills and advanced SQL knowledge
Experience with AWS cloud services: EC2, EMR, Athena
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
Experience extracting/querying/joining large data sets at scale
A desire to work in a collaborative, intellectually curious environment
Strong communication and organizational skills
Benefits
This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility.",Tiger Analytics,Midtown Toronto
849,"Product Manager, Data","Summary

Wikimedia is looking for an experienced and collaborative Product Manager to join our Product team while working closely with our analytics engineering team, data engineering team, and numerous other teams at Wikimedia to strengthen our data and analytics products.

Wikipedia is one of the largest internet properties in the world, visited by 1 billion people a month across 280 different languages. Our properties and API's generate a huge amount of data that we process through our custom-built open-source stack. We use this data to inform our strategy, make specific product decisions, inform academic research, and, increasingly, plug this directly into the product itself.

Due to our scale, our commitment to opensource, our desire to share our data with academics, and our strict privacy restrictions, this is no easy task. In fact, today, core capabilities like A/B testing, funnel analysis, and metrics like user retention are not readily available to our teams.

You will work with experienced teams of data engineers, data scientists, analysts, and product managers to set and execute a strategy and roadmap for improving our end-to-end data infrastructure to make collecting data, processing it and using it to make decisions as efficient as possible. In doing so, you will learn from and partner with stakeholders across data science, research, design and product as well as academics and Wikimedia volunteers.

This is an opportunity to 'do good' while having a high level of impact on a large-scale media property.

You are responsible for:
Partner closely with data leaders across the organization to help define and set a coordinated data strategy across the organization
Ideate and develop data products and experiences that enable data scientists, analysts, product managers, and lay people to discover and consume information about Wikipedia.
Collaborate closely with product and engineering teams to handle new requests, prioritize work, communicate progress, and ensure that we deliver impactful work that aligns with our strategic priorities.
Understand the needs of users in order to prioritize new features
Balance privacy concerns against the value of the insights your team enables.
Del iver iterative products that drive incremental value and enable quick feedback from stakeholders wherever feasible
Use both qualitative and quantitative methods to measure the impact of your work
Work to expand global access to free knowledge!

Skills and Experience:
2+ years of experience designing and building data products that span across data analytics, data flows, etc. as a product manager or equivalent role
Proven track-record implementing complex data systems leveraging supporting data analysis, reasoning, and optimization as part of the decision making process
Expertise in data handling approaches and technologies with good understanding of system development lifecycles and modern data architectures (Data Lakes, Data Warehouse)
Experience working with structured and unstructured data
Understanding of data governance, data modeling, data pipelines, and data infrastructure
Familiarity working in an agile software development environment
Capability to work within cross-functional teams to drive results
Outstanding written and verbal communication skills with the ability to translate complex technical requirements
Bachelor's degree or equivalent in relevant work experience

Qualities that are important to us:
Problem-solver
Passionate about data and how it can be leveraged to drive data-driven decisions

Additionally, we'd love it if you have:
Background in software development, engineering, data science or analytics
Experience working with microservice architectures
Experience with open-source technology
Experience interacting with free and open-source software projects and communities
Experience editing Wikipedia or contributing to other wiki projects

The Wikimedia Foundation is...

...the nonprofit organization that hosts and operates Wikipedia and the other Wikimedia free knowledge projects. Our vision is a world in which every single human can freely share in the sum of all knowledge. We believe that everyone has the potential to contribute something to our shared knowledge, and that everyone should be able to access that knowledge, free of interference. We host the Wikimedia projects, build software experiences for reading, contributing, and sharing Wikimedia content, support the volunteer communities and partners who make Wikimedia possible, and advocate for policies that enable Wikimedia and free knowledge to thrive. The Wikimedia Foundation is a charitable, not-for-profit organization that relies on donations. We receive financial support from millions of individuals around the world, with an average donation of about $15. We also receive donations through institutional grants and gifts. The Wikimedia Foundation is a United States 501(c)(3) tax-exempt organization with offices in San Francisco, California, USA.

As an equal opportunity employer, the Wikimedia Foundation values having a diverse workforce and continuously strives to maintain an inclusive and equitable workplace. We encourage people with a diverse range of backgrounds to apply. We do not discriminate against any person based upon their race, traits historically associated with race, religion, color, national origin, sex, pregnancy or related medical conditions, parental status, sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, or any other legally protected characteristics.

If you are a qualified applicant requiring assistance or an accommodation to complete any step of the application process due to a disability, you may contact us at recruiting@wikimedia.org or (415) 839-6885.

U.S. Benefits & Perks*

Fully paid medical, dental and vision coverage for employees and their eligible families (yes, fully paid premiums!)
The Wellness Program provides reimbursement for mind, body and soul activities such as fitness memberships, baby sitting, continuing education and much more
The 401(k) retirement plan offers matched contributions at 4% of annual salary
Flexible and generous time off - vacation, sick and volunteer days, plus 22 paid holidays - including the last week of the year.
Family friendly! 100% paid new parent leave for seven weeks plus an additional five weeks for pregnancy, flexible options to phase back in after leave, fully equipped lactation room.
For those emergency moments - long and short term disability, life insurance (2x salary) and an employee assistance program
Pre-tax savings plans for health care, child care, elder care, public transportation and parking expenses
Telecommuting and flexible work schedules available
Appropriate fuel for thinking and coding (aka, a pantry full of treats) and monthly massages to help staff relax
Paid travel to Wikimedia Foundation events all around the world!
Equipment including a laptop, monitor, plus a one-time stipend to cover any additional needs to make sure you have the best work experience
Great colleagues - diverse staff and contractors speaking dozens of languages from around the world, fantastic intellectual discourse, mission-driven and intensely passionate people


Please note that for remote roles located outside of the U.S., we defer to our PEO to ensure alignment with local labor laws.
More information

Wikimedia Foundation
Blog
Wikimedia 2030
Wikimedia Medium Term Plan
Our Commitment to Equity
This is Wikimedia Foundation
Facts Matter
Our Projects
Our Tech Stack","Wikimedia Foundation
4.2",Ontario
850,Senior Cloud Data Architect,"Overview:
You’ve got big plans. We have opportunities to match, and we’re committed to empowering you to become a better you, no matter what you do.

When you join KPMG, you’ll be one of over 219,000 professionals providing advisory and business enablement services across 147 countries.

With the support to do things differently, grow personally and professionally and bring your whole self to work, there’s no limit to the impact you can make. Let’s do this.

The opportunity:

Join a growing cloud advisory focused on next-gen solutions in a fast-paced environment. We care about building great relationships and we’re looking for experienced candidates who are drawn to technology. This is a chance to get in on the ground floor and a unique leadership opportunity to be part of a team dedicated to developing tomorrow’s cloud-based solutions.

We are seeking passionate and driven individuals who bring thought leadership to the exciting space of cloud data architecture!
What you will do:
You’re a seasoned leader with a track record for enabling the adoption of next-gen data technologies within regulated industries.
You’re a builder at heart and have designed, architected, implemented, and have a track record for deploying elegant solutions to complex problems.
In your career you’ve supported enterprises in modernizing their data platforms and BI systems.
You develop proof-of-concepts to demonstrate the possibilities.
You perform data analysis, map data elements and understand core BI concepts.
You’ve been significantly involved in the migration of on-premise data silos to cloud based data lakes within the context of hybrid cloud architectures.
You have served the needs of key stakeholders in this space including application developers, data scientists and risk controls partners.
You understand the importance of data governance and data stewardship and how these concepts translate into data architecture.
You have a broad and deep understanding of Canadian enterprise landscape and ideally have finance industry experience.
You have a clear and empathetic understanding of where Canadian enterprises are in their cloud journeys, what makes them tick and how to effectively drive change.

You’re ahead of the curve and understand where the industry is going. When working with clients you strive to bring everyone with you and elevate the teams you work with.

These roles can be filled in various locations across Canada, though you will be asked to work on projects outside your local office. We are a dynamic and innovative team and equally passionate about what we do and the quality of services we provide to our clients.
What you bring to this role:
10+ years of experience in SDLC with strong emphasis on current big data technologies including cloud based services. Examples: Spark, Scala, Spark Mlib, Hadoop, Tableau, Cassandra, DataBricks, Synapse, ASDL, DataFactory, Aurora, Dynamo, Kinesis, EMR, S3, Elastic Cache, Redshift, RDS & Airflow, etc.
10+ years of factory, Informatica, Python, Cognos,
10+ managing BI Frameworks, design principles, and standards. Working with Azure (Data Lake, Hadoop, Apache, Snowflake, SQL, Oracle, MySQL, PostgreSQL, Mongo DB, and Microservices architectures)
Good understanding of Data Governance and Data Lineage and how current technology solutions intersect with these concepts in related technology platforms.
Experience implementing Big Data and Data Warehouse Architectures including relevant current and legacy patterns: Star Schema, Snow flake Schema , Fact and Dimensional Tables, Physical and Logical Data Modeling using relevant tools
Architect, design & develop big data solutions including roadmap design and development, developing supporting infrastructure, organization structures that support big data initiatives.
Architecting and implementing analytics engines, in both batch and streaming scenarios, using Hadoop MR, Oozie, Spark SQL, Spark Mlib and Cassandra, sqoop, flume, kafka, Spark Streaming, Spark Mllib, etc. Candidate should also have good understanding of public cloud platforms that provide these or competing options.
Excellent understanding of Hadoop architecture and underlying framework including Hive, HDP, Pig, Flume, Storm and Map Reduce open source tools/technologies and storage management.
Extensive experience in data modeling, data architecture, solution architecture, data warehousing & business intelligence concepts and master data management (MDM).
Expertise in architecting big data pipelines covering key milestones: ingestion, staging, cleansing, transformation, model, analyse and report.
Experienced with NoSQL databases - Hbase, Cassandra & MongoDB, database performance tuning & data modeling.
Extensive knowledge in architecture design of ETL/ELT environments leveraging popular platforms e.g. Informatica Power Center, TeraData and large data volumes.
Experience in migrating data warehouses and databases into Hadoop/NoSQL platforms in cloud environments.
Experience in financial industry is a plus.

Keys to your success:

Ability to work independently with minimal supervision as well as work effectively within a multi-disciplinary team.
Superior verbal and written interpersonal communication skill.
Excellent client service skills.
Well organized with good prioritization/workload management abilities.
Professional discipline and importance of outstanding work.
Commitment to self-learning and continuous skill and professional knowledge development.
Professional curiosity.

Learn more about where a career at KPMG can take you.



Our Values, The KPMG Way:
Integrity, we do what is right | Excellence, we never stop learning and improving | Courage, we think and act boldly | Together, we respect each other and draw strength from our differences | For Better, we do what matters

KPMG in Canada is a proud equal opportunities employer and we are committed to creating a respectful, inclusive and barrier-free workplace that allows all of our people to reach their full potential. A diverse workforce is key to our success and we believe in bringing your whole self to work. We welcome all qualified candidates to apply and hope you will choose KPMG in Canada as your employer of choice.

If you have a question about accessible employment at KPMG, or to begin a confidential conversation about your individual accessibility or accommodation needs through the recruitment process, we encourage you to contact KPMG’s Employee Relations Service team for support at email: cdnersteam@kpmg.ca or phone: 416-777-8002 or toll free 1-888-466-4778 Option 3.

For general recruitment-related inquiries, please contact the HR Delivery Centre at cafmcdnhrsthotline@kpmg.ca.","KPMG
3.9",Midtown Toronto
851,Sr Scientist Formulation,"Let’s grow tomorrow, together! Would you like to join a team of passionate people who will help you learn and actively participate in the company's success like nowhere else?
Then read on and become part of our story!

How will you help change the landscape of technology and innovative products at Medicago?

Your role:

Reporting to the Director - Formulation Development, the incumbent is mainly responsible for the planning and scientific monitoring of projects, the analysis of results and the writing of technical documents. In addition, he supports his immediate supervisor in his duties and guides team members towards achieving corporate objectives. He works in a dynamic and highly collaborative environment, where he demonstrates scientific creativity and identifies innovative solutions.


Your responsibilities:
Manage and prioritize the formulation development activities for different projects;
Prepare strategic formulation development plans and monitor internal or external projects;
Supervise and participate in the writing of protocols and technical or scientific development reports related to his sector of activity;
Collect, verify, compile and present data relating to current activities and projects;
Carry out multifactorial statistical analyzes of the ""design of experiments"" type;
Write documents to ensure the technological transfer of processes to other teams;
Supervise the activities of continuous improvement and scientific and technical innovation;
Carry out a scientific watch (publications, patents, new technologies, etc.) in connection with the development of stable formulation;
Participate in the development and monitoring of budgets.


Minimum qualifications:
PhD in science or engineering with a minimum of 10 years of experience in the biopharmaceutical or in biotechnology, and preferably in drug product formulation development, or equivalent combination of education and work experience;
In-depth expertise in the fields of protein structure and chemistry;
In-depth knowledge of analytical and biophysical protein characterization methods (UV Spectroscopy, Fluorescence, LC-SEC, DLS, MALS, DSF, DSC, AUC, CE, SDS-PAGE, …);
Expertise in the development of formulation screening tools and techniques that can predict protein stability;
Proficient with data management and analysis programs as well as statistical analyzes;
Knowledge of regulatory guidance (e.g. ICH) on the requirements for stability studies and on the use of excipients for various modes of administration (IM, SC, IV, oral);
Experience of container/closures systems for drug product;
Knowledge of freeze-drying/lyophilization of biologics, an asset;
Knowledge of GMP standards, an asset;
Training in technical writing, an asset;
Leadership and excellent verbal communication skills;
Proficiency of written and spoken English;
Excellent capacity for synthesis and analysis;
Interest in teamwork.


Medicago is changing the game!

Our Vision: A world better prepared to deal with any disease.
Our Mission: To create and deliver effective responses to new global health challenges.
Innovation, collaboration, integrity, adaptability, ownership and involvement of our colleagues are the keys to the success of our research. We have been cultivating the future together since 1999.

Medicago's journey is a story of innovation and perseverance. Even the company's name - the Latin name for alfalfa, the first plant we worked with - is a reminder of our culture of adaptability. We're proud of our humble beginnings and our current growth and global reach.

As a pioneer in transient expression and plant-based manufacturing, Medicago has always sought a more effective way to improve human health. With nearly 20 years of experience and wisdom behind us, we are poised to revolutionize the traditional approach to vaccines and therapeutics.

Medicago promotes an open and inclusive work environment for all our employees.

It is important that you are legally entitled to work in the US or Canada at the time the job offer is made to you. You may be asked to provide proof of eligibility.

#LI-CM1","Medicago
3.8",Quebec
852,Senior Data Engineer,"About Us:
Our mission at Wrapbook is to increase the prosperity of the project economy. A significant shift has occurred within the workforce recently and 50M Americans are now engaged in freelance or project-based work. The popularity of project based employment has introduced flexibility for both employers and employees but also added complexities from a compensation and administrative standpoint. Our vertical fintech platform enables companies to seamlessly onboard, pay and insure their workforces.

We're building the best product for the entertainment industry but operate in a 50B market and have big goals we want to achieve. With legacy competition slow to react and over 30M raised from Andreessen Horowitz, Equal Ventures, Uncork Capital, Jeffrey Katzenberg and CAA co-founder Michael Ovitz, we are at an exciting stage of growth and there isn't a better time to join!

The Opportunity - Senior Data Engineer (Remote - USA / CANADA)

Wrapbook is looking for a Senior Data Engineer who will play a hands-on role in driving our mission to build an outstanding technology company. You will be working as part of a cross-functional team, building high quality data architecture. More than just understanding the strategic importance of data, you're eager to roll up your sleeves and build the infrastructure to support it. You will take complex product roadmap features and will be engaged in identifying, designing, and implementing process improvements for the team.

What you'll Do:
Build and deliver high quality data architecture to support data analysts
Design, implement, and maintain low-latency ETL pipeline from different data sources (e.g RDS, Salesforce, Zendesk, Google Analytics, etc)
Design data pipelines to extract data from a variety of sources, including unstructured, semi-structured, and fully structured data
Maintaining data infrastructure to keep up with the product roadmap
Work closely with data analyst on testing and deciding on what BI tools to use
Partner with our DevOps engineers to build a secure infrastructure for our data stack

What you'll Have:
3+ years of experience building and optimizing data pipelines, architectures, and data sets
Experience using any cloud platform such as AWS, Azure or Google Cloud
Experience working with relational databases (e.g. MySQL, PostgreSQL)
Demonstrated experience with data modeling, ETL and data performance tuning
Experience using Python for data processing
Exceptional communicator with the ability to translate technical concepts into easy to understand language for our stakeholders.
Desire to continuously learn how to implement the latest tech and analytical tools into our tech stack
Ability to think holistically about uses of data, designing for ease of data access
A degree in Computer Science, Mathematics or related field is preferred

Why Join Us:
At Wrapbook, creativity meets technology — and not just in the product.

In addition to a competitive salary and all the benefits you can expect from a fast-growing technology company, you'll get access to a team of creative problem solvers and the chance to see your contributions make large impacts Benefits include:

Unlimited Paid Time Off
Work from anywhere in Canada and USA
Health and Dental benefits
IT set up for your home
401k and RRSP
Learning and Development Allowance

Our Pledge to Fostering an Inclusive and Safe Workplace:
Wrapbook pledges to be a harassment- and discrimination-free space for everyone, regardless of age, disability, ethnicity, gender identity or expression, nationality, neurotype, personal appearance, political affiliation, professional background, race, religion, or sexual identity or orientation.

Apply Now

Have we got your attention? Submit your application today and a member of our Talent team will be in touch with you shortly!","Wrapbook
5.0",Ontario
853,Senior Data Engineer,"About Us:
Our mission at Wrapbook is to increase the prosperity of the project economy. A significant shift has occurred within the workforce recently and 50M Americans are now engaged in freelance or project-based work. The popularity of project based employment has introduced flexibility for both employers and employees but also added complexities from a compensation and administrative standpoint. Our vertical fintech platform enables companies to seamlessly onboard, pay and insure their workforces.

We're building the best product for the entertainment industry but operate in a 50B market and have big goals we want to achieve. With legacy competition slow to react and over 30M raised from Andreessen Horowitz, Equal Ventures, Uncork Capital, Jeffrey Katzenberg and CAA co-founder Michael Ovitz, we are at an exciting stage of growth and there isn't a better time to join!

The Opportunity - Senior Data Engineer (Remote - USA / CANADA)

Wrapbook is looking for a Senior Data Engineer who will play a hands-on role in driving our mission to build an outstanding technology company. You will be working as part of a cross-functional team, building high quality data architecture. More than just understanding the strategic importance of data, you're eager to roll up your sleeves and build the infrastructure to support it. You will take complex product roadmap features and will be engaged in identifying, designing, and implementing process improvements for the team.

What you'll Do:
Build and deliver high quality data architecture to support data analysts
Design, implement, and maintain low-latency ETL pipeline from different data sources (e.g RDS, Salesforce, Zendesk, Google Analytics, etc)
Design data pipelines to extract data from a variety of sources, including unstructured, semi-structured, and fully structured data
Maintaining data infrastructure to keep up with the product roadmap
Work closely with data analyst on testing and deciding on what BI tools to use
Partner with our DevOps engineers to build a secure infrastructure for our data stack

What you'll Have:
3+ years of experience building and optimizing data pipelines, architectures, and data sets
Experience using any cloud platform such as AWS, Azure or Google Cloud
Experience working with relational databases (e.g. MySQL, PostgreSQL)
Demonstrated experience with data modeling, ETL and data performance tuning
Experience using Python for data processing
Exceptional communicator with the ability to translate technical concepts into easy to understand language for our stakeholders.
Desire to continuously learn how to implement the latest tech and analytical tools into our tech stack
Ability to think holistically about uses of data, designing for ease of data access
A degree in Computer Science, Mathematics or related field is preferred

Why Join Us:
At Wrapbook, creativity meets technology — and not just in the product.

In addition to a competitive salary and all the benefits you can expect from a fast-growing technology company, you'll get access to a team of creative problem solvers and the chance to see your contributions make large impacts Benefits include:

Unlimited Paid Time Off
Work from anywhere in Canada and USA
Health and Dental benefits
IT set up for your home
401k and RRSP
Learning and Development Allowance

Our Pledge to Fostering an Inclusive and Safe Workplace:
Wrapbook pledges to be a harassment- and discrimination-free space for everyone, regardless of age, disability, ethnicity, gender identity or expression, nationality, neurotype, personal appearance, political affiliation, professional background, race, religion, or sexual identity or orientation.

Apply Now

Have we got your attention? Submit your application today and a member of our Talent team will be in touch with you shortly!","Wrapbook
5.0",Ontario
854,Big Data Solution Architect - Verdun,"About the role:

Do you have a solid experience in Big Data and would like to exploit it by designing innovative and innovative solutions?
Do you want to influence the Bank's IT strategies and orientations?
Do you want to use your expertise to build the digital bank of tomorrow?
The IT - Advanced Analytics Ecosystem team is looking for a Big Data Solutions Architect to join a project at the heart of our data strategy. We need someone who is creative in designing analytical solutions, able to deliver concrete results while meeting commitments, and able to collaborate with pleasure and efficiency in multidisciplinary teams.
Working within an architectural team means being at the center of the Bank's transformation and playing a key role in the design of secure and forward-thinking solutions.

More details on responsibilities:

In collaboration with domain architecture, development teams and operations, design and implement complex big data solutions.
Define big data and analytics strategy using relevant technologies and analytics industry trends.
Lead the implementation of the strategy defined in the design and architecture of the components of the customer analytical platform using Cloud infrastructures (Azure, AWS) as well as several software components required by data scientists.
Lead the design of reference architecture models for the integration of structured and unstructured data
Define technical evaluation criteria for the selection of products and technologies and to determine the technical approaches to be favored for the solutions to be successful, within a design of coherent systems.
Participate and execute proof-of-concept exercises for the adoption of new big data management technologies, software engineering tools and new models within current structures.
Use its influence to recommend methods to improve the reliability, efficiency and quality of data.
Follow the implementation of solutions until their deliveries while ensuring compliance with established architectures (corporate architecture).

What you are offering:

Completed Bachelor's degree, related to the industry, and 10 years of relevant experience or Completed Master's degree, related to the industry and 7 years of relevant experience
Experience and knowledge of Azure cloud, AWS.
Experience in establishing architectures related to data security, firewalls, encryption, identity and access management (IAM), networks, compliance (SOX / HIPPA / PII) and protection Datas
Hands-on experience with several big data tools (Spark, Kafka, Snowflake, Databricks, Qlik)
Experience in designing data pipelines and automating big data platform applications / services using Python, PySpark, SQL and Javascript; and in their automation through development and operations processes and tools (DevOps)
Experience with Git, Ansible, Terraform, Jenkins in mission critical production environments desirable.
Excellent knowledge of container management practices and tools (Docker, Kubernetes).
Excellent knowledge of architecture design, data modeling and implementation of big data platform architectures and analytical applications.
Knowledge of and experience with advanced analytical capabilities, including machine learning using supervised and unsupervised techniques

Advantages


Responsibilities


Qualifications


Summary
","Randstad
4.2",Verdun
855,Data Science Architect,"As a full spectrum AWS integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. We take customers on their journey to enable, operate, and innovate using cloud technologies – from migration strategy to operational excellence and immersive transformation.

If you like a challenge, you’ll love it here, because we’re solving complex business problems every day, building and promoting great technology solutions that impact our customers’ success. The best part is, we’re committed to you and your growth, both professionally and personally.



Overview

As a Data Science Architect, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role in delivering modern data solutions for clients including data ingestion/data pipeline design and implementation, data warehouse & data lake architectures, cognitive computing and cloud services. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

If you get a thrill working with cutting-edge technology and love to help solve customers’ problems, we’d love to hear from you. It’s time to rethink the possible. Are you ready?
What you’ll be doing:
Lead, define and implement end-to-end modern data platforms in support of analytics and AI use cases
Collaborate with enterprise architects, data architects, ETL developers & engineers, data scientists, and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities
Address aspects such as data privacy & security, data ingestion & processing, data storage & compute, analytical & operational consumption, data modeling, data virtualization, self-service data preparation & analytics, AI enablement, and API integrations
Be the technical liaison between customers and engineering teams
Directly collaborate with the sales team to formulate and execute a sales strategy to facilitate the adoption of AWS and big data technologies and help build offerings
Be an AWS evangelist by educating a variety of customers on the value of AWS and AWS’s Data services
Traveling up to 50% of the time
Qualifications & Experience:
5+ years experience leading engagements from design to implementation of creative data solutions leveraging the latest in Big Data frameworks, supporting on-premise, cloud (Ideally AWS) and hybrid architectures to enable use cases in analytics and AI
5+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads
3+ years experience with analytics/data management strategy formulation, architectural blueprinting, business case development and effort estimation of disruptor based analytics
3+ years working in the cloud or multi-server complex environments. Experience with AWS a requirement.
Ability to simplify complex technical concepts into an easy-to-understand non-technical language in order to facilitate, communicate and interact with executives and business stakeholders
Experience with Agile development methods in data-oriented projects
Strong candidates will also have some of the following capabilities:
Strong SQL, Database, Data Modeling, Data Warehousing and Development skills
Strong programming / scripting experience using various languages such as Java, .NET, Python, Scala, Javascript, etc.
Experience in Cloud Big Data & Analytics Services on the cloud (AWS preferred ie. S3, Redshift, Athena, EMR, Glue, Quicksigh,, etc.)
Experience with Dashboarding and Reporting Tools used in the Industry (Tableau, Qlik, etc.)
Experience with industry ETL tools (Informatica, Talend, SSIS, etc.)
Have strong people management skills: leading teams, training, onboarding, offboarding, etc.
Certifications in architecture, data engineering and development from AWS (Preferred)
Subject matter data expertise in Financial Services (Banking, Insurance), Consumer Products (Retail), Energy & Resources, Life Sciences (Healthcare) and Government (Transport, Higher Ed, Social Services) industries
Experience with implementation of data security, encryption, PII/PSI legislation, identity and access management across sources and environments
Knowledge of software configuration management environments and tools such as JIRA, Git, Jenkins, TFS, Shell, powershell, Bitbucket, etc.
Educational Qualifications:
Bachelor’s Degree or higher in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or a related field is desired
#Onica
#LI-Remote
#LI-VM

About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.


More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.","Rackspace
3.5",Midtown Toronto
856,Big Data Engineer,"Who we are:
Semios is a market leader in leveraging the internet-of-things (IoT) and big data to improve the sustainability and profitability of specialty crops. With 500 million data points being reported by our sensors every day, we leverage our big data analytics, such as in-depth pest and disease modeling, to empower tree fruit and tree nut growers with decision-making tools to minimize resources and risks.
Check this video out as it shows what we do and our positive environmental impact!

Our innovative work has received several industry awards:
THRIVE - Top 50 Leading AgTech (2020) – recognized as exemplifying some of the best in agriculture technology around the globe.
Global CleanTech Top 100 (2020) – identified as one of the companies best positioned to solve tomorrow’s clean technology challenges.
Google Accelerator (2020) - Selected as 1 of 9 companies for the inaugural Google for Startups Accelerator Canada cohort, who are all using technology to solve complex challenges.
We know our journey is only achievable by having a great team who shares ideas, tries new things and learns as we go.

Who you are:
Motivated by meaningful work, you are looking for more than just a job; you want to work for a dynamic, growing company that finds solutions to real-life problems, such as helping the world reduce the use of pesticides and helping nature feed a growing population. Your ideal work environment includes a collaborative team spirit with the opportunity to learn and grow as you take the initiative to try new things.

You are looking to make a difference, you want to know your work with big data has real world benefits. You are curious, eager to learn and collaborative. You are excited to contribute to the future of Semios’ data engineering approaches and infrastructure.

What you will do:
The DI team at Semios plays a very important role in shaping the various products and features that the company provides to customers. We as a team are growing very rapidly, so you will always have the opportunity to contribute towards shaping the architecture, design and scalability of our processes and pipelines. You will collaborate with a very passionate and diverse group of individuals that love Data Engineering, and work with the latest technologies in the industry. As a Big Data Engineer, you have the opportunity to help design and build complex and exciting data engineering solutions to help growers make data driven decisions, which in turn will have a real-world impact on peoples’ lives and in agriculture.

Requirements

We want you to succeed, so you will need:
Fluency in Python and popular data packages including object oriented programming techniques.
Advanced SQL knowledge and direct experience working with relational databases, data warehouses, and NoSQL stores.
Professional experience developing data solutions on cloud platforms like GCP or AWS.
Professional experience with workflow management tools like Airflow, Prefect, and/or Dagster.
Excellent verbal and written communication skills with a talent to distill complex ideas to different audiences.
Flexibility in working both autonomously and within a team environment.
Solid understanding of data benchmarking and performance tuning.
Excellent troubleshooting skills to rapidly identify and resolve issues.
Ability to evaluate new technologies, determine suitability, and integrate into the environment effectively.

Nice to have:
Advanced Education or Certificate(s) in Big Data.
Google BigQuery.
Experience with analytics engineering tools (dbt).
Experience with container management systems like Kubernetes, Helm, and/or Docker-compose.
Experience working in Agile methodology.
Knowledge of Project Management Tools like JIRA and/or Confluence.
Knowledge of Data Visualization & Charting tools like BI Systems, Matplotlib, and/or Seaborn.
Benefits

Why this is the opportunity for you:
Sleep better knowing you're making the world a better place through more sustainable food production
Work with a team that values fun, laughter, and each other
Have a lasting impact as you help to build a company
Learn a lot along the way!",Semios,Vancouver
857,Ingénieur de données I / Data Engineer I,"Role and Responsibilities


(English will follow)


Ingénieur de données


Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.


Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!

Regardez la vidéo d’un/e collègue qui partage sa passion : https://www.youtube.com/watch?v=DuWzMIEZ_9I&list=PL20BE384270BA6C02&index=2&t=0s

Travail significatif qui favorise le perfectionnement professionnel

Possibilité de travailler dans l’industrie technologique et de s’y épanouir

Environnement de travail axé sur la collaboration

Faire partie d’une équipe à haut rendement


Ce que nous avons à offrir

Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important

Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif

Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise

Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires

Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année

Plaisir au travail : Activités sociales et communautaires tout au long de l’année!


Votre mission

En tant qu’ ingénieur des données au sein de notre équipe de l’accélérateur numérique, votre mission est d’améliorer l’expérience client en faisant la transformation des données dans un format pouvant être exigeant sur un certain nombre de plans pour d’autres intervenants en analyse. Cela sera accompli principalement par l’élaboration, l’entretien et la mise à l’essai d’infrastructures destinés à la production de données. Cette équipe jouera également un rôle important dans la promotion de solutions d’architecture pour des projets de science des données et de modélisation avancée.


Votre rôle et responsabilités principales

Créer et maintenir une architecture de pipeline de données optimale et évolutive.

Assembler des ensembles de données complexes qui respectent les exigences opérationnelles fonctionnelles et non fonctionnelles.

Concevoir l’infrastructure requise pour l’extraction, la transformation et le chargement de données optimaux à partir d’une grande variété de sources de données et de technologies de « données massives ».

Définir, concevoir et mettre en œuvre des améliorations de processus internes : l’automatisation des processus manuels, l’optimisation de la transmission de données, la nouvelle conception de l’infrastructure pour une plus grande évolutivité, etc.

Mettre au point des outils d’analyse qui utilisent le pipeline de données pour fournir des perspectives applicables en matière d’acquisition de clients, d’efficacité opérationnelle et d’autres mesures clés du rendement opérationnel.

Travailler avec des intervenants, y compris les équipes de la direction, de l’expérience client et de la conception pour les assister dans la résolution de questions techniques liées aux données et le soutien de leurs besoins en infrastructure.

Maintenir les données séparées et en sécurité à travers les frontières nationales par l’entremise de plusieurs centres de données.

Travailler avec des experts en données et en analyse pour parvenir à une meilleure fonctionnalité de nos systèmes de données.

Être un agent de changement et un promoteur de la mentalité agile

Contribuer au milieu de travail collaboratif et stimulant

Se garder à l’affût des nouvelles tendances et apporter des idées d’innovation


Vos qualifications

Baccalauréat en informatique, en ingénierie ou un domaine connexe

Au moins trois (3) ans d’expérience dans l’industrie en matière de travail avec des données, de code, de création de scripts (Python/Java/Scala/SQL/JS/Bash), de conception, et de mise à l’essai

Au moins trois (3) ans d’expérience en matière d’élaboration et d’administration de gros systèmes de données

Solides connaissances des principes fondamentaux du soutien à la clientèle en matière d’algorithmes et de structures de données.

Expérience en soutien et en travail avec des équipes interfonctionnelles dans un environnement dynamique Expérience en utilisation d’outils de traitement de données massives : Hadoop, Spark, Kafka, etc.

Expérience en utilisation de bases de données relationnelles SQL et NoSQL, y compris Postgres et Cassandra.

Expérience en utilisation de pipelines de données et d’outils de gestion du flux de travail : Azkaban, Luigi, Airflow , etc.

Expérience en utilisation de services infonuagiques AWS : EC2, EMR, RDS, Redshift

Expérience en utilisation de services infonuagiques Microsoft : Azure, Databrick , etc.

Expérience en utilisation de systèmes de traitement de flux : Storm, Spark-Streaming, etc.

Expérience en utilisation de langages de script orientés objet et à fonction d’objet : Python, Java, C++, Scala, etc.

Volonté de participer à tous les niveaux de l’exécution des travaux liés à un projet, au besoin

Excellentes aptitudes pour la communication verbale et écrite, en français et en anglais


À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Camille Launay, spécialiste de l’acquisition de talents ( camille.launay@cae.com ) ou Feriel Hadjloum, Gestionnaire de produits numériques ( feriel.hadjloum@cae.com ).


Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.

#LI-CL1


******************************************************

Data Engineer


If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.


Here are few reasons why folks love working at CAE !

Watch the video of a colleague sharing his/her passion: https://www.youtube.com/watch?v=DuWzMIEZ_9I&list=PL20BE384270BA6C02&index=2&t=0s

Meaningful work that drives professional development

Ability to enter and grow within the technology industry

Work in a collaborative environment

Be part of a high-performance team


What we have to offer

Benefits: fully flexible for you to choose what is important

Retirement: Defined Benefits Retirement Plan & Group Reg istered Retirement Savings Plan (RRSP)

Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts

Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan

Work-Life Balance: Flextime & California Fridays all year

Fun at work: social and community events all-year round !


Your mission


As a Data Engineer you will be asked to transform data into a format that can be consuming for other analytics stakeholders. This should be accomplished mainly through developing, maintenance and testing infrastructure for data generation. You will also play an instrumental role enabling architecture solutions for Data Science and advance modelling projects.


Your Role & Main Responsibilities


Create and maintain optimal and scalable data pipeline architecture

Assemble large, complex data sets that meet functional / non-functional business requirements

Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and ‘big data’ technologies.

Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.

Work with stakeholders including the Executive, CX and Design teams to assist with data-related technical issues and support their data infrastructure needs.

Keep data separated and secure across national boundaries through multiple data centers.

Work with data and analytics experts to strive for greater functionality in our data systems.

Be a change agent & Agile mindset promoter

Contribute to the collaborative and stimulating work environment

Be connected to the industry to know tendencies and suggest innovative ideas


Your Qualifications


Bachelor's degree in Computer Science, Engineering, or related field

A minimum of 3 years industry experience working with data, coding and scripting (Python/Java/Scala/SQL/JS/Bash), design and testing

A minimum of 3 years experience developing and administering large data systems

Solid knowledge of CS fundamentals in algorithms and data structures

Experience supporting and working with cross-functional teams in a dynamic environment.

Experience with big data tools : Hadoop, Spark, Kafka, etc.

Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.

Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.

Experience with AWS cloud services: EC2, EMR, RDS, Redshift

Experience with Microsoft cloud services: Azure, Databrick, etc.

Experience with stream-processing systems: Storm, Spark-Streaming, etc.

Experience with object-oriented / object function scripting languages : Python, Java, C++, Scala, etc.

Willingness to participate in all levels of project work when necessary

Excellent English and French written and verbal communication skills.


At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Camille Launay , Talent Acquisition Specialist ( camille.launay@cae.com ) or Feriel Hadjloum, Digital Product Manager ( feriel.hadjloum @cae.com ).


Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.


Position Type


Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.","CAE Inc.
3.8",Saint-Laurent
858,Head of International Analytics & Data Science,"About the Role
The Analytics & Data Science team is looking for an individual to lead our International Analytics team. This role is critical for DoorDash as we expand our logistics platform into new countries. This individual will lead a team that works cross functionally with product management, strategy & operations, marketing, analytics, and senior leadership to accelerate growth in our current international markets (Canada and Australia) and lead the strategy and execution of new market launches (more coming!)
As a leader on the Analytics & Data Science team, you’ll use your quantitative background to lead & mentor other data scientists and dive into large datasets to guide decision-making. You won’t simply copy & paste what worked in the US to other countries--you’ll need to understand the unique needs of each countries’ users and evaluate the needs of all three sides of the marketplace: consumers, merchants, and Dashers.
You’ll manage, hire, and lead a global team to tackle a multitude of exciting challenges including opportunity sizing, experimentation, and ongoing tracking of our business progress and product-market fit in countries around the world. You’re excited about this opportunity because you will… Build and lead a global team that creates quantitative analysis to provide insights that help marketing, business, and product leaders understand performance, customer quality, & user behaviors Work closely with our Product Management, Engineering, and Strategy & Operations teams to build best-in-class and beloved products while finding + scaling product-market fit in countries around the world Create full-cycle analytics experiments, reports, and dashboards using SQL, R, Python, or other scripting and statistical tools Present in key meetings and business reviews with our executive team and founders Be excited to travel (when it’s safe!) to meet with business partners and the team in each market Build a world class international team that includes hiring new leaders as well as mentoring junior analysts on how to use more advanced methods We’re excited about you because you have… A degree in Math, Physics, Statistics, Economics, Computer Science, or similar domain (Ph.D., Master’s or advanced degree preferred) 10+ years of experience in data analytics, data science, consulting, or related quantitative role 5+ years of direct people management experience in Analytics Prior experience in building a B2C business from scratch with a focus on a dynamic marketplace, logistics or economics environment desired but not required Expertise with SQL queries, ETL, A/B Testing, and statistical analysis (e.g. hypothesis testing, experimentation, regressions) with statistical packages, such as Matlab, R, SAS or Python Proficiency in one or more analytics & visualization tools (e.g. Chartio, Looker, Tableau) The insight to take ambiguous problems and solve them in a structured, hypothesis-driven, data-supported way A self-starter with the determination to initiate and lead projects to completion in a scrappy environment Prior experience working abroad or in international expansion preferred but not required Fluent English required, proficiency in additional languages a plus Why You’ll Love Working at DoorDash We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies. We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day. We are learners - Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are customer-obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility. We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.
We offer great compensation packages and comprehensive health benefits. About DoorDash
DoorDash is a technology company that connects customers with their favorite local and national businesses in all 50 US states, Canada, and Australia. Founded in 2013, DoorDash empowers merchants to grow their businesses by offering on-demand delivery, data-driven insights, and better in-store efficiency, providing delightful experiences from door to door. By building the last-mile delivery infrastructure for local cities, DoorDash is bringing communities closer, one doorstep at a time. Read more on the DoorDash Engineering blog or at www.doordash.com . Our Commitment to Diversity and Inclusion
We’re committed to growing and empowering a more inclusive community within our company, industry, and cities. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.","DoorDash
4.0",Midtown Toronto
859,"Director, Data Sciences","Full-timeVancouver




JUNE 14, 2021

Job ID: 21291

AbCellera is a young, energetic, and rapidly growing biotech company with an amazing team that searches, decodes, and analyzes natural immune systems to find antibodies that its partners can develop into drugs to prevent and treat disease.

We are seeking a Director, Data Sciences to manage and unify the interrelated projects between the diverse teams within the Department of Data Sciences (DSCI). This person will be accountable for the project portfolio within DSCI: management, execution, translation, continuity, improvement and life cycle. This position will be key to integrate, unify and align the portfolio of interrelated projects, tools and required infrastructure across the DSCI teams. We are seeking an experienced manager with a scientific and technical background, as well as knowledge of how to manage, productionize, maintain continuity of, and integrate technically diverse but interrelated systems projects. This position will report to the CTO and manage the Team Leads & Group Leaders of the five DSCI teams.

How you might spend your days:

Overseeing the Department in the development of new insights and tools and advanced data science capabilities
Playing a strategic role to build and manage cross-team data integration, data visualization, dashboards, predictive analytics, and data mining
Distilling project requirements into problem definitions, dealing with ambiguity and competing objectives
Communicating the findings to key stakeholders through reports and presentations
Collaborating with Department leads and key stakeholders to create a unified roadmap tailored to constantly aid the DSCI teams, end users and partners

We'd love to hear from you if you have:

A master’s degree (PhD preferred) in Statistics, Machine Learning, Mathematics, Computer Science, Statistics Economics, or similar
At least 10 years of working experience in Data Sciences, with at least 5 years experience in managing Machine Learning Scientists, Data Scientists, Research Scientists, Applied Scientists, or similar
4+ years of academic or industry experience in a scientific sector (life sciences, physics, chemistry, healthcare or biotech)
Exceptional communication skills to convey technical messages in a clear and understandable manner, leading to business-wide understanding of Departmental performance.
Has experience with data services, data architecture and integration of infrastructure, tools and project portfolios
Possess superior computer and technological knowledge/skills and have passion for analytics and software architecture.
Proficiency in one or more scripting languages
Exceptional leadership skills, ability to lead a cross-functional group in a unified direction as well as an ability to influence leadership and executives. Must demonstrate an ability to form strong and meaningful connections with others.
Software project management skills an asset

Offers & benefits:

The opportunity to work with an inspired team on challenging problems that matter
An attractive compensation package, including health and lifestyle benefits
A minimum of 4 weeks’ vacation
Opportunities for personal and professional development

About AbCellera:

At AbCellera, we’re solving tough problems and creating innovative solutions from the ground up - custom immunizations, microfluidics, high-throughput imaging, genomics, computation, machine learning and laboratory automation. We’re revolutionizing how our scientists can explore antibodies and the scale at which they can do so. This is life-changing research and you could be a part of it.

You’ll join a diverse and multi-disciplinary team of biologists, biochemists, engineers, bioinformaticians, computer scientists and physicists - all working together to bring better therapies to patients. We’re a growing company with a high-throughput pipeline and the drive to be the best in the industry. This isn’t just about having the best technology. We know we need a world-class team of visionaries and innovators. We look for people with drive and energy. Idealists. People we love and people we trust. This may be unconventional, but it is the key to our success. We’re looking for someone like you to help us get there.

To apply:

Please send us your application through our website and refer to Job ID 21291 in your cover letter. We apologize in advance, but we receive a large volume of applications, and will only contact those who are selected for an interview.","AbCellera Biologics
4.8",Vancouver
860,Data & AI Strategy Manager,"We are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Accenture Applied Intelligence

You are:
A consultant that other consultants admire. You’ve spent years helping clients use analytics to make their companies more effective and more efficient. Clients listen to you and rely on you to guide them through crucial digital transformations.

The work:

Work with clients to understand how analytics can help their businesses retail, financial, health or government
Be a thought leader for data and analytics that fit your industry specialization
Help generate insights and recommendations for clients
Guide the early stages of data and analytical transformations
Help senior clients understand and use data-driven strategies in new ways and markets
Get data, analytics and AI projects across the line for clients
Manage and motivate teams



Here’s what you need:

A Bachelor's degree in a quantitative field like statistics, econometrics, mathematics, engineering
At least 5 years working as a consultant helping clients, building strategies, designing and using data and analytics, especially in a professional services environment
At least 5 years running business transformation and data management projects
At least 3+ years' experience with major cloud technologies – conceptual (helping enable end-to- end data journeys in the cloud)

Bonus points if:

Exceptional presentation skills – ability to convey technology and business value propositions (how to take data and insights turning them into action and business value for clients)
Experience in foundational data capabilities such as data management, data governance, visualization and data science
Ability to understand and apply statistical methods and outputs to create client value in a business context
Experience with evolving approaches and technologies such as Big Data, Artificial Intelligence, Machine Learning, Cognitive Systems, and Robotics
Handling different projects at the same time comes easily to you","Accenture
4.1",Montreal
861,Data Engineer - Remote within Canada,"The data engineer is a critical role for TGOD as our business hits unprecedented scale. You will provide and grow in-house expertise on ELT/ETL formulations and API interactions. Our data is a critical business asset – how we handle and manage that data must enable our agile business and be compliant with laws/regulations to preserve its confidentiality, availability and integrity. This role forms part of TGOD’s data science functions and will support the director of data science in leading and managing all data related activities including business intelligence.

Key Responsibilities

Support and develop data pipelines for all core systems and 3rd party integrations into the data lake and analytics database.
Leverage API endpoints for operational use of centralized data assets
Develop broad domain and technical knowledge in AWS solutions.
Demonstrate strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.

Basic Qualifications

Bachelor's degree in Computer Science, Information Systems Management, IT Security, Finance, Technology or related field; or 3 years relevant work experience in a data-related field
2+ years Python, SQL (Redshift, Postgres) is a must. Strong ELT/ETL background
1+ years using APIs for data extract and load (Postman, Lambda)
1+ years with linux shell/bash for automation and server administration
Experience with Apache Airflow and Docker is preferred
Experience with web scraping is preferred
Experience in the BI/Analytics/Data Warehousing space is preferred
Experience with Amazon Web Services ecosystem (Redshift, S3, Fargate, EC2, EFS, Lambda, Cloudformation, Cloudwatch, VPC, Codecommit, SES, SNS) and general cloud architecture
Demonstrate critical inquiry with attention to detail
Ability to effectively articulate recommendations/conclusions verbally and in writing

Preferred Qualifications

Tableau server(Ubuntu) and Tableau desktop
SAP HANA cloud data model, data extraction and API use cases
Version control best practices
Highly independent, organized and efficient.
Snowflake data warehouse
Data presentation skills to both business and technical teams.

Job Types: Full-time, Permanent

Benefits:

Dental care
Employee assistance program
Extended health care
Life insurance
Paid time off
Vision care
Work from home

Schedule:

Monday to Friday

Experience:

Python: 2 years (preferred)
AWS cloud: 1 year (preferred)
Linux: 1 year (preferred)
Snowflake: 1 year (preferred)

Work remotely:

Yes","The Green Organic Dutchman
4.2",Mississauga
862,"Senior Data Engineer, ClearAngel","ClearAngel is building YC for the 99% of founders. Those who traditionally don't have access to advice, capital or network -- we want to support that long tail.

Most founders don't live in Silicon Valley or have the pristine pedigree to get in front of the ""right"" people. For far too long, startups have played on a scarcity model.

This is limiting the potential of founders. We fundamentally believe that great founders and companies are everywhere. Where there are problems, opportunities exist. We want to empower those founders.

We are building ClearAngel to democratize access to advice, network and capital.

We do this by scaling access to the rest of the world:
Access to advice (knowledge, resources)
Access to network (intros, people, community)
Access to capital

The role of the Senior Data Engineer is to lead and build pipelines and solutions for the analytic and product challenges surrounding the features and vision of the Clear Angels product and platform. Your responsibilities will be a superset of a typical Senior Data Engineer, as there are often experiments and uncertainty that require creative solutioning at the earliest stages.

Responsibilities:
You will own data products end to end, from design and architecture to deployment and maintenance, leading others where necessary through development
Working closely with every member of the team, vendors and external partners, you will produce significant components of the ClearAngel code
Collaborate with all functions of Clearco, ranging from core Engineering team to Data Science team to the marketing team
You be in constant communication with the team to understand what features of the platform need to be built out, and solve bug fixes when necessary
You will scope out business needs for ClearAngel, and action them with speed and accuracy and then lead and execute on it yourself.
You will run and participate in founder townhalls, communicating closely with early-stage entrepreneurs
When it comes to product and engineering on ClearAngel, buck stops with you. Coordinate, roll up your sleeves, do what's necessary to get the ball moving forward

What we look for:
Great communication skills, with a desire or experience to lead a small team of other devs in the near future
Desire to help founders. We take a strong founder first stance on this team
Be self sufficient when it comes to execution. Figure out how to solve problems and make things happen, not waiting for help or permission
On this team, we maximize learning. You will fail if you're not learning fast enough
Comfort working in a high growth, constantly changing environment
Heavy bias towards action. Ability to solve problems end-to-end on their own. You will implement ideas and experiments on your own with minimal support
Have experience working in a senior software engineering role, you are an expert when it comes to coding and you're ready to roll up your sleeves to get the job done!
Have a strong business sense, you can foresee potential issues and solve them quickly
Demonstrated ability to collaborate effectively across multiple teams
Strong interest in building businesses, ecommerce and fintech

Technical Requirements:
Ideally, you have worked on 3 or more different stacks in your career in a professional setting for at least 8 months each. This means you probably have between 2 years and 6 years of experience. Bonus points for systems managing time-series
Able to architect and scale data integrations (shopify, paypal, plaid, etc.) from third-party API docs independently, extracting the right business value for the vision and roadmap of Clear Angel
Interested and able to prototype solutions that might not scale to 1,000,000 users but can get the job done while we derisk the business outcomes
Comfortable working in server and database environments that are changing constantly
Comfortable in a fast pace, changing roadmap team building the plane after jumping off the cliff
Comfortable with relational databases and schemas involving time-series
Skills and interest in Python, SQL, Snowflake, Kubernetes and pipeline management/orchestration tools (Eg. Airflow)","Clearco
3.9",Ontario
863,Data Driven Marketing Analyst,"Our culture lifts you up—there is no ego in the way. Our common purpose? We all want to win for our customers. We aim to always be evolving, dynamic, and ambitious. We believe in the power of genuine connections. Each employee is a part of what makes us unique on the market: agile, dedicated, problem solvers.

Time Type:
Regular

Job Description :

SOMMAIRE DES RESPONSABILITÉS DU POSTE :

As Marketing Data Driven Analyst, you will play an active role in Cogeco’s Marketing strategies. Reporting to the Director of Data Driven Marketing & Media ROI, your role will be to support Cogeco’s marketing team to better understand marketing performance and identify opportunities. Recognized as a growth hacker, you will access multiple data sets to help understand performance, identify trends and room for optimisation. You will work in close collaboration with Data Scientists, media and marketing specialists to make sure data is at the center of our decision process and to generate insights.

PRINCIPALES RESPONSABILITÉS:

Work with stakeholders throughout the Digital sales and marketing team and regional managers teams to identify opportunities for leveraging company data to drive data driven marketing campaigns.

Analyze closely the data from the company marketing campaigns and customer base to drive optimization and improvement of campaigns and business strategies.

Interpreting data, analyzing results using statistical techniques.

Identify, analyze, and interpret trends or patterns in complex datasets.

Support business users to make sure that they become self sufficient and autonomous from an analytics perspective.

Coordinate with different functional teams to make, implement or present marketing campaign dashboards, reports and other data visualizations.

Develop processes and tools to monitor business performance.


EXIGENCES ESSENTIELLES:


FORMATION ACADÉMIQUE

Master in BI, Machine Learning, Data Science, Mathematics, Computer Science.

EXPÉRIENCES DE TRAVAIL

3-5 years as leading a data function in industry.


COMPÉTENCES PARTICULIÈRES:

Knowledge of data science frameworks: SQL, R, Python, Spark, Scala, or equivalent.

Knowledge of visualization tools such as Tableau, Power BI, Qlik or equivalent.

Understanding of best practices in visualization, KPI definition and storytelling.

Ability to help internal customer to become more autonomous and empathy towards the end users of dashboards and reports.

Strong problem solving, time management and work organization skills.

Strong knowledge of statistics.

Solid understanding of modern data infrastructure. Skills with in Google Cloud Plateform, Big Query.

Ability to combine qualitative and quantitative insights.

Strong business and product intuition.

Understanding of broad spectrum of methods and disciplines in data science, and the applicability of different techniques for different contexts, e.g. not just focused on deep learning.

Constantly learning/growth mindset.

You’ll benefit from:

Flexibility: yes, we think that what you do matters. At work and at home.

Fun: we laugh a lot, it makes every day brighter.

Discounted services: we provide amazing services to our clients, and you’ll get them at home, because you deserve them.

Rewarding Pay: let’s be honest, everybody likes to make a good salary. We offer attractive compensation packages, and it comes with a great culture.

Benefits: we’ve got you covered.

Career Evolution: join us and we will give you the tools to achieve your career goals!

Technology: you have a passion for technology? Excellent, we do too. Here, you will manage, influence, play, create, fix, and shape the industry.

Location :
Montréal, QC

Company :
Cogeco Connexion Inc

Being inclusive is simply welcoming you to be yourself!

Being inclusive also means fostering a climate of trust and respect, and encouraging diversity and equity for every candidate wanting to be part of the Cogeco team.

Being inclusive allows us to reduce barriers in the workplace and to take actions to enable accessibility for all!

Being inclusive is more than a word, it's our commitment to you!



If you need any accommodations to apply or as part of the recruitment process, please contact us confidentially at inclusiondiversite@cogeco.com","Cogeco Connexion Inc
3.1",Montreal
864,"SENIOR DATA ENGINEER, SOPHI","SENIOR DATA ENGINEER, SOPHI
POSITION CODE: 2021-077
LOCATION: The Globe and Mail, Toronto (Temporarily Remote)
SALARY: Commensurate with qualifications and experience
POSITION OVERVIEW:
We’re looking for experienced individuals with deep knowledge of data streaming, serialization, databases and distributed systems, and proficient in writing custom libraries but also know when to use off-the-shelf solutions when necessary. Ideal candidates are self-motivated engineers with a passion for both business and technology innovation, more importantly they quickly adapt with changing technologies. We value people who are passionate about system design and have an eye for improving product quality. We currently work with Scala, Kotlin, Java, Python, NodeJS, Postgres, Go, Kafka, and Flink.
RESPONSIBILITIES:
Develop and optimize system components for maximum performance and scalability across a vast array of environments.
Have a commitment to collaborative problem solving, sophisticated design, and product quality
Ensure that system components and the overall application are robust and easy to maintain.
Contribute to backlog reviews, technical solutions design and implementations
Be disciplined in implementing software in a timely manner while ensuring product quality isn’t compromised
MINIMUM QUALIFICATIONS:
Strong analysis and problem solving skills
Deep understanding of good programming practices, design patterns, Functional Programming, and Object Oriented Analysis and Design
Successfully implemented and released a large number of data pipelines and web services using modern engineering frameworks in the past 3 years
Formal training in software engineering, computer science or computer engineering.
Worked as part of a mature engineering team
IDEAL CANDIDATE:
Have strong working knowledge with Scala and/or Kotlin.
Understands reactive programming, Threads and Futures.
Successfully implemented realtime and batch analytics using Kafka, Flink, Apache Beams and/or Google DataFlow.
Strong working knowledge of data warehouses include Redshift, Snowflake, and/or Apache Druid.
Have a working knowledge with containerization and build pipelines
Successfully implemented data systems for very large data volumes such as click streams and/or IoT sensors data.
THE GLOBE AND MAIL IS DEDICATED TO DIVERSITY AND INCLUSION IN THE WORKPLACE
The Globe and Mail is committed to fostering an inclusive, accessible work environment, where all employees feel valued, respected and supported. We believe this strengthens our business and our journalism. We welcome and encourage applications from individuals from all groups, regardless of race, ethnicity, culture, gender, sexual orientation, religion, socio-economic status, age, and physical ability. As required by the Federal Contractors Program, The Globe also tracks the proportion of staff in the four Employment Equity categories (Women, Aboriginal Peoples, Persons with Disabilities, and Members of Visible Minorities) to ensure we are reflecting the areas in which we work.
The Globe and Mail offers accommodation for applicants with disabilities as part of its recruitment process. If you are contacted to arrange for an interview, please advise us if you require an accommodation.","The Globe and Mail
3.8",Midtown Toronto
865,Azure Data Engineering Consultant,"We Are:
Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds Visit us here to find out more about Applied Intelligence.

You Are:
A Big Data consulting pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.

The Work:
Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.

Big Data professionals use Big Data methodologies, solutions and tools to help organizations optimize their business performance by managing, sorting and filtering volumes of data as well as extracting meaningful value from these large volumes of data.

A professional at this position level within Accenture has the following responsibilities:

Design and build robust data pipelines using scalable tools and techniques (yes, we’re talking big data) to produce high quality data structures
Implement quicker data processing methods and integrate complex business logic compatible with daily or real-time/streaming frameworks
Increase automation and scaling of complex data sets based on the customer’s analytic use case, such as structured data delivery for business analysis, daily extraction of mission enabling data for data mining/exploration, and transforming data for applied intelligence to power impactful data visualizations


Here’s What You Need:

- Minimum 3 years of designing, building and operationalizing large scale enterprise data solutions and applications using Azure data and analytics services in combination with custom solutions - Spark, Azure Data Lake, HDInsights, SQL DW, DocumentDB, Search, Elastic Pool etc.

Minimum 3 years of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on Azure.
Minimum 3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc.
High emphasis on consulting/client facing experience, this is a must have
Bilingual French is an asset
Bonus Points if:

Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions.
Minimum 3 years of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders.
3 years of hands-on experience architecting and designing data lakes on Azure cloud serving analytics and BI application integrations.
3 years of experience in designing and optimizing data models on Azure
Minimum 3 years of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services.
Minimum 3 years architecting and implementing metadata management on Azure
Architecting and implementing data governance and security for data platforms on Azure.
Designing operations architecture and conducting performance engineering for large scale data lakes a production environment.
Craft and lead client design workshops and provide tradeoffs and recommendations towards building a solution.
Accenture Overview

We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world what’s possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality.

Important information

To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn

Our Commitment to Inclusion & Diversity

At Accenture, inclusion and diversity are fundamental to our culture and embedded in our core values. We are committed to creating a workforce where our people can feel comfortable, be themselves and contribute. Like Canada itself, Accenture employees represent a tremendous variety of cultures, ethnicities, beliefs, backgrounds and languages. We offer an inclusive environment regardless of personal characteristics such as ethnicity, religion, gender, sexual orientation, gender identity or expression, age or disability.

Requesting an Accommodation

Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.

If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.

Other Employment Statements

It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be available to travel when needed.

Job candidates are not required to disclose any offence for which a pardon has been granted.","Accenture
4.1",Midtown Toronto
866,Senior Java/Data Engineer (VP),"Citi’s Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citi’s Capital Markets, Securities Services and Banking lines of businesses.

Our mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurial spirit.

We are looking for a Senior Data Engineer with experience in developing data pipelines to join our team, part of the Citi’s Innovation Lab, working on a trade surveillance platform used across multiple businesses within our Institutional Clients Group.

As a Senior Data Engineer on our team, you will be responsible for designing, building and integrating data pipelines.

You will work with data publishers, data consumers, the development team and stakeholders to ensure we are meeting our requirements. You will contribute to the team’s strategy around security, development, testing, and deployment best practices.

This is an exciting opportunity to work on a mission critical project, take a leading role in evolving our platform, and be a difference maker at Citi.

Key Responsibilities:

Working closely with a global team building large distributed data-centric applications in the trade supervision and surveillance technology space.
Designing and building message and data processing/streaming services to enable seamless integration with multiple business systems.
Designing and building pipelines for data analytics.
On-boarding of new data streams from external systems.
Working closely with data scientists to ensure data is of the highest quality and is available when needed.
Act as data pipeline subject matter expert to the global application team as well as other internal and external stakeholders.
Building close relationships with clients and stakeholders to understand the use cases for the platform and prioritising work accordingly.
Working well in a multidisciplinary DevOps-focused team and building close relationships with engineers, data scientists, business analysts, and production support teams.
Holds themselves accountable for ensuring high quality results and acts as a mentor and coach to other team members.

Skills & Qualifications:

You have experience driving the technical direction on data-intensive projects.
You will have specific examples of times that you have:
Delivered value to business by getting applications into production.
Designed systems from scratch that can scale with large volumes of data.
You have expertise in multiple programming languages and building data pipelines, such as Java, Python, Spark, and Kafka.
You have expertise working with message/event streaming services, ideally using Kafka.
You have experience working with both relational and non-relational databases, such as MongoDB, Elastic, Oracle, Redis, Zookeeper, and others.
You understand the full spectrum of the data processing and integration ecosystem, including testing strategies.
You have experience working in a DevOps culture and are comfortable working with CI/CD tools such as IBM UrbanCode Deploy, TeamCity, and Jenkins
You have experience in systems observability including monitoring and health patterns and the tools to ensure the highest production stability.
You have high development standards, especially for code quality, code reviews, unit testing, continuous integration, and deployment.
You have proven capability to interact with clients and deliver results – from ideation to production.
You have experience working in fast paced development environments.
You agree that verbal and written communication skills are vital.
Experience creating pipelines that serve machine learning, statistical, and predictive algorithms is an asset.
Experience with analytical tools such as Tableau is an asset.
Experience working in virtualized environment, as well as container orchestration services such as Kubernetes/OpenShift is an asset.

Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply.

-

Job Family Group:

Technology

-

Job Family:

Applications Development

-

Time Type:

-

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting","Citi
3.9",Mississauga
867,Director of Data Engineering Intelligence,"Associate Director of Data Engineering




The Data Engineering teams build and maintain the tools, data pipelines and infrastructure that support our client’s data management and analytics needs. Our solutions bring structure to customer systems and customer data across mid-tier and enterprise customers.

We are looking for a Data Engineering Intelligence leader who loves to design, combine and build data systems using best of breed technologies. This role will focus on everything from the requirements and documentation phase (including interpretation of those requirements and coming up with better ideas to do things), DWs deployment, ETL, SSAS and data cube buildings, and deployment of various presentation layer tools. If that describes you, please join us in building scalable platforms for our global customers.

The right leader must possess a fine balance with their BA skills and deep technical knowledge; a passion for data and enthusiasm for building a strong data foundation for our clients.

What you will do:

Optimize existing and architect from scratch new data platforms to collect, transform and enable clients ease of query and analysis.

Integrate and leverage machine learning infrastructure to empower data scientists to more easily gain access to a consistent view of client’s data.

Be a subject matter expert on market-leading data trends, technologies tools and their compatible components for data injection, processing and presentation.

Conduct business requirements session plans and flows

Summarize technical design to non-technical audiences while at the same time providing direction to the delivery team to execute upon

Along with the Data Practice Lead, execute on the vision and strategy for the Data Engineering teams

Provide thought leadership on data technologies: what are the best practices on identifying, storing, provisioning, processing, and governing data, with particular attention to compliance and security needs

Recruit talented individuals to the team.

Support the sales team on data services opportunities and conversations with clients

Requirements:

Full stack BI development experience. Everything from the E part of ETL through the T and L and all the way through the presentation layer. Data integration experience is a plus.

Fluency in a programming language such as Python or Scala, and their respective standard data processing libraries. Python is preferred.

Experience working with data lakes and data processing systems that operate across a large organization and that make use of technologies such as Spark, Hive, Presto, Databricks or Snowflake.

Skill with stakeholder management to collect and prioritize requests and translate to roadmap

Cube Building, Data Mart building, and dimensional modeling experience.

Bachelor’s Degree in MIS, Business Administration, Computer Science or related field.",Sphere Inc.,Midtown Toronto
868,Sr. Data Product Manager - RBC Ventures ( Ampli ),"RBC Ventures is a new kind of business – one that marries the strength of one of the world’s most trusted and successful financial institutions with a mission to reimagine the role we play in people’s lives – to move RBC ‘beyond banking’. We’re building a world-class organization focused on designing exceptional experiences, exploring new business models and creating exponential value. In 2020, we were named by Fast Company as one of the 100 Best Workplaces for Innovators and we’re looking for team members with the curiosity to explore, the capabilities to build and capacity to help us deliver our mission.


What is the opportunity?

Ampli, an RBC Venture, is a free cash back app focused on helping Canadians get rewarded for their everyday purchases. https://www.linkedin.com/company/myampli/

We are hiring a Sr. Data Product Manager who will be responsible for the roadmap of our data platform. The ideal candidate is logical, analytical, and curious. They understand the technical aspects of data engineering and analysis but are focused on what the data is saying and how we can use it to provide a more personalized and targeted experience for our customers.

This person will work closely with the Product Managers in the other areas of Ampli, the data engineers and the data scientist. Machine learning will be a core part of this process and the data PM will work closely with the data scientists to determine the questions we need answered. This person will build strategies and implement solutions that drive data-oriented decisions across the organization.


What you’ll do:

Value creation, evolution & stewardship: Seek out ways to derive and yield new value from our data, especially via ML, NLP, etc and working with the other product managers on how to use the data to improve the UX in their areas of the product.
Product Roadmap: Develop ML product/platform roadmap and requirements working with cross functional teams to execute by planning and managing expectations with stakeholders across the company. Deliver key ML features and capabilities from concept-to-launch.
Coordinate and Communicate: Work with cross functional and vertical leads to absorb, prioritize and lead everyday challenges.
Operational Efficiencies: Analyze data and developer feedback to understand needs, reduce time to onboard and build on the platform, and improve overall stakeholder experience.
Prioritization: Make hard trade-offs between competing priorities as well as architectural improvements and operational excellence.
Measure Success: Define a set of success metrics to measure customer satisfaction and business impact and utilize them in decision-making.


What we’re looking for:

Degree in Computer Science or equivalent with 5+ years of data analysis and product management experience.
Hands on data extraction and analytical experience with SQL, Google Firebase, Metabase and Tableau.
Self-starter, thinker in action, a planner and a doer, can work well with ambiguity; always a team player.
Possess the entrepreneurial drive to develop and grow disruptive products and thrive in an ever-changing and agile environment.
Proven ability to think big picture strategy AND roll-up-your sleeves to deliver.
Demonstrated experience in building or delivering data store/warehouse solutions using ML, NLP, etc.
Excellent communication skills and ability to explain learnings to both technical and non-technical partners.


Nice to have:

Experience with Python.
SaaS or cloud-based app product experience.
Experience and success in both small startup environments and large matrix organizations.
Experience working with large financial institutions.
Experience exploring new capabilities and technologies to drive innovation.


RBCVentures


Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at jobs.rbc.com.

JOB SUMMARY
City: Toronto
Address: 20 Bay Street
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel (%): 0
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 07/16/2021
Platform: Technology and Operations
Req ID: 377759
Ad Code(s): RBC Ventures","RBC
4.1",Midtown Toronto
869,Research Scientist - Visual Analytics,"Company Description


The Bosch Research and Technology Center North America with offices in Sunnyvale, California, Pittsburgh, Pennsylvania and Cambridge, Massachusetts is part of the global Bosch Group (www.bosch.com), a company with over 70 billion euro revenue, 400,000 people worldwide, a very diverse product portfolio, and a history of over 125 years. The Research and Technology Center North America (RTC-NA) is committed to providing technologies and system solutions for various Bosch business fields primarily in the areas of Human-Machine Collaboration (HMC), Robotics, Energy Technologies, Internet Technologies, Circuit Design, Semiconductors and Wireless, and MEMS Advanced Design.

The focus of our global research on Human Machine Collaboration includes Big Data Visual Analytics, Explainable AI, Audio Analytics, NLP, Conversational AI, Mixed Reality and Smart Wearables, etc. We develop intuitive, interactive and intelligent solutions to enable inspiring UX for Bosch products and services in application areas such as autonomous driving, car infotainment and driver assistance systems (ADAS), Industry 4.0 and Internet of Things (IoT), security systems, smart home and building solutions, health care, and robotics.

As a part of the global research unit, our Visual Analytics & eXplainable AI group is responsible for shaping the future industrial AI experience for Bosch products and services by combining cutting-edge technologies of machine learning, data analysis and interactive visualization. We research and develop scalable, transparent, and intelligent big data analytic solutions for various domains including autonomous driving, Industry 4.0 (I4.0), connected vehicles, IoT, car multimedia etc. With our award-winning talents (IEEE VIS best paper & best paper runner-ups), we also actively collaborate with leading groups in academia to promote research ideas and publish research findings in internationally renowned conferences and journals, e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, and ICML.



Job Description

Conduct advanced research and engineering in visual analytics and information visualization for related business domains of autonomous driving, connected vehicles, Industry 4.0, IoT etc.
Apply research results to real-world use cases with high quality implementation.
Integrate the resulting systems/software into existing Bosch platforms.
Summarize research findings in high-quality paper and patent submissions.
Actively scout for the latest technology and predict market trends by monitoring news, technical events and seminars.
Provide expert opinions on relevant technology areas to management team to facilitate strategic planning, R&D roadmap development, and business investment.
Summarize research findings in high-quality paper and/or patent submissions.


Qualifications


Required:

Ph.D students in Computer Science or related fields
3+ years of research experience or equivalent graduate research experience in visual analytics, information visualization, HCI, applied machine learning and related fields
Strong programming skills for full stack web development on both frontend (e.g., React, Vue.js, and D3.js) and backend (e.g., Flask, Django)
Good communication and teamwork skills;

Desired:

Publication record in top venues of visualization, data mining, or machine learning research (e.g., IEEE VIS, TVCG, SIGKDD, NeurIPS, AAAI, ICML, and ICRL);
Knowledge in machine learning and data mining, with application to eXplainable AI, high-dimensional data analysis, event sequence/log mining and computer vision;
Familiar with one or more main-stream machine learning platforms (e.g., scikit-learn, TensorFlow, and PyTorch);
Knowledge in interaction and user experience design;
Knowledge in graphical design;
Good leadership skills to drive research topics.

Additional Information

Major(s): Computer Science or related fields
Degree level: Ph.D
Start Date: June, 2021","Bosch Group
4.1",Waterloo
870,Intermediate Environmental Engineer or Scientist,"At EXP, we know that great experiences start with the right people. We believe that work should be challenging, and the challenge should be fun. We also know that exponential possibilities are more likely to occur with a respectful, satisfying and empowering company. We value and respect our employees - their experience and expertise as well as their energy, passion and diversity - and their innovative approach to work and to life.


Your Challenge

EXP Services Inc. is currently looking for an Intermediate Environmental Engineer or Scientist to join our Environmental team in our Ottawa, ON office. Reporting to the Discipline Manager, the successful applicant will be part of an active contaminated sites and environmental services team.


Your Responsibilities

This individual will be responsible for assessing, reporting, controlling and managing contaminated site projects and other environmental assignments as necessary.

Duties will include:

Preparation of technical reports
Project management including Phase I, II Environmental Site Assessments (ESA), remediation, hazardous material surveys and abatement programs and related environmental project duties
Design of remediation programs and soil vapour mitigation systems is an asset
Budget tracking and cost control;
Proposal Preparation
Review and evaluate technical work of other staff;
Field work (approximately 40% field work/ 60% office work)
Manage data as needed
Liaising with contractors and clients
Coordinating and conducting environmental field programs, as needed
Maintain excellent client relationships in various industries.


The Skills and Knowledge You Bring

University Degree or College Diploma in a related field is required, such as Environmental, Chemical or Civil Engineering, Environmental Science or Geology.
5+ years of progressive experience in environmental assessment and remediation, experience as a Project Manager is an asset.
Licensure or potential for licensure in Ontario through PEO or PGO is an asset.
Experience conducting Phase I, II and III ESAs, hazardous material surveys/abatement programs, environmental compliance audits, remediation design and/or hydrogeology.
Expertise in environmental assessment and remediation techniques, budget management, report preparation, and client relationship management;
Project execution timely, on-budget, well organized and client focused;
Understanding of the applicable legislation
A motivated, self starter with a demonstrated ability to work independently as well as within a team environment.
Strong organizational and time management skills as well as attention to detail.
Excellent oral and written communication skills, as well as advanced technical writing abilities.
A valid driver's license and access to a vehicle are required.
Must be comfortable in the field on construction/environmental project sites.
Opportunity to participate in business development activities
Knowledge of Microsoft Office.


What EXP Can Offer

With a mission to understand, innovate, partner and deliver, EXP provides engineering, architecture, design and consulting services to the world’s built and natural environments.

Our heritage dates back to 1906, when the earliest of EXP’s predecessor companies started its engineering infrastructure practice. Today, over 3,000 creative EXP professionals across North America provide the passion and expertise needed to deliver successful projects around the world.

Our promise is to offer you a challenging career in a positive and dynamic work environment, and it is a promise we take seriously.

Join a dynamic team at EXP that provides you with innovative projects, the capacity to develop your career, a full range of benefits, flexible working hours, and much more! When you explore what EXP has to offer, you’ll find exponential possibilities.

For more information, visit www.exp.com .","exp
3.6",Ottawa
871,Sr. Data Engineer - FinTech,"5+ years of experience as a Data Engineer or in a similar role
Experience with data modeling, data warehousing, and building ETL pipelines
Experience in SQL
Knowledge of batch and streaming data architectures
Experience with AWS technologies including Redshift, RDS, S3, EMR, EML or similar solutions built around Hive/Spark etc.
Experience communicating with senior management as well as with colleagues from engineering, analytics, and business backgrounds.
Exceptional written communication skills
Experience using big data technologies (Hadoop, Hive, HBase, Spark etc.)
Demonstrated strength in data modeling, ETL development, and data warehousing
Knowledge of data management fundamentals and data storage principles
Knowledge of distributed systems as it pertains to data storage and computing
Proficiency in Python or other similar languages.
Amazon Financial Technology Team is looking for a results-oriented data engineer, who can help us build the next generation of distributed, scalable financial systems. Our ideal candidate thrives in a fast-paced environment, enjoys the challenge of highly complex business contexts that are typically being defined in real-time. We need someone to design and develop data solutions that facilitate global financial transactions worth billions (USD) annually.
As a data engineer, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business teams in analysis on various cost savings initiatives, many non-standard and unique business problems and use creative-problem solving to deliver actionable output.
You will be responsible for designing and implementing an analytical environment using third-party and in-house reporting tools, modeling metadata, building reports and dashboards. You will have an opportunity to work with leading edge technologies like Redshift, Hadoop/Hive/Pig. You will be writing scalable queries and tuning performance on queries running over billion of rows of data.

You should be analytical, have a high level of customer focus and a passion for process improvement. You should be motivated self-starter that can work in a fast paced, ambiguous environment. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions.


Masters in computer science, mathematics, statistics, economics, or other quantitative fields.
Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations
Excellent knowledge of Advanced SQL working with large data sets.
Knowledge of Advanced Statistics and implementing ML models.
Demonstrated ability to mentor junior team members in all aspects of their engineering skill-sets
Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strateg
Experience providing technical leadership and mentoring other engineers for best practices on data engineering
Strong business acumen, proven ability to influence others, strong attention to detail, excellent organization skills, and ability to manage multiple projects","AMZN CAN Fulfillment Svcs, ULC
3.8",Vancouver
872,"Senior Applied Scientist, Alexa Speech","Master's degree in Electrical Engineering, Computer Sciences, or Mathematics with specialization in speech recognition, natural language processing, image processing, or machine learning.
5+ years relevant industry experience
Experience with programming languages such as C/C++, Python, Java or Perl.
Amazon is looking for a passionate, talented, and inventive Scientist with a strong machine learning background to help build industry-leading Speech and Language technology. Our mission is to push the envelope in Automatic Speech Recognition (ASR), Natural Language Understanding (NLU), and Audio Signal Processing, in order to provide the best-possible experience for our customers.

As a Scientist, you will work with talented peers to develop novel algorithms and modeling techniques to advance the state of the art in spoken language understanding. Your work will directly impact our customers in the form of products and services that make use of speech and language technology. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate advances in spoken language understanding.

We are hiring in all areas of spoken language understanding: ASR, NLU, text-to-speech (TTS), and Dialog Management.

Position Responsibilities:

Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for machine learning (ML) and/or natural language (NL) applications.
Develop and/or apply statistical modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications in business and engineering.
Routinely build and deploy ML models on available data.
Research and implement novel ML and statistical approaches to add value to the business. Mentor junior engineers and scientists.
PhD in relevant fields + 3 years relevant industry experience
Experience in building speech recognition and natural language processing systems (e.g. commercial speech products or government speech projects)
Solid Machine Learning background and familiar with standard speech and machine learning techniques.
Proficient in neural network and/or deep learning are pluses.
Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field
Solid software development experience
Good written and spoken communication skills.
To learn more about the Digital Products team at Amazon, visithttp://www.amazon.com/careers/digitalproducts and apply now.

Amazon is committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act. If contacted for an employment opportunity, please advise Human Resources if you require accommodation.","Amazon Dev Centre Canada ULC
3.8",Midtown Toronto
873,Senior Data Engineer,"It’s an exciting time to be at Infoblox. Named a Top 25 Cyber Security Company by The Software Report and one of Inc. magazine’s Best Workplaces for 2020, we are leading the way to next-level DDI with our Secure Cloud-Managed Network Services, bringing next-level security, reliability, and automation to cloud and hybrid systems—all managed through a single pane of glass. Our success depends on bright, energetic, talented people who share a passion for building the next generation of networking technologies—and having fun along the way.

We are looking for a Senior Data Engineer to join our Cloud Engineering team in Burnaby, BC, reporting to the Senior Manager, Software Engineering. In this role, you will develop platforms and products for Infoblox’s SaaS product lines. This is an excellent opportunity to work closely with data scientists and product development teams to curate and refine data powering our latest cloud products. Come join our growing Cloud Engineering team and help us build world-class solutions!

You’re the ideal candidate if you are a savvy software engineer with experience in data engineering and a solid background in Spark and Python. Preferably you know that countMinSketch is not a children’s game. You have worked in a Cloud environment and are comfortable wearing several hats in a small organization with a wide range of responsibilities. You know that Big Data is both a blessing and a curse; without sound data engineering, it loses its potential. You are passionate about the nexus between data and computer science-driven to figure out how best to represent and summarize data in a way that informs good decisions and drives new products. When someone says, “my Spark job failed,” your first question is, “what’s the skew?”

What you’ll do:

Curate very large-scale data from a multitude of sources into appropriate sets for research and development for the data science, threat analysts, and developers across the company
Design, test, and implement storage solutions for various consumers of the data
Design and implement mechanisms to monitor data sources over time for changes using summarization, monitoring, and statistical methods
Leverage computer science algorithms and constructs, including probabilistic data structures, to distill extensive data into sources of insight and enable future analytics
Convert prototypes into production data engineering solutions through disciplined software engineering practices, Spark optimizations, and modern deployment pipelines
Collaborate on design, implementation, and deployment of applications with the rest of the software engineering team
Support data scientists and product teams in building, debugging, and deploying Spark applications that best leverage data
Build and maintain tools for automation, deployment, monitoring, and operations
Create test plans, test cases, and run tests with automated tools


What you’ll bring:

6+ years of experience with Python3, and 2+ years experience with Spark. Scala experience is helpful
5+ years of experience in data engineering, data science, and related data-centric fields using large-scale data environments
3+ years of experience in using SQL and working with modern relational databases, including MySQL or PostgreSQL
3+ years of experience with developing ETL pipelines and data manipulation scripts
Proficient in Object-Oriented Design and S.O.L.I.D principles
Strong emphasis on unit testing and code quality
Proficient with AWS products (EMR S3, Lambda, VPC, EC2, API Gateway, etc)
MS or BS in Computer Science or a related field, or equivalent work experience required


What success looks like:

After six months, you will…
Complete onboarding by demonstrating knowledge of the Data Lake and associated technologies and CI/CD processes by deploying ETL pipelines for curation & warehousing to production
Complete rotations on “bug duty” where you will gain experience with the different systems, tools, and processes in the Data Lake by resolving reported issues
Contribute to the team's velocity by participating in Scrum and driving stories to completion
After about a year, you will…
Be an expert on the Data Lake target state architecture and drive engineering design and grooming sessions for new feature development
Apply coding best practices and provide in-depth reviews on the team's pull requests
Be a thought leader in one or more domains of the Data Lake, driving development and mentoring teammates in this domain



We’ve got you covered:

Our holistic benefits package includes coverage of your health, wealth, and wellness—as well as a great work environment, employee programs, and company culture. We offer competitive compensation, a comprehensive benefits package including health, dental, and vision coverage, and an Employee and Family Assistance Program to support the wellbeing of our employees and their families. We have a strong culture and live our values every day—we believe in transparency, curiosity, respect, and above all, having fun while delighting our customers.

Speaking of a great work environment, here are just a few of the perks you may enjoy…

Boutique office space with state-of-the-art amenities, located in the heart of Metro Vancouver area; bike-friendly and steps from SkyTrain and Metrotown Mall
Onsite parking paid for by the company
Generous company contribution towards RRSP (Independent of employee contribution!)
Onsite massages, gym membership, fitness classes, ping-pong table, dartboard, and a nap room/wellness room for moms
Stay fueled with healthy snacks, free bean-to-cup gourmet coffee options and selections of exotic teas, juices, and refreshing beverages, and biweekly Thirsty Thursday local craft beers, BC wines, and BC ciders
Enjoy our generous PTO policy and flexible work environment because we know the importance of having a great work-life balance (Sometimes, you do your best work in slippers)
We are passionate about lifelong learning and growth and offer opportunities through a world-class learning platform (Litmos), training, workshops, mentorship, and an annual up to $5,000 Career Development reimbursement benefit
Our teams spend time together outside of work, too — we have several annual team outings, have gone on hikes and Grouse Grind, hosted family BBQs, Go Karting, boat cruises, etc.
Be confident bringing your whole self to work — we’re proud to be an inclusive company with diverse teams and our values grounded in ethics and equality



Why Infoblox?

We’ve created a culture that embraces diversity, equity, and inclusion and rewards innovation, curiosity, and creativity. We achieve remarkable results by working together in a supportive environment that focuses on continuous learning and embraces change. So, whether you’re a software engineer, marketing manager, customer care pro, or product specialist, you belong here, where you will have the opportunity to grow and develop your career. Check out what it’s like to be a Bloxer. We think you’ll be excited to join our team.


#LI-AB1","Infoblox
4.1",Burnaby
874,"Senior Data Analyst, Global Investments","Why join us?

Are you looking to join a dynamic pension plan that embodies the strong values of its 500,000 members and is an industry leading global investor? If so, we would love to tell you our story.

At OMERS we put our people first and are proud to embrace the diversity of thought and leadership that comes from having locations in Toronto, London, New York, Singapore, Sydney and other major cities across North America and Europe. Our culture is truly one of a kind. We get stuff done, and have fun doing it! We take great pride in contributing to the communities where we live with an ever-constant eye to the global investment markets.
The Senior Data Analyst, Global Investments Technology (GIT) will join a team that leads the delivery of the products and platforms that enable OMERS Global Investments (GI) to analyze opportunities, action investment decisions and optimize the OMERS investment portfolio. GIT works across investment teams including Capital Markets, Infrastructure, Private Equity, Growth Equity and Ventures, and in close collaboration with Finance, Risk & Compliance teams.

As a key member of the Global Investments Technology team, the Senior Data Analyst is instrumental in enhancing data & analytics capabilities by championing industry best practices and delivering high quality datasets, reports, and training to enhance business decision making.

The Senior Data Analyst will develop Power BI datasets and reports to support OMERS investment entities, maintain a healthy business relationship to assist in meeting business demands and deliver training workshops to promote a data culture. The Senior Data Analyst will also support and collaborate with data engineers, data scientists and investment professionals and engage in technical support, research and knowledge sharing through the implementation as part of 1 or more product team(s).

As a member of this team, you will be responsible for:
Technical
Organizing workshops with partners to gather requirements and develop low/high fidelity wireframes
Developing and monitoring Power BI Premium Dataflows to gather, transform and democratize structured and unstructured data assets
Developing Power BI datasets by applying best-practice semantic modeling techniques
Building visually stunning reports that clearly communicate an effective story
Leading solution build, delivery, support and troubleshooting
Provisioning and managing resources of Premium Capacity
Managing the Power BI / Power Platform infrastructure
Usage Monitoring and Auditing
Organizational
Operating in an Agile development environment
Communicating effectively with analysts and various partners across multiple teams and with various other partners such as product managers, data engineers and members of senior management
Managing change and communicating impacts to partners and fellow team members
Facilitating collaboration and sharing through best practices of delivering and sharing content
Identifying, defining and implementing opportunities for improving existing processes
Exhibiting the ability to work on multiple projects simultaneously and ensuring timely delivery
Leading the Power BI Community of Interest to review the latest features and updates
Collaborating with other teams and establishing Power Platform Governance and Support

To succeed in this role, you have:
Professional
Experience . 5+ years solving complex technical projects as a full-stack (M & DAX) Power BI developer
A Bachelor’s Degree in a scientific or engineering field of study or equivalent work experience
Microsoft certification – Data Analyst Associate
Industry Knowledge of best practices learned from MVP & Product Team articles and Investments/Finance.
Training . Excited to support new Power BI users by running various internal community initiatives such as presentations, hands-on workshops, or troubleshooting end-user obstacles.
Demonstrated success building deep technical relationships and aligning expectations across various partners.
Problem - Solving. The ability to trace data lineage and resolve technical issues with minimal direction.
Teamwork . Motivated and keen to work in a collaborative environment with a focus on team success.
Technical
A depth of Power BI experience wrangling complex data using M functions and developing sophisticated semantic logic using DAX expressions
Connect/Transform. Knows what “M” is, how to merge, append, and perform more advanced UI transforms
Model. Basic knowledge of dimension / fact tables and can identify them in a dimensional model. Comfortable with simple DAX, knows the CALCULATE function well and can explain how it works.
Visualization. Recommends appropriate visualizations to answer business questions and references examples of published materials that explain how to choose a visual. Proficient at all ways to manipulate look & feel.
Admin/Architecture . Has experience configuring Administrative features in the tenant. Knows how to install and manage a gateway. Basic levels of understanding of licensing.
Embed/Custom Visuals . Understand that Power BI can be embedded internally and knows how to add and share in Teams.
Breadth of technical experience and knowledge in the MSFT data and analytics ecosystem, with Subject Matter Expertise in two or more of the following items:
Power BI Service administration
Power BI Desktop
Tabular Editor and DAX Studio
Azure Synapse Analytics
Azure Data Factory
Azure Machine Learning
Azure Databricks

Our story:
Founded in 1962, OMERS is one of Canada’s largest defined benefit pension plans, with $105 billion in net assets as at December 31, 2020. OMERS is a jointly-sponsored pension plan, with 1,000 participating employers ranging from large cities to local agencies, and over half a million active, deferred and retired members. OMERS members include union and non-union employees of municipalities, school boards, local boards, transit systems, electrical utilities, emergency services and children’s aid societies across Ontario. Contributions to the Plan are funded equally by members and employers. OMERS teams work in Toronto, London, New York, Amsterdam, Luxembourg, Singapore, Sydney and other major cities across North America and Europe – serving members and employers and originating and managing a diversified portfolio of high-quality investments in public markets, private equity, infrastructure and real estate.

OMERS is committed to having a workforce that reflects the communities in which we live and work. We are an equal opportunity employer committed to a barrier-free recruitment and selection process. At OMERS inclusion and diversity means belonging. How we create a sense of belonging is through our employees and our vast network of Employee Resource Groups. Whether you are passionate about gender, pride, or visible minorities, we have groups that are focused on making a difference in all of our lives.","OMERS
3.5",Midtown Toronto
875,"Cloud Data Architect, Omnia AI","Job Type: Permanent
Primary Location: Toronto, Ontario, Canada
All Available Locations: Toronto; Calgary; Montreal; Vancouver


Learn from deep subject matter experts through mentoring and on the job coaching
Partner with clients to solve their most complex problems
Be empowered to lead and have impact with clients, our communities and in the office.


You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.

What will your typical day look like?


As a Cloud Data Architect on our Data & Analytics Modernization team within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in modern data solutions including data ingestion/data pipeline frameworks, data warehouse & data lake architectures, cognitive computing and cloud services. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:

Lead, define, design and implement end-to-end modern data platforms in support of analytics and AI use cases
Collaborate with enterprise architects, data architects, ETL developers & engineers, data scientists and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities
Address aspects such as data privacy & security, data ingestion & processing, data storage & compute, analytical & operational consumption, data modeling, data virtualization, self-service data preparation & analytics, AI enablement, and API integrations
Define and develop solution architectures, lead development teams, estimate effort and mentor junior colleagues
Lead technical meetings with client staff, and advise client with technical option analyses based on leading practices
About the team


Omnia AI, Deloitte’s Artificial Intelligence (AI) practice is comprised of a collaborative team of experts who use their hands-on experience with cutting-edge information assets to facilitate successful AI transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.

Enough about us, let’s talk about you


You are someone with:

5+ years experience leading engagements from design to implementation of creative data solutions leveraging the latest in Big Data frameworks, supporting on-premise, cloud (AWS, Azure, GCP) and hybrid architectures to enable use cases in analytics and AI
5+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads
3+ years experience with analytics/data management strategy formulation, architectural blueprinting, business case development and effort estimation of disruptor based analytics
Ability to simplify complex technical concepts into easy-to-understand non-technical language in order to facilitate, communicate and interact with executives and business stakeholders, working with Agile development methods in data-oriented projects
Completed Bachelor’s Degree (or higher) in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or related field is desired; certifications in architecture (TOGAF), data engineering and development on AWS, Azure, GCP and/or Hadoop distributions are an asset.

If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:

You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.


The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.","Deloitte
3.9",Midtown Toronto
876,Senior Java/Data Engineer (Backend/Middleware) (VP),"Citi’s Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citi’s Capital Markets, Securities Services and Banking lines of businesses.

Our mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurial spirit.

We are looking for a Senior Data Engineer with experience in developing data pipelines to join our team, part of the Citi’s Innovation Lab, working on a trade surveillance platform used across multiple businesses within our Institutional Clients Group.

As a Senior Data Engineer on our team, you will be responsible for designing, building and integrating data pipelines. The trade surveillance platform will be looking at running various models at scale on large data sets to identify and act upon possible market abuse in the market.

You will work with our stakeholders and data consumers to ensure we are meeting their requirements. You will contribute to the team’s strategy around security, development, testing, and deployment best practices.

This is an exciting opportunity to work on a mission critical project, take a leading role in evolving our platform, and be a difference maker at Citi.

Job Background/context:

We believe the future’s here. Right here with us. Home to where we define, ideate, develop and distribute production-ready financial solutions of far-reaching impact. And right now, the door’s open to direct the future of our technology for a truly global client base. This means collaborating with the keenest minds in data science, big data, software engineering, web development, UX design and more. Doers looking to bring the next bold ideas to life for a fascinating array of clients - investing, trading and transacting at the forefront of change in markets and economies the world over.

If you have this kind of vision, capable of seeing ahead, of developing a clear path forward in a quest to try the as yet untried, here is the opportunity. In a supported, resource-rich, vibrant co-working environment, part of an ecosystem of globally interconnected labs, realizing a broader mission of enabling growth and economic progress on a scale you won’t find anywhere else.

Key Responsibilities:

Working closely with a global team building large distributed data-centric applications in the trade surveillance and compliance space.
Designing and building message and data processing/streaming services to enable seamless integration with multiple business systems.
On-boarding of new data streams from external systems.
Working closely with data scientists to ensure data is of the highest quality and is available when needed.
Act as data pipeline subject matter expert to the global application team as well as other internal and external stakeholders.
Building close relationships with clients and stakeholders to understand the use cases for the platform and prioritising work accordingly.
Working well in a multidisciplinary DevOps-focused team and building close relationships with engineers, data scientists, business analysts, and production support teams.
Holds themselves accountable for ensuring high quality results and acts as a mentor and coach to other team members.

Skills & Qualifications:

You have experience driving the technical direction on data-intensive projects.
You will have specific examples of times that you have:
Delivered value to business by getting applications into production.
Designed systems from scratch that can scale with large volumes of data.
You have expertise in multiple programming languages and building data pipelines, ideally using Spark and Java.
You have expertise working with message/event streaming services, ideally using Kafka or Solace.
You have experience working with both relational and non-relational databases, ideally Oracle, Mongo and Elastic Search
You understand the full spectrum of the data processing and integration ecosystem, including testing strategies.
You have experience working in a DevOps culture and are comfortable working with CI/CD tools (ideally IBM UrbanCode Deploy, TeamCity, and/or Jenkins.)
Ideally, you have experience working in virtualized environment, as well as container orchestration services such as Kubernetes/OpenShift.
You have experience in systems observability including monitoring and health patterns and the tools to ensure the highest production stability.
You have high development standards, especially for code quality, code reviews, unit testing, continuous integration and deployment.
You have proven capability to interact with clients and deliver results – from ideation to production.
You have experience working in fast paced development environments.
You agree that verbal and written communication skills are vital.

Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply.

-

Job Family Group:

Technology

-

Job Family:

Applications Development

-

Time Type:

-

Citi is an equal opportunity and affirmative action employer.

Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

Citigroup Inc. and its subsidiaries (""Citi”) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review Accessibility at Citi.

View the ""EEO is the Law"" poster. View the EEO is the Law Supplement.

View the EEO Policy Statement.

View the Pay Transparency Posting","Citi
3.9",Mississauga
877,Behavioral Scientist,"Duties/Responsibilities:

Analyzing a breadth of data points to uncover human truths
Apply learnings to tactical creative and strategy work on a weekly and monthly basis
Assist in biometric creative testing using a proprietary structure
Build testing recommendations and test studies
Proactively collaborate with Creative, Strategy, and Analytics teams to ensure agency partners comprehend and apply findings
Collaborate with the Analytics team to craft social media tests and strategies that drive consumers through business and engagement funnels

Requirements/Qualifications:

In-depth knowledge of Behavioral Sciences:
Base understanding of psychology, social psychology, evolutionary psychology, and/or consumer neuroscience
Understanding of Behavioral Economics cognitive process including heuristics and biases
Understanding of cognitive motivations including explicit and implicit motivational territories.
Demonstrated knowledge of traditional and behavioral science research:
In-depth knowledge of traditional qualitative and quantitative marketing research techniques
In-depth knowledge of behavioral qualitative and quantitative marketing research techniques
In-depth understanding of the “scientific method” and Random Control Trials
In-depth understanding of Consumer Neuroscience techniques.
Demonstrated ability to discover what business questions internal and external stakeholders are trying to answer and formulate and execute a Behavioral Science Research Plan and provide actionable results.",thinkCOMPASS,Concord
878,Senior Data Engineer - Remote,"About KOHO
KOHO is a quickly scaling FinTech company backed by leading investors and advisors from around the world. We started KOHO because we believe in doing two things:

Democratizing access to the best financial products and giving everyone a great financial foundation.

Since our journey began 6 years ago, we’ve raised more than $130M, grown the KOHO Collective to over 200 employees and created accounts for more than 300,000 Canadians.

About the Role
As our newest Senior Data Engineer, you would bring your database design sense and meticulous standards for clean data to the table. More than just understanding the strategic importance of data in a financial context, you’re eager to roll up your sleeves and build the infrastructure to support it. We value potential as much as we value experience, so if you think you’d be a great fit we’d love to hear from you.

Please Note: This is a remote position based in Canada that is available to those who are legally entitled to work in Canada.
Responsibilities
Maintaining clean and consistent access to all our data sources
Providing a solid foundation for calculating key business metrics
Maintaining data infrastructure to keep up with the product roadmap
Understanding data lineage and governance for a variety of data sources
Communicating updates and changes to the broader data team as well as contributing to and maintaining data-related documentation
Participate in rotating on-call duties, including incident management
Desired Skills & Experience
Minimum of five years of experience working with data
Able to design efficient and scalable cloud architectures
Experience writing complex SQL Queries
Knowledge of ETL patterns, including testing and maintenance
Familiar with relational / non-relational database approaches and knowing which to apply where and when
Understanding of hot/warm/cold data concepts and when each is appropriate
Understanding of event-driven and stream-based processing patterns
Ability to think holistically about uses of data, designing for ease of data access
Working knowledge of one of Python, Java
Experience with Kubernetes cluster management is an asset
Experience with data processing frameworks such as Apache Spark
Nice-to-Have Skills
Experience with Google Cloud Platform (BigQuery, Dataflow, PubSub)
Knowledge of Go
Joining the (lovely!) KOHO Team
We invest time and resources into making sure KOHO is as good as the people we hire. Our culture is one of collaboration, creativity, and diverse perspective. Here are some of the reasons we attract the best people:

Balance Your Life - Unlimited PTO, generous vacation, and a lifestyle spending account
Work Anywhere in Canada - Permanently remote and $1,000 to set up your home office
Level Up - Access to an in-house certified performance coach
Reach Your Goals - Salary assessments twice a year, annual training allowance
The KOHO Culture - We have won 5 ""Great Place to Work ®"" awards since 2019

The Fine Print
We are an equal opportunity employer and value diversity and uniqueness at our company.

KOHO is trusted with highly sensitive information. Upon joining the team, you may be asked to undergo security screening including a criminal record check.

#LI-Remote","Koho
3.3",Canada
879,Senior Marketing Scientist,"Senior Marketing Scientist


Who is Pod Marketing?


POD Marketing is an innovative digital marketing agency whose strategy is to build specific capabilities and programs within industries. We are a full-service agency and can offer our clients solutions such as: branding, website development, lead generation, digital advertising, content creation, SEO, video creation, marketing automation, etc. We discover what works for one client and help apply those learnings to new clients within the same industry. Currently, we are supporting the following verticals:


Eye Care: www.marketing4ecps.com

Dental: www.smileshopmarketing.com

Home Services: www.adhomemarketing.com

Chiropractors: www.powersurgemarketing.ca

Senior Living: CITIZEN - Coming Soon


Our company was founded in 2014, and has built a tremendous culture for the people and clients we work with. We have grown quickly over our 6+ years in business, now working with over 200 clients across North America and employing an amazing team of over 50 employees. To learn more about our culture, visit the POD Marketing YouTube channel.


We are looking for a full time Senior Search Engine Marketing Specialist (SEM / PPC) to join our team. If this sounds like a position that you would be interested in, please read the job description below.


Role Overview


The Senior SEM / PPC specialist will have 2 – 5 years of hands-on experience developing and managing advertising campaigns on platforms including Google, Facebook, Instagram, LinkedIn and Microsoft Bing Ads.


The ideal candidate is results-oriented and data-driven performance marketer with demonstrated experience managing multiple paid advertising campaigns. You take a customer-centric approach, and you're passionate about doing what's right for our customers and brand. You are highly analytical and count A/B testing, optimizing customer acquisition costs, and analyzing campaign performance among your core competencies. You likely have some deep experience in a few marketing channels, and have the aptitude to learn new channels quite quickly.


Most importantly, you are eager to roll up your sleeves to find opportunities and efficiencies in a fast-moving company at the forefront of digital marketing.


Responsibilities



Plan, develop, build, manage and optimize all digital advertising solutions including but not limited to Pay-Per-Click (PPC), Online Display and Social Media Ads
Manage campaign expenses, staying on budget, estimating monthly costs and reconciling discrepancies
Track, report, and analyze website analytics, Pay-Per-Click (PPC) initiatives and social media campaigns
Generate necessary codes that will be placed on a client’s website to measure conversions.
Collaborate with internal teams (Marketing Science, Sales, Web Dev, Social Media, Content, SEO, etc.) to manage accounts and execute client specific marketing roadmaps



Required Experience & Skills


Must Have:



Bachelor’s degree in marketing/business or related field
2 – 5 years of SEM experience and success managing Pay-Per-Click (PPC) campaigns across Google
1 – 2 years of experience setting up analytics and conversion tracking codes on client websites (Google Analytics / Google Tag Manager)
Up-to-date with the latest trends and best practices in search engine marketing
In-depth experience with bid management tools
Experience with website analytics tools
Strong analytical skills and experience generating SEM reports (Excel, Google Sheets, Google Data Studio)
Familiarity with A/B and multivariate experiments
Analytical and data driven mindset
Ability to manage multiple projects and deadlines



Nice to Have:



Post-secondary degree in STEM
Mentorship and training experience
Advanced knowledge of Google Analytics and Paid Advertising (Google, Bing, Facebook/Instagram)
Basic knowledge of SEO
Prior agency experience (like a real agency, not a one-person “agency”)
Self-driven projects (websites/blogs/data science)



This person should have passion above all else. They are a person who wants to grow their career, not just find a job.


How to Apply


At Pod, we believe “that most job requirements and conceptual knowledge are easily trainable. But you can’t teach drive, ambition, or passion.” (Take a look at this article, Finding Your Unicorn, written by our President, Kevin Wilhelm). Our hiring managers consider alignment with our core values and passion for our company culture to be as valuable as experience and education.


After reading this job description, we want you to ask yourself:


Am I the exact right person for this role?


Do I align with Pod’s core values and culture?


If you’ve answered yes to both questions, we want to hear from you! Here are a few easy steps that will help us get to know you better.



Ensure your professional resume is up to date and highlights some of the key points we are looking for.
Create an engaging and personalized cover letter for us to read. If you don’t include a cover letter, you will NOT be considered for this role. Make sure to highlight your Google Ads / Facebook Ads experience. Video cover letters are given extra attention.
Apply through our website (https://www.podmarketinginc.com/careers/)



All successful candidates will be contacted via email to discuss next steps. We appreciate all applications and wish you all the best of luck.","POD Marketing Inc.
5.0",Calgary
880,"Senior Scientist - Instrument Design, ICP Mass Spec. R&D","Senior R&D Scientist – ICP-MS
PerkinElmer is a global technology leader, driving growth and initiative in the Environmental and Human Health Science markets. The Company is a leading force in the development, production, marketing, servicing, and supporting of laboratory instrumentation and ancillary services throughout the world.
PerkinElmer is searching for an experienced research and development scientist to help create innovative solutions in our Inductively Coupled Plasma –Mass Spectrometry (ICP-MS) product line. The successful candidate will become a key member of a group of senior PerkinElmer researchers, and will liaise with other scientists at PerkinElmer’s partners and collaborators.

This position is based in Woodbridge, Ontario, Canada.

Duties and Responsibilities:
Initiate and execute scientific research and product development, with primary focus on next generation instrument development, technology, trade secrets, and intellectual property.
Provide mass spectrometry expertise and guidance within the R&D product development team, ensuring thorough conceptualization, design, and validation of new products.
Conduct scientific experiments to evaluate new technologies; adapt, modify, improve, develop, and apply them to future products.
Prepare reports on research progress and technical feasibilities based on findings from the experiments.
Influence the scientific community and instrument market via patents, publications, and conference presentations.
Work with applications, manufacturing, engineering, and service personnel to improve real-world performance, quality, value, manufacturability, and serviceability of ICP-MS products.
Demonstrate independent and creative scientific thinking, ability to solve complex problems, and resilience to setbacks and changes.
Contribute effectively to multiple collaborative projects in a lean, agile, cross-functional team environment.

Basic Qualifications:
Ph.D. in science or related fields (Physics, Chemistry, or Engineering, with strong laboratory, computer and mathematics skills) and 3+ years of mass spectrometer instrument development experience.
or
MS in science, engineering, or related fields (Physics, Chemistry, or Engineering, with strong laboratory, computer, and mathematics skills) and 6+ years of mass spectrometer instrument development experience.
Prior mass spectrometry instrument industrial design experience (preferably ICP-MS)

Preferred Qualifications:
Knowledge of mass spectrometry theory and components ( e.g. sample introduction, plasma and other ion sources, vacuum technology, electromagnetic fields, quadrupole-based mass analyzers, RF systems, ion detectors, and data acquisition hardware)
Strong “hands on” instrumentation design, optimization, and troubleshooting skills.
Ability to solve complex problems and dissect projects into manageable tasks
Excellent group interpersonal skills.
Proven track record of patents and/or publications in peer-reviewed journals.
Strong written and oral communication skills.
Demonstrated organizational skills to effectively manage multiple tasks with different priorities.
Previous successful academic or work-related experience mentoring peers.",PerkinElmer,Belle River
881,Product Development Confectionary Scientist,"At Cronos Group, we hire talented people who thrive on solving difficult problems and give them the opportunity to hone new skills and approaches. If you want to play a part in shaping an innovative industry and help build a historically significant company, we want to meet you.

If you are an experienced confectionary scientist with a strong work ethic, enjoy collaborative multi-disciplinary projects and are a motivated self-starter, then this is the job for you! As the Confectionary Scientist you will be leading the development and commercialization of new confectionary products and enhancing existing products. You will work closely with key interdisciplinary stakeholders to drive products forward from concept to implementation. There is a key emphasis on administrative and organizational skills while managing and administrating multidisciplinary projects to take confectionary product concepts from benchtop R&D to commercialization. The ideal candidate is energetic, collaborative, and forward- thinking.

This position is based out of Stayner, Ontario Canada.

What you’ll be doing:

Lead the development of cannabis edible products (confectionary products, chocolate products, baked-goods, beverages and other food products) including product formulations, specifications, packaging, stability, nutritional fact calculations and critical production parameters.
Taking ownership for the development and commercialization of new and enhancement of existing products that meet regulatory, quality, operational, sales, marketing, and financial expectations.
Familiar with regulatory requirements of confectionary and edible products in the Cannabis Act and Canadian Food Inspection Agency (CFIA) requirements; ensuring that products comply with government regulations and certification requirements.
Maintain R&D workspace and R&D equipment for the development and design of confectionary and chocolate products. Designing experiments and leading formulation design, recipe development and standardization of final formulation specifications.
Collaborate with operations for manufacturing equipment selections, technical transfer of production manufacturing, and final product quality and integrity; ensuring critical control parameters and product attributes are successfully transferred to the operations teams.
Ensure inventory traceability and administrative documentation of all cannabis product being used for Product Development activities (all R&D and scale up activities) Collect, organize and interpret data from experiments, prepare reports and present results
Work with procurement and quality teams to select & qualify suppliers and draft raw material specifications.
Collaborate with innovation and finance team to help develop costings of product and assist in business case development.
Track and report on industry trends and competitor intelligence: track and develop subject-matter expertise regarding economic, regulatory, and marketing issues and trends including monitoring new product filings and other product development related publications.
Work with consumer insights and marketing teams to discovery new opportunities and define technically feasible products to meet novel consumer needs and existing market gaps.


You’ll need to have:

Post-secondary education in Food Science, Science, Engineering, Culinary or related field.
A minimum of 5+ years in food product development or cannabis edible product development
Experience with all types of confectionary manufacturing processes (eg, chocolate panning, chocolate enrobing, gummy manufacturing, hard-candy manufacturing, etc…)



We are committed to fostering a diverse and inclusive work environment, and we welcome and encourage applications from people with disabilities and people with diverse backgrounds, identities, and cultures. For candidates with disabilities, accommodations are available upon request in all phases of the selection process.","Cronos Group Inc.
2.7",Stayner
882,Product Development Confectionary Scientist,"At Cronos Group, we hire talented people who thrive on solving difficult problems and give them the opportunity to hone new skills and approaches. If you want to play a part in shaping an innovative industry and help build a historically significant company, we want to meet you.

If you are an experienced confectionary scientist with a strong work ethic, enjoy collaborative multi-disciplinary projects and are a motivated self-starter, then this is the job for you! As the Confectionary Scientist you will be leading the development and commercialization of new confectionary products and enhancing existing products. You will work closely with key interdisciplinary stakeholders to drive products forward from concept to implementation. There is a key emphasis on administrative and organizational skills while managing and administrating multidisciplinary projects to take confectionary product concepts from benchtop R&D to commercialization. The ideal candidate is energetic, collaborative, and forward- thinking.

This position is based out of Stayner, Ontario Canada.

What you’ll be doing:

Lead the development of cannabis edible products (confectionary products, chocolate products, baked-goods, beverages and other food products) including product formulations, specifications, packaging, stability, nutritional fact calculations and critical production parameters.
Taking ownership for the development and commercialization of new and enhancement of existing products that meet regulatory, quality, operational, sales, marketing, and financial expectations.
Familiar with regulatory requirements of confectionary and edible products in the Cannabis Act and Canadian Food Inspection Agency (CFIA) requirements; ensuring that products comply with government regulations and certification requirements.
Maintain R&D workspace and R&D equipment for the development and design of confectionary and chocolate products. Designing experiments and leading formulation design, recipe development and standardization of final formulation specifications.
Collaborate with operations for manufacturing equipment selections, technical transfer of production manufacturing, and final product quality and integrity; ensuring critical control parameters and product attributes are successfully transferred to the operations teams.
Ensure inventory traceability and administrative documentation of all cannabis product being used for Product Development activities (all R&D and scale up activities) Collect, organize and interpret data from experiments, prepare reports and present results
Work with procurement and quality teams to select & qualify suppliers and draft raw material specifications.
Collaborate with innovation and finance team to help develop costings of product and assist in business case development.
Track and report on industry trends and competitor intelligence: track and develop subject-matter expertise regarding economic, regulatory, and marketing issues and trends including monitoring new product filings and other product development related publications.
Work with consumer insights and marketing teams to discovery new opportunities and define technically feasible products to meet novel consumer needs and existing market gaps.


You’ll need to have:

Post-secondary education in Food Science, Science, Engineering, Culinary or related field.
A minimum of 5+ years in food product development or cannabis edible product development
Experience with all types of confectionary manufacturing processes (eg, chocolate panning, chocolate enrobing, gummy manufacturing, hard-candy manufacturing, etc…)



We are committed to fostering a diverse and inclusive work environment, and we welcome and encourage applications from people with disabilities and people with diverse backgrounds, identities, and cultures. For candidates with disabilities, accommodations are available upon request in all phases of the selection process.","Cronos Group Inc.
2.7",Stayner
883,"Manager, Data Science - Machine Learning TORONTO, ONSOFTWARE","Who We Are

Tonal is the smartest home gym and personal trainer. It has completely revolutionized the way people work out at home, with its sleek design and advanced A.I. technology. We’ve united a diverse team of experts and decades of research to reinvented strength training, making it more efficient, more effective, and more engaging.

With this in mind, we want to bring that same innovative approach to the workplace. At Tonal, we continue our shift of emphasis by growing our instrumental team. We collectively weave our knowledge and creativity, as we redefine the future of fitness. We are passionate about building products that transform lives, and building teams that transform the status quo. Together, we can be our strongest.

What You Will Do

Lead a team of passionate data scientists focused on modeling members’ fitness performance and providing weight recommendations
Develop algorithms to sense, understand, and derive insights on human motion while exercising via computer vision, pose detection, and more.
Review the team’s designs, algorithms, and code while also spending time developing your own
Lead the initiative to fully leverage the world's largest and best fitness data set
Collaborate closely with fitness experts on training methodologies. Validate and innovate on new more effective training methodologies using a data-driven approach
Work closely and collaborate with front-end and back-end teams to take the team’s work to production
Drive the direction of Tonal’s architecture, data collection, analytics, infrastructure, tools, and learning systems
Leverage your creativity to identify innovative opportunities for new data-driven features

Who You Are

Advanced degree in engineering, scientific, or mathematical field
5+ years data science experience
2+ years leading and/or managing technical teams
Knowledge of machine learning and signal processing algorithms
Working experience with data filtering and cleansing techniques
Strong knowledge of Python and SQL
Working knowledge of software development, including RESTful APIs
Team player with high integrity
Open to feedback and constantly striving to learn and improve
High degree of self-awareness

Tonal is committed to meeting the diverse needs of people with disabilities in a timely manner that is consistent with the principles of independence, dignity, integration and equality of opportunity. Should you have any accommodation requests, please reach out to us via our confidential email, accessibility@tonal.com. All requests will be addressed and responded to in accordance with Tonal’s Accessibility Policy and local legislation.","Tonal
4.4",Midtown Toronto
884,Senior AI / ML Scientist,"Antuit.ai is the leader in AI-powered SaaS solutions, empowering world-class Consumer Products and Retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. Antuit.ai’s executives, comprised of industry leaders from SAP, SAS, IBM, and Accenture, and our team of Ph.Ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. Antuit is funded by Goldman Sachs and Zodius Capital.

The Role:

Antuit.ai is interested in hiring an AI and Machine Learning Researcher to design and develop advanced machine learning algorithms and systems in the programming language of choice (PySpark + Python). The successful candidate should also have ample experience in developing and deploying machine learning algorithms and data transformation modules. Experience of working in the demand forecasting or supply chain domain would be an added advantage.

Responsibilities:

Responsibilities includes, but are not limited to the following:

Research and implement AI algorithms and tools as a proof-of-concept and move it to the production-ready state
Pefrom appropriate feature extraction and data representation
Optimize and transform data science prototypes/solutions for speed, reliability, and scale
Implementing scalable algorithms using Spark and Dask.
Collaborate cross-functionally with domain experts to identify gaps and structural problems

Qualifications and Skills:

The successful candidate will have the following profile/experience:
D. or M.S. in Computer Science, Computer Engineering, Electrical Engineering, Statistics, Applied Mathematics, or other related fields.
5+ years’ experience working in applied machine learning.
Extensive experience in designing, tunning, and deploying scalable Deep Learning models with Tensorflow and Keras.
Experience in developing scalable machine learning pipelines using PySpark and Dask
Familiarity with linear and non-linear regression models and time-series forecasting models and libraries in python.
Experience in developing ML/AI algorithms using Nvidia CUDA is an advantage.
Skilled in developing and deploying machine learning models and solutions, analytical problem-solving, pattern recognition, and predictive modeling
Understanding of data structures, data modeling, and software architecture. The experience of working on cloud infrastructures will be helpful.
Strong communication skills.
Strong work ethic and passion for learning and contributing to the development
Collaborative mindset. Able to collaborate closely and effectively with teams

Information Security Responsibilities

Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System.
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).

EEOC

Antuit.ai is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.ai.

“Antuit.ai thanks all applicants; however, only those selected for an interview will be contacted. “","Tonal
4.4",Midtown Toronto
885,Senior AI / ML Scientist,"Antuit.ai is the leader in AI-powered SaaS solutions, empowering world-class Consumer Products and Retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. Antuit.ai’s executives, comprised of industry leaders from SAP, SAS, IBM, and Accenture, and our team of Ph.Ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. Antuit is funded by Goldman Sachs and Zodius Capital.

The Role:

Antuit.ai is interested in hiring an AI and Machine Learning Researcher to design and develop advanced machine learning algorithms and systems in the programming language of choice (PySpark + Python). The successful candidate should also have ample experience in developing and deploying machine learning algorithms and data transformation modules. Experience of working in the demand forecasting or supply chain domain would be an added advantage.

Responsibilities:

Responsibilities includes, but are not limited to the following:

Research and implement AI algorithms and tools as a proof-of-concept and move it to the production-ready state
Pefrom appropriate feature extraction and data representation
Optimize and transform data science prototypes/solutions for speed, reliability, and scale
Implementing scalable algorithms using Spark and Dask.
Collaborate cross-functionally with domain experts to identify gaps and structural problems

Qualifications and Skills:

The successful candidate will have the following profile/experience:
D. or M.S. in Computer Science, Computer Engineering, Electrical Engineering, Statistics, Applied Mathematics, or other related fields.
5+ years’ experience working in applied machine learning.
Extensive experience in designing, tunning, and deploying scalable Deep Learning models with Tensorflow and Keras.
Experience in developing scalable machine learning pipelines using PySpark and Dask
Familiarity with linear and non-linear regression models and time-series forecasting models and libraries in python.
Experience in developing ML/AI algorithms using Nvidia CUDA is an advantage.
Skilled in developing and deploying machine learning models and solutions, analytical problem-solving, pattern recognition, and predictive modeling
Understanding of data structures, data modeling, and software architecture. The experience of working on cloud infrastructures will be helpful.
Strong communication skills.
Strong work ethic and passion for learning and contributing to the development
Collaborative mindset. Able to collaborate closely and effectively with teams

Information Security Responsibilities

Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System.
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).

EEOC

Antuit.ai is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.ai.

“Antuit.ai thanks all applicants; however, only those selected for an interview will be contacted. “","Antuit
4.1",Remote
886,Senior AI / ML Scientist,"Antuit.ai is the leader in AI-powered SaaS solutions, empowering world-class Consumer Products and Retail companies to digitally transform their supply chain, merchandising, marketing and omnichannel operations. Antuit.ai’s executives, comprised of industry leaders from SAP, SAS, IBM, and Accenture, and our team of Ph.Ds., data scientists, technologists, and domain experts are passionate about generating real value for our clients. Antuit is funded by Goldman Sachs and Zodius Capital.

The Role:

Antuit.ai is interested in hiring an AI and Machine Learning Researcher to design and develop advanced machine learning algorithms and systems in the programming language of choice (PySpark + Python). The successful candidate should also have ample experience in developing and deploying machine learning algorithms and data transformation modules. Experience of working in the demand forecasting or supply chain domain would be an added advantage.

Responsibilities:

Responsibilities includes, but are not limited to the following:

Research and implement AI algorithms and tools as a proof-of-concept and move it to the production-ready state
Pefrom appropriate feature extraction and data representation
Optimize and transform data science prototypes/solutions for speed, reliability, and scale
Implementing scalable algorithms using Spark and Dask.
Collaborate cross-functionally with domain experts to identify gaps and structural problems

Qualifications and Skills:

The successful candidate will have the following profile/experience:
D. or M.S. in Computer Science, Computer Engineering, Electrical Engineering, Statistics, Applied Mathematics, or other related fields.
5+ years’ experience working in applied machine learning.
Extensive experience in designing, tunning, and deploying scalable Deep Learning models with Tensorflow and Keras.
Experience in developing scalable machine learning pipelines using PySpark and Dask
Familiarity with linear and non-linear regression models and time-series forecasting models and libraries in python.
Experience in developing ML/AI algorithms using Nvidia CUDA is an advantage.
Skilled in developing and deploying machine learning models and solutions, analytical problem-solving, pattern recognition, and predictive modeling
Understanding of data structures, data modeling, and software architecture. The experience of working on cloud infrastructures will be helpful.
Strong communication skills.
Strong work ethic and passion for learning and contributing to the development
Collaborative mindset. Able to collaborate closely and effectively with teams

Information Security Responsibilities

Understand and adhere to Information Security policies, guidelines and procedure, practice them for protection of organizational data and Information System.
Take part in Information Security training and act accordingly while handling information.
Report all suspected security and policy breach to Infosec team or appropriate authority (CISO).

EEOC

Antuit.ai is an at-will, equal opportunity employer. We consider applicants for all positions without regard to race, color, religion, national origin or ancestry, gender identity, sex, age (40+), marital status, disability, veteran status, or any other legally protected status under local, state, or federal law.

To apply, please send your resume or CV to careers@antuit.ai.

“Antuit.ai thanks all applicants; however, only those selected for an interview will be contacted. “","Antuit
4.1",Remote
887,Data Engineer (Only for those on the autism spectrum),"Specialisterne Canada is recruiting on behalf of CIBC!

Specialisterne Canada specializes in working with businesses to hire people on the autism spectrum or who identify as neurodivergent[1]. Presently, Specialisterne Canada is working with CIBC to recruit for a several positions in downtown Toronto.

Specialisterne Canada provides recruitment, staffing solutions and management support to businesses interested in creating a more neurodiverse workforce. Specialisterne has an expertise in developing more comfortable processes and work environments where employees can feel productive and supported. We help managers understand the strengths of their employees and implement strategies to help them thrive in the workplace.

CIBC places a high value on diversity in its workforce, recognizes the business benefits that accrue from responding to challenges from multiple perspectives, and is exercising a leadership position in the hiring of people with disabilities.

Applications should be submitted in full no later than July 2nd, 2021.

DATA ENGINEER

Full-time, Permanent

Downtown Toronto/Remote

Are you interested in using and developing your skills in software development? Do you enjoy problem solving and critical thinking? Does transforming data into technology-based solutions sound like something you would enjoy?

Here is what you will do:

Develop technology-based solutions to identify potential money laundering as part of governmental compliance
Work alongside a team of Business Systems Analysts to understand business requirements and define technical infrastructure
Design and develop various applications following an agile development process to meet business needs
Perform unit testing to identify bugs and make adjustments as needed to ensure system functionality
Work with data to construct pipelines, apply transformation and cleansing rules and assess data quality

What you will bring:

Have a degree or diploma in Computer Science, Computer Engineering, Data Science, Analytics, Information Technology or a similar discipline
Use your Scala or Spark programming skills to perform analysis and develop applications in line with business requirements
Use your knowledge of SQL or other relational databases to retrieve, manipulate and manage data
Enjoy taking an experimental approach to solving problems and challenges while leveraging your critical thinking skills

Nice to have (not requirements):

Knowledge or experience with Hadoop

[1]Neurodiversity is the concept that there is great diversity in terms of how human brains are wired and work. For the purposes of this recruitment program, this umbrella term has been defined to include but not be limited to conditions such as Autism, ADHD/ADD, PDD-NOS, Mental Health Conditions, Learning Disabilities, and similar ways of being.

Job Types: Full-time, Permanent

Benefits:

Casual dress
Dental care
Disability insurance
Extended health care
Life insurance
Paid time off
RRSP match
Vision care

Schedule:

Monday to Friday

Work remotely:

Temporarily due to COVID-19","Specialisterne Canada
2.6",Midtown Toronto
888,Intermediate/Senior Data Analyst,"Driven by the mission to democratize education, Paper is the leader in personalized learning. Partnering with innovative schools and school districts, Paper helps deliver true educational equity through their category leading Educational Support System (ESS) that offers virtual access to 24/7 tutors and essay reviewers. Founded in 2014, Paper philosophically believes that all students should be given the tools and resources to reach their academic potential, independent of socio-economic status, geography, language or other barriers. Today, Paper is partnered with over 700 schools and supports over 750,000 students. We are headquartered in Montreal, Quebec with remote employees across the US and Canada. Paper is proud to have been named by GSV as one of the most transformational growth companies in digital learning .
Paper is looking for an experienced Data Analyst to join our growing R&D and analytics team. This position will be responsible for conducting full lifecycle analysis for cross functional teams. This will include requirements elicitation, domain modeling, experiment design, data reporting, and long-term reporting maintenance. The data analyst will also be expected to participate in maintaining and extending existing data transformation pipelines as well as monitoring performance and quality control plans to identify improvement opportunities. The ideal candidate is an experienced data enthusiast who enjoys acting as an enabler and gatekeeper for the company's data so stakeholders can understand and use it to make strategic business decisions. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of uncovering new insights from data to support the company's mission and growth.

Responsibilities

Interpret data, analyze results using statistical techniques and provide ongoing reports, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.

Acquire data from primary or secondary data sources.

Participate in fulfilling data requests from multiple teams.

Design and carry-out experiments to test business assumptions or assess the impact of interventions.

Prepare reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data and suggest data-driven interventions.

Collaborate with data engineers, data scientists, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance.

Create appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary.

Work with management to prioritize business and information needs.

Requirements

Technical expertise regarding data models, database design development, data mining and segmentation techniques.

Knowledge of statistics and experience using statistical packages for analyzing datasets.

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.

Adept at queries, report writing and presenting findings.

Strong project management and organizational skills.

Experience supporting and working with cross-functional teams in a dynamic environment.

Programming experience (Python, R, Mathlab, etc).

We are looking for a candidate who has attained a degree in Mathematics, Physics, Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Having prior experience using the following software/tools is a plus:

Experience with databases (SQL),

Experience with ELT frameworks (e.g. dbt)

Experience in experiment design

Experience with reporting packages (Tableau etc)

Position can be located in any geography in the US or Canada.
About Paper

A great place to work! Paper offers a fast-paced, dynamic, inclusive work environment where all employees have an impact. You will be challenged to achieve, develop, and grow as part of a hyper-growth company.

The diverse experiences, ideas, and identities of PAPER's team members help us make better decisions and drive great results. We foster an inclusive work environment that welcomes team members of all backgrounds and perspectives. We are committed to providing a meaningful environment for every member of our team. We hire exceptional people and reward them with trust, autonomy, mentorship, and growth.

We are naturally curious and have strong attention to detail. We love working in a team environment where trust is key and we all strive to make an impact every day. If this sounds like the right fit, please apply and come work with us.",Paper,Quebec
889,Sr. Data Engineer (Python),"TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us.

Department Overview

The Team

Our team is made up of a number of business SMEs and data engineering enthusiasts coming from a variety of diverse backgrounds and industries. We take pride in innovation and developing futuristic analytics apps for the Front Office. Our app provides much needed metrics and client information to the Front Office that enables informed decision making and supplements revenue generation opportunity identifications. We have already delivered solutions to a number of front-office desks, and are seeking to speed up the delivery for the remaining desks.

We also collaborate with multiple teams across the dealer to brainstorm on data pipelines. Being a downstream consumer of huge amounts of data, we drive key decisions around how/when/where of the data elements. Our team is a high-visibility team, as the data is used across the Dealer, by all the desk heads, and senior management. And, this visibility is going to increase along with onboarding new workstreams and data sets for the remaining Front Office Desks.

We also know how to have fun by organizing and participating in various social events. Though coronavirus pandemic spoiled our in-person team get togethers this year, but, we do organize team trips to the driving range, bowling, baseball games, ski trips, and of course: frequent trips to the bar.

Job Description

Brief Role Description
An experienced Data Engineer to work on a fast-paced front-office facing Client Analytics Data Engineering team at a leading wholesale bank (investment banking + global markets) with a great culture. Analyze, design and develop highly impactful analytics that help support and drive decision making, and highlight areas of revenue generation. This role will focus heavily on analyzing huge data sets, writing Python code, and working closely with the business to elicit requirements.

Required Skills

5+ years data analytics experience, with significant experience in Jupyter Notebooks and Python; specifically, in Pandas, NumPy, Plotly and Dash.
Should have experience in both data analysis & requirements gathering as the role involves high engagement with the users.
Excellent communication skills required as this is a front-office facing Client Analytics application with heavy user interaction with traders and salespersons.
Experience in Capital Markets is necessary, as the team is involved in trade data, market data and reference data analytics.
Experience in Fixed Income, Foreign Exchange & Derivative products – at least intermediate understanding of the inner workings of various products offered in the above asset classes.
Passion for data analytics with strong sense of best practices.
Self-starting and motivated, with sense of responsibility
Strong sense of ownership
Enjoys working in a fast-paced environment
Has an eye for design and usability



Job Requirements

The Role

Data Engineer on a fast-paced front-office facing Client Analytics Data Engineering team at a leading investment bank with a great culture.
Lead individual data analysis and insights workstreams from start to finish, in close collaboration with the Front Office.
Gather requirements from the stakeholders, analyze data based on the requirements, present finding to the stakeholders, and iterate over the process until methodologies and metrics are finalized.
Perform data analysis on huge sets of trade data, market data and reference data to generate metrics that can be used to support and drive decision making for the front office.
Add to the Python codebase, the novel ideas and techniques that can be used to innovate and improve upon the existing infrastructure.
Provide user training and support to front office for the UI as well as for Jupyter Notebooks.
Translate business requirements to functional specifications for the development team.
Take part in design sessions to brainstorm on the best approach and design that should be followed to implement the solution. Should not be afraid to speak their mind.
Follow agile approach in monthly release cycles. Perform analysis, planning and testing of the requirements to ensure accurate delivery of the solution.
Help debug and solve issues in different envs and identify any potential bugs that can harm the application.
Willingness to work hard in a flexible environment using agile methodologies.
Comfortable working with new software tools - not afraid of new technology.
Help support existing production applications (provide L3 support as needed)
Update Confluence (wiki) site and documentation to reflect additions/changes to the workstreams, or other essential information.
Ensure effective communication of estimates & timelines to the rest of the team, including status updates of current work
Contribute to the development of project plans by providing input and manage project estimates / initiatives, communicating project status to business and management and providing timely escalation of issues
Support releases as needed

Teamwork
Collaborate with other team members (developers/Data Engineers/PM) and stakeholders in order to understand/gather business requirements and analyze data.
Responsible for turning business requirements into functional specification, interacting directly with the front office traders for further requirements elaboration & discussion
Work closely with Project Managers, Delivery / Partner Management, Data Engineers, sponsors and relevant stakeholders to clarify requirements, develop analysis plans and strategies
Teamwork: Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services
Participate in knowledge transfer within the team and business units as needed

Desired Interpersonal Skills
Takes great personal pride in building robust analytics solutions
Strong sense of ownership
Passionate about data and data analysis
Enjoys working in a fast-paced environment
Has excellent written and verbal communication skills
Has strong customer focus



Additional Information

Join in on what others in TD Technology Solutions are doing:

Inspire a positive work environment and help champion quality, innovation, teamwork and service to the business.
Learn voraciously, stretch your thinking,

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Job Family

Business Systems Analysis

Job Category - Primary

Technology Solutions

Job Category(s)

Technology Solutions

Hours

37.5

Business Line

Corporate

Time Type

Full Time

Employment Type

Regular

Country

Canada

**Province/State (Primary)

Ontario

City (Primary)

Toronto

Work Location

TD Centre - North - 77 King Street West

Job Expires

22-Jun-2021","TD Bank
4.0",Midtown Toronto
890,Data Engineer - Salentica,"SS&C is a global provider of investment and financial services and software for the financial services and healthcare industries. Named to Fortune 1000 list as top U.S. company based on revenue, SS&C is headquartered in Windsor, Connecticut and has 20,000+ employees in over 90 offices in 35 countries. Some 18,000 financial services and healthcare organizations, from the world's largest institutions to local firms, manage and account for their investments using SS&C's products and services.

Job Description

Data Engineer

Location: King Street, Toronto

SS&C Technologies Holdings, Inc. is a global provider of financial services software and software-enabled services. Founded in 1986, SS&C has built the most comprehensive powerhouse of software technology in the financial services industry – technology that complements our unrivaled expertise and professionalism in fund administration, insurance and pension funds, and asset and wealth management accounting and operations. Named by Forbes as one of America’s best midsize employers, SS&C has more than 20,000 employees and 15,000 clients worldwide, and is headquartered in Windsor, Connecticut, with offices throughout North America, Europe, Asia Pacific, Africa, and Australia.

SS&C Salentica, a subsidiary of SS&C Technologies is an industry-leading provider of software and services to the Financial Services industry. We are currently looking for an industry proven, self-motivated Product Manager to join our team of experienced professionals. The successful candidate will be a conscientious worker with a record of success, who has demonstrated they can work collaboratively and adapt to changing technologies.

Responsibilities:

Build data driven systems, architectures, and platforms to provide innovative solutions for long-term analytical outputs and cloud based application development projects.
Participate on cross-functional teams of technology, product, and business specialists to deliver best-in-class, customer-centric, big data projects by leveraging leading edge tools and technologies.
Use strong technical and quantitative knowledge and skills to identify new opportunities for business solutions within vast amounts and varieties of data, delivers compelling proposals, defines requirements, designs new projects, and guides them through successful delivery and validation to drive business growth.
Translate business problems into analytical, data-driven methodology to improve business efficiencies and make significant financial gains.
Communicate complex analysis in a clear, understandable way to non-experts.
Design and continuously improves algorithms. Mines raw, relevant data from a variety of sources to identify patterns and correlations and to generate best-in-class actionable and meaningful insights.
Manage stakeholders and guides them in unlocking the value in their data.
Influences architectures that will lead to transformation of data analytics platforms and information technology overall.

Qualifications:

Minimally requires a Master's degree, or Bachelor's degree and 2 years of related experience, or high school degree and 4 years of related experience.
Experience in the Financial Services industry
Experience with CRM applications and/or digital reporting portal applications
Technical skills with any or all of:

Java programming, AWS infrastructure, Linux, Bash scripting

Self-motivator; able to grasp concepts quickly with minimal supervision, take ownership of problems and follow them through to completion
Intermediate professional working on projects of a moderate scope or on varied tasks that require resourcefulness, self-initiative, and significant independent judgement
Outstanding communication skills; both oral and written
Demonstrates a developing functional knowledge to evaluate the implications of issues and make recommendations for solutions.
Guide less experienced team members. May recommend new procedures.

SS&C Offers:

An extensive health benefit plan
RRSP Matching Program and Bonus Potential
Generous training allowance and Tuition Reimbursement Program
Candidate Referral Program
Business casual work environment
Work/Life Balance
Close to all transit

To further explore this opportunity, please APPLY NOW through our careers page on the corporate website. No phone calls please. We thank all candidates for their interest, but only those under consideration will be contacted.

#LI-LM1

Unless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. SS&C offers excellent benefits including health, dental, 401k plan, tuition and professional development reimbursement plan. SS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.","SS&C Technologies
3.1",Midtown Toronto
891,Data Engineer (4-month contract),"ABOUT US

CI Global Asset Management is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.


POSITION: Data Engineer
LOCATION: Toronto (M5J 0A3)
STATUS: Contract (6 months)


JOB OVERVIEW

We are currently seeking a Data Engineer to join our Client Reporting and Data Management team. The successful candidate will work closely with our data science team on the development of our centralized predictive analytics function. In this role, you will assist with solving high-value business problems by extracting and manipulating large, complex datasets for use by data scientists. The role will be a four month contract position, with an option to extend based on performance.


WHAT YOU WILL DO

Collaborate with business analysts, data scientists, software engineers, and solution architects to develop data pipelines to feed our data marketplace
Extract, analyze & interpret large, complex datasets for use in predictive modelling
Utilize AWS tools to develop automated, productionized data pipelines
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Develop and support ETL code for data warehouse and data marts to support the reporting and data analytic systems.


WHAT YOU WILL BRING

Experience

At least 1 year of work experience in quantitative analysis
Strong CS fundamental, Data Structure and Algorithm knowledge
Strong understanding of Statistics
Experience working and preparing data for Data Science / Machine Learning models preferred
Experience with large-scale, AWS big data storage such as S3 and EBS
Experience creating ETL jobs using AWS Glue
Experience with AWS Data pipeline tools like Cloudwatch and Stepfunctions
Experience working with data preparation tools like Talend
Experience in the Financial Services Industry is an asset

Education/Training

Post-secondary degree in a quantitative discipline

Knowledge, Skills, and Abilities

Strong knowledge with programming methodologies (version control, testing, QA) and agile development methodologies.
In-depth knowledge of AWS tools required to develop automated, productionized data pipelines
In depth knowledge of and experience with relational, SQL and NoSQL databases
Fluency with SQL, R and Python (pandas, boto3, scikit-learn, sparkmagic)
Experience working with large, complex datasets
Excellent communication, writing and interpersonal skills


WHAT YOU CAN EXPECT FROM US

Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:

Recognition & Compensation
Training & Development
Health & Well-being
Communication & Feedback


If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.

Only qualified candidates selected for an interview will be contacted.

CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.


Posting Tags: IND# #LI-POST","CI Financial
3.4",Midtown Toronto
892,Data Engineer (4-month contract),"ABOUT US

CI Global Asset Management is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.


POSITION: Data Engineer
LOCATION: Toronto (M5J 0A3)
STATUS: Contract (6 months)


JOB OVERVIEW

We are currently seeking a Data Engineer to join our Client Reporting and Data Management team. The successful candidate will work closely with our data science team on the development of our centralized predictive analytics function. In this role, you will assist with solving high-value business problems by extracting and manipulating large, complex datasets for use by data scientists. The role will be a four month contract position, with an option to extend based on performance.


WHAT YOU WILL DO

Collaborate with business analysts, data scientists, software engineers, and solution architects to develop data pipelines to feed our data marketplace
Extract, analyze & interpret large, complex datasets for use in predictive modelling
Utilize AWS tools to develop automated, productionized data pipelines
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Develop and support ETL code for data warehouse and data marts to support the reporting and data analytic systems.


WHAT YOU WILL BRING

Experience

At least 1 year of work experience in quantitative analysis
Strong CS fundamental, Data Structure and Algorithm knowledge
Strong understanding of Statistics
Experience working and preparing data for Data Science / Machine Learning models preferred
Experience with large-scale, AWS big data storage such as S3 and EBS
Experience creating ETL jobs using AWS Glue
Experience with AWS Data pipeline tools like Cloudwatch and Stepfunctions
Experience working with data preparation tools like Talend
Experience in the Financial Services Industry is an asset

Education/Training

Post-secondary degree in a quantitative discipline

Knowledge, Skills, and Abilities

Strong knowledge with programming methodologies (version control, testing, QA) and agile development methodologies.
In-depth knowledge of AWS tools required to develop automated, productionized data pipelines
In depth knowledge of and experience with relational, SQL and NoSQL databases
Fluency with SQL, R and Python (pandas, boto3, scikit-learn, sparkmagic)
Experience working with large, complex datasets
Excellent communication, writing and interpersonal skills


WHAT YOU CAN EXPECT FROM US

Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:

Recognition & Compensation
Training & Development
Health & Well-being
Communication & Feedback


If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.

Only qualified candidates selected for an interview will be contacted.

CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.


Posting Tags: IND# #LI-POST","CI Financial
3.4",Midtown Toronto
893,Enterprise Data Engineer,"Job Types

Full-time, permanent

COVID-19 Considerations

We adhere to all Alberta COVID-19 protocols.

Location

Calgary, AB

Who we are:

Competing in a data-driven world, most businesses struggle to capture real value from data and analytics. Data management constraints cause mid-size and large companies to miss key opportunities in the value chain. Companies are left vulnerable to underwhelming performance and encroachment by competitors.

A4 Systems is a world-class team of cyber physical system product developers, transforming quality data into primary competitive advantage. A trusted partner to industries like manufacturing, agriculture, and energy, A4 builds mission-critical SaaS products for customers to achieve breakthrough performance.

What you’ll be doing:

This is an excellent opportunity to develop practical solutions to real world industrial data problems. The focus is on backend development implementing data pipelines in a microservices environment without relying on GCP or AWS tooling. You will develop integrations with our ERP platform to customise and extend functionality.

Who you are:
Bachelor’s Degree in Computer Science, engineering, or equivalent
This is an intermediate role for a developer with 3-5 years experience who is ready to take on new challenges.
Experience in the Open Source ecosystem is key along with proven ability to acquire new skills.
A desire and capacity to learn are key.
Rapid implementation of solutions – with a focus on delivery followed by iterations to build on success.
Ability to manage multiple technologies to create comprehensive backend solutions.
3-5 years of Experience with the following:
Python
JavaScript
Nice to Have:
Java
Docker
Kubernetes
GraphQL
Apollo
Apache NiFi
noSQL, ideally Cassandra
PostgreSQL
Odoo ERP","A4 Systems
5.0",Calgary
894,Enterprise Data Engineer,"Job Types

Full-time, permanent

COVID-19 Considerations

We adhere to all Alberta COVID-19 protocols.

Location

Calgary, AB

Who we are:

Competing in a data-driven world, most businesses struggle to capture real value from data and analytics. Data management constraints cause mid-size and large companies to miss key opportunities in the value chain. Companies are left vulnerable to underwhelming performance and encroachment by competitors.

A4 Systems is a world-class team of cyber physical system product developers, transforming quality data into primary competitive advantage. A trusted partner to industries like manufacturing, agriculture, and energy, A4 builds mission-critical SaaS products for customers to achieve breakthrough performance.

What you’ll be doing:

This is an excellent opportunity to develop practical solutions to real world industrial data problems. The focus is on backend development implementing data pipelines in a microservices environment without relying on GCP or AWS tooling. You will develop integrations with our ERP platform to customise and extend functionality.

Who you are:
Bachelor’s Degree in Computer Science, engineering, or equivalent
This is an intermediate role for a developer with 3-5 years experience who is ready to take on new challenges.
Experience in the Open Source ecosystem is key along with proven ability to acquire new skills.
A desire and capacity to learn are key.
Rapid implementation of solutions – with a focus on delivery followed by iterations to build on success.
Ability to manage multiple technologies to create comprehensive backend solutions.
3-5 years of Experience with the following:
Python
JavaScript
Nice to Have:
Java
Docker
Kubernetes
GraphQL
Apollo
Apache NiFi
noSQL, ideally Cassandra
PostgreSQL
Odoo ERP","A4 Systems
5.0",Calgary
895,Enterprise Data Engineer,"Job Types

Full-time, permanent

COVID-19 Considerations

We adhere to all Alberta COVID-19 protocols.

Location

Calgary, AB

Who we are:

Competing in a data-driven world, most businesses struggle to capture real value from data and analytics. Data management constraints cause mid-size and large companies to miss key opportunities in the value chain. Companies are left vulnerable to underwhelming performance and encroachment by competitors.

A4 Systems is a world-class team of cyber physical system product developers, transforming quality data into primary competitive advantage. A trusted partner to industries like manufacturing, agriculture, and energy, A4 builds mission-critical SaaS products for customers to achieve breakthrough performance.

What you’ll be doing:

This is an excellent opportunity to develop practical solutions to real world industrial data problems. The focus is on backend development implementing data pipelines in a microservices environment without relying on GCP or AWS tooling. You will develop integrations with our ERP platform to customise and extend functionality.

Who you are:
Bachelor’s Degree in Computer Science, engineering, or equivalent
This is an intermediate role for a developer with 3-5 years experience who is ready to take on new challenges.
Experience in the Open Source ecosystem is key along with proven ability to acquire new skills.
A desire and capacity to learn are key.
Rapid implementation of solutions – with a focus on delivery followed by iterations to build on success.
Ability to manage multiple technologies to create comprehensive backend solutions.
3-5 years of Experience with the following:
Python
JavaScript
Nice to Have:
Java
Docker
Kubernetes
GraphQL
Apollo
Apache NiFi
noSQL, ideally Cassandra
PostgreSQL
Odoo ERP","A4 Systems
5.0",Calgary
896,Enterprise Data Engineer,"Job Types

Full-time, permanent

COVID-19 Considerations

We adhere to all Alberta COVID-19 protocols.

Location

Calgary, AB

Who we are:

Competing in a data-driven world, most businesses struggle to capture real value from data and analytics. Data management constraints cause mid-size and large companies to miss key opportunities in the value chain. Companies are left vulnerable to underwhelming performance and encroachment by competitors.

A4 Systems is a world-class team of cyber physical system product developers, transforming quality data into primary competitive advantage. A trusted partner to industries like manufacturing, agriculture, and energy, A4 builds mission-critical SaaS products for customers to achieve breakthrough performance.

What you’ll be doing:

This is an excellent opportunity to develop practical solutions to real world industrial data problems. The focus is on backend development implementing data pipelines in a microservices environment without relying on GCP or AWS tooling. You will develop integrations with our ERP platform to customise and extend functionality.

Who you are:
Bachelor’s Degree in Computer Science, engineering, or equivalent
This is an intermediate role for a developer with 3-5 years experience who is ready to take on new challenges.
Experience in the Open Source ecosystem is key along with proven ability to acquire new skills.
A desire and capacity to learn are key.
Rapid implementation of solutions – with a focus on delivery followed by iterations to build on success.
Ability to manage multiple technologies to create comprehensive backend solutions.
3-5 years of Experience with the following:
Python
JavaScript
Nice to Have:
Java
Docker
Kubernetes
GraphQL
Apollo
Apache NiFi
noSQL, ideally Cassandra
PostgreSQL
Odoo ERP","A4 Systems
5.0",Calgary
897,Applied Deep Learning Scientist (Focus on Computer Vision),"Location: Montreal, Canada

Dans des marchés en rapide évolution, les clients à travers le monde font confiance à Thales. Thales est une entreprise où les personnes les plus brillantes du monde entier se regroupent pour mettre en commun leurs idées et ainsi s'inspirer mutuellement. Dans tous les secteurs où œuvre Thales, notamment l’aérospatiale, le transport, la défense, la sécurité et l'espace, nos équipes d’architectes conçoivent des solutions innovantes qui rendent demain possible dès aujourd’hui.

Carrefour mondial de l’intelligence artificielle, Montréal est le foyer du nouveau centre de recherche et de technologie spécialisé en intelligence artificielle (cortAIx) collaborant avec les principaux groupes canadiens de recherche en intelligence artificielle à Montréal et à Toronto. S’appuyant sur ses compétences dans les principaux marchés industriels, Thales donne vie à l'intelligence artificielle au profit de ses clients tout en créant de passionnants emplois pour les chercheurs et les développeurs experts en intelligence artificielle en vue de trouver des solutions qui transformeront notre monde, du fond des océans aux confins de l'univers et du cyberespace. Ayant très tôt opté pour le modèle d’innovation ouverte et collaborative, Thales procède actuellement à la création de la structure du centre de recherche et de technologie spécialisé en intelligence artificielle (cortAIx). Piloté par Thales, le centre cortAIx, en collaboration avec l'Institut québécois d'intelligence artificielle (MILA), l'Institut de valorisation des données (IVADO) et l’Institut Vector de Toronto, est situé dans le célèbre quartier Petite-Italie, au cœur de la communauté de l’innovation à Montréal.

In fast changing markets, customers worldwide rely on Thales. Thales is a business where brilliant people from all over the world come together to share ideas and inspire each other. In aerospace, transportation, defence, security and space, our architects design innovative solutions that make our tomorrow's possible.

Montreal – a world leading AI hub, is home to new Centre of Research & Technology in Artificial Intelligence eXpertise (cortAIx) collaborating with leading Canadian AI research groups in Montreal and Toronto. With competencies in major industrial markets Thales is bringing artificial intelligence to life for our customers creating exciting jobs for AI researchers and developers who will create solutions that will transform our world from the bottom of oceans to the depths of space and cyberspace. As an early adopter of open, creative and collaborative innovation model, Thales is building the Centre of Research and Technology in Artificial Intelligence eXpertise (cortAIx). Led by Thales, cortAIx, in collaboration with the MILA (Artificial Intelligence Institute of Quebec), the IVADO (Institute of Data Valorization) and the Vector Institute of Toronto, is located in Montreal’s famous Little Italy, in the heart of Montreal’s innovation community.

RAISON D’ÊTRE:

Un chercheur en intelligence artificielle (IA) appliquée en recherche et technologie (R&T) est chargé de découvrir, d'activer et d'intégrer des concepts d'IA innovants dans les solutions Thales. Il / elle prouve leur viabilité à travers la mise en œuvre de Proofs of Concept (PoC) et guide leur croissance de maturité à travers des prototypes et des démonstrateurs qui à leur tour illustreront et permettront leur plein potentiel commercial.

MISSIONS PRINCIPALES

En tant que chercheur en IA appliquée à la recherche et à la technologie, vous dirigerez les activités clés tout au long de nos projets au rythme rapide.

Pour réussir dans ce rôle, la curiosité pour ce qui est nouveau, la volonté de remettre en question le statu quo, l'ouverture d'esprit et la pensée originale sont essentielles. L'individu doit rapidement apprendre et évaluer les nouvelles techniques et technologies afin de décider de les adopter, de les adapter ou de les abandonner. Il doit également être capable de proposer de nouvelles idées, de les présenter, de les remettre en question et de les améliorer continuellement. L'individu doit posséder des compétences techniques approfondies et pratiques et être familiarisé avec les derniers outils et environnements de développement Deep Learning, avec un fort accent sur les applications de vision par ordinateur, afin de contribuer à la mise en œuvre de ces idées.

Proposer des concepts innovants et les mettre en œuvre est rarement un processus individualiste. Le scientifique fait partie d'une équipe multidisciplinaire. Un fort esprit d'équipe et des capacités de travail d'équipe sont obligatoires. Il / elle contribuera en tant qu'expert technique à des projets de Recherche et Technologie au sein de Thales et de ses business units. Par conséquent, de bonnes compétences en communication sont nécessaires.

EXIGENCES

Maîtrise en informatique, ingénierie ou mathématiques
Expérience préalable en intelligence artificielle, apprentissage automatique
Compétences démontrées dans la conception de systèmes d’IA
Bonne base en mathématiques, statistiques et probabilités
Solide connaissance des fondations de l'apprentissage automatique avec un accent sur les applications de vision par ordinateur
Connaissance des architectures traditionnelles d'apprentissage profond (MLP, CNN, UNET, etc.) et des architectures d'apprentissage génératif profond (GAN, VAE) pour les tâches de vision par ordinateur.
Solides compétences en développement avec des frameworks d'apprentissage automatique tels que Scikit-learn, Tensorflow, Keras, PyTorch, Theano
Solides compétences en programmation Python
Connaissance pratique du système d'exploitation Linux
Volonté de contribuer dans un environnement axé sur l’équipe
Capacités de leadership démontrées dans des organisations scolaires, civiles ou commerciales
Capacité à travailler de manière créative et analytique dans un environnement de résolution de problèmes
Compétences avérées en communication verbale et écrite en anglais (conférences, présentations, publications, etc.)

QUALIFICATIONS PRÉFÉRÉES

Doctorat en informatique, ingénierie ou mathématiques
Minimum 3 ans d'expérience en machine learning en Python avec un intérêt pour le Deep Learning
Un historique de développement de logiciels d'IA (Deep Learning Focus) exceptionnel avec des preuves Github (ou similaires)
Compétences démontrées dans la conception de systèmes d’IA
Intérêt démontré pour le Deep Learning appliqué, y compris 1 / stade précoce de préparation des données, augmentation, génération, 2 / réglage systématique du modèle Deep Learning, 3 / modélisation d'expériences de Machine Learning réplicables, 4 / pipeline d'apprentissage profond pour la sélection et la validation de modèles ML.
Expérience de travail avec des langages de programmation tels que C, C ++, Java, des langages de script (Perl / Python / Ruby) ou similaires
Une expertise en apprentissage automatique embarqué (par exemple, quantification du Deep Learning) est un atout majeur
Expérience pratique de la visualisation des données, des outils / langages d'analyse
Travail d’équipe et collaboration démontrés dans des environnements professionnels
Capacité d'établir une crédibilité auprès des clients et des autres membres de l'équipe
Expérience préalable dans un environnement de recherche et technologie ou d'innovation (brevets, conception de systèmes, etc.)
Historique des publications dans les grandes conférences d'Intelligence Artificielle: CVPR, NeurIPS, IJCAI, AAAI, etc.

JOB PURPOSE

A Research and Technology (R&T) Applied Artificial Intelligence (AI) Scientist is responsible for discovering, enabling and integrating innovative AI concepts into Thales solutions. He/she proves their viability through the implementation of Proofs of Concept (PoCs) and guides their maturity growth through prototypes and demonstrators that will in turn illustrate and enable their full business potential.

KEY JOB FUNCTIONS

As a Research and Technology Applied AI Scientist, you will drive the key activities throughout our fast-paced projects.

To be successful in this role, curiosity for what is new, willingness to challenge the status quo, open-mindedness and out-of-the-box thinking are crucial. The individual should quickly learn and assess new techniques and technologies in order to decide whether to adopt, adapt or discard them. He/she also needs to be able to come up with new ideas, present them, challenge them and improve them continuously. The individual must possess deep, hands-on technical skills and be familiar with latest Deep Learning development tools and environments, with a strong focus on Computer Vision applications, in order to contribute to the implementation of those ideas.

Coming up with innovative concepts and implementing them is rarely an individualistic process. The scientist is part of a multi-disciplinary team. Strong team spirit and teamwork capabilities are mandatory. He/she will contribute as a technical subject matter expert to Research and Technology projects across Thales and its business units. Therefore, good communication skills are required.

ESSENTIAL SKILLS AND QUALIFICATIONS

PhD/Masters degree in computer science, engineering or mathematics fields
Prior experience in artificial intelligence, machine learning
Minimum 3 years of machine learning experience in Python with interest in Deep Learning
A track record of outstanding AI (Deep Learning focus) software development with Github (or similar) evidence
Demonstrated abilities in designing AI systems
Demonstrated interest in applied Deep Learning, including 1/ early stage of data preparation, augmentation, generation, 2/ systematic Deep Learning model tuning, 3/ replicable Machine Learning experiments modeling, 4/ Deep Learning pipeline for ML model selection and validation.
Work experience with programming languages such as C, C++, Java, scripting languages (Perl/Python/Ruby) or similar
Expertise in Embedded Machine Learning (e.g., Deep Learning quantization) is a strong plus
Good foundation in mathematics, statistics and probability
Strong knowledge of Machine Learning foundations with a focus on Computer Vision applications
Knowledge of mainstream Deep Learning architectures (MLP, CNN, UNET, etc) and Deep Generative Learning architectures (GAN, VAE) for computer vision tasks.
Strong development skills with Machine Learning frameworks such as Scikit-learn, Tensorflow, Keras, PyTorch, Theano
Strong Python programming skills
Working knowledge of Linux OS
Eagerness to contribute in a team-oriented environment
Demonstrated leadership abilities in school, civil or business organisations
Ability to work creatively and analytically in a problem-solving environment
Proven verbal and written communication skills in English (talks, presentations, publications, etc.)

Chez Thales, nous proposons des CARRIÈRES passionnantes, pas de simples emplois. Fort de ses 80 000 collaborateurs dans 68 pays, Thales a mis en place une politique de mobilité permettant, chaque année, à des milliers d'employés de faire progresser leur carrière tant dans leur domaine d’expertise que dans de nouveaux domaines de compétences, cela aussi bien dans leur pays d’origine qu’à l'étranger. Ensemble, nous pensons qu’adopter une politique de flexibilité est une manière plus actuelle de travailler. C’est ici que commence votre parcours exceptionnel, postulez sans tarder!

At Thales we provide CAREERS and not only jobs. With Thales employing 80,000 employees in 68 countries our mobility policy enables thousands of employees each year to develop their careers at home and abroad, in their existing areas of expertise or by branching out into new fields. Together we believe that embracing flexibility is a smarter way of working. Great journeys start here, apply now!

Thales s’engage à promouvoir un lieu de travail diversifié et inclusif pour tous. Thales s’engage à fournir des accommodements à toute les étapes du processus de recrutement. Les candidats retenus pour une entrevue qui ont besoin d’accommodement sont priés d’en informer à la suite de l’invitation pour une entrevue. Nous travaillerons avec vous pour répondre à vos besoins. Toutes les informations relatives à l'accommodement fourni seront traitées de manière confidentielle et utilisées uniquement dans le but de fournir une expérience de candidat accessible.

Thales is committed to a diverse and inclusive workplace for all. Thales is committed to providing accommodations in all parts of the interview process. Applicants selected for an interview who require accommodation are asked to advise accordingly upon the invitation for an interview. We will work with you to meet your needs. All accommodation information provided will be treated as confidential and used only for the purpose of providing an accessible candidate experience.","Thales Group
3.7",Montreal
898,Software Developer – Data Science,"Join our team

The Data Strategy & Enablement team is on a continuous journey towards helping TELUS become a world-class leader in data solutions, doing so by delivering data analytics capabilities built upon unified scalable platforms, advanced AI tooling, high quality data, and a data-product and data platform oriented culture while always keeping an eye on the horizon, preparing for the next big thing.

We are entrepreneurial and passionate, believers that so much more is possible and can be achieved by creating value and great outcomes for our customers, team members, communities, and environment and that through meaningful transformation we can integrate dynamic change in our professional lives.

Together, we will develop and execute strategic programs that will enhance the experience for TELUS subscribers and internal stakeholders across TELUS.

Always wanted to work with a team of innovators and be part of a culture that embraces creativity and collaboration? If so, we’d love to talk with you!
Here’s the impact you’ll make and what we’ll accomplish together

As a Software Developer - Data Science, you’ll be a part of the team and journey that will transform the way we do business across various domains. You will provide vision and strategic guidance to evolve from common static analysis to dynamic machine learning deployment.

You will combine your expert knowledge of data science with your strong software development skills to automate and facilitate machine learning model development, training and deployment and will leverage your experience in building reusable algorithms, functions and libraries.

You will be working in an environment defined by continuous integration on multiple solutions that will exchange information. You will have to understand a complex architecture and guide its evolution.

You’ll collaborate with teams across the company to help identify new business opportunities while championing data driven decision making and the accelerated adoption of AI.
Here's how
Lead the software development and implementation of ML & AI and Big Data solutions
Support and evolve the Advanced Analytics and Data Management roadmap by leveraging industry research, best practices and emerging tools/technology on Software Development
Focus on code quality and timely delivery of AI products and solutions with a focus on performance, maintainability and scalability
Build and maintain a strong engagement with key stakeholders to understand business needs and priorities
Identify opportunities for code optimization and refine to improve effectiveness/accuracy and enhance ROI
Collaborate with Data Scientists and Data Engineers within TELUS as well as external business stakeholders
Influence how we approach business challenges and opportunities by driving the adoption of a data driven mindset

Qualifications
You're the missing piece of the puzzle
You are recognized for addressing business needs via your application of software development, data mining and analysis, predictive modeling, statistics and other advanced analytical techniques in which you have previous hands-on work experience
3+ years of experience working in a software engineering role with a track record of building highly scalable and robust systems
You are sought out when it comes to analyzing and translating technicalities into business implications
You have solid development experience with consuming and designing RESTful APIs in Python
You are comfortable using various front end frameworks like React
You are familiar with at least one of the cloud computing platforms - GCP, AWS, Azure
Strong understanding of application level and system level software design patterns
Great-to-haves
BS/MS degree in Computer Science, Engineering, or relevant field
Machine learning and data science knowledge
Experience with agile methodology and work in a start-up environment
GCP or other cloud certifications
A bit about us
Our business is connecting Canadians. Our social impact is using our world-leading technology to create meaningful change, give back to help communities thrive, and help those who need it most. When you join our team, you’re helping us make the future friendly. We’re committed to diversity and equitable access to employment opportunities based on ability —your unique contributions and talents will be valued and respected here.

Primary Location: CA-ON-Toronto
Other Locations: CA-BC-Victoria, CA-QC-Montreal, CA-QC-Quebec City, CA-BC-Vancouver, CA-ON-Toronto, CA-AB-Edmonton, CA-ON-Ottawa, CA-BC-Burnaby, CA-AB-Calgary

Schedule: Full-time","TELUS
3.9",Midtown Toronto
899,"Senior Actuarial Manager, Data Science","What you will do

Join a leadership team of actuaries, data scientists and engineers at the forefront of leveraging data to drive decisions at every level of our organization. The insurance industry is undergoing a data-driven, technology revolution and you will be in the driver’s seat.

Insurance pricing, underwriting, claims and other core insurance functions are all looking for actionable insights that can be coaxed out of our data. You and your team will work with these business areas to realize this value & further embed data science in our operations.

Our leadership team collectively seeks to expand our very strong and diverse talent base. You will take shared ownership for continuing this successful growth.

What you need to succeed

As a senior manager, you will need the following skills and experience to succeed in the role:

7+ years of experience in the general insurance industry.

Expert knowledge in at least one insurance discipline eg: Pricing, claims, underwriting, marketing, fraud or other. Ideal candidates have experience leading teams in multiple disciplines.

The capacity to oversee, develop and mentor a highly productive team of data scientists, actuaries & insurance professionals

Cross-functional skills that allow you to straddle the worlds of data scientists, actuaries, engineers & core insurance functions.

The ability to establish a vision with stakeholders and create a culture that treats data as an essential asset

The drive to advance our department’s capability to evolve the business by leading the development and deployment of long-term tools.

What sets you apart

Amazing people skills . You are able to translate and communicate complex algorithms to non-technical experts. You are someone who understands that it is not enough to just have a great algorithm but critical to generate buy-in for the solution.

Excellent leadership skills . You constantly seek to improve the engagement, innovation and empowerment of our team members

Subject matter expert. You are recognized as an expert in one or more areas of; pricing, underwriting, claims, predictive modeling, data science, marketing or other specializations.

A can-do team player. You are willing to roll-up your sleeves and do whatever is needed to move projects forward. That means you will take opportunities be a project manager, developer, modeler and chief communicator of solutions.

Customer focused. You prioritize building relationships with business partners to identify their needs and develop innovative solutions.

Additional Information

A viva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.","Aviva
3.7",Montreal
