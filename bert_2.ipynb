{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert 2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSIUha/0GW5wYCHNHP7sjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RemeAjayi/ds-job-detective/blob/main/bert_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zXK2ABz7CUE",
        "outputId": "2d774e6a-b0f6-46e6-df78-3c40efe165c1"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 135 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.0)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=eebd494d81a683f87ee42c55a17b9ad74f062f1e153b2f557c2e3ab032738356\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=afb1117ddc9bcefea2c972e0dae4393b0dc94ed15ad31e7e2c9e8bb75095f807\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=c833d8ce0d4665c52092d5c69a74bed38470463508b55287f3025f54aeadbe54\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jde5La0uyX7A",
        "outputId": "5a857446-3813-4358-ae4d-e2f3e18b6dd7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.5.0\n",
            "Hub version:  0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxZ3szYaya1t"
      },
      "source": [
        "bert_layer=hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",trainable=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm0yJ1HDzAig"
      },
      "source": [
        "MAX_SEQ_LEN=128\n",
        "input_word_ids = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KVxp2EQzGoo"
      },
      "source": [
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOjGaaZizMp9"
      },
      "source": [
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx2E2NBGzQW7"
      },
      "source": [
        "FullTokenizer=bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "\n",
        "do_lower_case=bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "tokenizer=FullTokenizer(vocab_file,do_lower_case)\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1-eBDgZzrle"
      },
      "source": [
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxef-ct8z20I",
        "outputId": "cb0313d2-fb02-4902-eb3b-1e60fae12290"
      },
      "source": [
        "# Get the GPU device name. Checking if exists\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# device name should appear as /device:GPU:0 if present and running\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "#     raise SystemError('GPU device not found')\n",
        "    print('checked')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checked\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuN8N2NDz5qv",
        "outputId": "1faa36a4-f305-4036-e26a-ac935732571e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzeESd5lz8oF",
        "outputId": "b3885adc-7328-4745-cea3-04f420317935"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/np_train_skills_no_commas.csv')\n",
        "train.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19769 entries, 0 to 19768\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Unnamed: 0  19769 non-null  int64  \n",
            " 1   Phrase      19768 non-null  object \n",
            " 2   Target      13004 non-null  float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 463.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MRPP_QBr0Dgf",
        "outputId": "2bbac477-fa80-465c-ec9c-1267d1e526bd"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>significant scope impact</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>monitor compliance</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>self-service reporting solutions</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>experience</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>strong attention detail commitment</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                              Phrase  Target\n",
              "0           0            significant scope impact     0.0\n",
              "1           1                  monitor compliance     0.0\n",
              "2           2    self-service reporting solutions     0.0\n",
              "3           3                          experience     0.0\n",
              "4           4  strong attention detail commitment     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGoAZT910GtL",
        "outputId": "b1793e67-798e-48ad-c712-379abaf95f6c"
      },
      "source": [
        "train = train.dropna()\n",
        "train.isnull().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "Phrase        0\n",
              "Target        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMIxg4Pm0I03",
        "outputId": "2d2c5724-b453-4d48-b639-9bb22de04541"
      },
      "source": [
        "# splitting data 1st iter 85/15 2nd iter 80/20 \n",
        "# ensuring shuffling due to the sequentual nature of the training set\n",
        "X = train.Phrase\n",
        "y = train.Target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "                                                    X, y, \n",
        "                                                    test_size = .2,\n",
        "                                                    random_state = 42,\n",
        "                                                    shuffle = True\n",
        "                                                    )\n",
        "\n",
        "print('{:>5,} training samples'.format(len(X_train)))\n",
        "print('{:>5,} validation samples'.format(len(X_test)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10,403 training samples\n",
            "2,601 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13tqU95U0LD2"
      },
      "source": [
        "def create_single_input(sentence,MAX_LEN):\n",
        "  \n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  \n",
        "  stokens = stokens[:MAX_LEN]\n",
        "  \n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "  \n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlA-eag40pYp"
      },
      "source": [
        "def build_model():\n",
        "  x = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
        "  x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(24, activation='tanh')(x)\n",
        "  x = tf.keras.layers.Dense(12, activation='relu')(x)\n",
        "  out = tf.keras.layers.Dense(1, activation='softplus')(x)\n",
        "  #x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  #out = tf.keras.layers.Dense(1, activation=\"softplus\", name=\"dense_output\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "        inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzs5osG01Re",
        "outputId": "09d3cbfd-1087-4263-f3f2-afdfe4ca2cac"
      },
      "source": [
        "inputs=create_input_array(X_train)\n",
        "model = build_model()\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(inputs,y_train,epochs=6,batch_size=60,validation_split=0.2,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10403/10403 [00:01<00:00, 7666.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            " 59/139 [===========>..................] - ETA: 1:47:16 - loss: 0.5684 - accuracy: 0.6983"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flye7nQT_1yl"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyzXGIQE1jfm"
      },
      "source": [
        "test_inputs=create_input_array(X_test)\n",
        "\n",
        "print(model.predict(test_inputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMW4dlr503S"
      },
      "source": [
        "# found it was necessary to make a directory on colab while saving the model for easier retrieval\n",
        "model.save('bert_skills_clf.h5', overwrite=True, include_optimizer=True)\n",
        "# # predictions before we clear and reload model\n",
        "pre_save_preds = model.predict(test_inputs) \n",
        "# # # Clear and load model\n",
        "model = None\n",
        "model = build_model()\n",
        "model.load_weights('bert_skills_clf.h5')\n",
        "\n",
        "# # predictions after we clear and reload model\n",
        "post_save_preds = model.predict(test_inputs) \n",
        "# Are they the same?\n",
        "all(pre_save_preds == post_save_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0XaLd4B1d"
      },
      "source": [
        "accr = model.evaluate(test_inputs, y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGf6HeFp6acw"
      },
      "source": [
        "# Test on (assuming) unseen data\n",
        "unseen = np.array([ \n",
        "                   'mongodb',\n",
        "                   'statistics , mathematics , biostatistics',\n",
        "                   'experience in python', \n",
        "                   'language e.g',\n",
        "                   'this is fucking bullshit', \n",
        "                   'the definition', \n",
        "                   'hard-worker',\n",
        "                   'san francisco bay area' ,\n",
        "                   'many things',\n",
        "                   'passion for data',\n",
        "                   ])\n",
        "\n",
        "unseen_inputs=create_input_array(unseen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZnUffTX6bqW"
      },
      "source": [
        "unseen_truth = [0, 1, 1, 0, 1, 0, 1, 0, 0, 1]\n",
        "accr = model.evaluate(unseen_inputs, unseen_truth)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2CcA1N06lSd"
      },
      "source": [
        "unseen_predictions = model.predict(unseen_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHGpzzxW6mPW"
      },
      "source": [
        "predictions = pd.DataFrame(dict(list(zip(unseen, unseen_predictions))))\n",
        "predictions.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSwJXz2U_HRt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}