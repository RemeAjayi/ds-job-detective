PROJECT PLANNING

Jun 18 - Jun 28, Do Info Extraction techniques in following articles 
1) Follow steps in https://github.com/WomenWhoCode/WWCodeDataScience/blob/master/Intro_to_NLP/3_NLP_DeepDive2.ipynb

2) https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools

3) https://towardsdatascience.com/how-i-used-natural-language-processing-to-extract-context-from-news-headlines-df2cf5181ca6

4) https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da

5) https://www.geeksforgeeks.org/feature-extraction-techniques-nlp/

6) https://www.kdnuggets.com/2017/05/deep-learning-extract-knowledge-job-descriptions.html

In Separate Notebook, give author credit

7) https://nikkisharma536.medium.com/white-paper-job-skills-extraction-with-lstm-and-word-embeddings-d71d1f96024f

8) https://medium.com/mlearning-ai/how-to-automate-job-searches-using-named-entity-recognition-part-1-16c150acafa0

9) In Separate Notebook, give author credit- 
file:///Users/olohireme/Documents/Data%20Science%20Projects/ds-job-detective/articles/applsci-09-02852.pdf
 






GOAL is information extraction and pattern finding
- Scrape Linkedin Jobs, Indeed Jobs, Glassdoor jobs with Selenium for Data Science Job posts in Canada
- Combine only columns that are common between all 3, rename if necessary i.e if data is the same but column title is different
- Remove duplicates
- Create a 'Job Board' column to indicate which job board it came from
- do POS tagging with nltk, visualize with yellowbrick
- Understand N-grams
- Document what you did on Medium draft, write one article after every stage
- Write your name as author on every code file.
- Get the requirements for each post. Maybe for 2 weeks worth of posts on each site
- Check word embeddings, similar words - just on job descriptions maybe
- Convert Job descriptions to a bag of words and try to cluster, see if clustering can group packages and languages and other skills
- Also use spacy to try to separate packages, tools, languages and skills. 
- Resource 1 for spacy: https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/
- Resource 2 for spacy: https://skeptric.com/extract-skills-3-conjugations/
- Check most likely requirements for different level of experience i.e. words that show up for entry level, 3 to 5 yrs etc
- Can you tell which words are packages, programming languages or degree requirements from your model
- Perform analysis by region, experience level etc (spend 2 weeks on analysis alone)
- Create a visualization on map of Canada
- Use Word2Vec and/or BERT and/or RNN
- Deploy on Streamlit(give yourself time to learn this), this is self-supervised. Streamlit may be great because of the visualization. 
- Record a video of your exploration of the app and share on LinkedIn and twitter and with Ken Jee on Discord, with all Waterloo peeps.
A column each for low salary and high salary
Tokenize job descriptions like here - https://towardsdatascience.com/how-to-use-nlp-to-find-a-tech-job-and-win-a-hackathon-7aa270ec608d
In your documentation and data exploration, answer questions like you were a market research firm trying to help a talent recruitment
agency create a product for employers. 

Years of experience and Job seniority

plotly visualization ideas here - https://towardsdatascience.com/how-to-use-nlp-in-python-a-practical-step-by-step-example-bd82ca2d2e1e

For indeed add &lang=en to get only English language jobs